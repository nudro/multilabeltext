ParentId,clean,Actual,Predictions
40057001,"'Create AbstractBaseUser' 'Try to create AbstractBaseUser and custom auth.nnmodels.py nnclass Account(AbstractBaseUser):n    account_id = models.AutoField(primary_key=True)n    first_name = models.CharField(max_length=255)n    last_name = models.CharField(max_length=255)n    birthday_date = models.DateField(blank=True null=True)n    sex = models.TextField(blank=True null=True)  # This field type is a guess.n    country = models.CharField(max_length=255 blank=True null=True)n    city = models.CharField(max_length=255 blank=True null=True)n    email = models.CharField(unique=True max_length=320)n    mobile_number = models.CharField(unique=True max_length=45 blank=True null=True)n    registration_date = models.DateTimeField()n    expired_date = models.DateField(blank=True null=False)n    account_type = models.TextField()  # This field type is a guess.nn    objects = AccountManagernn    USERNAME_FIELD = 'email'nn    REQUIRED_FIELDS = 'first_name' 'last_name' 'registration_date' 'account_type'nn    class Meta:n        managed = Falsen        db_table = 'account'nnnAccountManagernnclass AccountManager(BaseUserManager):n    def create_user(self first_name last_name birthday_date sex country city emailn                    mobile_number registration_date expired_date account_type password):nn        fields = first_name last_name birthday_date sex country emailn                  mobile_number registration_date expired_date account_type passwordnn        user = self.model(n            email=self.normalize_email(email)n            first_name=first_namen            last_name=last_namen            birthday_date=birthday_daten            sex=sexn            country=countryn            city=cityn            mobile_number=mobile_numbern            registration_date=registration_daten            expired_date=expired_daten            account_type=account_typen        )nn        user.set_password(password)n        user.save()n        return usernnnsetting.pynn    INSTALLED_APPS = n        'models'n        ...n    AUTH_USER_MODEL = 'models.Account'nn    AUTHENTICATION_BACKENDS = ('models.backend.EmailOrPhoneBackend')nnnbackend.pynnclass EmailOrPhoneBackend(object):n    def authenticate(self username=None password=None **kwargs):n        try:n            # Try to fetch the user by searching the username or email fieldn            user = Account.objects.get(Q(mobile_number=username) | Q(email=username))n            if user.check_password(password):n                return usern        except Account.DoesNotExist:n            # Run the default password hasher once to reduce the timingn            # difference between an existing and a non-existing user (#20760).n            Account().set_password(password)nnnI try to creatae new user by parsing post data and saving it to db:nndef post(self request *args **kwargs):n    postDict = dict(request.POST)nn    account = Account();nn    for element in postDict:n        jsonPostDict = json.loads(element)nn        for value in jsonPostDict:nn            print('key is : ' + value)n            print('value is : ' + jsonPostDictvalue)nn            if value == 'firstName':n                account.first_name = jsonPostDictvaluen                print('set first name')n            if value == 'lastName':n                account.last_name = jsonPostDictvaluen                print('set last name')n            if value == 'email':n                account.email = jsonPostDictvaluen                print('set email')n            if value == 'password':n                account.set_password(jsonPostDictvalue)n                print('set password')nn    account.account_type = 'free'n    account.save()nn    return HttpResponseRedirect(""/admin"" request *args **kwargs)nnnLog: nnkey is : firstNamenvalue is : anset first namenkey is : emailnvalue is : artem@gmail.comnset emailnkey is : passwordnvalue is : qwdsfgh23enset passwordnkey is : lastNamenvalue is : anset last namenInternal Server Error: /signupnTraceback (most recent call last):n  File ""/usr/local/lib/python3.4/dist-packages/django/db/backends/utils.py"" line 64 in executen    return self.cursor.execute(sql params)npsycopg2.ProgrammingError: ERROR:  row ""password"" in table ""account"" does not existnLINE 1: INSERT INTO ""account"" (""password"" ""last_login"" ""first_name...n                               ^nnnThe above exception was the direct cause of the following exception:nnTraceback (most recent call last):n  File ""/usr/local/lib/python3.4/dist-packages/django/core/handlers/exception.py"" line 39 in innern    response = get_response(request)n  File ""/usr/local/lib/python3.4/dist-packages/django/core/handlers/base.py"" line 187 in _get_responsen    response = self.process_exception_by_middleware(e request)n  File ""/usr/local/lib/python3.4/dist-packages/django/core/handlers/base.py"" line 185 in _get_responsen    response = wrapped_callback(request *callback_args **callback_kwargs)n  File ""/usr/local/lib/python3.4/dist-packages/django/views/generic/base.py"" line 68 in viewn    return self.dispatch(request *args **kwargs)n  File ""/usr/local/lib/python3.4/dist-packages/django/views/generic/base.py"" line 88 in dispatchn    return handler(request *args **kwargs)n  File ""/usr/finstatement/project/account_management/views.py"" line 44 in postn    account.save()n  File ""/usr/local/lib/python3.4/dist-packages/django/contrib/auth/base_user.py"" line 80 in saven    super(AbstractBaseUser self).save(*args **kwargs)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/base.py"" line 796 in saven    force_update=force_update update_fields=update_fields)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/base.py"" line 824 in save_basen    updated = self._save_table(raw cls force_insert force_update using update_fields)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/base.py"" line 908 in _save_tablen    result = self._do_insert(cls._base_manager using fields update_pk raw)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/base.py"" line 947 in _do_insertn    using=using raw=raw)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/manager.py"" line 85 in manager_methodn    return getattr(self.get_queryset() name)(*args **kwargs)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/query.py"" line 1045 in _insertn    return query.get_compiler(using=using).execute_sql(return_id)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/models/sql/compiler.py"" line 1054 in execute_sqln    cursor.execute(sql params)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/backends/utils.py"" line 79 in executen    return super(CursorDebugWrapper self).execute(sql params)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/backends/utils.py"" line 64 in executen    return self.cursor.execute(sql params)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/utils.py"" line 94 in __exit__n    six.reraise(dj_exc_type dj_exc_value traceback)n  File ""/usr/local/lib/python3.4/dist-packages/django/utils/six.py"" line 685 in reraisen    raise value.with_traceback(tb)n  File ""/usr/local/lib/python3.4/dist-packages/django/db/backends/utils.py"" line 64 in executen    return self.cursor.execute(sql params)ndjango.db.utils.ProgrammingError: Ðx9eÐ¨Ðx98Ðx91Ðx9aÐx90:  row ""password"" in table ""account"" does not existnLINE 1: INSERT INTO ""account"" (""password"" ""last_login"" ""first_name...n                               ^nn15/Oct/2016 08:40:22 ""POST /signup HTTP/1.1"" 500 147276nnnI should add password row to my database or I make some mistakes in customization of auth or backend?n' 'Look at you Account model. There is no password field. You should add this field and than you can save data there.n'",['django'],['django']
40057064,"'Why is pandas map slower than list comprehension' 'Does someone know why pandas/numpy map is slower then list comprehension?nI thought I could optimize my code replacing the list comprehensions by map. Since map doesn't need the list append operation.nnHere is one test:nndf = pd.DataFrame(range(100000))nnnList comprehension:nn%timeit -n 10 df""A"" = x for x in df0nn#10 loops best of 3: 550 ms per loopnnnPandas map nn%timeit -n 10 df""A"" = df0.map(lambda x: x)nn#10 loops best of 3: 797 ms per loopnnnUpdatenbased on comment bellow - list comprehension and map calling same function f list comprehension fasternndef f(x):n    return xnn%timeit -n 100 df""A"" = df0.map(f)nn#100 loops best of 3: 475 ms per loopnn%timeit -n 100 df""A"" = f(x) for x in df0nn#100 loops best of 3: 399 ms per loopnn' 'Here are my results:nnlist comprehension:nnIn 33: %timeit df""A"" = x for x in df0n10 loops best of 3: 72.6 ms per loopnnnsimple column assignment:nnIn 34: %timeit df""A"" = df0nThe slowest run took 5.75 times longer than the fastest. This could mean that an intermediate result is being cached.n1000 loops best of 3: 661 Âµs per loopnnnusing .map() method:nnIn 35: map_df = pd.Series(np.random.randint(0 10**6 100000))nnIn 36: %timeit df""A"" = df0.map(map_df)n10 loops best of 3: 19.8 ms per loopnn'",['pandas'],"['pandas', 'numpy']"
40057073,"'Transferring blocks of code into a callable def sequence' 'Good Evening CodersnThis block of code is designed to showcase a selection of similar images in quick succession to make it look like a gif however for this to fit in my program I need to be able to fit it all into a runnable def sequence that can be run by typing one word (eg runImages()) and after the images have stopped showing (in root.after) have the function open a different def sequencennimport tkinter as tknfrom itertools import cyclennroot = """"n#create a splash screen 80% of display screen size centeredn#quickly diplaying a cycle of images disapearing after 10 secondsnn#lists the images that will be cyclednimages = ""Dragon_Realm1.gif"" ""Dragon_Realm2.gif"" ""Dragon_Realm3.gif"" ""Dragon_Realm4.gif"" ""Dragon_Realm5.gif"" ""Dragon_Realm6.gif""nphotos = cycle(tk.PhotoImage(file=image) for image in images)nn#creates the canvas for the image to go onnglobal rootnroot = tk.Tk()nroot.overrideredirect(True)nwidth = root.winfo_screenwidth()nheight = root.winfo_screenwidth()nn#sets the size of the splash screen and its distance from the sides of the screennroot.geometry('%dx%d+%d+%d' % (1536 864 width/10 height/20))ndisplayCanvas = tk.Label(root)ndisplayCanvas.pack()nn#after 10 milliseconds the slideshow will begin and after 10 seconds be destroyed n#this is the thing that isnt workingnndef slideShow():n   img = next(photos)n   tk.Label(tkinter.Tk).config(image=img)n   #after 0.05 seconds begin the slideshown   root.after(1 slideShow)nnnroot.after(10 lambda: slideShow())nroot.after(10000 root.destroy)n#The root.after needs to encapsulate running a different def sequencennroot.mainloop()nnnAny help with this would be greatly appreciatedn' nan",['tkinter'],['tkinter']
40057092,"'Django get form not ordered list' ""i changed my admin form when creating new objects to hide some fields but it orders fields alphabetically i want to order them as they are in my model.any suggestions?nn_add_fields = ('name' 'size' 'slug'n               'img' 'description' 'quantity')nndef get_form(self request obj=None **kwargs):n    model_form = super(ItemAdmin self).get_form(n        request obj **kwargsn    )nn    if obj is None:n        model_form._meta.fields = self._add_fieldsn        model_form.base_fields = {n            field: model_form.base_fieldsfieldn            for field in self._add_fieldsn        }nn    return model_formnn"" ""You need to use OrderedDict from collections module to achieve that:nnfrom django.contrib import adminnfrom collections import OrderedDictnnnclass ItemAdmin(admin.ModelAdmin):nn    _add_fields = ('name' 'category'n                   'img' 'description' 'quantity')nn    def get_form(self request obj=None **kwargs):n        model_form = super(ItemAdmin self).get_form(n            request obj **kwargsn        )nn        if obj is None:n            model_form._meta.fields = self._add_fieldsn            d = OrderedDict()n            for field in self._add_fields:n                dfield = model_form.base_fieldsfieldn            model_form.base_fields = dn        return model_formnn""",['django'],['django']
40057128,"'Python Pandas Data Formatting: Diffnce in passing index and iloc' ""This is the sample data:nndict_country_gdp = pd.Series(52056.0178140258.8086240034.8506339578.07441n    index = 'Luxembourg''Norway' 'Japan' 'Switzerland')nnnWhat is the difference between dict_country_gdp0 and dict_country_gdp.iloc0? nnWhile the result is the same when to use which?n"" 'As you are working with one dimensional series  or .iloc will give same results.  nnONE DIMENSIONAL SERIES:nnimport pandas as pdnndict_country_gdp = pd.Series(52056.01781 40258.8086240034.8506339578.07441)nndict_country_gdpnnOut: n0    52056.01781n1    40258.80862n2    40034.85063n3    39578.07441ndtype: float64nndict_country_gdp0nOut: 52056.017809999998nndict_country_gdp.iloc0nOut: 52056.017809999998   nnnMULTI-DIMENSIONAL SERIES: nndict_country_gdp = pd.Series(52056.01781 40258.8086240034.8506339578.0744152056.01781 40258.8086240034.8506339578.07441)nndict_country_gdp nOut: n52056.01781    52056.01781n40258.80862    40258.80862n40034.85063    40034.85063n39578.07441    39578.07441ndtype: float64nnnNow in this scenario you cannot access series using  operator. nndict_country_gdp0nOut: KeyError: 0.0nndict_country_gdp.iloc0nOut: 52056.017809999998 nnniloc provides more control while accessing multidimensional series:nndict_country_gdp0:2nOut: Series( dtype: float64)nndict_country_gdp.iloc0:2nOut: n52056.01781    52056.01781n40258.80862    40258.80862ndtype: float64nnnDocumentation states:nn.iloc is primarily integer position based (from 0 to length-1 of the axis) but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds except slice indexers which allow out-of-bounds indexing. (this conforms with python/numpy slice semantics). Allowed inputs are:nnnAn integer e.g. 5nA list or array of integers 4 3 0nA slice object with ints 1:7nA boolean arraynA callable function with one argument (the calling Series DataFramenor Panel) and that returns valid output for indexing (one of thenabove)nnnThis is why one cannot use  operator with dataframe objects. Only iloc can be used when it comes to dataframes and multidimensional series.  n'","['pandas', 'dictionary']","['pandas', 'numpy']"
40057218,"'Regex expression excluding ""-"" tag' 'Hi right now my regex expression is working as intended. However i wish to specifically exclude  items such as nhow do i update my regex such that it would exclude entries with ""-d*""/ negative quantity? ?nnhttps://regex101.com/r/4EUzLo/1n' 'This should work for you:nn'd+s*(a-zA-Z.*w)s+d.*'nnnThe 'd+ will only match the positive quantities and with less steps.nnNow just extract the info from the capture group.nn Demo n'",['regex'],['regex']
40058133,"'import all csv files in directory as pandas dfs and name them as csv filenames' 'I'm trying to write a script that will import all .csv files in a directory to my workspace as dataframes. Each dataframe should be named as the csv file (minus the extension: .csv).nnThis is what i have so far but struggling to understand how to assign the correct name to the dataframe in the loop. I've seen posts that suggest using exec() but this does not seem like a great solution.nnpath = ""../3_Data/Benefits""                     # dir pathnall_files = glob.glob(os.path.join(path ""*.csv"")) #make list of pathsnnfor file in all_files:n    dfn = file.split('')-1.split('.')0 # create string for df namen    dfn = pd.read_csv(fileskiprows=5) # This line should assign to the value stored in dfnnnnAny help appreciated thanks.n' 'DataFrame have no name their index can have a name. This is how to set it.nnimport globnimport osnnpath = ""./data/""nall_files = glob.glob(os.path.join(path ""*.csv"")) #make list of pathsnnfor file in all_files:n    # Getting the file name without extensionn    file_name = os.path.splitext(os.path.basename(file))0n    # Reading the file content to create a DataFramen    dfn = pd.read_csv(file)n    # Setting the file name (without extension) as the index namen    dfn.index.name = file_namenn# Example showing the Name in the print outputnn#      FirstYear  LastYearn# Name                     n# 0         1990      2007n# 1         2001      2001n# 2         2001      2008nn'",['pandas'],['pandas']
40058134,"'Pythn count multiple values in dictionary of list' ""I have been trying to count the values in a dictionary with respect to the key. However I could not achieved desired result. I will demonstrate with more details below:nnfrom collections import Counternd = {'a': 'Adam''Adam''John' 'b': 'John''John''Joel' 'c': 'Adam''Adam''John}n# create a list of only the values you want to countn# and pass to Counter()nc = Counter(values1 for values in d.itervalues())nprint cnnnMy output:nnCounter({'Adam': 2 'John': 1})nnnI want it to count everything in the list not just first value of the list. Also I want my result to be with respect to the key. I will show you my desired output below:nn{'a': {'Adam': 1 'John': 2} 'b':{'John': 2 'Joel': 1} 'c':{'Adam': 2 'John': 1 }}nnnIs it possible to get this desired output? Or anything close to it? I would like to welcome any suggestions or ideas that you have. Thank you.n"" ""Try this using dict comprehensionnnfrom collections import Counternd = {'a': 'Adam''Adam''John' 'b': 'John''John''Joel' 'c': 'Adam''Adam''John'}nc = {i:Counter(j) for ij in d.items()}nprint cnn"" ""You're picking only the first elements in the each list with values1 instead you want to iterate through each values using a for that follows the first:nn>>> from collections import Countern>>> d = {'a': 'Adam''Adam''John' 'b': 'John''John''Joel' 'c': 'Adam''Adam''John'}n>>> Counter(v for values in d.itervalues() for v in values) # iterate through each valuenCounter({'John': 4 'Adam': 4 'Joel': 1})nn""","['list', 'dictionary']","['dictionary', 'list']"
40058143,"'Handling multiple variables in python' 'Here's issue I am learning python newly i want to use loop for generating inputs from user which are then operated for some custom function (say Lcm or squaring them and returning ) so how to perform code nConsider nnkl=00nnwhile l>=10:n    n_k=input(""Enter"")n    k=k+1n    l=l+1n    #Do something within for loopn    #here problem begins n    #lets say i am dividing each variable by c which is here in for loop n    for c in range(somevalue0-1):nnnnow how should i operate the variables clearly i have no intention writting n_0%c n_1%c etc nAny Help???n' 'Instead of n_k being a single variable i think you want n to be a list. A list is just a bunch of variables stored together. For example the code:nnn = 1 4 2nnnprint(n0) #0th element of the listnprint(n1) #1st element of the listnprint(n2) #2nd element of the listnnnoutputs nn1n4n2nnthe line n = 1 4 2 is just defining the list. The elements of the list are accessed using the nindex notation.nnIn python you can also add elements to a list at any time using the append statement. To illustrate let's define an empty list and add some elements to it.nnn = nn.append(8)nnnNow if we try nnprint(n0)nnnthe code will print 8.nnSo let's say we wanted to square a list of numbers we receive from user input we would writennn = nk = 0nnnum_inputs = 10nnwhile k < num_inputs:n    n.append(input(""Enter:""))n    k = k + 1nnk = 0nwhile k < num_inputs:n    print(nk * nk)n    k = k + 1nnnHope it helps.n'",['python-2.7'],"['list', 'python-2.7']"
40058183,"'Django export-import/tablib error' 'I try to import .xls file with code:nn...ndataset = tablib.Dataset()ntest_resource = resources.modelresource_factory(model=Product)()nfile = 'd:test.xls'ndataset.xls = open(file).read()nnnand it's throw an error:nnTraceback (most recent call last):n  File ""<console>"" line 1 in <module>n  File ""D:000_open_serverOpenServerdomainsPythonshopenvlibsite-packagestablibformats_xls.py"" line 72 in import_setn    xls_book = xlrd.open_workbook(file_contents=in_stream)n  File ""D:000_open_serverOpenServerdomainsPythonshopenvlibsite-packagestablibpackagesxlrd3__init__.py"" line 395 in open_workbookn    biff_version = workbook.getbof(XL_WORKBOOK_GLOBALS)n  File ""D:000_open_serverOpenServerdomainsPythonshopenvlibsite-packagestablibpackagesxlrd3__init__.py"" line 1460 in getbofn    opcode = self.get2bytes()n  File ""D:000_open_serverOpenServerdomainsPythonshopenvlibsite-packagestablibpackagesxlrd3__init__.py"" line 881 in get2bytesn    return (hi << 8) | lo #(to_py3):nTypeError: unsupported operand type(s) for <<: 'str' and 'int'nnnI have tried to upgrade tablib and django-export-import but this has no effect. nI think that this compatibility problem but export-import and tablib docs say's ""python 3+"". What else can i try?n' nan",['django'],['django']
40058391,"'Matplotlib logarithmic x-axis and padding' 'I am struggling with matplotlib and padding on the x-axis together with a logarithmic scale (see the first picture).nWithout a logarithmic scale the padding applies nicely (see the second one).nAny suggestations how to get a padding between plot lines and the axis line in the bottom left corner so that one can see the points on the line?nnThanks.nnThe code:nnimport matplotlib.pyplot as pltnimport numpy as npnfrom matplotlib.pyplot import *nfrom matplotlib.ticker import ScalarFormatternnstyle.use('fivethirtyeight')nnfig ax = plt.subplots()nnT = np.array(2**x for x in range(07+1))nopt1 = np.array(x for x in range(07+1))nopt2 = np.array(x*2 for x in range(07+1))nopt3 = np.array(x*4 for x in range(07+1))nnax.grid(True) nxlabel(""#nodes"")nylabel(""time(s)"")nlegend(loc=""best"") ntitle(r""Node start times"") nnplt.xticks(2**x for x in range(07+1))nnplt.plot(Topt1""o-"" label=""opt1"")nplt.plot(Topt2 ""s-"" label=""opt2"")nplt.plot(Topt3 ""d-"" label=""opt2"")nplt.legend(loc=""upper left"")n# This should be called after all axes have been addednplt.tight_layout()nplt.margins(0.05 0.05)n# 1 2 4 ...nax.set_xscale('log' basex=2)nax.xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter(""%d""))nplt.show()n#savefig(""plot_1.pdf"")nnnnn' 'This does not address your padding issue but you could use clip_on=False to prevent the points from being cut off. It seems you also need to make sure they're above the axes using zordernnplt.plot(Topt1""o-"" label=""opt1"" clip_on=False zorder=10)nplt.plot(Topt2 ""s-"" label=""opt2"" clip_on=False zorder=10)nplt.plot(Topt3 ""d-"" label=""opt2"" clip_on=False zorder=10)nn'",['matplotlib'],['matplotlib']
40058436,"'Python: count frequency of words from a column and store the results into another column on my data frame' 'I want to count the number of each word that appears in each row of one column ('Comment') and store in a new column ('word') on my data frame called headlamp.nI'm trying with the following down code however I get and error.nnfor i in range(0len(headlamp)):n    headlamp'word'.apply(lambda text: Counter("" "".join(headlamp'Comment'i.astype(str)).split("" "")).items())n---------------------------------------------------------------------------nKeyError                                  Traceback (most recent call last)n<ipython-input-16-a0c20291b4f5> in <module>()n  1 for i in range(0len(headlamp)):n  ----> 2     headlamp'word'.apply(lambda text: Counter("""".join(headlamp'Comment'i.astype(str)).split("" "")).items())nn  C:UsersRafaelAnaconda2envsgl-envlibsite-packagespandascoreframe.pyc in __getitem__(self key)n  1995             return self._getitem_multilevel(key)n  1996         else:n  -> 1997             return self._getitem_column(key)n  1998 n  1999     def _getitem_column(self key):nn  C:UsersRafaelAnaconda2envsgl-envlibsite-packagespandascoreframe.pyc in _getitem_column(self key)n  2002         # get columnn  2003         if self.columns.is_unique:n  -> 2004             return self._get_item_cache(key)n  2005 n  2006         # duplicate columns & possible reduce dimensionalitynn  C:UsersRafaelAnaconda2envsgl-envlibsite-packagespandascoregeneric.pyc in _get_item_cache(self item)n  1348         res = cache.get(item)n  1349         if res is None:n  -> 1350             values = self._data.get(item)n   1351             res = self._box_item_values(item values)n   1352             cacheitem = resnn   C:UsersRafaelAnaconda2envsgl-envlibsite-packagespandascoreinternals.pyc in get(self item fastpath)n   3288 n   3289             if not isnull(item):n   -> 3290                 loc = self.items.get_loc(item)n   3291             else:n   3292                 indexer = np.arange(len(self.items))isnull(self.items)nn   C:UsersRafaelAnaconda2envsgl-envlibsite-packagespandasindexesbase.pyc in get_loc(self key method tolerance)n   1945                 return self._engine.get_loc(key)n   1946             except KeyError:n   -> 1947                 returnself._engine.get_loc(self._maybe_cast_indexer(key))n   1948 n   1949         indexer = self.get_indexer(key method=method tolerance=tolerance)nn   pandasindex.pyx in pandas.index.IndexEngine.get_loc (pandasindex.c:4154)()nn   pandasindex.pyx in pandas.index.IndexEngine.get_loc (pandasindex.c:4018)()nn   pandashashtable.pyx in pandas.hashtable.PyObjectHashTable.get_item (pandashashtable.c:12368)()nn   pandashashtable.pyx in pandas.hashtable.PyObjectHashTable.get_item (pandashashtable.c:12322)()nn   KeyError: 'word'nnnAny help will be highly appreciaten' ""You can try this:nnheadlamp'word' = headlamp'Comment'.apply(lambda x: len(x.split()))nnnExample:nnheadlamp = pd.DataFrame({'Comment': 'hello world''world''foo''foo and bar'})nprint(headlamp)n       Commentn0  hello worldn1        worldn2          foon3  foo and barnnheadlamp'word' = headlamp'Comment'.apply(lambda x: len(x.split()))nprint(headlamp)n       Comment  wordn0  hello world     2n1        world     1n2          foo     1n3  foo and bar     3nn"" 'Using the most_common() method you can achieve what you want.nnFeel free to use this piece of code:nnimport pandas as pdnfrom collections import Counternndf = pd.DataFrame({'Comment': 'This has has words words words that are written twice twice' 'This is a comment without repetitions' 'This comment has ponctuations!'} index = 0 1 2)nn#you must create the new column before trying to assing any valuendf'Words' = """"nn#counting frequenciesni = 0nfor row in df'Comment':n    df'Words'i = str(Counter(row.split()).most_common())n    i+=1nnprint dfnnnOutput:nn                                             Comment  n0  This has has words words words that are writte...   n1              This is a comment without repetitions   n2                    This comment has ponctuations!   nn                                               Words  n0  ('words' 3) ('twice' 2) ('has' 2) ('tha...  n1  ('a' 1) ('comment' 1) ('This' 1) ('is'...  n2  ('This' 1) ('comment' 1) ('has' 1) ('p...  nn'",['pandas'],['pandas']
40058441,"'How to select element locations from two Pandas dataframes of identical shape where the values match within a certain range?' 'How to select element locations from two Pandas dataframes of identical shape where the values match within a certain range? A code to do this might be simple to write but I want to know if there is a smart way to make this conditional selection (like loc) with Pandas data frames as I will need it for large image files and I believe Pandas is generally quick and efficient. n' ""I need more information about nnn  he values match within a certain rangennnBut this is an example selecting values that are the same in the two DataFrame. By replacing the test by any other test you could reach your goals.nn# Test datandf1 = DataFrame({'col1':1.2 3.2 4.2 'col2':0 2.1 4.8 'col3': 2.0 0 8.2})ndf2 = DataFrame({'col1':2.2 3.2 4.2 'col2':4.1 0 4.8 'col3': 2.0 4.7 8.2})nn# df1n#    col1  col2  col3n# 0   1.2   0.0   2.0n# 1   3.2   2.1   0.0n# 2   4.2   4.8   8.2nn# df2n#    col1  col2  col3n# 0   2.2   4.1   2.0n# 1   3.2   0.0   4.7n# 2   4.2   4.8   8.2nn# Assuming the two DataFrame have the same index and columns you can simply do thatnndf2df2 == df1nn#    col1  col2  col3n# 0   NaN   NaN   2.0n# 1   3.2   NaN   NaNn# 2   4.2   4.8   8.2nn""",['pandas'],['pandas']
40058513,"'pyopencl erro : LogicError: clGetPlatformIDs failed: ' ""When I run a Python script I get an error:nnn  LogicError: clGetPlatformIDs failed: nnnI install anaconda and conda-forge package pyopencl.nnLogicError                                Traceback (most recent call last)n/home/inat/Git/xrt/tests/raycing/info_opencl.py in <module>()n      2 n      3 print('n' + '=' * 60 + 'nOpenCL Platforms and Devices')n----> 4 for platform in cl.get_platforms():  # Print each platform on this computern      5     print('=' * 60)n      6     print('Platform - Name:  ' + platform.name)nn/home/inat/APP/anaconda3/lib/python3.5/site-packages/pyopencl/cffi_cl.py in get_platforms()n    661 def get_platforms():n    662     platforms = _CArray(_ffi.new('clobj_t**'))n--> 663     _handle_error(_lib.get_platforms(platforms.ptr platforms.size))n    664     return Platform._create(platforms.ptr0i)n    665             for i in range(platforms.size0)nn/home/inat/APP/anaconda3/lib/python3.5/site-packages/pyopencl/cffi_cl.py in _handle_error(error)n    623     _lib.free_pointer(error.msg)n    624     _lib.free_pointer(error)n--> 625     raise en    626 n    627 # }}}nnLogicError: clGetPlatformIDs failed: <unknown error -1001>nn"" nan",['python-3.x'],['python-3.x']
40058597,"'tkinter - change button colour while hovering over it' 'I have a button. It has some BG and FG and while it's clicked BG and FG change. But I need colors to change when I hover over it as well. How can this be accomplished (something less complicated and more understandable for begginer than Change button colour when hovering over with tkinter if possible)?nnHere's what I've got now - nnbutton = tk.Button(root text=""I'm a button"" command=saysth bd=0 bg=""black"" fg=""green""n                   activebackground=""green"" activeforeground=""black"" font=""courier 30"")nn' nan",['tkinter'],['tkinter']
40058697,"'Select hidden option value from source using python selenium chromedriver' 'I am reading a Docx file here is the link  parsing some text from that & then Using python selenium bindings & chrome-driver I am trying to click a Hidden option value from source (driver.page_source) . I know it isn't available to select. Here is my code so far :nnimport time renfrom selenium import webdrivernfrom selenium.webdriver.common.keys import Keysnfrom selenium.webdriver.common.by import Bynfrom docx import opendocx getdocumenttextnfrom requests import Sessionnndef read_return(word_file):n    document = opendocx(word_file)n    paratextlist = getdocumenttext(document)n    newparatextlist = n    for paratext in paratextlist:n        newparatextlist.append((paratext.encode(""utf-8"")).strip('n').strip('t').strip('r'))n    newparatextlist = str(newparatextlist).replace("""""""").replace("""""""")n    with open('sample.txt''wb')as writer:n        writer.write(newparatextlist)n    return newparatextlistnnword_file = read_return('Taxatierapport SEK - Auto Centrum Bollenstreek - Peugeot 308 - 5603.docx')nnx = lambda x:re.findall(xword_filere.DOTALL)0.strip().replace(""'""""&#39;"").replace('""''&#39;')nVoertuig = x(""::OBJECT::' '(.+?)'"")nnMerk = x(""::MERK::' '(.+?)'"")nModel = x(""::TYPE::' '(.+?)'"")nTOELATING = x(""::BOUWJAAR 1STE TOELATING::' '(.+?)'"")nd1 = TOELATING.split(""-"")0nd2 = TOELATING.split(""-"")1nd3 = TOELATING.split(""-"")2nTRANSMISSIE = x(""::TRANSMISSIE::' '(.+?)'"")nBRANDSTOF = x(""::BRANDSTOF::' '(.+?)'"")nnprint ""%rn%rn%rn%rn%rn%rn%rn%rn"" %(Voertuig Merk Model d1 d2 d3 TRANSMISSIE BRANDSTOF)nnif Voertuig == ""Personenauto"":n    value = 1nelif Voertuig == ""Personenbussen"":n    value = 7nelif Voertuig == ""Bedrijfsauto&#39;s tot 3.5 ton"":n    value = 3nelif Voertuig == ""Bedrijfsauto&#39;s 4x4"":n    value = 2nelif Voertuig == ""Motoren"":n    value= 5nnxr = 0; yr = 0; zr = 1972nwhile xr < 32:n    if int(d1) == xr:n        dvalue1 = xrn    else:n        passn    xr+=1nnwhile yr < 13:n    if int(d2) == yr:n        dvalue2 = yrn    else:n        passn    yr+=1nnwhile zr < 2018:n    if int(d3) == zr:n        dvalue3 = zrn    else:n        passn    zr+=1nndriver = webdriver.Chrome('chromedriver.exe')ndriver.get('https://autotelexpro.nl/LoginPage.aspx')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_txtVestigingsnummer""').send_keys('3783')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_txtGebruikersnaam""').send_keys('Frank')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_Password""').send_keys('msnauto2016')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_btnLogin""').click()ntime.sleep(10)n#try:ndriver.find_element(By.XPATH value ='//select@name=""ctl00$cp$ucSearch_Manual$ddlVoertuigType""/option@value=""'+str(value)+'""').click()ndriver.find_element(By.XPATH value ='//select@name=""ctl00$cp$ucSearch_Manual$ddlBouwdag""/option@value=""'+str(dvalue1)+'""').click()ndriver.find_element(By.XPATH value ='//select@name=""ctl00$cp$ucSearch_Manual$ddlBouwmaand""/option@value=""'+str(dvalue2)+'""').click()ndriver.find_element(By.XPATH value ='//select@name=""ctl00$cp$ucSearch_Manual$ddlBouwjaar""/option@value=""'+str(dvalue3)+'""').click()ndriver.find_element(By.XPATH value ='//select@name=""ctl00$cp$ucSearch_Manual$ddlMerk""/option@value=""130""').click()n#except:ndriver.quit()nntime.sleep(5)ndriver.quit()nnnso Using requests module i make a POST request to the link & manage to get a response that does have the needed options data  See here : nn<select name=""ctl00$cp$ucSearch_Manual$ddlMerk"" onchange=""updateInputForServerNoPB();InvalidateVehicleSearchResult();setTimeout(&#39;__doPostBack(&#39;ctl00$cp$ucSearch_Manual$ddlMerk&#39;&#39;&#39;)&#39; 0)"" id=""ctl00_cp_ucSearch_Manual_ddlMerk"" class=""NormalDropdownlist"" style=""width:174px;"">n        <option selected=""selected"" value=""-1"">- Kies merk -</option>n        <option value=""95"">Alfa Romeo</option>n        <option value=""154"">Aston Martin</option>n        <option value=""96"">Audi</option>n        <option value=""97"">Bentley</option>n        <option value=""98"">BMW</option>n        <option value=""352"">Bugatti</option>n        <option value=""100"">Cadillac</option>n        <option value=""342"">Chevrolet</option>n        <option value=""101"">Chevrolet USA</option>n        <option value=""102"">Chrysler</option>n        <option value=""103"">Citroen</option>n        <option value=""337"">Corvette</option>n        <option value=""104"">Dacia</option>n        <option value=""105"">Daihatsu</option>n        <option value=""166"">Daimler</option>n        <option value=""162"">Dodge</option>n        <option value=""106"">Donkervoort</option>n        <option value=""107"">Ferrari</option>n        <option value=""108"">Fiat</option>n        <option value=""94"">Ford</option>n        <option value=""111"">Honda</option>n        <option value=""340"">Hummer</option>n        <option value=""112"">Hyundai</option>n        <option value=""365"">Infiniti</option>n        <option value=""113"">Jaguar</option>n        <option value=""114"">Jeep</option>n        <option value=""150"">Kia</option>n        <option value=""115"">Lada</option>n        <option value=""116"">Lamborghini</option>n        <option value=""117"">Lancia</option>n        <option value=""168"">Land Rover</option>n        <option value=""432"">Landwind</option>n        <option value=""118"">Lexus</option>n        <option value=""119"">Lotus</option>n        <option value=""120"">Maserati</option>n        <option value=""330"">Maybach</option>n        <option value=""121"">Mazda</option>n        <option value=""122"">Mercedes-Benz</option>n        <option value=""304"">Mini</option>n        <option value=""124"">Mitsubishi</option>n        <option value=""126"">Morgan</option>n        <option value=""127"">Nissan</option>n        <option value=""128"">Opel</option>n        <option value=""130"">Peugeot</option>n        <option value=""132"">Porsche</option>n        <option value=""134"">Renault</option>n        <option value=""135"">Rolls-Royce</option>n        <option value=""138"">Saab</option>n        <option value=""139"">Seat</option>n        <option value=""140"">Skoda</option>n        <option value=""226"">smart</option>n        <option value=""343"">Spyker</option>n        <option value=""210"">SsangYong</option>n        <option value=""141"">Subaru</option>n        <option value=""142"">Suzuki</option>n        <option value=""417"">Think</option>n        <option value=""144"">Toyota</option>n        <option value=""147"">Volkswagen</option>n        <option value=""145"">Volvo</option>nn    </select>nnn I am wondering is there anyway's i can add the above string text to driver.page_source  So that i can iterate over the options values using driver properties ?n' 'from selenium import webdrivernfrom selenium.webdriver.common.by import Bynimport timenfrom selenium.webdriver.support.ui import Selectnnndriver = webdriver.Chrome()ndriver.maximize_window()ndriver.get('https://autotelexpro.nl/LoginPage.aspx')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_txtVestigingsnummer""').send_keys('3783')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_txtGebruikersnaam""').send_keys('Frank')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_Password""').send_keys('msnauto2016')ndriver.find_element(By.XPATH value ='//*@id=""ctl00_cp_LogOnView_LogOn_btnLogin""').click()ntime.sleep(10)nnncurrentselection = driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlVoertuigType'"")nselect = Select(currentselection)nselect.select_by_visible_text(""Motoren"")ntime.sleep(5)nntry:n    x=driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwdag'"")n    select = Select(x)n    select.select_by_visible_text(""1"")nn    y=driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwmaand'"")n    select = Select(y)n    select.select_by_visible_text(""1"")nn    z=driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwjaar'"")n    select = Select(z)n    select.select_by_visible_text(""2017"")n    time.sleep(5)nnn    car = driver.find_element_by_css_selector(""#ctl00_cp_ucSearch_Manual_ddlMerk"")n    select = Select(car)n    select.select_by_visible_text(""BTC"")nexcept:n    print ""Not able to select""nnnthis code will help.nSee better way is explicit wait but for temp solution i have used time.sleep()nnUpdate: If you want to get the option from car dropdown this is a method which can be used:nndef getallcarlist():n    currentselection = driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlVoertuigType'"")n    select = Select(currentselection)n    select.select_by_visible_text(""Motoren"")n    time.sleep(5)nn    x = driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwdag'"")n    select = Select(x)n    select.select_by_visible_text(""1"")nn    y = driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwmaand'"")n    select = Select(y)n    select.select_by_visible_text(""1"")nn    z = driver.find_element_by_xpath("".//*@id='ctl00_cp_ucSearch_Manual_ddlBouwjaar'"")n    select = Select(z)n    select.select_by_visible_text(""2017"")n    time.sleep(5)nn    car = driver.find_element_by_css_selector(""#ctl00_cp_ucSearch_Manual_ddlMerk"")n    carlist =n    for option in car.find_elements_by_tag_name('option'):n        carlist.append((option.text).encode('utf8'))n    return carlistnnnthis is way to call it nnlistcar= getallcarlist()nfor c in listcar:n    print cnnnthe output will be:nn- Kies merk -nAGMnAJPnAprilianBenellinBetanBMWnBTCnBullitnDerbinDucatinEnergicanGileranHarley DavidsonnHeskethnHondanHusqvarnanHyosungnIndiannKawasakinKTMnKymconLongjianMashnMorgannMorsnMoto GuzzinMV AgustanNimotonOssanPeugeotnPiaggionQuadronRazzonRenaultnRoyal EnfieldnSachsnScomadinSuzukinSWMnSYMnTriumphnTurbhonVespanVictorynVolta MotorbikesnYamahanYibennZero Motorcyclesnn'",['python-2.7'],"['python-2.7', 'python-3.x']"
40058912,"'randomly controlling the percentage of non zero values in a matrix using python' ""I am looking to create matrices with different levels of sparsity. I intend to do that by converting all the values that are nonzero in the data matrix to 1's and the remaining entries would be 0.nnI was able to achieve that using the following code. But I am not sure how would I be able to randomly make the 1's to 0's in the final matrix with control on the percentage of 1's.nnFor eg:nnthe numpy.random.choice nnn  numpy.random.randint(2 size = data_shape p=0.750.25)nnnenables us to create matrices with control over the percentage of 1's. How do I control the percentage of 1's in a similar way in the final matrix?nnimport numpy as npnimport scipy.sparse as spnimport numpy.ma as mannindptr = np.array(0 2 3 6)nindices = np.array(0 2 2 0 1 2)ndata = np.array(1 2 3 4 5 6)nmatrix = sp.csr_matrix((data indices indptr) shape=(3 3)).toarray()nprint(matrix)nnmask = ma.masked_greater(matrix 0)nprint(mask)nprint(mask.mask)nnmatrix2 = mask.masknint_matrix = matrix2.astype(int)nprint(int_matrix)nnnOutput:nnData matrix:n1 0 2n 0 0 3n 4 5 6nMasked matrix:n-- 0 --n 0 0 --n -- -- --nMasked values:n True False  Truen False False  Truen  True  True  TruenFinal matrixn1 0 1n 0 0 1n 1 1 1nnnThanks for the help!!!n"" 'You could do something like this -nnidx = np.flatnonzero(a)nN = np.count_nonzero(a!=0) - int(round(0.25*a.size))nnp.put(anp.random.choice(idxsize=Nreplace=False)0)nnnSample runnn1) Input array :nnIn 259: anOut259: narray(0 1 0 1 1n       0 1 1 0 1n       1 1 0 0 0n       1 0 1 1 0)nnn2) Get the non-zero indices :nnIn 260: idx = np.flatnonzero(a)nnn3) Get the number of non-zeros to be set as zeros :nnIn 261: N = np.count_nonzero(a!=0) - int(round(0.25*a.size))nnn4) Finally we select N randomly chosen indices from idx and set those in a as zeros :nnIn 262: np.put(anp.random.choice(idxsize=Nreplace=False)0)nnn5) Verify array -nnIn 263: anOut263: narray(0 0 0 1 0n       0 1 0 0 0n       1 0 0 0 0n       1 0 0 1 0)nnn6) Finally we see the percentage of non-zeros and verify it to be 25% :nnIn 264: np.count_nonzero(a!=0)/float(a.size)nOut264: 0.25nn'","['python-3.x', 'numpy']",['numpy']
40058993,"'Combinations of chars via a generator in Python' 'I am trying to get all the combinations with replacement (in other words the cartesian product) of strings with length(8) . The output is too big and I am having trouble storing it in memory all at once  so my process gets killed before it finishes.nnThis is the code I use which is way more faster than Python's stdlib itertools:nnimport numpy as npnndef cartesian(arrays out=None):n""""""Generate a cartesian product of input arrays.nParametersn----------narrays : list of array-liken    1-D arrays to form the cartesian product of.nout : ndarrayn    Array to place the cartesian product in.nReturnsn-------nout : ndarrayn    2-D array of shape (M len(arrays)) containing cartesian productsn    formed of input arrays.nExamplesn--------n>>> cartesian((1 2 3 4 5 6 7))narray(1 4 6n       1 4 7n       1 5 6n       1 5 7n       2 4 6n       2 4 7n       2 5 6n       2 5 7n       3 4 6n       3 4 7n       3 5 6n       3 5 7)n""""""narrays = np.asarray(x) for x in arraysnshape = (len(x) for x in arrays)ndtype = arrays0.dtypennix = np.indices(shape)nix = ix.reshape(len(arrays) -1).Tnnif out is None:n    out = np.empty_like(ix dtype=dtype)nnfor n arr in enumerate(arrays):n    out: n = arraysnix: nnnreturn outnnnHow would I make it return a generator out of the result  instead of storing everything to memory all at once ?n' 'My impression from other questions is that product is the fastest way of iteratively generating cartesian combinations:nnIn 494: g=itertools.product(1234567)nIn 495: list(g)nOut495: n(1 4 6)n (1 4 7)n (1 5 6)n (1 5 7)n (2 4 6)n (2 4 7)n (2 5 6)n (2 5 7)n (3 4 6)n (3 4 7)n (3 5 6)n (3 5 7)nnnYour code is a mapping of np.indices which is slower:nnIn 499: timeit np.indices((322)).reshape(3-1).TnThe slowest run took 11.08 times longer than the fastest. This could mean that an intermediate result is being cached.n10000 loops best of 3: 61.6 Âµs per loopnIn 500: timeit list(itertools.product(1234567))n100000 loops best of 3: 3.51 Âµs per loopnn'","['python-2.7', 'numpy']",['numpy']
40059033,"'How to use recursion in python' ""I am trying to solve a problem which stimulate movements of a robot. The robot starts with position (0 0 'N'). The command is given in a list of strings. the 'turn' function turns from N to E to S to W and back to N. The move function moves in the specific direction: NS in y axis and EW in x axis. N: y+1 S: y-1 W: x-1 E: x+1nnThe part I am having trouble with is when trying to use shortcuts in the function. Using 'turnleft' instead of 'turn' 'turn' 'turn' 'turnright' instead of 'turn'nndef macro_interpreter(code macros):nnnwhen call the function:nnprint(macro_interpreter('turnleft' 'turnright' {'turnleft': 'turn' 'turn' 'turn' 'turnright' : 'turn' 'bigleftturn' : 'move' 'move' 'turnleft' 'move' 'move' 'bigrightturn' : 'move' 'move' 'turnright' 'move' 'move'}))nnnthe definition of the term is given in a dictionary.nMy code only runs for the first command and then terminate it ignores the second code in the listnndef macro_interpreter(code macros):n    xyindex = 0 0 0n    state = 'N' 'E' 'S' 'W'n    for command in code:n        if command in macros:n            return macro_interpreter(macroscommand macros)n        else:n            if command == 'move':n                if stateindex == 'N':n                    y += 1n                elif stateindex == 'E':n                    x += 1n                elif stateindex == 'S':n                    y -= 1n                elif stateindex == 'W':n                    x -= 1n            elif command == 'turn':n                try:n                    index = index + 1n                except IndexError:n                    index = 0n    return (x y stateindex)            nn"" 'The linennreturn macro_interpreter (macros etc.nnnwill do just that. It will leave the for loop and return from the outer call. End of story.n' 'If you always hit the one else statement in the loop over the code commands then you never will recurse because  command not in macros. nnAfter the first iteration code == 'turn' 'turn' 'turn' but macros contains no key ""turn""nnnnIf you wish to do this more correctly then you can pass along x y and the ""direction index state"" as parameters to the function then increment / modify those within the recursive call rather than only modify local variables of the function and always restart them back at (00 0). nnAlso you need to replace that try except with index = (index + 1) % len(state) because no IndexError is going to be caught by incrementing a number nnnnSo something like this nnstate = 'N' 'E' 'S' 'W'ndef macro_interpreter(code macros x=0y=0index=0):n    # TODO: check if x or y have gone outside ""the board"" n        # TODO: return to break from recursion nn    for command in code:n        if command in macros:n            return macro_interpreter(macroscommand macrosxyindex)n        else:n            if command == 'move':n                if stateindex == 'N':n                    return macro_interpreter(code1: macrosxy=y+1index)nn' ""I suspect it's because you return nnmacro_interpreter(macroscommand macros)nnnThis simply exits the function once the recursed code is run. You'll see if you changennreturn macro_interpreter(macroscommand macros)nnntonnprint macro_interpreter(macroscommand macros)nnnthat the code will print what you want it to do. How you want to actually handle the output is up to you.n"" ""There are some amendments which i did in your code to support recursion properly. This code will do what you want to acheive. nndef macro_interpreter(code macros x=0 y=0 index=0):n    state = 'N' 'E' 'S' 'W'n    for command in code:n        if command in macros:n            x y curr_state = macro_interpreter(macroscommand macros x y index)   n            # update new index with new state value         n            index = state.index(curr_state)n        else:n            if command == 'move':n                if stateindex == 'N':n                    y += 1n                elif stateindex == 'E':n                    x += 1n                elif stateindex == 'S':n                    y -= 1n                elif stateindex == 'W':n                    x -= 1n            elif command == 'turn':                n                index = (index + 1)%len(state)n    return (x y stateindex)   nnnNow if i run your test casenn>> print macro_interpreter('turnleft' 'turnright' {'turnleft': 'turn' 'turn' 'turn' 'turnright' : 'turn' 'bigleftturn' : 'move' 'move' 'turnleft' 'move' 'move' 'bigrightturn' : 'move' 'move' 'turnright' 'move' 'move'})n Output:- (0 0 'N')nnnI hope this will helps you.  n""",['python-3.x'],['python-2.7']
40059136,"'Error on join condition with SqlAlchemy' 'I'm trying to use SQLAlchemy on my python app but I have a problem with the many to many relationship.nI have 4 tables:nnusers flags commandes channels and commandes_channels_flagsnncommandes_channels_flags contain a foreign key for each concerned table (commandes channels and flags)nnAn user has a flag_id as foreign key too.nnSo I try to link commandes channels and flag. the objective is to know that a command can run on a channel for a flag.nnI did this:nnfrom sqlalchemy import Column Integer String ForeignKeynfrom sqlalchemy.ext.declarative import declarative_basenfrom sqlalchemy.orm import relationshipnnBase = declarative_base()nnnclass User(Base):n    __tablename__ = 'users'nn    id = Column(Integer primary_key=True)n    pseudo = Column(String(50) unique=True nullable=False)n    flag_id = Column(ForeignKey('flags.id'))nnnclass Flag(Base):n    __tablename__ = 'flags'nn    id = Column(Integer primary_key=True)n    irc_flag = Column(Integer)n    nom = Column(String(50))nn    users = relationship(""User"" backref=""flag"" order_by=""Flag.irc_flag"")n    commande = relationship(""Commande"" secondary=""commandes_channels_flags"" back_populates=""flags"")n    channel = relationship(""Channel"" secondary=""commandes_channels_flags"" back_populates=""flags"")nnnclass Channel(Base):n    __tablename__ = 'channels'nn    id = Column(Integer primary_key=True)n    uri = Column(String(50))n    topic = Column(String(255))nn    commande = relationship(""Commande"" secondary=""commandes_channels_flags"" back_populates=""channels"")n    flag = relationship(""Flag"" secondary=""commandes_channels_flags"" back_populates=""channels"")nnnclass Commande(Base):n    __tablename__ = 'commandes'nn    id = Column(Integer primary_key=True)n    pattern = Column(String(50))nn    channel = relationship(""Channel"" secondary=""commandes_channels_flags"" back_populates=""commandes"")n    flag = relationship(""Flag"" secondary=""commandes_channels_flags"" back_populates=""commandes"")nnnclass CommandeChannelFlag(Base):n    __tablename__ = 'commandes_channels_flags'nn    id = Column(Integer primary_key=True)n    commande_id = Column(ForeignKey('commandes.id'))n    channel_id = Column(ForeignKey('channels.id'))n    flag_id = Column(ForeignKey('flags.id'))nnnBut I have this error:nnsqlalchemy.exc.InvalidRequestError: Mapper 'Mapper|Commande|commandes' has no property 'channels'nnnI understand that I have an error in my tables linking but I can't find it.n' 'back_populates needs to match the exact name of the related property on the other model. In Channel you have back_populates=""channels"" but in Commande you have:nnchannel = relationship(""Channel"" secondary=""commandes_channels_flags"" back_populates=""commandes"")nnnInstead change channel = relationship to channels = relationship.nnYou'll also need to change the other relationship properties to Flag.commandes Flag.channels Channel.commandes Channel.flags and Commande.flags to match your back_populates arguments.n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40059195,"'What would be wrong with this function that return a rounded number in millions' ""I'm a beginner doing an online course using ipython notebook and panda.nnWe are given a functionnndef roundToMillions (value):n    result = round(value / 1000000)n    return resultnnnand some tests nnroundToMillions(4567890.1) == 5nnroundToMillions(0) == 0  # always test with zero...nnroundToMillions(-1) == 0 # ...and negative numbersnnroundToMillions(1499999) == 1 # test rounding to the nearestnnnWe are told .. Define a few more test cases for both functions .nnI can't think of any more tests though.nnThe question posed is:nnWhy can't you use roundToMillions() to round the population to millions of inhabitants?nnI don't quite understand what could be wrong with the function. nnThis course is free and so there is not really much help available.n"" ""In terms of test cases this loop will generate many test cases and the results speak for themselves:nnfor x in xrange(-2000000 2000000 250000):nprint roundToMillions(x) xn>> -2.0 -2000000 n>> -2.0 -1750000n>> -2.0 -1500000n>> -2.0 -1250000n>> -1.0 -1000000n>> -1.0 -750000n>> -1.0 -500000n>> -1.0 -250000n>> 0.0 0n>> 0.0 250000n>> 0.0 500000n>> 0.0 750000n>> 1.0 1000000n>> 1.0 1250000n>> 1.0 1500000n>> 1.0 1750000nnnSo obviously it's rounding down.nnThis is due to integer division. removing the round shows this:nndef roundToMillions (value):n    result = value / 1000000n    return resultnprint roundToMillions(999999)n>> 0 nnnThis is fixed by adding a .0 to the function:nndef roundToMillions (value):n    result = round(value / 1000000.0)n    return resultnnfor x in xrange(0 1000000 250000):n    print roundToMillions(x) xn>> 0.0 0n>> 0.0 250000n>> 1.0 500000n>> 1.0 750000nprint roundToMillions(999999)n>> 1.0nnnFor more on integer division have a look at nnprint (3/2)n>> 1nprint (3.0/2.0)n>> 1.5nn""",['pandas'],"['python-2.7', 'python-3.x']"
40059284,"'Resolving Catastrophic Backtracking issue in RegEx' 'I am using RegEx for finding URL substrings in strings.nThe RegEx I am using has been taken from tohster's answer on - nWhat's the cleanest way to extract URLs from a string using Python?nnThe RE is -nnr'^(?:(?:https?|ftp)://)(?:S+(?::S*)?@)?(?:(?:1-9d?|1dd|201d|220-3)(?:.(?:1?d{12}|20-4d|250-5)){2}(?:.(?:1-9d?|1dd|20-4d|250-4))|(?:(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)(?:.(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)*(?:.(?:a-zu00a1-uffff{2})))(?::d{25})?(?:/^s*)?$'nnnI have done some changes to it - nnn  n  In the IPv4 detection part I changed the order of the IP range to be found. > Precisely changed 1-9d?|1dd|201d|220-3 to 250-5|20-40-9|10-> 9{2}|1-90-9|0-9 at 2 instances.n  Made the https group - (?:https?|ftp)://)?(?:S+(?::S*)?@) optional.n  nnnThe final version is -nn(?:(?:https?|ftp)://)?(?:S+(?::S*)?@)?(?:((250-5|20-40-9|10-9{2}|1-90-9|0-9).){3}(250-5|20-40-9|10-9{2}|1-90-9|0-9)|(?:(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)(?:.(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)*(?:.(?:a-zu00a1-uffff{2})))(?::d{25})?(?:/^s*)?nnnThe final RE I am using seems to be very promising and has improved significantly as per my requirements(as compared to the original one) and works in Python as well as Java Script except for the fact that due to the changes I have done have caused the following examples to give ""catastrophic backtracking"" error -nnn  asasasasasac31.23.53.122asasassasdn  n  12312312312321.32.34.2312312312321n  n  12.3423423432.234123123.123n  n  31.134232131.231.34nnnCan be tested at - https://regex101.com/r/i6jDei/1nnMy contention is that the first example - asasasasasac31.23.53.122asasassasd should have some slick way to pass as the IP is surrounded by non-numeric chars.nnAlso is there a way to pass the first two of the above examples as valid IPv4 addresses?nnTo resolve ambiguity I would opt for the largest possible Address i.e.nnn  31.23.53.122n  n  21.32.34.231nn' 'The issue of the catastrophic backtracking is caused by the pattern (?:(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)(?:.(?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+)*(?:.(?:a-zu00a1-uffff{2})) where (?:a-zu00a1-uffff0-9+-?)*a-zu00a1-uffff0-9+) will jump through a lot of combinations if the overall pattern can not be matched. As you can see the character classes are basically the same so e.g. for asasasasasac31 it can match like:nn(asasasasasac31)n(a)(sasasasasac31)n(a)(s)(asasasasac31)n(as)(asasasasac31)nnnThis is not really the way it actually takes just to show how many combinations exist.nnThe mistake here seems to be the - being optional which I see no reason for. If we remove the - we get it working for your samples (and reduce the number of steps for the already working samples). nnSee the updated regex101-demo where I also added your samples that caused the catastrophic backtracking.nnThe final pattern then is:nn(?:(?:https?|ftp)://)?(?:S+(?::S*)?@)?(?:((250-5|20-40-9|10-9{2}|1-90-9|0-9).){3}(250-5|20-40-9|10-9{2}|1-90-9|0-9)|(?:(?:a-zu00a1-uffff0-9+-)*a-zu00a1-uffff0-9+)(?:.(?:a-zu00a1-uffff0-9+-)*a-zu00a1-uffff0-9+)*(?:.(?:a-zu00a1-uffff{2})))(?::d{25})?(?:/^s*)?nn'",['regex'],['regex']
40059298,"'How to avoid a specific tag while extracting xpath' 'By using xpath(.//div@class=""entry-content""/div/p//text()') i am getting all the text1text2.....text6. How to take only ""text3""""text4""""text5""""text6""??nn`<div class=""entry-content"">n   <div>n     <p>n     <st>text1</st>n     </p>n     <p>n     <st>text2</st>n     </p>n   </div>n   <p>""text3""</p>n   <div>n     <p>n     <st>""text4""</st>n     </p>n     <p>n     <st>""text5""</st>n     </p>n     <p>n     <st>""text6""</st>n     </p>n   </div>n</div>`nn' 'If you only want nodes within the second div use the pathnn.//div@class=""entry-content""/div2/p//text()nnnIf want nodes in all divs except the first writenn.//div@class=""entry-content""/divposition()>1/p//text()nnnIf you want to select on some other basis then explain what rules you want to apply. (Your question says ""avoid a specific tag"" but you are very unspecific about what tag you want to avoid).n' 'As per your clarification it seems that ""p"" are the nodes you want to avoid in particular the first 2 of them. As they may appear at different depth level one of the ways you achieve it is with this xpath expression which is basically a variation of the solution provided by Michael Kay:nn//div@class=""entry-content""//descendant::pposition()>2//text()nn'","['python-2.7', 'python-3.x']",['python-2.7']
40059485,"'Django website not returning any data when using DNS' ""I have a simple Django website running on a Digital Ocean instance. I configured my DNS provider to point my URL to the Digital Ocean instance's IP address. When I enter that IP address in a browser everything works as expected but when I use the URL I get the correct site but no data is presented.nnThe site was created using Mezzanine running on nginx and using postgres as a database.nWhat could be wrong? I'm not sure where/how to troubleshoot this error.n"" nan",['django'],['django']
40059606,"'how to create empty numpy array to store different kinds of data' 'I am trying to start with an empty numpy array. As the code progresses the first column should be filled with datetime.datetime the second column should be filled with str the third columns with float and fourth column with int.nnI tried the following:nnA = np.empty(10 4)nA00 = datetime.datetime(2016 10 1 1 0)nnnI get the error:nnTypeError: float() argument must be a string or a numbernn' 'You can use dtype=object.nnA = np.empty(10 4 dtype=object)nA00 = datetime.datetime(2016 10 1 1 0)nnnIt is also possible to use structured arrays but then you have a fixed length for string objects. If you need arbitrary big objects you have to use dtype=object. But this often contradicts the purpose of arrays.n' ""A structured array approach:nndefine a dtype according to your column specs:nnIn 460: dt=np.dtype('OU10fi')nIn 461: from datetime import datetimennnInitalize an empty array with 3 elements (not 3x4)nnIn 462: A = np.empty((3) dtype=dt)nIn 463: AnOut463: narray((None '' 0.0 0) (None '' 0.0 0) (None '' 0.0 0) n      dtype=('f0' 'O') ('f1' '<U10') ('f2' '<f4') ('f3' '<i4'))nnnfill in some values - by field name (not column number)nnIn 464: A'f1'='one''two''three'nIn 465: A'f0'0=datetime(2016 10 1 1 0)    nIn 467: A'f2'=np.arange(3)nIn 468: AnOut468: narray((datetime.datetime(2016 10 1 1 0) 'one' 0.0 0)n       (None 'two' 1.0 0) n       (None 'three' 2.0 0) n      dtype=('f0' 'O') ('f1' '<U10') ('f2' '<f4') ('f3' '<i4'))nnnView on element of this array:nnIn 469: A0nOut469: (datetime.datetime(2016 10 1 1 0) 'one' 0.0 0)nnnI chose to make the 1st field object dtype so it can hold a datetime object - which isn't a number or string.nnnp.datetime64 stores a date as a float and provides a lot of functionality that datetime objects don't:nnIn 484: dt1=np.dtype('datetime64sU10fi')nIn 485: A1 = np.empty((3) dtype=dt1)nIn 486: A1'f0'=datetime(2016 10 1 1 0)nIn 487: A1'f3'=np.arange(3)nIn 488: A1nOut488: narray((datetime.datetime(2016 10 1 1 0) '' 0.0 0)n       (datetime.datetime(2016 10 1 1 0) '' 0.0 1)n       (datetime.datetime(2016 10 1 1 0) '' 0.0 2) n      dtype=('f0' '<M8s') ('f1' '<U10') ('f2' '<f4') ('f3' '<i4'))nnnA third approach is to make the whole array object dtype.  That's effectively a glorified list.  Many operations resort to plain iteration or just aren't implemented.  It's more general but you loose a lot of the power of normal numeric arrays.n""",['numpy'],['numpy']
40059607,'Match path but not os.path' 'I want to match the string path but not the string os.path. How do I go about that ? Tried (?!(os.path))bpathb but I still get all os.pathSn' 'You can use a look-behind based regex likenn(?<!os.)bpathbnnnThis basically matches the exact word path and ensures that it is not preceded by os. If you want to avoid similar constructs like sys.path or xx.path you could use (?<!w.) as look-behind instead.nnSee the regex101 demo.n' 'If you want to skip any path starting with . trynn(?<!.)pathnnThis will skip sys.path or os.path but will match path.nne.g. if test strings is if path and not os.path.sep in pathnnmatch will be:nnif path and not os.path.sep in pathnnSee demo at regex101n',"['regex', 'python-2.7']",['regex']
40059682,"'How can I select and order items based on a subquery?' 'I have the following models in Django:nnclass Author(models.Model):n    name = models.CharField(max_length=100)n    age = models.IntegerField()n    country = models.ForeignKey(Country)nnclass Book(models.Model):n    name = models.CharField(max_length=300)n    pages = models.IntegerField()n    price = models.DecimalField(max_digits=10 decimal_places=2)n    rating = models.FloatField()n    authors = models.ForeignKey(Author)n    pubdate = models.DateField()nnnHow can I get a queryset of Authors sorted by the first time they published a book?nnIn SQL I could do this using:nnSELECT *n  FROM ( SELECT author_id n               MIN(pubdate) as daten           FROM booksn          GROUPn             BY author_idn         HAVINGn            MIN(pubdate)) AS first_publishedn  JOIN authorn    ON author.id = first_published.author_idn LIMIT 15nOFFSET 15n ORDERn    BY first_published.author_idnnnIt's been a while with Django and I haven't been able to figure out how to do this.nnnnNow this is just nasty:nnfrom django.db.models.sql.compiler import SQLCompilern_quote_name_unless_alias = SQLCompiler.quote_name_unless_aliasnSQLCompiler.quote_name_unless_alias = lambda selfname: name if name.startswith('(') else _quote_name_unless_alias(selfname)nnsubquery = ""(SELECT author_id MIN(pubdate) as first_release_date FROM app_books GROUP BY author_id HAVING MIN(pubdate)) AS releases""ncondition = ""releases.author_id = app_authors.id""norder = '-releases.first_release_date'nAuthor.objects.get_queryset().extra(tables=subquery where=condition).order_by(order)nn' ""Try thisnnAuthor.objects.all().annotate(s=Min('book__pubdate')).order_by('s')nnnWhen if some author dont have booksnnAuthor.objects.exclude(book__pubdate__isnull=True).annotate(s=Min('book__pubdate')).order_by('s')nn""",['django'],['django']
40059955,'Django - Delay in creating database entry' 'I have a Django app where I create a db entry in the view. I then want to perform background processing on the new entry. Instead of sending the created object to the task I send the object's id then the background task can fetch the db object as explained here. Below is my code:nn# In tasks.pyn@shared_taskndef my_task(model_id):n    my_model = MyModel.objects.get(pk=model_id)n    # Do stuff with my_modelnn# In views.py:ndef some_view(request):n    if request.method == 'POST' and request.is_ajax():n        instance = MyModel.objects.create(**kwargs)n        tasks.my_task.delay(instance.id)n        ....nnnHowever when I try to get the object in the background task I get matching query does not exist error. If I add sleep(1) before getting the object it works as excepted. I do not understand why I'm getting this error since the object should be in the DB? Does anybody know how to solve this? I don't really want to add a sleep command everywhere.nnI'm using Postgres as my DB.n' 'Try thisnnfrom django.db import transactionnwith transaction.atomic():n    instance = MyModel.objects.create(**kwargs)ntasks.my_task.delay(instance.id)nn',['django'],['django']
40059979,"'Mean tensor product' 'I have another question which is related to my last problem( Python tensor product). There I found a mistake in my calculation. With np.tensordot I am calculating the following equation:nn<..> should display the average.nIn python code it does look like this (ewp is a vector and re a tensor): nnq1 = numpy.tensordot(re ewp axes=(1 0))nq2 = numpy.tensordot(q1 ewp axes=(1 0))nserc = q2 ** 2nnnornnserc = numpy.einsum('im m -> i' numpy.einsum('ilm l -> im'nnumpy.einsum('iklm k -> ilm' numpy.einsum('ijklm j -> iklm'nnumpy.einsum('ijk ilm -> ijklm' re re) ewp) ewp) ewp) ewp)nnnNow in both python codes I neglect that all possibilities are multiplied. But of course w_j and w_k are not independent for j=k. In the case that only j and k are the same we get < w_j*w_j*w_l*w_m> = <w_j>*<w_l>*<w_m>. For j=k=l we get: < w_j*w_j*w_j*w_m> = <w_j>*<w_m>. For j=k=l=m: < w_j*w_j*w_j*w_j> = <w_j>. Only if all variable are different independence is true and we get: < w_i*w_j*w_l*w_m> = <w_i>*<w_j>*<w_l>*<w_m>. Now this is what the code does for all possibilities. I hope this makes my problem understandable. Now my question is how can I represent this in my code? nnEdit: An idea that I have is to first create a 4dim. tensor which represents <w_j w_k w_l w_m>:nnwtensor = numpy.einsum('jkl m -> jklm' numpy.einsum('jk l -> jkl'nnumpy.einsum('j k -> jk' ewp ewp) ewp) ewp)nnnThen I need to change the values which are not idependent. I assume they should be on a diagonal? But I really don't know so much about tensor calculus so at this point I am struggling.nAfter manipulating the w tensor I would get the result by performing:nnserc = numpy.einsum('ijklm jklm -> i' numpy.einsum('ijk ilm ->nijklm' re re) wtensor)nnnEdit2: In another post I asked precisely how I can manipulate the 4dim so that it does fit here. Divakar had a really nice solution which can be seen here: Fill a multidimensional array efficiently that have many if else statementsnnfrom itertools import productnnn_dims = 4 # Number of dimsn# Create 2D array of all possible combinations of X's as rowsnidx = np.sort(np.array(list(product(np.arange(gn)nrepeat=n_dims)))axis=1)n# Get all X's indexed values from ewp arraynvals = ewpidxn# Set the duplicates along each row as 1s. With the np.prod coming upnnextn#these 1s would not affect the result which is the expected patternnhere.nvals:1:idx:1: == idx::-1 = 1n# Perform product along each row and reshape into multi-dim arraynout = vals.prod(1).reshape(gn*n_dims)nnnThe array which I am getting here is wtensor which I now can use in the code above:nnserc = numpy.einsum('ijklm jklm -> i' numpy.einsum('ijk ilm ->nijklm' re re) wtensor)nnnThis gives me finally the result which I wanted and basically answers the question.nAlthough there is one problem. The lenght of ewp which then also defines the size of the tensors shouldn't be larger then 6. Otherwise the code will use a lot of memory. My intention was to use it until a size of 8 so that is unfortunately now my next problem. n' ""Well you can do that efficiently with a combination of np.tensordot and np.einsum like so -nnserc = np.einsum('ilmilm->i'renp.tensordot(rewtensoraxes=(12)(01)))nn""",['numpy'],['numpy']
40059994,"'Pandas Get a list of index from dataframe.loc' 'I have looked through various sites and SO posts.Seems easy but somehow i am stuck with this.I am usingnnprint frame.loc(frame'RR'.str.contains(""^^123"" na=False)) 'RR'.isin(series1.str.slice(1))nnnto getnn3     Truen4    Falsen8    FalsenName: RR dtype: boolnnnNowsomehow i want the indexes only so that i can use that in dataframe.drop. Basically all the indexes where value is True  i have to grab indexes and drop them.Is there any other way as well without using indexes?n' 'You are testing two conditions on the same column so these can be combined (and negated):nnframe~((frame'RR'.str.contains(""^^123"" na=False)) & (frame'RR'.isin(series1.str.slice(1))))nnnHere after ~ operator it checks whether a particular row satisfies both conditions - same as the boolean array you get in the end. With ~ you turn True's to False's and False's to True's. Finally framecondition returns the rows that satisfy the final condition with boolean indexing.nnIn a more readable format:nncondition1 = frame'RR'.str.contains(""^^123"" na=False)ncondition2 = frame'RR'.isin(series1.str.slice(1))nframe~(condition1 & condition2)nnnAs an alternative (requires 0.18.0) you can get the indices of the True elements with:nnframe.loc(frame'RR'.str.contains(""^^123"" na=False)) 'RR'.isin(series1.str.slice(1))lambda df: df.indexnn'","['python-2.7', 'pandas']",['pandas']
40060069,"'Python script stuck in infinite loop' 'I am writing a beginner python script for the python challenge ARG. The basic aim is to write a script that will read through a mass of text pass through only the lower-case characters with exactly 3 capitals either side. The script is supposed to look at an incoming character from a list store the next 3 characters and previous 3 characters in a list. Once this has happened the script evaluates whether or not the incoming character is a capital if it is the loop starts over if not the script then evaluates if all three characters in the list are capitalised. If the conditions are met the script should print the current character else the loops starts over. nnWhenever I run this script I am left with no debug/error/warnings about the code but it never completes or writes anything to the file. nnhere is the code I have written any help would be appreciated. nn#code where f = text to be processed d = text file to be written tonnf = open(""test.txt"" ""r+"")nf = f.read()nfList = list(f)nlimit = len(fList)nn#Set location of resultnd = open(""noided.txt"" ""r+"")ni j k = 0 0 0nn#Main loopn#While there are characters left to be processednwhile i < limit:n    #Skip the first 4 charactersn    if i < 4:n        #print i fListin        i += 1n    else:n        #print i fListin        currentChar = fListin        count = 0n        prevChars = fListi-1fListi-2fListi-3n        nextChars = fListi:i + 3nn        if currentChar.isupper():nn            i += 1nn        else:n            while k < 3:n                if prevCharsk.isupper() and nextCharsk.isupper():n                    count += 1n                    k += 1n                elif count == 3:n                    print currentCharn                    d.write(currentChar)n                    i += 1n                else:n                    i += 1nn' 'For starters you have no variable named limit. Second it would be easier to use stack type of list. Think of the stack as a stack of papers. You can parse the letters from the file into the stack (using a for loop) but then you can compare each character before it enters the stack making this module useful for this kind of projectn'",['python-2.7'],"['list', 'python-3.x', 'python-2.7']"
40060094,"'kwargs overriding dict subclass' 'A minimal example is as follows:nnclass sdict(dict):n    class dval:n        def __init__(self val):n            self.val = valnn    def __init__(self args):n        dictionary = dict(args)n        for kv in dictionary.items():n            selfk = vnn    def __setitem__(selfkeyvalue):n         try:                   selfkey.val = valuen         except KeyError:       dict.__setitem__(selfkeyself.dval(value))n    def __getitem__(selfkey):n         return dict.__getitem__(selfkey).valnnnNow I can use this class inside a container to override assignment stuff:nnclass cont(object):n    def __init___(self):n        self._mydict = sdict(())n    @propertyn    def mydict(self):n        return self._mydictn    @mydict.settern    def mydict(selfdict_initializor):n        self._mydict = sdict(dict_initializor)n        return self.mydictnnnI use this so my container holds a dictionary with pointable primitives (i.e. mutable in python language) but whenever I retrieve the item I get the primitive itself. In my case floats which I multiply add etc... Adding __str__/__repr__ functions makes this work when printing these but for debugging purposes these are omitted.nnThis works nicely almost everywhere except when passing this along using kwargs:nndef test(ab): return a*bnc = cont()nc.mydict = {'a':1'b':2}nprint c.mydict'a'+c.mydict'b'type(c.mydict'a'+c.mydict'b')nprint test(**c.mydict)nnnOutput:nn3 <type 'int'>nTraceback (most recent call last):n  File ""D:kabanusworkspacepy-modulestest.py"" line 32 in <module>n    print test(**c.mydict)n  File ""D:kabanusworkspacepy-modulestest.py"" line 28 in testn    def test(ab): return a*bnTypeError: unsupported operand type(s) for *: 'instance' and 'instance'nnnObviously the unpacking procedure does not use __getitem__ to create values for the keywords. I also attempted to override values() and items() with no success. Next I set all dict methods not defined by me to None to see if any are called - no success either.nnBottom line - how do you get **kwargs unpacking to use __getitem__ or some other method?nIs this even possible?nnI also want to avoid defining mul add div and so forth if possible in class dval.n' 'Found the answer here and there should be a way to make this easier to find:nDoes argument unpacking use iteration or item-getting?nnSummary:nInheriting from builtins (dictlist...) is problematic since python may ignore your python API entirely (as it did for me) and use the underlying C. This happens in argument unpacking.nnSolution: use the available abstractions. In my example add:nnfrom UserDict import UserDictnnnand replace all ""dict"" occurrences in the code with UserDict. This solution should be true for lists and tuples. n'",['dictionary'],"['dictionary', 'list']"
40060253,"""Django Unitest: Table doesn't exist"" 'I created a simple test case like this:nnfrom unittest import TestCasenimport user_managernnnclass UserTest(TestCase):n    def test_register(self):n        email = ""dung7@gmail.com""n        password = ""123456""n        result user = user_manager.setup_new_user(email password)n        self.assertEqual(result CodeID.SUCCESS)nnnThen I run the testcase:nnpython manage.py test usersnnnAnd here is the log:nnCreating test database for alias 'default'...n/Users/admin/Projects/MyApp/venv/lib/python2.7/site-packages/django/db/backends/mysql/base.py:112: Warning: Table 'mysql.column_stats' doesn't existn  return self.cursor.execute(query args)nCreating test database for alias 'myapp_log'...n.FEn======================================================================nERROR: test_register (users.tests.UserTest)n----------------------------------------------------------------------nTraceback (most recent call last):n...nProgrammingError: (1146 ""Table 'test_myapp.user' doesn't exist"")nnnSo it created a test database but seem like it didn't create the tables. Here is my DATABASES setting:nnDATABASES = {n    'default': {n        'ENGINE': 'django.db.backends.mysql'n        'NAME': ""myapp""n        'USER': ""root""n        'PASSWORD': """"n        'HOST': '127.0.0.1'n        'PORT': ''n    }n    'myapp_log': {n        'ENGINE': 'django.db.backends.mysql'n        'NAME': ""myapp_log""n        'USER': ""root""n        'PASSWORD': """"n        'HOST': '127.0.0.1'n        'PORT': ''n    }n}nnnAnd my model:nnclass User(BaseModel):n    uid = models.IntegerField(primary_key=True)n    email = models.CharField(max_length=200)n    password = models.CharField(max_length=200)n    create_time = models.IntegerField()n    update_time = models.IntegerField()n    status = models.IntegerField()n    social_token = models.CharField(max_length=200)n    social_app = models.IntegerField()nn    class Meta:n        db_table = 'user'nnnAnyone know why the table 'user' is not created?nnUPDATE:nnuser_manager from my testcase will do some query and add new record on table user. nnAnd I thought when I run the testcase Django will somehow read my models and create a test database with all the table from those models. Am I right about this?n' 'Your test database needs to be different than your production database. Test databases are destroyed once the test cases are run. In your case the database was not created. You should go through this documentation for detailed information https://docs.djangoproject.com/en/1.10/topics/testing/overview/ nCan you also add the snippet of your user_manager modulen' ""So I found out I need to put my models.py in my users folder and add 'users' into the INSTALL_APPS setting. Now it worked.n""",['django'],['django']
40060285,"""Python2.7 & Sympy: UnicodeError: N escapes not supported (can't load unicodedata module)"" 'I'm trying to use sympy (for solve some equations) but when I try to import it on my code (or in the shell) I get this error:nnPython 2.7.11 (v2.7.11:6d1b6a68f775 Dec  5 2015 20:40:30) MSC v.1500 64 bit (AMD64) on win32nType ""help"" ""copyright"" ""credits"" or ""license"" for more information.n>>> import sympynTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""C:python27libsite-packagessympy__init__.py"" line 46 in <module>n    from .core import *n  File ""C:python27libsite-packagessympycore__init__.py"" line 8 in <module>n    from .expr import Expr AtomicExprn  File ""C:python27libsite-packagessympycoreexpr.py"" line 6 in <module>n    from .evalf import EvalfMixin pure_complexn  File ""C:python27libsite-packagessympycoreevalf.py"" line 28 in <module>n    from sympy.utilities.iterables import is_sequencen  File ""C:python27libsite-packagessympyutilities__init__.py"" line 20 in <module>n    from .timeutils import timedn  File ""C:python27libsite-packagessympyutilitiestimeutils.py"" line 11 in <module>n    _units = u('s') u('ms') u('N{GREEK SMALL LETTER MU}s') u('ns')n  File ""C:python27libsite-packagessympycorecompatibility.py"" line 109 in un    return codecs.unicode_escape_decode(x)0nUnicodeError: N escapes not supported (can't load unicodedata module)nnnWhy I get this error? How can I solve?nnI'm on Windows 10 (64 bit) and I'm using python 2.7.11 as you can see in the previous code.n' nan",['python-2.7'],"['python-2.7', 'pandas']"
40060349,"'How to color text to later be put in a docx file?' 'I want to color a text present in the string and pass the string to another python file so that to put received colored string into a docx file. I tried in this way but it is not working.nnfrom termcolor import colorednfrom docx import Documentnndocument = Document()nitem_i=""nn Comma is required in line dependent clause is in beginningnn"" nctxt = colored(item_i 'blue')np=document.add_paragraph()np.add_run(ctxt)ndocument.add_page_break()nndocument.save('demo.docx')nnnit displays properly in terminal but not in file it shows an errornnfrom termcolor import colorednnitem_i=""nn Comma is required in line dependent clause is in beginningnn"" nctxt = colored(item_i 'blue')nprint ctxtnnnIn this format it displays properly. Kindly help me to resolve this issue.n' 'You should be using docx's text formatting since as Jacques de Hooge said termcolor is for terminal. See here.nnfrom docx.shared import RGBColornnnThennnrun = p.add_run(item_i)nrun.font.color.rgb = RGBColor(0x00 0x00 0xFF)nn'",['python-2.7'],['python-2.7']
40060461,"'Add quotation at start and end of every other line ignoring empty line' 'I need help on organizing texts. I have the list of thousands vocabs in csv. There are term definition and sample sentence for each word. Term and definition is separated by the tab and sample sentence is separated by an empty line.nnFor example:nnexacerbate  worsennnThis attack will exacerbate the already tense relations between the two communitiesnnexasperate  irritate vexnnhe often exasperates his mother with pranksnnexecrable   very bad abominable utterly detestablennan execrable performancennnI want to organize this so that the sample sentence is enclosed by double quotation marks has no empty line before and after itself and the term in sentence is replaced by the hyphen. All that change while keeping the tab after the term the new line in the beginning of each term and the only a space between the definition and the example sentence. I need this format for importing it to flashcards web application.nnDesired outcome using above example:nnexacerbate  worsen ""This attack will âx80x93 the already tense relations between the two communities""nexasperate  irritate vex ""he often âx80x93 his mother with pranks""nexecrable   very bad abominable utterly detestable ""an âx80x93 performance""nnnI am using Mac. I know basic command lines (including regex) and python but not enough to figure this out by myself. If you could help me I am very grateful.n' 'Not necessarily bullet-proof but this script will do the job based on your example:nnimport sysnimport reninput_file = sys.argv1nnnis_definition = Truenncurrent_entry = """"ncurrent_definition = """"nnfor line in open(input_file 'r'):n    line = line.strip()nn    if line != """":n        if is_definition == True:n            is_definition = Falsenn            current_entry current_definition = line.split(""t"")nn        else:n            is_definition = Truenn            example = linenn            print (current_entry + ""t"" + current_definition + ' ""' + re.sub(current_entry + r'w*' ""-"" line) + '""')nnnoutput:nnexacerbate  worsen ""This attack will - the already tense relations between the two communities""nexasperate  irritate vex ""he often - his mother with pranks""nexecrable   very bad abominable utterly detestable ""an - performance""nnnThe problem with our current approaches is that it won't work for irregular verbs like: ""go - went"" or ""bring - brought"" or ""seek - sought"".n' 'Try:nnsuffixList = ""s"" ""ed"" ""es"" ""ing"" #et ceteranfile = vocab.read()nfile.split(""n"")nnvocab_words = filei for i in range(0 len(file)-2 4)nvocab_defs = filei for i in range(2 len(file) 4)nnfor defCount in range(len(vocab_defs)):n    vocab_defsdefCount = """""" + vocab_defsdefCount + """"""nnnewFileText = """"nfor count in range(len(vocab_words)):n    vocab_defscount = vocab_defscount.replace(vocab_wordscount.split("" "")0 ""-"")n    for i in suffixList:n        vocab_defscount = vocab_defscount.replace(""-%s"" % i ""-"")n    newFileText += vocab_wordscountn    newFileText += ""  ""n    newFileText += vocab_defscountn    newFileText += ""n""nnnew_vocab_file.write(newFileText)nnnOutputs:nn============== RESTART: /Users/chervjay/Documents/thingy.py ==============nexacerbate  worsen  ""This attack will - the already tense relations between the two communities""nexasperate  irritate vex  ""he often - his mother with pranks""nexecrable   very bad abominable utterly detestable  ""an - performance""nn>>> nn' 'Open the terminal to the directory where you have the input file.nSave the following code in a .py file:nnimport sysnimport stringnimport difflibnimport itertoolsnnnwith open(sys.argv1) as fobj:n    lines = fobj.read().split('nn')nnwith open(sys.argv2 'w') as out:n    for i in range(0 len(lines) 2):n        line1 example = linesi:i + 2n        words = w.strip(string.punctuation).lower()n                 for w in example.split()nn        # if the target word is not in the example sentencen        # we will find the most similar onen        target = line1.split('t')0n        if target in words:n            most_similar = targetn        else:n            most_similar = difflib.get_close_matches(target words 1)0n        new_example = example.replace(most_similar '-')n        out.write('{} ""{}""n'.format(line1.strip() new_example.strip()))nnnThe program needs the input file name and the output file name as command line arguments. That is execute from the terminal the following command:nn$ python program.py input.txt output.txtnnnwhere program.py is the above program input.txt is your input file and output.txt is the file that will be created with the format you need.nnnnI ran the program against the example you provided. I had manually add the tabs because in the question there are only spaces. This is the output produced by the program:nnexacerbate  worsen ""This attack will - the already tense relations between the two communities""nexasperate  irritate vex ""he often - his mother with pranks""nexecrable   very bad abominable utterly detestable ""an - performance""nnnThe program correctly substitutes exacerbates with a dash in the second example even though the word is exacerbate. I cannot guarantee that this technique will work for every word in your file without having the file.n' '#!/usr/local/bin/python3nnimport rennwith open('yourFile.csv' 'r') as myfile:n    data = myfile.read()    nnprint(re.sub(r'(^A-Za-z+)t(.+)nn(.+)1s|ed|es|ing*(.+)$'r'1t2 ""3-4""' data flags = re.MULTILINE))nnnOutput:nnn  exacerbate    worsen ""This attack will - the already tense relations between the two communities""n  n  exasperate irritate vex ""he often - his mother with pranks""n  n  execrable  very bad abominable utterly detestable ""an - performance""nn'",['regex'],"['regex', 'python-2.7']"
40060520,"'contour plot from data: plot doesnt represent the real data' 'I am trying to do a contour plot from a data file. The plot that I am getting is not the representation of the data. I think the problem lies with the grid or the interplation (tried all forms of interpolation). Thanks to the previous posts on the subject my script looks like the following.nnimport numpy as npnimport matplotlib.pyplot as pltnimport scipy.interpolatencontour_levels = 0 1 2 34nXYZ=np.genfromtxt(r'bvkP.txt' unpack=True)nxiyi=np.mgrid0.1:0.7:0.30.001:0.011:0.005nzi = scipy.interpolate.griddata((X Y) Z (xi yi))    nfig = plt.figure()nCS=plt.contourf(xi yi zilevels=contour_levels)nplt.clabel(CS inline=20fmt = '%2.0f' fontsize=12)nproxy = plt.Rectangle((00)11fc = pc.get_facecolor()0)n    for pc in CS.collectionsncontour_filled = plt.contourf(xi yi zi contour_levels)nplt.xlabel(""X"")nplt.ylabel(""Y"")nplt.legend(proxy ""I"" ""E"" ""D""""Il"")nplt.show()nnnA sample data looks like thisnn0.1 0.001   1n0.4 0.001   3n0.1 0.006   0n0.4 0.006   2nnnAny help in fixing this problem is very much appreciated.n' nan",['matplotlib'],['matplotlib']
40060556,"'Infinite loop when try to redirect stdout' 'I'm trying to send stdout to both console and QTextBrowser widget. But I'm getting some kind of infinite loop and then application exits.nnHere is my code:nnimport sysnfrom PyQt5 import QtWidgets uicnfrom PyQt5.QtCore import *nnqtCreatorFile = ""qt_ui.ui""nUi_MainWindow QtBaseClass = uic.loadUiType(qtCreatorFile)nnclass MainWindow(QtWidgets.QMainWindow Ui_MainWindow):n    def __init__(self):n        QtWidgets.QMainWindow.__init__(self)n        Ui_MainWindow.__init__(self)n        self.setupUi(self)n        self.start_button.clicked.connect(printing)nndef printing():n    print(""Pressed!n"")nnclass Logger(QObject):n    def __init__(self):n        super().__init__()n        self.terminal = sys.stdoutnn    def write(self message):n        self.terminal.write(message)n        self.log_browser.setText(message) #problem is in this linenn    def flush(self):n        passnnif __name__ == ""__main__"":n    sys.stdout = Logger()n    app = QtWidgets.QApplication(sys.argv)n    window = MainWindow()n    window.show()n    sys.exit(app.exec_())nnnAs a result when click start_button following is observed:nn""C:...python.exe"" ""E:/.../qt_gui.py""nPressed!nPressed!nPressed!n... (totaly 332 times)nPressed!nPressed!nPressed!nnProcess finished with exit code 1nnnI just can't understand why this line makes loop:nnself.log_browser.setText(message)nnnEdit after 1st answer:nnI replaced the line above with print(message) but still getting same results. I would appreciate any help.n' ""Looks like the code you posted is not code you have run but assuming it is representative there are two errors: base class of Logger must be inited and self.log_browser is not defined anywhere. But this does not cause loop app exits (because there is an exception but no exception hook see ). Since I don't know what log_browser should be I defined it as a Mock() (from unittest.mock) which will accept anything done to it and problem goes away. nnclass Logger(QObject):n    def __init__(self):n        super().__init__()n        self.terminal = sys.stdoutn        from unittest.mock import Mockn        self.log_browser = Mock()nn    def write(self message):n        self.terminal.write(message)n        self.log_browser.setText(message) # problem was this linenn    def flush(self):n        passnn"" 'You could emit a custom signal from Logger and connect it to the log browser:nnclass Logger(QObject):n    loggerMessage = pyqtSignal(str)nn    def __init__(self):n        super().__init__()n        self.terminal = sys.stdoutnn    def write(self message):n        self.terminal.write(message)n        self.loggerMessage.emit(message)nn    def flush(self):n        passnnif __name__ == ""__main__"":nn    sys.stdout = Logger()n    app = QtWidgets.QApplication(sys.argv)n    window = MainWindow()n    sys.stdout.loggerMessage.connect(window.log_browser.insertPlainText)n    window.show()n    sys.exit(app.exec_())nn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40060568,"'How to sum all the keys of a dictionary value to the same dictionary value' ""Let's say I have a dictionary that hasn{'a' : '0'n 'b' : '2'n 'a' : '3'n 'b' : '5'}nnI want the dictionary to say {'a' : '3'n                              'b' : '7'}nnHow would I do this ? n"" ""You can't create dictionary which contains the same key twice. The definition of the dictionary is that you can store in it every key-value option only once.n""",['dictionary'],['dictionary']
40060580,"'Dictionary removing duplicate along with subtraction and addition of values' 'New to python here. nI would like to eliminate duplicate dictionary key into just one along with performing arithmetic such as adding/subtracting the values if duplicates are found.nnCurrent Code Outputnnn  {('GRILLED AUSTRALIA ANGU'): (('1') ('29.00')) ('Beer' 'Carrotn  Cake' 'Chocolate Cake'): (('10' '1' '1') ('30.00' '2.50'n  '3.50')) ('Beer' 'Beer'): (('1' '1') ('3.00' '3.00')) ('Carrotn  Cake' 'Chocolate Cake'): (('1' '1') ('2.50' '3.50')) ('Carrotn  Cake'): (('1') ('2.50')) ('BRAISED BEANCURD WITH'): (('1')n  ('10.00')) ('SAUSAGE WRAPPED WITH B' 'ESCARGOT WITH GARLIC H' 'PANn  SEARED FOIE GRAS' 'SAUTE FIELD MUSHROOM W' 'CRISPY CHICKEN WINGS'n  'ONION RINGS'): (('1' '1' '1' '1' '1' '1') ('10.00' '12.00'n  '15.00' '9.00' '7.00' '6.00')) ('Beer' 'Beer' 'Carrot Cake'n  'Chocolate Cake'): (('-1' '10' '1' '1') ('-3.00' '30.00' '2.50'n  '3.50')) ('Beer'): (('10') ('30.00'))}nnnWhat i want: example:nnSUBTRACTION FOR DUPLICATEnnn  {'Beer': 9 27}  {'carrot cake': 1 2.5}  {'Chocolate Cake': 1n  3.5} nnnnotice that for duplicate item entry i trimmed Beer into one along with (10-1=9) for quantity amount and (30-3=27) for the cost. How do i automate this process?nnADDITION FOR DUPLICATEnnn  {'Beer': 2 6}nnnnotice that I added beer and beer into one entry and along with the quantity (1+1) and cost (3+3=6)nnMy code:nnimport csvnfrom itertools import groupbynfrom operator import itemgetternimport rennd = {}nn#open directory and saving directorynwith open(""rofl.csv"" ""rb"") as f open(""out.csv"" ""wb"") as out:n    reader = csv.reader(f)n    next(reader)n    writer = csv.writer(out)n    #the first column headern    writer.writerow(""item""""quantity""""amount"")n    groups = groupby(csv.reader(f) key=itemgetter(0))nnn    for k v in groups:n        v = list(v)nnn        sales=  x1 for x in v8: n        salesstring= str(sales)nn        #using re.findall instead of re.search to return all via regex for itemsn        itemoutput= re.findall(r""(?<=ss)w+(?:sw+)*(?=ss)""textwordfortransaction)nn        #using re.findall instead of re.search to return all via regex for amount aka quantityn        amountoutput= re.findall(r""'(-?d+)s+(?:A-Za-z *)""textwordfortransaction)nn        #using re.findall instead of re.search to return all via regex for costnn        costoutput= re.findall(r""(?:'-?d+A-Za-z *)(-?d+.?d*)""textwordfortransaction)nn        dtuple(itemoutput) = tuple(amountoutput)tuple(costoutput)nnn        #writing the DATA to output CSVn        writer.writerow(d)n        #to remove the last entry else it would keep on stacking the previousn        d.clear()nnnlink to csv file if needednhttps://drive.google.com/open?id=0B1kSBxOGO4uJOFVZSWh2NWx6dHcn' 'Working with your current output as posted in the question you can just zip the different lists of tuples of items and quantities and prices to align the items with each other add them up in two defaultdicts and finally combine those to the result.nnoutput = {('GRILLED AUSTRALIA ANGU'): (('1') ('29.00')) ...}nnfrom collections import defaultdictnprices quantities = defaultdict(int) defaultdict(int)nfor key val in output.items():n    for item quant price in zip(key *val):n        quantitiesitem += int(quant)n        pricesitem += float(price)nnresult = {item: (quantitiesitem pricesitem) for item in prices}nnnAfterwards result is this: Note that you do not need a special case for subtracting duplicates when the quantity and/or price are negative; just add the negative number.nn{'ESCARGOT WITH GARLIC H': (1 12.0) n 'BRAISED BEANCURD WITH': (1 10.0) n 'CRISPY CHICKEN WINGS': (1 7.0) n 'SAUSAGE WRAPPED WITH B': (1 10.0) n 'ONION RINGS': (1 6.0) n 'PAN SEARED FOIE GRAS': (1 15.0) n 'Beer': (31 93.0) n 'Chocolate Cake': (3 10.5) n 'SAUTE FIELD MUSHROOM W': (1 9.0) n 'Carrot Cake': (4 10.0) n 'GRILLED AUSTRALIA ANGU': (1 29.0)}nnnnnIf you want to keep the individual items separate just move the declaration of prices quantities and result inside the outer loop:nnfor key val in output.items():n    prices quantities = defaultdict(int) defaultdict(int)n    for item quant price in zip(key *val):n        quantitiesitem += int(quant)n        pricesitem += float(price)n    result = {item: (quantitiesitem pricesitem) for item in prices}n    # do something with result or collect in a listnnnExample result for the two-beer line:           nn('Beer' 'Beer' 'Carrot Cake' 'Chocolate Cake') (('-1' '10' '1' '1') ('-3.00' '30.00' '2.50' '3.50'))n{'Chocolate Cake': (1 3.5) 'Beer': (9 27.0) 'Carrot Cake': (1 2.5)}nnnIf you prefer the result to group the items quantities and prices together use this:nnitems = list(prices)nresult = (items quantitiesx for x in items pricesx for x in items)nnnResult is this like this:nn('Carrot Cake' 'Beer' 'Chocolate Cake' 1 9 1 2.5 27.0 3.5)nn'",['dictionary'],"['regex', 'dictionary']"
40060691,"'How to input from input direcory folder and save output file in same name as input file in output folder in python' 'I want to create input directory for my code will take input files from input directory and save same name as input file in output (different folder) directory.nnScript: nnimport sysnimport globnimport errnonimport osnnnd = {}nchainIDs = ('A' 'B')natomIDs = ('C4B' 'O4B' 'C1B' 'C2B' 'C3B' 'C4B' 'O4B' 'C1B')ncount = 0nfor doc in os.listdir('/C:/Users/Vishnu/Desktop/Test_folder/Input'):ndoc1 = ""doc_path"" + docndoc2 = ""/C:/Users/Vishnu/Desktop/Test_folder/Output"" + doc1nif doc1.endswith("".pdb""):nwith open(doc) as pdbfile:n       single_line = ''.join(line for line in f)n       single_space = ' '.join(single_line.split())n       for line in map(str.rstrip pdbfile):n            if line:6 != ""HETATM"":n                continuen            chainID = line21:22n            atomID = line13:16.strip()n            if chainID not in chainIDs:n                continuen            if atomID not in atomIDs:n                continuen            try:n                dchainIDatomID = linen            except KeyError:n                dchainID = {atomID: line}nn    n = 4n    for chainID in chainIDs:n        for i in range(len(atomIDs)-n+1):n            for j in range(n):n                   with open(doc2.format(count)  ""w"") as doc2:n                         doc2.write(dchainIDatomIDsi+j)n                         count += 1   nnelse:ncontinuennnBelow error while running above code I am new in python just learning can anyone please help?nerror:nnwith open(doc) as pdbfile:n    ^nIndentationError: expected an indented blockn>>> nnnInput file:nnHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C  nHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C  nHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           C  nHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           O  nHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           C  nHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           C  nHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           C  nHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           C  nHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           O  nHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           C  nHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28           C  nHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           C  nHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           C  nHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           O  nHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           C  nHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99           C  nHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           C  nnnCol 2 is Residue name Col 4 is A B C D is the chain ID:nnExpected Output for each chain ID (A B ..... Z) Chain ID may be A to Z but mostly A to H:nnfor A chain: nnHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C nHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C   nnHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C  nHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nnHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C  nHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C  nnHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C  nHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C  nHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nnHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C  nHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nn' 'The IndentationError is showing up because you seem to have indented two tabs underneath your with open(doc) as pdbfile: line. nnHope this helps! n' 'import sysnimport globnimport errnonimport osnnnd = {}nchainIDs = ('A' 'B')natomIDs = ('C4B' 'O4B' 'C1B' 'C2B' 'C3B' 'C4B' 'O4B' 'C1B')ncount = 0ndoc_path=r'C:UsersVishnuDesktopTest_folderInput'ntar_path=r'C:UsersVishnuDesktopTest_folderOutput'nfor doc in os.listdir(doc_path):n    doc1 = doc_path+''+ docn    doc2 = tar_path+''+ docnn    if doc1.endswith("".pdb""):n        print(doc1doc2)n        with open(doc1) as pdbfile:n           # single_line = ''.join(line for line in f)n           # single_space = ' '.join(single_line.split())n           for line in map(str.rstrip pdbfile):n                if line:6 != ""HETATM"":n                    continuen                chainID = line21:22n                atomID = line13:16.strip()n                if chainID not in chainIDs:n                    continuen                if atomID not in atomIDs:n                    continuen                try:n                    dchainIDatomID = linen                except KeyError:n                    dchainID = {atomID: line}n           n = 4n           for chainID in chainIDs:n               for i in range(len(atomIDs)-n+1):n                   for j in range(n):n                          with open(doc2  ""w+"") as s:n                                s.write(dchainIDatomIDsi+j)n                                count += 1   nn    else:n        continuenn'","['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x', 'list']"
40060842,"'Moving Average- Pandas' 'I would like to add a moving average calculation to my exchange time series.nnOriginal data from QuandlnnExchange = Quandl.get(""BUNDESBANK/BBEX3_D_SEK_USD_CA_AC_000"" authtoken=""xxxxxxx"")nn    ValuenDate               n1989-01-02  6.10500n1989-01-03  6.07500n1989-01-04  6.10750n1989-01-05  6.15250n1989-01-09  6.25500n1989-01-10  6.24250n1989-01-11  6.26250n1989-01-12  6.23250n1989-01-13  6.27750n1989-01-16  6.31250nnnCalculating Moving AvaragennMovingAverage = pd.rolling_mean(Exchange5)nn              ValuenDate          n1989-01-02      NaNn1989-01-03      NaNn1989-01-04      NaNn1989-01-05      NaNn1989-01-09  6.13900n1989-01-10  6.16650n1989-01-11  6.20400n1989-01-12  6.22900n1989-01-13  6.25400n1989-01-16  6.26550nnnI would like to add the calculated Moving Average as a new column to the right after 'Value' using the same index (Date). Preferably i would also like to rename the calculated moving average to 'MA'n' 'The rolling mean returns a Series you only have to add it as a new column of your DataFrame (MA) as described below. nnFor information the rolling_mean function has been deprecated in pandas newer versions. I have used the new method in my example see below a quote from the pandas documentationnnn  Warning Prior to version 0.18.0 pd.rolling_* pd.expanding_* and pd.ewm* were module level functions and are now deprecated. These are replaced by using the Rolling Expanding and EWM. objects and a corresponding method call.nnndf'MA' = df.rolling(window=5).mean()nnprint(df)n#             Value    MAn# Date                   n# 1989-01-02   6.11   NaNn# 1989-01-03   6.08   NaNn# 1989-01-04   6.11   NaNn# 1989-01-05   6.15   NaNn# 1989-01-09   6.25  6.14n# 1989-01-10   6.24  6.17n# 1989-01-11   6.26  6.20n# 1989-01-12   6.23  6.23n# 1989-01-13   6.28  6.25n# 1989-01-16   6.31  6.27nn'","['python-3.x', 'pandas']",['pandas']
40060952,"'Why does list index go out of range when using random module?' ""I am building a Chatbot and I was able to make it answer to me randomly. I added all the responses in a list and whenever I greet it It shoots me a random answer. Now this is fine but sometimes the program throws an exception - IndexError: list index out of range. I don't understand why the list index is going out of range. The list has 6 items and by using random.randint(0len(slist)) I was able to get a random response.nnI have used exception handling to fix this problem. But I want to know why it gives an error. nnHere's the code without exception handling: nnif self.Has_user_greeted == False:n    self.AI_Greet()n else:n    # goes out of range heren    self.AI_respond = random.randint(0len(self.AI_Greeted))n    print(self.AI_Greetedself.AI_respond)nn"" 'That is because list indexes start at 0 and randint will choose a number in the range you specify inclusively with the upper bound. Observe this example: nn>>> a = 123n>>> len(a)n3nnnSo now try to get the value at index 3:nn>>> a3nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>nIndexError: list index out of rangennnBecause the highest index is actually 2. nnWhat you want to do in your example is simply -1 the length: nnrandom.randint(0len(self.AI_Greeted) - 1)nn' ""randint does not act like the rest of Python (for historical reasons relating to other computer languages). In particular randint() does include the upper bound unlike Python's list indices and len().nnSo use randint(0len(self.AI_Greeted) - 1).n""",['python-3.x'],"['list', 'python-2.7']"
40060983,"'How to use a previously trained model to get labels of images - TensorFlow' 'After training a model (according to the mnist tutorial) and saving it using this code:nnsaver = tf.train.Saver()nsave_path = saver.save(sess'/path/to/model.ckpt')nnnI want to use the saved model in order to find labels for a new batch of images. I succeeded to load the model and test it with an already exist database as follows:nn# load MNIST datanfolds = build_database_tuple.load_data(data_home_dir='/path/to/database')nn# starting the session. using the InteractiveSession we avoid build the entiee comp. graph before starting the sessionnsess = tf.InteractiveSession()nn# start building the computational graphn...nnBUILD AND DEFINE ALL THE LAYERSnn...nny_conv=tf.nn.softmax(tf.matmul(h_fc1_drop W_fc2) + b_fc2)nn# TRAIN AND EVALUATION:ncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv) reduction_indices=1))ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)ncorrect_prediction = tf.equal(tf.argmax(y_conv1) tf.argmax(y_1))naccuracy = tf.reduce_mean(tf.cast(correct_prediction tf.float32))nnnsess.run(tf.initialize_all_variables())nsaver = tf.train.Saver()n# Restore variables from disk.nsavepath = '/path/to/model.ckpt'nsaver.restore(sess save_path=savepath)nprint(""Model restored."")nnprint(""test accuracy %g""%accuracy.eval(feed_dict={x: folds.test.images y_: folds.test.labels keep_prob: 1.0}))nnnAlthough I succeed to load and test the model I don't know how to get y' array (the model's predictions for the database images).nnI scanned the web and found a lot of answers for this question but I couldn't project those answers for this particular case (e.g. this answer that given about the CIFAR10 tutorial which really different from the MNIST tutorial).nnA detailed answer will highly appreciated (I'm new with tensorflow and still learning the terminology). Thanks a lot for your help!n' 'Define an OP for performing classification likennpredictor = tf.argmax(y_conv1)nnnand then run it on trained model with new inputsnnprint(sess.run(predictor feed_dict={ x = new_data }))nnnsince ""predictor"" does not depend on y you do not have to provide it and this will still execute.nnIf you just want to see predictions on test images you can also do both things in one run call by removing your accuracy eval call and doingnnacc predictions = sess.run(accuracy predictorn                            feed_dict={x: folds.test.imagesn                                       y_: folds.test.labelsn                                       keep_prob: 1.0}))nnprint('Accuracy' acc)nprint('Predictions' predictions)nn' 'Another option to what lejlot just answered(and this option is primarily for learning and understanding  what the network is doing ) could be:You can make predictions  using feedforward using the weights and biases that your network already learned that means that al the computations you defined in your  ""BUILD AND DEFINE ALL THE LAYERS"" should be applied to  a new dataset for example asuming that your network is of the shape inputs-> relu layer -> softmax layer. You would compute:nnrelu_layer_oututs = tf.nn.relu(tf.matmul(input_dataweights_layer1)+biases_layer1 );nprediction = tf.nn.softmax(tf.matmul(relu_layer_outputsweights_layer2)+biases_layer2);nn'",['python-2.7'],['pandas']
40061044,"'Keep pandas matplotlib plot open after code completes' ""I am using pandas builtin plotting as per below. However as soon as the plotting method returns the plot disappears. How can I keep the plot(s) open until I click on them to close?nnimport matplotlibnmatplotlib.use('TkAgg')nimport matplotlib.pyplot as pltnndef plot_data():n    #...create dataframe df1n    pd.options.display.mpl_style = 'default'n    df1.boxplot()n    df1.hist()nnif __name__ == '__main__':n    plot_data()nn"" 'Use a plt.show(block=True) command to keep the plotting windows open.nn...ndf1.boxplot()ndf1.hist()nplt.show(block=True)nnnIn my version of matplotlib (1.4.3) block=True is necessary but that may not be the case for all versions (Keep plotting window open in Matplotlib)n'","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40061092,'Threadsafe way to copy-and-clear array' 'One array accumulates datagrams. On interval or some length it flushed to database.nnIt accumulates on datagram_received network event asynchronous.nnclass Protocol:n    flows = n    def datagram_received(self data addr):n    ...n            self.flows.append(flow)nnnAnd flushed by this method:nndef store(self):n    flows = n    while len(self.flows):n        flows.append(self.flows.pop(0))n    self.db.insert(flows)n    sleep(10)n    self.store()nnnHow to optimize it to replace while with one thread-safe operation?nnThis module runs one instance of class but in two threads.n' nan,['python-3.x'],"['python-2.7', 'python-3.x']"
40061167,"'If strings are immutable then how is this possible?' ""I am new to python and was going through the python3 docs. In python strings are said to be immutable then how is this possible:nnif __name__ == '__main__':n        l = 'string'n        print(l)n        l = l:2n        print(l)nnnreturns this output:nnstringnstnn"" 'Informally l now points to a new immutable string which is a copy of a part of the old one.nnWhat you cannot do is modify a string in place. nna = ""hello""na0 = ""b""  # not allowed to modify the string `a` is referencing; raises TypeErrornnprint(a)  # not reached since we got an exception at the previous linennnbut you can do this:nna = ""hello""na = ""b"" + a1:  # ok since we're making a new copynnprint(a)  # prints ""bello""nn' 'The key to understand this problem is to realize that variable in Python is just a ""pointer"" pointing to an underlying object. And you confused the concept of immutable object and immutable variable(which does not exist in Python).nnFor instance in your case l was initially a pointer pointing to a str object with content ""string"". But later you ""redirect"" it to a new str object whose content is ""st"". Note that when the program runs to the line l = l:2 it's the pointer being modified not the object pointed to by the pointer. If you will you can also ""redirect"" l to another object with type other than str say l = 123. Just remember the original object pointed to by l(str ""string"") is not modified at all it's still there in the memory(as long as it is not garbage collected) but just no longer pointed to by l.nnFor you to better understand the concept of immutable object let's look at a mutable object. For example list in Python is mutable. nnl = 1 2 3 # a new list with three elementsnl.append(4) # append a new element 4 to the list (l is now modified!!!)nnnIn the code above we modified l by appending a new element to it. Throughout the program l points to the same object but it's the object pointed to by l that is changed in the process. n'",['python-3.x'],['python-3.x']
40061185,"""Easiest way to return sum of a matrix's neighbors in numpy"" ""I am trying to make a program that needs a matrix's neighbor(excluding itself) sum ex:nn matrix(0 0 0n        1 0 1n        0 1 0)  nnnwould return:nnmatrix(1 2 1n        1 3 1n        2 2 2)nnnI have a working code here but its big and messy and I'm new to numpy so I need some help cleaning it up and optimizing. (I feel like there has to be a better way)nnexample code:nnimport numpy as npnndef NiSum(m):n    new = n    for x in range(m.shape0-1):n        row = n        for y in range(m.shape1-1):n            Ni = 0n            for a in 11101-1010-1-11-10-1-1:n                Ni += mx+a0y+a1n            row.append(Ni)n        new.append(row)n    return np.matrix(new)nnnexample = np.matrix('0 0 0 0 0 0 0 0; '*3+'0 0 0 1 1 1 0 0; '*3+'0 0 0 0 0 0 0 0;0 0 0 0 0 0 0 0 ')nnNiSum(example)nnnThanks for any help !n"" 'You are summing all values in that 3x3 neighbourhood but excluding the element itself. So we can use Scipy's 2D convolution and subtract that input array/matrix from it for the desired output like so -nnfrom scipy.signal import convolve2dnnconvolve2d(anp.ones((33)dtype=int)'same') - annnSample run -nnIn 11: anOut11: nmatrix(0 0 0n        1 0 1n        0 1 0)nnIn 12: convolve2d(anp.ones((33)dtype=int)'same') - anOut12: nmatrix(1 2 1n        1 3 1n        2 2 2)nnnOr simply form a kernel with all ones but zero at the center and use the same 2D convolution -nnIn 31: kernel = np.array(111101111)nnIn 32: np.asmatrix(convolve2d(akernel'same'))nOut32: nmatrix(1 2 1n        1 3 1n        2 2 2)nn' 'Define a function which computes the sum of all neighbors for a matrix entry if they exist:nndef sumNeighbors(Mxy):n    l = n    for i in range(max(0x-1)x+2): # max(0x-1) such that no negative values in range() n        for j in range(max(0y-1)y+2):n            try:n                t = Mijn                l.append(t)n            except IndexError: # if entry doesn't existn                passn    return sum(l)-Mxy # exclude the entry itselfnnnThen you can iterate for every entry in your matrix and pass its result into a new matrix N:nnimport numpy as npnnM = 1 2 3n    4 5 6n    7 8 9 nnM = np.asarray(M)nN = np.zeros(M.shape)nnfor i in range(M.shape0):n    for j in range(M.shape1):n        Nij = sumNeighbors(M i j)nnprint ""Original matrix:n"" Mnprint ""Summed neighbors matrix:n"" NnnnOutput:nnOriginal matrix:n1 2 3n 4 5 6n 7 8 9nSummed neighbors matrix:n 11.  19.  13.n  23.  40.  27.n  17.  31.  19.nn'","['python-3.x', 'numpy']",['numpy']
40061280,"'Why can yield be indexed?' ""I thought I could make my python (2.7.10) code simpler by directly accessing the index of a value passed to a generator via send and was surprised the code ran. I then discovered an index applied to yield doesn't really do anything nor does it throw an exception:nndef gen1():n    t = yield0n    assert tn    yield Falsenng = gen1()nnext(g)ng.send('char_str')nnnHowever if I try to index yield thrice or more I get an exception:nndef gen1():n    t = yield000n    assert tn    yield Falsenng = gen1()nnext(g)ng.send('char_str')nnnwhich throwsnnTypeError: 'int' object has no attribute '__getitem__'nnnThis was unusually inconsistent behavior and I was wondering if there is an intuitive explanation for what indexing yield is actually doing?n"" 'You are not indexing. You are yielding a list; the expression yield0 is really just the same as the following (but without a variable):nnlst = 0nyield lstnnnIf you look at what next() returned you'd have gotten that list:nn>>> def gen1():n...   t = yield0n...   assert tn...   yield Falsen...n>>> g = gen1()n>>> next(g)n0nnnYou don't have to have a space between yield and the 0 that's all.nnThe exception is caused by you trying to apply the subscription to the contained 0 integer:nn>>> 0        # list with one element the int value 0n0n>>> 00     # indexing the first element so 0n0n>>> 000  # trying to index the 0nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>nTypeError: 'int' object is not subscriptablennnIf you want to index a value sent to the generator put parentheses around the yield expression:nnt = (yield)0nnnDemo:nn>>> def gen1():n...     t = (yield)0n...     print 'Received: {!r}'.format(t)n...     yield Falsen...n>>> g = gen1()n>>> next(g)n>>> g.send('foo')nReceived: 'f'nFalsenn'",['python-2.7'],"['python-2.7', 'list']"
40061307,"'Comparatively slow python numpy 3D Fourier Transformation' 'Dear StackOverflow community!nnFor my work I need to perform discrete fourier transformations (DFTs) on large images. In the current example I require a 3D FT for a 1921 x 512 x 512 image (along with 2D FFTs of 512 x 512 images). Right now I am using the numpy package and the associated function np.fft.fftn(). The code snippet below exemplarily shows 2D and 3D FFT times on an equal-sized/slightly smaller 2D/3D random-number-generated grid in the following way:nnimport sysnimport numpy as npnimport timenntas = time.time()na = np.random.rand(512 512)ntab = time.time()nb = np.random.rand(100 512 512)nntbfa = time.time()nnfa = np.fft.fft2(a)ntfafb = time.time()nfb = np.fft.fftn(b)ntfbe = time.time()nnprint ""initializing 512 x 512 grid:"" tab - tasnprint ""initializing 100 x 512 x 512 grid:"" tbfa - tabnprint ""2D FFT on 512 x 512 grid:"" tfafb - tbfanprint ""3D FFT on 100 x 512 x 512 grid:"" tfbe - tfafbnnnOutput:nninitializing 512 x 512 grid: 0.00305700302124ninitializing 100 x 512 x 512 grid: 0.301637887955n2D FFT on 512 x 512 grid: 0.0122730731964n3D FFT on 100 x 512 x 512 grid: 3.88418793678nnnThe problem that I have is that I will need this process quite often so the time spent per image should be short. When testing on my own computer (middle-segment laptop 2GB RAM allocated to virtual machine (--> therefore smaller test grid)) as you can see the 3D FFT takes ~ 5 s (order-of-magnitude). Now at work the machines are way better cluster/grid-architecture systems and FFTs are much faster. In both cases the 2D ones finish quasi instantaneously.nnHowever with 1921x512x512 np.fft.fftn() takes ~ 5 min. Since I guess scipy's implementation is not much faster and considering that on MATLAB FFTs of same-sized grids finish within ~ 5 s my question is whether there is a method to speed the process up to or almost to MATLAB times. My knowledge about FFTs is limited but apparently MATLAB uses the FFTW algorithm which python does not. Any reasonable chance that with some pyFFTW package I get similar times? Also 1921 seems an unlucky choice having only 2 prime factors (17 113) so I assume this also plays a role. On the other hand 512 is a well-suited power of two. Are MATLAB-like times achievable if possible also without padding up with zeros to 2048?nnI'm asking because I'll have to use FFTs a lot (to an amount where such differences will be of huge influence!) and in case there is no possibility to reduce computation times in python I'd have to switch to other faster implementations.nnAny advice is greatly appreciated!n' 'Yes there is a chance that using FFTW through the interface pyfftw will reduce your computation time compared to numpy.fft or scipy.fftpack. The performances of these implementations of DFT algorithms can be compared in benchmarks such as this one : some interesting results are reported in Improving FFT performance in PythonnnI suggest the following code for a test:nnimport pyfftwnimport numpynimport timenimport scipynnf = pyfftw.n_byte_align_empty((127512512)16 dtype='complex128')n#f = pyfftw.empty_aligned((33128128) dtype='complex128' n=16)nf: = numpy.random.randn(*f.shape)nn# first call requires more time for plan creationn# by default pyfftw use FFTW_MEASURE for the plan creation which means that many 3D dft are computed so as to choose the fastest algorithm.nfftf=pyfftw.interfaces.numpy_fft.fftn(f)nn#help(pyfftw.interfaces)ntas = time.time()nfftf=pyfftw.interfaces.numpy_fft.fftn(f) # here the plan is applied nothing else.ntas = time.time()-tasnprint ""3D FFT pyfftw:"" tasnnf = pyfftw.n_byte_align_empty((127512512)16 dtype='complex128')n#f = pyfftw.empty_aligned((33128128) dtype='complex128' n=16)nf: = numpy.random.randn(*f.shape)nnntas = time.time()nfftf=numpy.fft.fftn(f)ntas = time.time()-tasnprint ""3D FFT numpy:"" tasnntas = time.time()nfftf=scipy.fftpack.fftn(f)ntas = time.time()-tasnprint ""3D FFT scipy/fftpack:"" tasnn# first call requires more time for plan creationn# by default pyfftw use FFTW_MEASURE for the plan creation which means that many 3D dft are computed so as to choose the fastest algorithm.nf = pyfftw.n_byte_align_empty((128512512)16 dtype='complex128')nfftf=pyfftw.interfaces.numpy_fft.fftn(f)nntas = time.time()nfftf=pyfftw.interfaces.numpy_fft.fftn(f) # here the plan is applied nothing else.ntas = time.time()-tasnprint ""3D padded FFT pyfftw:"" tasnnnFor a size of 127*512*512 on my modest computer I got:nn3D FFT pyfftw: 3.94130897522n3D FFT numpy: 16.0487070084n3D FFT scipy/fftpack: 19.001199007n3D padded FFT pyfftw: 2.55221295357nnnSo pyfftw is significantly faster than numpy.fft and scipy.fftpack. Using padding is even faster but the thing that is computed is different.nnLastly pyfftw may seem slower at the first run due to the fact that it uses the flag FFTW_MEASURE according to the documentation. It's a good thing if and only if many DFTs of the same size are successively computed.n'",['numpy'],['numpy']
40061325,"'Creating a Django model that can have a many-to-many relationship with itself' ""I'm trying to write a Django model that can have a many-to-many relationship with itself.nnThis is my models.py:nnclass Apps(models.Model):n    name = models.CharField(n        verbose_name = 'App Name'n        max_length = 30n    )n    logo = models.ImageField(n        verbose_name = 'Logo'n        )n    description = models.TextField(n        verbose_name = 'Description'n    )n    google_url = models.URLField(n        verbose_name = 'Google Play Link'n        null = Truen    )n    apple_url = models.URLField(n        verbose_name = 'Apple AppStore Link'n        null = Truen    )n    youtube_url = models.URLField(n        verbose_name = 'Youtube Video Page'n        null = Truen    )n    similar_apps = models.ManyToManyField(n        'self'n        through         = 'SimilarApps'n        related_name    = 'similar_apps'n        verbose_name    = 'Similar Apps'n        help_text       = 'Similar Apps'n        symmetrical     = Falsen        )nn    def __unicode__(self):n        return u'%s' % (self.user.name)nnclass SimilarApps(models.Model):n    primary = models.ForeignKey(n        Appsn        verbose_name    = 'Primary App'n        related_name    = 'primary_app'n        help_text       = 'First of 2 similar Apps.'n    )n    secondary = models.ForeignKey(n        Appsn        verbose_name    = 'Matched App'n        related_name    = 'matched_app'n        help_text       = 'Second of 2 similar Apps.'n    ) nnnWhen I run manage.py makemigrations I get the following errornn<class 'appsrfun.admin.SimilarAppsInline'>: (admin.E202) 'appsrfun.SimilarApps' has more than one ForeignKey to 'appsrfun.Apps'.nappsrfun.Apps.similar_apps: (fields.E302) Reverse accessor for 'Apps.similar_apps' clashes with field name 'Apps.similar_apps'.n    HINT: Rename field 'Apps.similar_apps' or add/change a related_name argument to the definition for field 'Apps.similar_apps'.nappsrfun.Apps.similar_apps: (fields.E303) Reverse query name for 'Apps.similar_apps' clashes with field name 'Apps.similar_apps'.n    HINT: Rename field 'Apps.similar_apps' or add/change a related_name argument to the definition for field 'Apps.similar_apps'.nnnPlease tell me this is possible and explain how to do it.  Thanksn"" ""This has just got through makemigrations and I'm going to test it:nnclass App(models.Model):n    name = models.CharField(n        verbose_name    = 'App Name'n        max_length      = 30n    )n    logo = models.ImageField(n        verbose_name    = 'Logo'n        )n    description = models.TextField(n        verbose_name    = 'Description'n    )n    google_url = models.URLField(n        verbose_name    = 'Google Play Link'n        null            = Truen    )n    apple_url = models.URLField(n        verbose_name    = 'Apple AppStore Link'n        null            = Truen    )n    youtube_url = models.URLField(n        verbose_name    = 'Youtube Video Page'n        null            = Truen    )n    similar_app = models.ManyToManyField(n        'self'n        through         = 'MySimilarApp'n        verbose_name    = 'Similar App'n        help_text       = 'Similar App'n        symmetrical     = Falsen        through_fields  = ('primary''secondary')n        )nn    def __unicode__(self):n        return u'%s' % (self.user.name)nnclass MySimilarApp(models.Model):n    primary = models.ForeignKey(n        Appn        verbose_name    = 'Primary App'n        related_name    = 'primary_app'n        help_text       = 'First of 2 similar Apps.'n    )n    secondary = models.ForeignKey(n        Appn        verbose_name    = 'Matched App'n        related_name    = 'matched_app'n        help_text       = 'Second of 2 similar Apps.'n    )       nn""",['django'],['django']
40061330,'Django Official Tutorial Poll: How do you manage Choice in Admin Panel?' 'The official tutorial (Part 2) makes it easy to add and delete Questions in the admin panel by adding admin.site.register(Question) into admin.py.nnhttps://docs.djangoproject.com/en/1.10/intro/tutorial02/nnHowever I am curious how to manage the answers the Choice object too.nnaturally I import and add admin.site.register(Choice)  into admin.py.nnSo it works. But I have these concerns:nnA. Questions and Choice are managed separately.nnB. In the Choice index menu it doesnt show which Question (Key) a Choice is assigned to not unless you click into each of the records to show a drop down menu of Keys you can choose from.nnI would like to know how:nnA. to manage Question and Choice in a more hierarchal structure i.e. you click into a Question item and you can edit not only the Question itself but also the Choices it is affiliated with.nnB. In the Choice index table menu is it possible to list another column to show the Key object(Question) to the item?nnOr if there are any other more intuitive way to do admin management?nnThe official Django tutorial in my opinion isn't really well explained it took me quite sometime to google around to figure out what is really happening. It will be great too if someone here could offer a better up-to-dated tutorial for beginners like me to go and have a try.n' nan,['django'],['django']
40061493,"'Scatterplot of two Pandas Series coloured by date and with legend' 'I am studying financial time series in the format of pandas series. To compare two series I do a scatterplot and to visualise the time evolution in the scatterplot I can colour them. This is all fine.nnMy question relates to the legend showing the colours.nI would like the legend to show the date/year that the colour corresponds to rather than just an the index of the data entry as now. But I haven't been able to do this or to find a question like this on stackoverflow.nnI know the time series knows the dates and if you just plot a time series the x-axis will show the dates.nnMy code isnnfrom pandas_datareader import data as webnimport matplotlib.pyplot as pltnimport pandas as pdnn#Download datanstart = '2010-1-1'nend = '2016-10-1'nAAPL = web.DataReader('AAPL' 'yahoo' start=start end=end)'Adj Close'nTSLA = web.DataReader('GOOG' 'yahoo' start=start end=end)'Adj Close'nn#Scatterplotnplt.scatter(AAPL TSLA alpha=.4 c=range(len(AAPL)))nplt.colorbar()nplt.xlabel(""AAPL"")nplt.ylabel(""TSLA"")nplt.grid()nplt.show()nnnThis code produces this plot:nScatterplot with colours and legendnnThanksn' 'While there might be an easier answer out there (anyone?) to me the most straightforward way is to change the colorbar ticks manually. nnTry the following before you invoke plt.show():nnclb = plt.gci().colorbar # get the colorbar artistn# get the old tick labels (index numbers of the dataframes)nclb_ticks = int(t.get_text()) for t in clb.ax.yaxis.get_ticklabels()n# convert the old index ticks into year-month-day formatnnew_ticks = AAPL.indexclb_ticks.strftime(""%Y-%m-%d"")nclb.ax.yaxis.set_ticklabels(new_ticks)nnnNote that strftime does not appear to be implemented in pandas versions older than 0.18. In that case you'll have to replace .strftime(""%Y-%m-%d"") with .apply(lambda x: x.strftime('%Y-%m-%d')) as explained here.nnn'","['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40061555,"'Using other file names than models.py for Django models?' 'When creating a reusable app should I put all models I define into single file models.py or can I group the models into several files like topic1.py topic2.py?nnPlease describe all reasons pro and contra.n' ""The models submodule is special in that it is automatically imported at a specific time during the initialization process. All your models should be imported at this time as well. You can't import them earlier than that and importing them later may cause errors. nnYou can define your models in a different module but you should always import all your models into your models.py or models/__init__.py. E.g.:nn# models/topic1.pynnclass Topic1(models.Model):n    ...nn# models/__init__.pynnfrom .topic1 import Topic1nnnIf you import each model into models.py or models/__init__.py that also allows you to import all the models directly from that file. In the example that means that you can import Topic1 from myapp.models not just from myapp.models.topic1. This way you can keep your models organized across multiple files without having to remember each model's precise location whenever you need to import them. n"" 'it depend how much model you define if you have only 1 to 5 class model just put it into single file but if you have more than 5 class model i suggesting put it on several filesnnbut in my experience if the model put in a serveral files it become little cumbersome when it comes to importing stuffn'",['django'],['django']
40061869,"'Python requests add extra headers to HTTP GET' 'I am using python 2.7 requests module.nnI made this HTTP GET with the custom header below;nnheader ={n            ""projectName"": ""zhikovapp""n            ""Authorization"": ""Bearer HZCdsf=""n        }nresponse = requests.get(bl_url headers = header)nnnThe server returns a response that was not valid. On closer examination of the header that was sent I discovered python requests module added some extra headers.nn{n'Accept-Encoding': 'gzip deflate' n'projectName': 'zhikovapp'n'Accept': '*/*' n'User-Agent': 'python-requests/2.11.1' n'Connection': 'keep-alive' n'Authorization': 'Bearer HZCdsf='n}nnnThe extra headers are Accept-Encoding Accept Connection User-Agent. Is this a bug in python requests module? I am using requests ver 2.11.1nnHow can I remove these extra headers added by python requests module?n' 'you can do a prepared request.nnhttp://docs.python-requests.org/en/latest/user/advanced/#prepared-requestsnnthen you can delete the headers manuallynndel prepped.headers'Content-Type'nn'",['python-2.7'],['python-2.7']
40061884,"'Read the contents of each file into a separate list in Python' ""I would like to ready the contents of each file into a separate list in Python.  I am used to being able to do something similar with a bash for loop where I can say:nnfor i in file_path; do writing stuff; donennnWith glob I can load each of the files but I want to save the contents in a list for each file to use them for comparison purposes later without hardcoding the names and number of lists. This is how far I have gotten in python:nnimport sysnimport globnimport errnonnlist_$name ##<this is not pythonnnpath = './dir_name/*'   nfiles = glob.glob(path)   nfor name in files:n    try:n        with open(name) as f:n            lines = f.read().splitlines()nnn    except IOError as exc:n        if exc.errno != errno.EISDIR:n            raisennnIs what I want to do even possible or do I have to use a shell script to process each file as a loop?n"" ""import sysnimport globnimport errnonnlist_$name ##<this is not pythonnnpath = './dir_name/*'   nfiles = glob.glob(path)nncontents =    nfor name in files:n    try:n        with open(name) as f:n            lines = f.read().splitlines()n            contents.append (lines)nnn    except IOError as exc:n        if exc.errno != errno.EISDIR:n            raisenn    # Your contents list will now be a list of lists each list containing the contents of one file.nn""",['list'],"['list', 'python-2.7']"
40061889,"'Problems mapping a series to a min(list key=lambda x: abs(series)) function' ""I want to find a number in series and find which number it's closest to in 123. Then use the key to replace the series value with the appropriate letter.nnkey = {1: 'A' 2:'B' 3:'C')nseries = pd.Series(x*1.2 for x in range(10))nnnpd.DataFrame = keymin(123 key=lambda x: abs(x-series))nnnThe series is a column from the pd.DataFrame I've just tried to simplify it for here.n"" ""use the apply method and then map your Series such has:nnkey = {1: 'A' 2:'B' 3:'C'}nseries = pd.Series(x*1.2 for x in range(10))nndef find(myNumber):n    return min(123 key=lambda x:abs(x-myNumber))nnseries.apply(find).map(key)nOut50: n0    An1    An2    Bn3    Cn4    Cn5    Cn6    Cn7    Cn8    Cn9    Cndtype: objectnnnit also should work if you replace series by the entire dataframe such has:nndf.apply(find).map(key)nn""","['pandas', 'numpy']",['pandas']
40062073,"'Patch method only in one module' ""For example I have some module(foo.py) with next code:nnimport requestsnndef get_ip():n    return requests.get('http://jsonip.com/').contentnnnAnd module bar.py with similiar code:nnimport requestsnndef get_fb():n    return requests.get('https://fb.com/').contentnnnI just can't understand why next happens:nnfrom mock import patchnnfrom foo import get_ipnfrom bar import get_fbnnwith patch('foo.requests.get'):n    print(get_ip())n    print(get_fb())nnnThey are two mocked:nn<MagicMock name='get().content' id='4352254472'>n<MagicMock name='get().content' id='4352254472'>nnIt is seemed to patch only foo.get_ip method due to with patch('foo.requests.get') but it is not.nI know that I can just get bar.get_fb calling out of with scope but there are cases where I just run in context manager one method that calls many other and I want to patch requests only in one module.nIs there any way to solve this? Without changing imports in modulen"" 'The two locations foo.requests.get and bar.requests.get refer to the same object so mock it in one place and you mock it in the other.  nnImagine how you might implement patch.  You have to find where the symbol is located and replace the symbol with the mock object.  On exit from the with context you will need to restore the original value of the symbol.  Something like (untested):nnclass patch(object):n    def __init__(self symbol):n        # separate path to container from name being mockedn        parts = symbol.split('.')n        self.path = '.'.join(parts:-1n        self.name = parts-1n    def __enter__(self):n        self.container = ... lookup object referred to by self.path ...n        self.save = getattr(self.container name)n        setattr(self.container name MagicMock())n    def __exit__(self):n        setattr(self.container name self.save)nnnSo your problem is that the you are mocking the object in the request module which you then are referring to from both foo and bar.nnnnFollowing @elethan's suggestion you could mock the requests module in foo and even provide side effects on the get method:nnfrom unittest import mocknimport requestsnnfrom foo import get_ipnfrom bar import get_fbnndef fake_get(*args **kw):n    print(""calling get with"" args kw)n    return mock.DEFAULTnnreplacement = mock.MagicMock(requests)nreplacement.get = mock.Mock(requests.get side_effect=fake_get wraps=requests.get)nwith mock.patch('foo.requests' new=replacement):n    print(get_ip())n    print(get_fb())nnnnnA more direct solution is to vary your code so that foo and bar pull the reference to get directly into their name space.nnfoo.py:nnfrom requests import getnndef get_ip():n    return get('http://jsonip.com/').contentnnnbar.py:nnfrom requests import getnndef get_ip():n    return get('https://fb.com/').contentnnnmain.py:nnfrom mock import patchnnfrom foo import get_ipnfrom bar import get_fbnnwith patch('foo.get'):n    print(get_ip())n    print(get_fb())nnnproducing:nn<MagicMock name='get().content' id='4350500992'>nb'<!DOCTYPE html>n<html lang=""en"" id=""facebook"" ...nnnnnUpdated with a more complete explanation and with the better solution (2016-10-15)nnNote: added wraps=requests.get to call the underlying function after side effect. n' 'Not to steal @Neapolitan's thunder but another option would be to simply mock foo.requests instead of foo.requests.get:nnwith patch('foo.requests'):n    print(get_ip())n    print(get_fb())nnnI think the reason why both methods get mocked in your case is that since requests.get is not explicitly imported in foo.py mock will have to look up the method in the requests module and mock it there rather than mocking it in the requests object already imported into foo so that when bar later imports requests and accesses requests.get it is geting the mocked version. However if you patch foo.requests instead you are just patching the module object already imported into foo and the original requests module will not be affected.nnAlthough not particularly helpful for this particular problem this article is very useful for understanding the subtleties of patchn'",['python-3.x'],"['python-2.7', 'django']"
40062621,"'Drop duplicates for rows with interchangeable name values (Pandas Python)' ""I have a DataFrame of formnnperson1 person2 ... someMetricnJohn Steve ... 20nPeter Larry ... 12nSteve John ... 20nnnRows 0 and 2 are interchangeable duplicates so I'd want to drop the last row. I can't figure out how to do this in Pandas.nnThanks!n"" ""Here's a NumPy based solution  -nndf~(np.triu(df.person1.values:None == df.person2.values)).any(0)nnnSample run -nnIn 123: dfnOut123: n  person1 person2 someMetricn0    John   Steve         20n1   Peter   Larry         13n2   Steve    John         19n3   Peter  Parker          5n4   Larry   Peter          7nnIn 124: df~(np.triu(df.person1.values:None == df.person2.values)).any(0)nOut124: n  person1 person2 someMetricn0    John   Steve         20n1   Peter   Larry         13n3   Peter  Parker          5nn"" ""an approach in pandasnndf = pd.DataFrame(n{'person2':  {0: 'Steve' 1: 'Larry' 2: 'John' 3: 'Parker' 4: 'Peter'} n'person1': {0: 'John' 1: 'Peter' 2: 'Steve' 3: 'Peter' 4: 'Larry'} n'someMetric': {0: 20 1: 13 2: 19 3: 5 4: 7}})nnnprint(df)n  person1 person2 someMetricn0    John   Steve         20n1   Peter   Larry         13n2   Steve    John         19n3   Peter  Parker          5n4   Larry   Peter          7nnndf'ordered-name' = df.apply(lambda x: '-'.join(sorted(x'person1'x'person2'))axis=1)ndf = df.drop_duplicates('ordered-name')ndf.drop('ordered-name' axis=1 inplace=True)nprint dfnnnwhich gives:nn  person1 person2  someMetricn0    John   Steve          20n1   Peter   Larry          13n3   Peter  Parker           5nn""",['pandas'],['pandas']
40062728,"'cipher encoder in python using dictionaries' 'I'm trying to practice using dictionaries and functions on python. I am trying to write a program that encrypts a simple phrase or sentence with an encrypted alphabet: nnOriginal alphabet: ABCDEFGHIJKLMNOPQRSTUVWXYZnEncrypted alphabet: TDLOFAGJKRICVPWUXYBEZQSNMH. nnnThe user is to enter the phrase or sentence to be encrypted so it could contain upper or lowercase alphabet spaces commas and periods. The output though should only be uppercase letters with spaces and punctuation marks. nncipher ={""A"":""T""""a"":""T""""B"":""D""""b"":""D""""C"":""L""""c"":""L""""D"":""O""""d"":""O""""E"":""F""""e"":""F""""F"":""A""""f"":""A""""G"":""G""""g"":""G""""H"":""J""""h"":""J""""I"":""K""""i"":""K""""J"":""R""""j"":""R""""K"":""I""""k"":""I""""L"":""C""""l"":""C""""M"":""V""""m"":""V""""N"":""P""""n"":""P""""O"":""W""""o"":""W""""P"":""U""""p"":""U""""Q"":""X""""q"":""X""""R"":""Y""""r"":""Y""""S"":""B""""s"":""B""""T"":""E""""t"":""E""""U"":""Z""""u"":""Z""""V"":""Q""""v"":""Q""""W"":""S""""w"":""S""""X"":""N""""x"":""N""""Y"":""M""""y"":""M""""Z"":""H""""z"":""H""}nndef encode(strcipher):n    result=""""n    for c in str:n        result = result + ciphercn    return resultnn' 'You should exclude those cases with unknown symbols and that could be done by:nn    cipher ={""A"":""T""""a"":""T""""B"":""D""""b"":""D""""C"":""L""""c"":""L""""D"":""O""""d"":""O""""E"":""F""""e"":""F""""F"":""A""""f"":""A""""G"":""G""""g"":""G""""H"":""J""""h"":""J""""I"":""K""""i"":""K""""J"":""R""""j"":""R""""K"":""I""""k"":""I""""L"":""C""""l"":""C""""M"":""V""""m"":""V""""N"":""P""""n"":""P""""O"":""W""""o"":""W""""P"":""U""""p"":""U""""Q"":""X""""q"":""X""""R"":""Y""""r"":""Y""""S"":""B""""s"":""B""""T"":""E""""t"":""E""""U"":""Z""""u"":""Z""""V"":""Q""""v"":""Q""""W"":""S""""w"":""S""""X"":""N""""x"":""N""""Y"":""M""""y"":""M""""Z"":""H""""z"":""H""}n    def encode(words cipher):n        result = ''n        for letter in words:n            if letter in cipher:n                result = result + cipherlettern            else:n                result = result + lettern        return resultnphrase = raw_input('Please enter your phrase: ')nprint encode(phrase cipher)nn' 'Sometimes it's better to ask forgiveness then permission. You could remove half your key: values and replace them with str.upper() that way small letters become big letters. If you call dict().get(key) you get the value of the key or you get None. The or operator between the dict and character evaluates to the character if the cipher.get(character) returns None. nndef get_chiper(plaintext):n    cipher = {""A"": ""T"" ""B"": ""D"" ""C"": ""L"" ""D"": ""O"" ""E"": ""F""n              ""F"": ""A"" ""G"": ""G"" ""H"": ""J"" ""I"": ""K"" ""J"": ""R""n              ""K"": ""I"" ""L"": ""C"" ""M"": ""V"" ""N"": ""P"" ""O"": ""W""n              ""P"": ""U"" ""Q"": ""X"" ""R"": ""Y"" ""S"": ""B"" ""T"": ""E""n              ""U"": ""Z"" ""V"": ""Q"" ""W"": ""S"" ""X"": ""N"" ""Y"": ""M""n              ""Z"": ""H""}n    return """".join(cipher.get(character.upper()) or charactern               for character in plaintext)nnnnnAnd the full encoding and decoding could be done with the same function by reversing the dict. nndef encode(plaintext cipher):n    return """".join(cipher.get(character.upper()) or charactern                   for character in plaintext)nnndef decode(secret encoding_cipher):n    decode_cipher = {value: key for key value in encoding_cipher.items()}n    return encode(secret decode_cipher)nnndef main():n    cipher = {""A"": ""T"" ""B"": ""D"" ""C"": ""L"" ""D"": ""O"" ""E"": ""F""n              ""F"": ""A"" ""G"": ""G"" ""H"": ""J"" ""I"": ""K"" ""J"": ""R""n              ""K"": ""I"" ""L"": ""C"" ""M"": ""V"" ""N"": ""P"" ""O"": ""W""n              ""P"": ""U"" ""Q"": ""X"" ""R"": ""Y"" ""S"": ""B"" ""T"": ""E""n              ""U"": ""Z"" ""V"": ""Q"" ""W"": ""S"" ""X"": ""N"" ""Y"": ""M""n              ""Z"": ""H""}nn    plaintext = ""hello foo from bar""n    secret = encode(plaintext cipher)n    plaintext = decode(secret cipher)n    print(secret plaintext)nnnif __name__ == '__main__':n    main()nn'",['dictionary'],"['dictionary', 'python-2.7']"
40062783,"'print the first item in list of lists' ""I am trying to print the first item in a list of lists.  This is what I have:nnMy list is like this:nn'32 2 6 6' '31 31 31 6' '31 2 6 6'nnnMy code is:nnfrom operator import itemgetternncontents = nfirst_item = list(map(itemgetter(0) contents))nprint first_itemnnnbut itemgetter only returns:n'3' '3' '3' istead of '32' '31' '31'ncan I use a delimiter?n"" ""You are dealing with a list of strings so you are getting the first index of each string which is in fact 3 for all of them. What you should do is a comprehension where you split each string on space (which is the default of split) and get the first index:nnfirst_element = s.split(None 1)0 for s in contentsnnnInside the comprehension the result of each s.split(None 1) will actually be => nn'32' '2 6 6' '31' '31 31 6' '31' '2 6 6'nnand you get the first index of that. nnOutput:nn'32' '31' '31'nn"" "">>> items = '32 2 6 6' '31 31 31 6' '31 2 6 6'n>>> s.partition(' ')0 for s in itemsn'32' '31' '31'nn""",['list'],"['list', 'python-2.7']"
40062810,"'Django annotate in template' 'I am working on a small project in which occupations posted are to be ranked. Ranking is on the basis of the number of times an occupation is posted. I have managed to query the data and rank the occupation. However in the template when I try display the occupations and their percentages it's only their 'id' which  is displayed. I want the occupation's name to appear instead. Below are the flowsn #models.pynn    class OccupationGroup(models.Model):n        group=models.CharField(max_length=200)n        def __str__(self):n            return self.groupnn     class Occupation(models.Model):n        group=models.ForeignKey(OccupationGroup)n        occupation=models.CharField(max_length=200)n        def __str__(self):n            return self.occupationn    class OccupationData(models.Model):n        group=models.ForeignKey(OccupationGroup) #added for testingn        occupation=ChainedForeignKey(Occupationchained_field='group' chained_model_field='group')#added for testingnn        county=models.CharField(max_length=600)n        date_of_advertisement=models.DateField(verbose_name=""Date of Adveertisement"")n        #source=models.CharField(max_length=200null=True blank=True verbose_name=""Source"")n        positions=models.CharField(max_length=200 verbose_name=""Number of positions"")nn        def __str__(self):n             return self.occupationnnnviews.pynndef demand(request):n    context_dict={}n    total_items = OccupationData.objects.count()n    items = n            {'data': g'occupation' 'value': g'total' * 100 /       total_items} for g in datan            ncontext_dict={'data':items}nreturn render(request'labourdemand/demand.html'context_dict)nnndemand.htmlnn{% for data in data %}nn                {{data.data }}n               {{ data.value|floatformat:""2"" }}%<br>nn{% endfor %}nnnSample Outputnn1 23%n2 21.22%n3 11.12%nnnRequired OutputnnChemists 23%nLawyers 21.22%nMathematicians 11.12%nnnWhat am I not getting right to get this work??   n' nan",['django'],['django']
40062923,"'Efficient way to capture QtWebEngine frames for hand-off to ML engine on Windows' 'I am new to python/Qt development but I have a simple PyQt5 QtWebEngine browser up and running on Windows. My end goal is to visually ""teach"" an ML engine how to browse content and ""visually"" classify various parts of a page - text images video ads etc.nnIs there an efficient method to capture the QtWebEngine rendered frames to a framebuffer or to capture the existing window's framebuffer from within python to feed those images into my ML code? There seem to be several options for Linux/MacOS (xvfb) but I can't seem to find any examples for Windows and right now I don't have the option of switching platforms.n' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40062948,'How to make that multiply all numbers in list (Permutation) with smaller code?' 'My problem is:nn    perm_list = list(range(ab-1))n    if len(perm_list) == 1:n       print(perm_list0)n    elif len(perm_list) == 2:n       print(perm_list0* perm_list1)n    elif len(perm_list) == 3:nnnI cant find a way to make that smaller if i can do it would be awesome.nBecause i will do that to 15 If i write that 15 times it will be bigger and more hard to write for me.n  If there is a smaller was to make that can you guys please tell me?n' 'Just use the itertools librarynnfrom itertools import permutationsnlst = list(range(3))nresult = list(permutations(lst 2))nprint(result)n=> (0 1) (0 2) (1 0) (1 2) (2 0) (2 1)nprint(list(permutations(lst 3)))n=>  (0 1 2) (0 2 1) (1 0 2) (1 2 0) (2 0 1) (2 1 0)nn',['python-3.x'],"['list', 'python-2.7']"
40062965,"'Problems with querying multiindex table in HDF when using data_columns' ""I try to query a multi-index table in a pandas HDF store but it fails when using a query over the index and data_columns at the same time. This only occurs when data_columns=True. Any idea if this is expected or how to avoid if I don't want to explicitly specify the data_columns?nnSee the following example it seems it does not recognize the index as a valid reference: nnimport pandas as pdnimport numpy as npnnfile_path = 'D:test_store.h5'nnp.random.seed(1234)npd.set_option('display.max_rows'4)n# simulate some datanindex = pd.MultiIndex.from_product(np.arange(1000010200)n                                    pd.date_range('19800101'periods=500)n                                   names='id''date')ndf = pd.DataFrame(dict(id2=np.random.randint(0 1000 size=len(index))n                       w=np.random.randn(len(index)))n                  index=index).reset_index().set_index('id' 'date')nn# store the datanstore =  pd.HDFStore(file_pathmode='a'complib='blosc' complevel=9)nstore.append('df_dc_None' df data_columns=None)nstore.append('df_dc_explicit' df data_columns='id2' 'w')nstore.append('df_dc_True' df data_columns=True)nstore.close()nn# query the datanstart = '19810201'nprint(pd.read_hdf(file_path'df_dc_None' where='date>start & id=10000'))nprint(pd.read_hdf(file_path'df_dc_True' where='id2>500'))nprint(pd.read_hdf(file_path'df_dc_explicit' where='date>start & id2>500'))ntry:n    print(pd.read_hdf(file_path'df_dc_True' where='date>start & id2>500'))nexcept ValueError as err:n    print(err)nn"" 'It's an interesting question indeed!nnI can't explain the following difference (why do we have index columns indexed when using data_columns=None (default due to the docstring of the HDFStore.append method) and we don't have them indexed when using data_columns=True):nnIn 114: store.get_storer('df_dc_None').tablenOut114:n/df_dc_None/table (Table(100000) shuffle blosc(9)) ''n  description := {n  ""index"": Int64Col(shape=() dflt=0 pos=0)n  ""values_block_0"": Int32Col(shape=(1) dflt=0 pos=1)n  ""values_block_1"": Float64Col(shape=(1) dflt=0.0 pos=2)n  ""date"": Int64Col(shape=() dflt=0 pos=3)n  ""id"": Int64Col(shape=() dflt=0 pos=4)}n  byteorder := 'little'n  chunkshape := (1820)n  autoindex := Truen  colindexes := {n    ""date"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""id"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""index"": Index(6 medium shuffle zlib(1)).is_csi=False}nnIn 115: store.get_storer('df_dc_True').tablenOut115:n/df_dc_True/table (Table(100000) shuffle blosc(9)) ''n  description := {n  ""index"": Int64Col(shape=() dflt=0 pos=0)n  ""values_block_0"": Int64Col(shape=(1) dflt=0 pos=1)n  ""values_block_1"": Int64Col(shape=(1) dflt=0 pos=2)n  ""id2"": Int32Col(shape=() dflt=0 pos=3)n  ""w"": Float64Col(shape=() dflt=0.0 pos=4)}n  byteorder := 'little'n  chunkshape := (1820)n  autoindex := Truen  colindexes := {n    ""w"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""index"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""id2"": Index(6 medium shuffle zlib(1)).is_csi=False}nnnNOTE: pay attention at colindexes in the output above.nnBut using the following simple hack we can ""fix"" this:nnIn 116: store.append('df_dc_all' df data_columns=df.head(1).reset_index().columns)nnIn 118: store.get_storer('df_dc_all').tablenOut118:n/df_dc_all/table (Table(100000) shuffle blosc(9)) ''n  description := {n  ""index"": Int64Col(shape=() dflt=0 pos=0)n  ""id"": Int64Col(shape=() dflt=0 pos=1)n  ""date"": Int64Col(shape=() dflt=0 pos=2)n  ""id2"": Int32Col(shape=() dflt=0 pos=3)n  ""w"": Float64Col(shape=() dflt=0.0 pos=4)}n  byteorder := 'little'n  chunkshape := (1820)n  autoindex := Truen  colindexes := {n    ""w"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""date"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""id"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""index"": Index(6 medium shuffle zlib(1)).is_csi=Falsen    ""id2"": Index(6 medium shuffle zlib(1)).is_csi=False}nnncheck:nnIn 119: pd.read_hdf(file_path'df_dc_all' where='date>start & id2>500')nOut119:n                  id2         wnid    daten10000 1981-02-02  935  0.245637n      1981-02-04  994  0.291287n...               ...       ...n10199 1981-05-11  680 -0.370745n      1981-05-12  812 -0.880742nn10121 rows x 2 columnsnn'",['pandas'],"['pandas', 'numpy']"
40063034,"'Fill a multidimensional array efficiently that have many if else statements' ""I want to fill an 4dim numpy array in a specific and efficient way. Because I don't know better I startet to write the code with if else statements but that doesn't look nice is probably slow and I also can not be really sure if I thought about every combination. Here is the code which I stopped writing down:nnsercnew2 = numpy.zeros((gn gn gn gn))nfor x1 in range(gn):n    for x2 in range(gn):n        for x3 in range(gn):n            for x4 in range(gn):n                if x1 == x2 == x3 == x4: n                    sercnew2x1 x2 x3 x4 = ewpx1n                elif x1 == x2 == x3 != x4:n                    sercnew2x1 x2 x3 x4 = ewpx1 * ewpx4n                elif x1 == x2 == x4 != x3:n                    sercnew2x1 x2 x3 x4 = ewpx1 * ewpx3n                elif x1 == x3 == x4 != x2:n                    sercnew2x1 x2 x3 x4 = ewpx1 * ewpx2n                elif x2 == x3 == x4 != x1:n                    sercnew2x1 x2 x3 x4 = ewpx2 * ewpx1n                elif x1 == x2 != x3 == x4:n                    sercnew2x1 x2 x3 x4 = ewpx1 * ewpx3n                elif ... many more combinations which have to be considerednnnSo basically what should happen is that if all variables (x1 x2 x3 x4) are different from each other the entry would be: nnsercnew2x1 x2 x3 x4 = ewpx1* ewpx2 * ewpx3 * ewpx4nnnNow if lets say the variable x2 and x4 is the same then:nnsercnew2x1 x2 x3 x4 = ewpx1* ewpx2 * ewpx3nnnOthers examples can be seen in the code above. Basically if two or more variables are the same then I only consider on of them. I hope the pattern is clear. Otherwise please let me note and I will try to express my problem better. I am pretty sure that there is a much more intelligent way to do it. Hope you know better and thanks in advance :)   n"" ""I don't really know what you mean by saying that those variables are the same but if indeed they are than all you have to do is just use set().nnfrom functools import reducenfrom operator import mulnsercnew2 = numpy.zeros((gn gn gn gn))nfor x1 in range(gn):n    for x2 in range(x1 gn):n        for x3 in range(x2 gn):n            for x4 in range(x3 gn):n                set_ = ewpn for n in set(x1 x2 x3 x4)n                sercnew2x1 x2 x3 x4 = reduce(mul set_ 1)nnnThe way it works is that it creates a set() which delete duplicates and later with reduce function I pick first number from the set_ multiplies it with 1 (the initializer value) and the result of this is going to be passed to reduce as first argument and second will be the second item from set_. Sorry for my bad explanation.n"" 'You can do it in a single for loop too. Building on Divakar's Trick for a list of indexes the first thing we need to do is figure out how to extract only the unique indices of a given element in the 4d array sercnew2.nnOne of the fastest ways to do this (Refer: https://www.peterbe.com/plog/uniqifiers-benchmark) is using sets. Then we simply have to initialize sercnew2 as an array of ones rather than zeros.nnfrom itertools import productnimport numpy as npnnsercnew2 = np.ones((gn gn gn gn))nn_dims=4nidx = list(product(np.arange(gn) repeat=n_dims))nnfor ijkl in idx:n    unique_items = set((ijkl))n    for ele in unique_items:n        sercnew2ijkl *= ewpelennnEDIT: As @unutbu suggested we could also use the cartesian_product function from http://stackoverflow.com/a/11146645/5714445 to speed up the initialization of idxnnEdit2: In case you are having difficulty understanding what product from itertools does it provides all permutations. For instance suppose gn=2 with repeat dimension set to 4 you getnn0 0 0 0n0 0 0 1n0 0 1 0n0 0 1 1n0 1 0 0n0 1 0 1n0 1 1 0n0 1 1 1n1 0 0 0n1 0 0 1n1 0 1 0n1 0 1 1n1 1 0 0n1 1 0 1n1 1 1 0n1 1 1 1nn' ""Really hoping that I have got it! Here's a vectorized approach -nnfrom itertools import productnnn_dims = 4 # Number of dimsnn# Create 2D array of all possible combinations of X's as rowsnidx = np.sort(np.array(list(product(np.arange(gn) repeat=n_dims)))axis=1)nn# Get all X's indexed values from ewp arraynvals = ewpidxnn# Set the duplicates along each row as 1s. With the np.prod coming up nextn#these 1s would not affect the result which is the expected pattern here.nvals:1:idx:1: == idx::-1 = 1nn# Perform product along each row and reshape into multi-dim arraynout = vals.prod(1).reshape(gn*n_dims)nn""",['numpy'],['numpy']
40063080,"'Casting an array of C structs to a numpy array' 'A function I'm calling from a shared library returns a structure called info similar to this:nntypedef struct cmplx {n  double real;n  double imag;n} cmplx;nntypedef struct info{n  char *name;n  int arr_len;n  double *real_datan  cmplx *cmplx_data;n} info;nnnOne of the fields of the structure is an array of doubles while the other is an array of complex numbers. How do I convert the array of complex numbers to a numpy array? For doubles I have the following:nnfrom ctypes import *nimport numpy as npnnclass cmplx(Structure):n    _fields_ = (""real"" c_double)n                (""imag"" c_double)nnnclass info(Structure):n    _fields_ = (""name"" c_char_p)n                (""arr_len"" c_int)n                (""real_data"" POINTER(c_double))n                (""cmplx_data"" POINTER(cmplx))nnc_func.restype = infonret_val = c_func()ndata = np.ctypeslib.as_array(ret_val.contents.real_data shape=(info.contents.arr_len))nnnIs there a numpy one liner for complex numbers? I can do this using loops.n' 'Define your field as double and make a complex view with numpy:nnclass info(Structure):n    _fields_ = (""name"" c_char_p)n                (""arr_len"" c_int)n                (""real_data"" POINTER(c_double))n                (""cmplx_data"" POINTER(c_double))nnc_func.restype = infonret_val = c_func()ndata = np.ctypeslib.as_array(ret_val.contents.real_data shape=(info.contents.arr_len))ncomplex_data = np.ctypeslib.as_array(ret_val.contents.cmplx_data shape=(info.contents.arr_len2)).view('complex128')nn'","['python-3.x', 'numpy']",['numpy']
40063124,"'Python tkinter moving object in def that as been created in another def' ""I am creating flappy bird style game. And my problem is that i cant move tubes that has been created on another def.nMy code isnnfrom tkinter import *nfrom random import randintnwindow = Tk()nc = Canvas(window width=800 height=800 bg='steelblue')ntube11 = randint(600 650)ntube12 = randint(400 700)ndef createtubes():n    tube1 = c.create_rectangle(800 800 tube11 tube12 fill='green')n    tube2 = c.create_rectangle(800 0 tube11 200 fill='green')   ndef automovement():n    if True:n        c.move(tube1 -3.5 0)n        c.move(tube2 -3.5 0)n    window.update_idletasks()n    window.after(10 automovement)nwindow.after(60 createtubes)nwindow.after(10 automovement)nc.pack()nwindow.mainloop()nn"" ""Try creating a classnnfrom tkinter import *nfrom random import randintnwindow = Tk()nc = Canvas(window width=800 height=800 bg='steelblue')ntube11 = randint(600 650)ntube12 = randint(400 700)nclass Tubes:n    def __init__(self):n        self.createtubes()n    def createtubes(self):n        self.tube1 = c.create_rectangle(800 800 tube11 tube12 fill='green')n        self.tube2 = c.create_rectangle(800 0 tube11 200 fill='green')   n    def automovement(self):n        if True:n            c.move(self.tube1 -3.5 0)n            c.move(self.tube2 -3.5 0)n        window.update_idletasks()n        window.after(10 self.automovement)ntube = Tubes()nwindow.after(10 tube.automovement)nc.pack()nwindow.mainloop()nn"" ""You can also use tags option on your rectangles.nntube1 = c.create_rectangle(800 800 tube11 tube12 fill='green' tags='tube')ntube2 = c.create_rectangle(800 0 tube11 200 fill='green' tags='tube')nnnAnd in your function only one move :nnc.move('tube' -3.5 0)nn""","['python-3.x', 'tkinter']",['tkinter']
40063242,'Python dataframe sum rows' 'If I have a dataframe with n rows is there a way to set the ith row to be sum of rowi and rowi-1 and do this so that the assignment to earlier rows is reflected in the latter rows? I would really like to avoid loops if possible.nnExample DF:nn             SPY   AAPL   GOOGn2011-01-10  0.44  -0.81   1.80n2011-01-11  0.00   0.00   0.00n2011-01-12 -1.11  -2.77  -0.86n2011-01-13 -0.91  -4.02  -0.68nnnSample pseudo code of summing two rows:nnDF2011-01-11 = DF2011-01-10 + DF2011-01-11nDF2011-01-12 = DF2011-01-11 + DF2011-01-12nnnand so on.n' 'based on your question you are looking for a cumulative sum of each columns. you could use the cumsum() methodnnDF.cumsum()nn               SPY    AAPL   GOOGn2011-01-10  0.4400 -0.8100 1.8000n2011-01-11  0.4400 -0.8100 1.8000n2011-01-12 -0.6700 -3.5800 0.9400n2011-01-13 -1.5800 -7.6000 0.2600nn' 'Use DF.shift()nnDF + DF.shift()nn',['pandas'],['pandas']
40063316,"'Python - How can i print a certain dictionary field from many dictionaries within a list?' 'I am currently working on a Guess Who like game for school work and I cannot seem to get this to work. What I am trying to do is get the field ""Name"" printed from all the dictionaries below within a list.nn Greg = {""Name"":""Greg"" ""HairLength"":""Short"" ""HairColour"":""Brown"" ""FacialHair"":""Yes"" ""Jewellery"":""Yes"" ""Hat"":""No"" ""Lipstick"":""No"" ""Gender"":""Male""}nn Chris = {""Name"":""Chris"" ""HairLength"":""Long"" ""HairColour"":""Blonde"" ""FacialHair"":""No"" ""Jewellery"":""No""""Hat"":""Yes"" ""Lipstick"":""Yes"" ""Gender"":""Male""}nn Jason = {""Name"":""Jason"" ""HairLength"":""Short"" ""HairColour"":""Brown"" ""FacialHair"":""Yes"" ""Jewellery"":""No""""Hat"":""Yes"" ""Lipstick"":""No"" ""Gender"":""Male""}nn Clancy = {""Name"":""Clancy"" ""HairLength"":""Bald"" ""HairColour"":""Red"" ""FacialHair"":""Yes"" ""Jewellery"":""No"" ""Hat"":""No""""Lipstick"":""No"" ""Gender"":""Male""}nn Betty = {""Name"":""Betty"" ""HairLength"":""Short"" ""HairColour"":""Blonde"" ""FacialHair"":""No"" ""Jewellery"":""Yes""""Hat"":""Yes"" ""Lipstick"":""Yes"" ""Gender"":""Female""}nn Helen = {""Name"":""Helen"" ""HairLength"":""Short"" ""HairColour"":""Brown"" ""FacialHair"":""No"" ""Jewellery"":""No"" ""Hat"":""No""""Lipstick"":""Yes"" ""Gender"":""Female""}nn Selena = {""Name"":""Selena"" ""HairLength"":""Long"" ""HairColour"":""Brown"" ""FacialHair"":""No"" ""Jewellery"":""Yes""""Hat"":""No"" ""Lipstick"":""No"" ""Gender"":""Female""}nn Jacqueline = {""Name"":""Jacqueline"" ""HairLength"":""Long"" ""HairColour"":""Red"" ""FacialHair"":""Yes"" ""Jewellery"":""Yes"" ""Hat"":""No""""Lipstick"":""No"" ""Gender"":""Female""}nnnAISuspects = (Greg Chris Jason Clancy Betty Selena HelennJacqueline)nUserSuspects = (Greg Chris Jason Clancy Betty Selena Helen Jacqueline)nnprint(""AISuspects:"")n#Here i want it to print the field ""Name"" in every dictionary within the list AISuspects nnnprint(""UserSuspects:"")n#Here i want it to print the field ""Name"" in every dictionary within the list UserSuspectsnnnExpected output and current output after the solution:nnAI Suspects:n'Greg' 'Chris' 'Jason' 'Clancy' 'Betty' 'Selena' 'Helen' 'Jacqueline'nnUser Suspects:n'Greg' 'Chris' 'Jason' 'Clancy' 'Betty' 'Selena' 'Helen' 'Jacqueline'n' ""You can use a list comprehension to get a list of all the suspects' namesnnsuspects_names = suspect'Name' for suspect in AISuspectsnnnThen you can use print(' '.join(suspect_names))nnIf you don't mind printing each name in a new line just use a for loop:nnfor suspect in AISuspects:n    print(suspect'Name')nnnTake care of those parenthesis around the lists definitions you don't need them and they're usually used to define tuples so I'd get rid of themn"" ""UserSuspects = Greg'Name' Chris'Name'Jason'Name' Clancy'Name' Betty'Name' Selena'Name' Helen'Name' Jacqueline'Name'nnnprint UserSuspectsnn""","['list', 'dictionary']","['dictionary', 'list']"
40063317,'Running uwsgi socket only works when I set chmod-socket=666' 'Is there any way I can get this socket running in 664?nnuwsgi --socket /etc/nginx/sites-available/TestServer.sock --wsgi-file TestServer/wsgi.py --chmod-socket=666nnn666 Django runs fine but 664 and I get a 502 Bad Gateway. Thanks for any help you can provide!n' nan,['django'],['django']
40063339,"'Python Plotting Data Using the Row referring to rows to columns from CSV file' 'Below is the data from CSV file : Each Value Separated by ""COMMA""nnSNameSub1Sub2Sub3 ... Sub10  n0 A405033 ... 78  n1 B555533 ... 66  n2 C9910034 ... 44nnnI want to Plot only the Row 0 - that is Student Name: A's subject marks from Sub1 till Sub 10 . The Graph should consist of ""BAR""  Bar with different Colours !! depending upon the marks the colours should vary for the Student.nnIf the a subject has got minimum colour then it show in RED... If a subject has highest marks it should show in another colour. Average marks for other subjects in different colours ? nnWhat should I do?n' 'Possibly the easiest way of many plots is to begin with one of the samples available at the matplotlib gallery. In this case I reminded myself about details using two of the samples since I don't use matplotlib often. This code represents part of a solution inasmuch as it does not read values from the csv.nnimport matplotlib.pyplot as pltnplt.rcdefaults()nimport numpy as npnimport matplotlib.pyplot as pltnnn# Example datansubjects = 'Sub%s'%_ for _ in range(111)nmarks = 51435560654378678844nminMark=min(marks)nmaxMark=max(marks)ncolors='green'*len(marks)nfor _ in range(len(colors)):n    if marks_==minMark:n        colors_='red'n    if marks_==maxMark:n        colors_='yellow'ny_pos = np.arange(len(subjects))nnplt.barh(y_pos marks align='center'color=colors)nplt.yticks(y_pos subjects)nplt.xlabel('marks')nplt.title('Subject Marks for Student A')nnplt.show()nnnWith csv filecontents like this:nnSNameSub1Sub2Sub3Sub10  n0A40503378  n1B55553366  n2C991003444nnnyou can recover the first line of marks using code like this:nnimport csvnnfirst = Truenwith open('temp2.csv') as csvfile:n    reader = csv.reader(csvfile)n    for line in reader:n        if first:n            first=Falsen            continuen        marks=linen        breaknnprint (marks)nn'","['python-2.7', 'pandas', 'numpy', 'matplotlib']",['matplotlib']
40063378,"'Python - converting to list' 'import requestsnfrom bs4 import BeautifulSoup nnwebpage = requests.get(""http://www.nytimes.com/"")nsoup = BeautifulSoup(requests.get(""http://www.nytimes.com/"").text ""html.parser"")nfor story_heading in soup.find_all(class_=""story-heading""): narticles = story_heading.text.replace('n' '').replace('  ' '')nprint (articles)nnnThere is my code it prints out a list of all the article titles on the website. I get strings: nnn  Looking Back: 1980 | Funny but Not Fit to Printn  n  Brooklyn Studio With Room for Family and a Dogn  n  Search for Homes for Sale or Rentn  n  Sell Your HomennnSo I want to convert this to a list = 'Search for Homes for Sale or Rent' 'Sell Your Home' ... witch will allow me to make some other manipulations like random.choice etc.nI tried:nnalist = articles.split(""n"")nprint (alist)nnnn  'Looking Back: 1980 | Funny but Not Fit to Print' n  n  'Brooklyn Studio With Room for Family and a Dog'n  n  'Search for Homes for Sale or Rent'n  n  'Sell Your Home'nnnIt is not a list that I need. I'm stuck. Can you please help me with this part of code. n' 'You are constantly overwriting articles with the next value in your list. What you want to do instead is make articles a list and just append in each iteration: nnimport requestsnfrom bs4 import BeautifulSoup nnwebpage = requests.get(""http://www.nytimes.com/"")nsoup = BeautifulSoup(requests.get(""http://www.nytimes.com/"").text ""html.parser"")narticles = nfor story_heading in soup.find_all(class_=""story-heading""): n    articles.append(story_heading.text.replace('n' '').replace('  ' ''))nprint (articles)nnnThe output is huge so this is a small sample of what it looks like:nn'Global Deal Reached to Curb Chemical That Warms Planet' 'Accord Could Push A/C Out of Sweltering Indiaâx80x99s Reach '.... nnnFurthermore you only need to strip spaces in each iteration. You don't need to do those replacements. So you can do this with your story_heading.text instead:nnarticles.append(story_heading.text.strip())nnnWhich can now give you a final solution looking like this: nnimport requestsnfrom bs4 import BeautifulSoup nnwebpage = requests.get(""http://www.nytimes.com/"")nsoup = BeautifulSoup(requests.get(""http://www.nytimes.com/"").text ""html.parser"")narticles = story_heading.text.strip() for story_heading in soup.find_all(class_=""story-heading"")nprint (articles)nn'",['list'],['python-2.7']
40063401,"'Python - Reversing data generated with particular loop order' ""Question: How could I peform the following task more efficiently?nnMy problem is as follows. I have a (large) 3D data set of points in real physical space (xyz). It has been generated by a nested for loop that looks like this:nn# Generate given dat with its orderingnx_samples = 2ny_samples = 3nz_samples = 4ngiven_dat = np.zeros(((x_samples*y_samples*z_samples)3))nrow_ind = 0nfor z in range(z_samples):n    for y in range(y_samples):n        for x in range(x_samples):n            row = x+.1y+.2z+.3n            given_datrow_ind: = rown            row_ind += 1nfor row in given_dat:n    print(row)`nnnFor the sake of comparing it to another set of data I want to reorder the   given data into my desired order as follows (unorthodox I know):nn# Generate data with desired orderingnx_samples = 2ny_samples = 3nz_samples = 4ndesired_dat = np.zeros(((x_samples*y_samples*z_samples)3))nrow_ind = 0nfor z in range(z_samples):n    for x in range(x_samples):n        for y in range(y_samples):n            row = x+.1y+.2z+.3n            desired_datrow_ind: = rown            row_ind += 1nfor row in desired_dat:n    print(row)nnnI have written a function that does what I want but it is horribly slow and inefficient: nndef bad_method(x_sampy_sampz_sampdata):n    zs = np.unique(data:2)n    xs = np.unique(data:0)n    rowlist = n    for z in zs:n        for x in xs:n            for row in data:n                if row0 == x and row2 == z:n                rowlist.append(row)n    new_data = np.vstack(rowlist)n    return new_datan# Shows that my function does with I wantnfix = bad_method(x_samplesy_samplesz_samplesgiven_dat)    nprint('Unreversed data')nprint(given_dat)nprint('Reversed Data')nprint(fix)n# If it didn't work this will throw an exceptionnassert(np.array_equal(desired_datfix))nnnHow could I improve my function so it is faster? My data sets usually have roughly 2 million rows. It must be possible to do this with some clever slicing/indexing which I'm sure will be faster but I'm having a hard time figuring out how. Thanks for any help!n"" 'You could reshape your array swap the axes as necessary and reshape back again:nn# (No need to copy if you don't want to keep the given_dat ordering)ndata = np.copy(given_dat).reshape(( z_samples y_samples x_samples 3))n# swap the ""y"" and ""x"" axesndata = np.swapaxes(data 12)n# back to 2-D arrayndata = data.reshape((x_samples*y_samples*z_samples3))nnassert(np.array_equal(desired_datdata))nn'",['numpy'],['numpy']
40063580,"'Pandas flatten hierarchical index on non overlapping columns' 'I have a dataframe and I set the index to a column of the dataframe. This creates a hierarchical column index. I want to flatten the columns to a single level. Similar to this question - Python Pandas - How to flatten a hierarchical index in columns however the columns do not overlap (i.e. 'id' is not at level 0 of the hierarchical index and other columns are at level 1 of the index).nndf = pd.DataFrame((1013'x') (1025'y') columns='id' 'A' 'B')ndf.set_index('id' inplace=True)nn      A    Bnidn101   3    xn102   5    ynnnDesired output is flattened columns like this:nnid    A    Bn101   3    xn102   5    ynn' ""there will always be an index in your dataframes. if you don't set 'id' as index it will be at the same level as other columns and pandas will populate an increasing integer for your index starting from 0.nndf = pd.DataFrame((1013'x') (1025'y') columns='id' 'A' 'B')nnIn52: dfnOut52: n    id  A  Bn0  101  3  xn1  102  5  ynnnthe index is there so you can slice the original dataframe. such hasnndf.iloc0nOut53: nid    101nA       3nB       xnName: 0 dtype: objectnnnso let says you want ID as index and ID as a column which is very redundant you could do:nndf = pd.DataFrame((1013'x') (1025'y') columns='id' 'A' 'B')ndf.set_index('id' inplace=True)ndf'id' = df.indexndfnOut55: n     A  B   idnid            n101  3  x  101n102  5  y  102nnnwith this you can slice by 'id' such has:nndf.loc101nOut57: nA       3nB       xnid    101nName: 101 dtype: objectnnnbut it would the same info has :nndf = pd.DataFrame((1013'x') (1025'y') columns='id' 'A' 'B')ndf.set_index('id' inplace=True)ndf.loc101nnOut58: nA    3nB    xnName: 101 dtype: objectnn"" 'Given:nn>>> df2=pd.DataFrame((1013'x') (1025'y') columns='id' 'A' 'B')n>>> df2.set_index('id' inplace=True)n>>> df2n     A  Bnid       n101  3  xn102  5  ynnnFor printing purdy you can produce a copy of the DataFrame with a reset the index and use .to_string:nn>>> print df2.reset_index().to_string(index=False)nid  A  Bn101  3  xn102  5  ynnnThen play around with the formatting options so that the output suites your needs:nn>>> fmts=lambda s: u""{:^5}"".format(str(s).strip())*3n>>> print df2.reset_index().to_string(index=False formatters=fmts)nid     A      Bn101    3      x  n102    5      ynn' ""You are misinterpreting what you are seeing.nn     A  Bnid       n101  3  xn102  5  ynnnIs not showing you a hierarchical column index.  id is the name of the row index.  In order to show you the name of the index pandas is putting that space there for you.nnThe answer to your question depends on what you really want or need.nnAs the df is you can dump it to a csv just the way you want:nnprint(df.to_csv(sep='t'))nnid  A   Bn101 3   xn102 5   ynnnnnprint(df.to_csv())nnidABn1013xn1025ynnnnnOr you can alter the df so that it displays the way you'd likennprint(df.rename_axis(None)) nn     A  Bn101  3  xn102  5  ynnnnnplease do not do this!!!!nI'm putting it to demonstrate how to manipulatennI could also keep the index as it is but manipulate both column and row index names to print how you would like.nnprint(df.rename_axis(None).rename_axis('id' 1))nnid   A  Bn101  3  xn102  5  ynnnBut this has named the columns' index id which makes no sense.n""",['pandas'],['pandas']
40063782,"'Can someone help me make the transition to a new window using Tkinter in Python?' 'Im very new and am interested in working with windows and Tkinter. please be gentle.nnhere is my code that is supposed to go to a new window then open an image in that new window. However instead of putting the image in the new window it puts it in the first window.nnI think this has something to do with toplevel but i cant seem to make that work right.    nnimport osnfrom PIL import Imagenfrom PIL import ImageTknfrom Tkinter import Tknimport osnnclass Application(Frame):n    """""" A GUI application with three buttons. """"""nn    def __init__(self master):n        """""" Initialize the frame""""""n        Frame.__init__(selfmaster)n        self.grid()n        self.create_widgets()nnnn    def create_widgets(self):n        """""" Create button text and entry widgets""""""n        self.instruction = Label(self text = ""First off what is your name?"")n        self.instruction.grid(row=0 column =0 columnspan=2 sticky=W)nn        #self.first = firstnn        self.name = Entry(self)n        self.name.grid(row=1 column =1 sticky=W)nn        self.submit_button = Button(self text =""Submitsss"" command = self.reveal)n        self.submit_button.grid(row = 2 column = 0 sticky =W)nn        self.text = Text(self width =35 height = 5 wrap = WORD)n        self.text.grid(row=3 column = 0 columnspan =2 sticky = W)nn        self.ok_button = Button(self text = ""Next"" command = self.go_to_2)n        self.ok_button.grid(row = 2 column = 0 sticky = E)nn    def reveal(self):n        """"""Display message based on the name typed in""""""n        content = self.name.get()nn        message = ""Hello %s"" %(content)nn        self.text.insert(0.0 message)nn    def go_to_2(self):n        self.destroy()n        #root = Tk()n        #self.newApplication = tk.Toplevel(self.master)n        #self.app3 = Application2(self.newApplication)n        root.title(""game"")n        root.geometry(""600x480"")nn        #root = Tk()n        #app2=Application2(root)nn        self.newWindow = Tk.Toplevel()n        self.app = Application2(self.newWindow)nnnclass Application2(Frame):n    """""" A GUI application with three buttons. """"""nn    def __init__(self master):n        """""" Initialize the frame""""""n        Frame.__init__(selfmaster)n        self.grid()n        self.create_widgets()n        #master.panel()n        master.title(""a"")n        #self.root.mainloop()n        master.img = ImageTk.PhotoImage(Image.open(""C:UsersdavidPicturessdf.jpg""))n        master.panel = Label(root image = master.img)n        master.panel.pack()n    def create_widgets(self):nnn        self.submit_button = Button(self text =""Submit"")n        self.submit_button.grid(row = 2 column = 0 sticky =W)n        self.name = Entry(self)n        self.name.grid(row=1 column =1 sticky=W)n        self.ok_button = Button(self text = ""Next"" command = self.go_to_3)n        self.ok_button.grid(row = 2 column = 0 sticky = E)n    def go_to_3(self):n        root = Tk()nn        app2=Application3(root)n    #def create_picture(self):nnnnnclass Application3(Frame):n    """""" A GUI application with three buttons. """"""nn    def __init__(self master):n        """""" Initialize the frame""""""n        Frame.__init__(selfmaster)n        self.grid()n        self.create_widgets()n    def create_widgets(self):n        self.button = Button(self text = ""ass"")n        root.mainloop()nnroot = Tk()nroot.title(""game"")nroot.geometry(""600x480"")nnnnnapp = Application(root)nroot.mainloop() nn#app2= Application2(root)nn#if __name__ == '__main__':n       # main()nn' 'Try this code:nnimport tkinter as tknnclass MainWindow(tk.Frame):n    counter = 0n    def __init__(self *args **kwargs):n        tk.Frame.__init__(self *args **kwargs)n        self.button = tk.Button(self text=""Create new window"" n                                command=self.create_window)n        self.button.pack(side=""top"")nn    def create_window(self):n        self.counter += 1n        t = tk.Toplevel(self)n        t.wm_title(""Window #%s"" % self.counter)n        l = tk.Label(t text=""This is window #%s"" % self.counter)n        l.pack(side=""top"" fill=""both"" expand=True padx=100 pady=100)nnif __name__ == ""__main__"":n    root = tk.Tk()n    main = MainWindow(root)n    main.pack(side=""top"" fill=""both"" expand=True)n    root.mainloop()nnnThis will make a window and you can push a button to pop up a new window. There is already a label on that window as an example.n' ""To create another toplevel widget use the Toplevel command. Don't try calling Tk() again.nnFor instance the following produces two toplevel Tk windows on screen:nnimport tkinter as tknroot = tk.Tk()ndlg = tk.Toplevel(root)nnnOne significant difference between the top toplevels is if you destroy root then you unload Tk and destroy all Tk windows. However a Toplevel widget can be destroyed without affecting the rest of the application so is suitable for use as a dialog or other separate window.n""",['tkinter'],['tkinter']
40064010,"'Convert QueryDict into list of arguments' 'I'm receiving via POST request the next payload through the view below:nnclass CustomView(APIView):nn""""""nPOST datan""""""ndef post(self request):                n    extr= externalAPI()n    return Response(extr.addData(request.data))nnnAnd in the externalAPI class I have the addData() function where I want to convert QueryDict to a simple list of arguments:nndef addData(self params):        n    return self.addToOtherPlace(**params)   nnnIn other words what I get in params is somethin like:nn<QueryDict: {u'data': u'{""object"":""a""""reg"":""1""}' u'record': u'DAFASDH'}>nnnAnd I need to pass it to the addToOtherPlace() function like:nnaddToOtherPlace(data={'object':'a' 'reg': 1} record='DAFASDH')nnnI have tried with different approaches but I have to say I'm not very familiar with dictionaries in python.nnAny help would be really appreciated.nnThanks!n' 'You can write a helper function that walks through the QueryDict object and converts valid JSON objects to Python objects string objects that are digits to integers and returns the first item of lists from lists:nnimport jsonnndef restruct(d):n    for k in d:n        # convert value if it's valid jsonn        if isinstance(dk list):n            v = dkn            try:n                dk = json.loads(v0)n            except ValueError:n                dk = v0nn        # step into dictionary objects to convert string digits to integern        if isinstance(dk dict):n            restruct(dk)n        elif dk.isdigit():n            dk = int(dk)nnnparams = {u'data': u'{""object"":""a""""reg"":""1""}' u'record': u'DAFASDH'}nrestruct(params)nprint(params)n# {'record': 'DAFASDH' 'data': {'object': 'a' 'reg': 1}}nnnNote that this approach modifies the initial object in-place. You can make a deepcopy and modify the copy instead if you're going to keep the original object intact:nnimport copynndef addData(self params):n    params_copy =  copy.deepcopy(params)  n    restruct(params_copy)   n    return self.addToOtherPlace(**params_copy) nn'","['django', 'dictionary']","['python-2.7', 'django']"
40064012,"'Why is Python 3.5 crashing on a MySQL connection with correct credentials?' 'I'm using Python 3.5.1 mysqlclient 1.3.9 (fork of MySQLdb that supports Python 3) and MariaDB 10.1 on Windows 10 (64-bit).nnWhen I runnnimport MySQLdbncon = MySQLdb.connect(user=my_user passwd=my_pass db=my_db)nnnPython crashes.nnIn pycharm I am also presented with the messagennProcess finished with exit code -1073741819 (0xC0000005)nnnI don't get any other errors. This is different to what happens when I run the same statements with incorrect credentials:nnTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""C:Program FilesPython35libsite-packagesMySQLdb__init__.py"" line 81 in Connectn    return Connection(*args **kwargs)n  File ""C:Program FilesPython35libsite-packagesMySQLdbconnections.py"" line 191 in __init__n    super(Connection self).__init__(*args **kwargs2)n_mysql_exceptions.OperationalError: (1045 ""Access denied for user 'root'@'localhost' (using password: YES)"")nnnThis error does not occur on my CentOS server which runs Python 3.4 mysqlclient 1.3.9 and MariaDB 10.1.nnI've tried using older versions of MariaDB as suggested by this question to no avail.nnWhat could be causing this crash and the mysterious lack of error reporting and how can I fix it?nnEdit: In my system logs I found this entry:nnGeneral:nnFaulting application name: python.exe version: 3.5.1150.1013 time stamp: 0x56639598nFaulting module name: python35.dll version: 3.5.1150.1013 time stamp: 0x56639583nException code: 0xc0000005nFault offset: 0x00000000000e571cnFaulting process id: 0x4a4nFaulting application start time: 0x01d2272a22ae1a1anFaulting application path: C:Program FilesPython35python.exenFaulting module path: C:Program FilesPython35python35.dllnReport Id: 6dd874e6-5ea5-4919-af8b-4880a2c7ac5enFaulting package full name: nFaulting package-relative application ID: nnnDetails: nn- System n  - Provider n    Name  Application Error n  - EventID 1000 n    Qualifiers  0 n   Level 2 n   Task 100 n   Keywords 0x80000000000000 n  - TimeCreated n    SystemTime  2016-10-15T21:21:48.041795500Z n   EventRecordID 7615 n   Channel Application n   Computer PETER-LENOVO n   Security nn- EventData n   python.exe n   3.5.1150.1013 n   56639598 n   python35.dll n   3.5.1150.1013 n   56639583 n   c0000005 n   00000000000e571c n   4a4 n   01d2272a22ae1a1a n   C:Program FilesPython35python.exe n   C:Program FilesPython35python35.dll n   6dd874e6-5ea5-4919-af8b-4880a2c7ac5enn' 'I'm not familiar with pycharm but I think your problem is as @nemanjap suggests with your MySQLdb installation. I just went through a similar nightmare (with Python 3.5) so I hope I can help. Here are my suggestions:nnnIf you haven't already install pipnInstall Visual Studio Community 2015 from https://www.visualstudio.com/downloads (you only need the Python compilation tools)nInstall wheel: pip install wheelnDownload the MySQLdb windows binary from http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python specifically mysqlclient-1.3.8-cp35-cp35m-win32.whl (I'm 64-bit too but I was being cautious)nDelete the MySQLdb folder from site-packages if it exists just in case.nAssuming you're in the same folder as the binary download run pip install mysqlclient-1.3.8-cp35-cp35m-win32.whlnnnWith a bit of luck you should be able to connect.nnnnNotesnnOn my machine I was getting instantly aborted connections (Got an error reading communication packets in my error.log) even though my credentials were 100% correct. On the windows side similar to OP Python just ""crashed"" meaning I got a shell restart and never reaching past the MySQLdb.connect line. Even a try block didn't allow further execution (so actually a crash as opposed to an exception or error). Thinking a compatibility issue (UNIX working totally fine) I tried to debug the MySQLdb in Windows all the way to import _mysql which is when I realized it was a C (compilation) issue.nnHaving thought all was installed well when I executed pip install MySQLdb-python I got the following:nnerror: Unable to find vcvarsall.batnnnWhich meant I needed to install the compilation tools for my version of Python (3.5) which is included in the VSC2015 installation. I re-ran and then got the following:nnCannot open include file: 'config-win.h'nnnWhich meant I needed some required headers from here: http://dev.mysql.com/downloads/connector/c/6.0.html#downloads (again 32-bit just to play it safe for now). Then I got a bunch of unresolved external symbol errors and realized how much I hate Windows and installed the pre-compiled version instead. Worked wonders.nnOh and before someone suggests a different module or method to connect like mysql-connector apart from not solving the problem there is usually the constraint that the same code (thus the same imported modules) should work on both Windows and UNIX machines. Plus this: http://charlesnagy.info/it/python/python-mysqldb-vs-mysql-connector-query-performancennSorry for the long post. I needed to vent! Good luck!n'",['python-3.x'],['python-3.x']
40064192,"'Swtiching X with Y on a chart made with openpyxl' 'Did anyone succeded in inverting X with Y (transpose) on a linear chart created with openpyxl ?nA workaround can be to switch x with y before represent it but im curios if openpyxl chart have this option to change x with y when represent the datannThis is my code to represent the chart:nnfrom openpyxl import Workbooknfrom openpyxl import load_workbooknfrom openpyxl.chart import LineChartnfrom openpyxl.chart import Referencenfrom openpyxl.chart.axis import DateAxisnnwb = Workbook()nwb = load_workbook(filename = 'location of file')nws = wb.activennnnc1 = LineChart()nc1.title = ""aaa""nc1.style = 2nc1.y_axis.title = 'bbb'nc1.x_axis.title = 'Time'nc1.width = 40nc1.height = 20nnnnnndata = Reference(ws min_row=2 min_col=1 max_col=ws.max_column max_row=ws.max_row)nc1.add_data(data titles_from_data=True)nnws.add_chart(c1 ""C28"")nwb.save('location of file')nnnIf this is my table:nn      C1     C2     C3    C4          nR1            1      2     3nR2    App1   3484   323   323nR3    App2   3399   3456  323nR4    App2   323    323  3456nnnWhen i represent it using openpyxl chart i want to have this:nenter image description herenbut instead i got this:nenter image description herennMy question is... can i easy invert them in representation without having to modify the table ?n' nan","['python-2.7', 'python-3.x']",[]
40064377,'Most Pythonic way to find/check items in a list with O(1) complexity?' 'The problem I'm facing is finding/checking items in a list with O(1) complexity. The following has a complexity of O(n):nn'foo' in list_barnnnThis has a complexity of O(n) because you are using the in keyword on a list. (Refer to Python Time Complexity)nnHowever if you use the in keyword on a set it has a complexity of O(1).nnThe reason why I need to figure out O(1) complexity for a list and not a set is largely due to the need to account for duplicate items within the list.  Sets do not allow for duplicates.  A decent example would be :nnchars_available = 'h' 'e' 'l' 'o' 'o' 'z'nchars_needed = 'h' 'e' 'l' 'l' 'o'nndef foo(chars_available chars_needed):n    cpy_needed = list(chars_needed)n    for char in cpy_needed:n        if char in chars_available:n            chars_available.remove(char)n            chars_needed.remove(char)n        if not chars_needed: return True  # if chars_needed == n    return Falsennfoo(chars_available chars_needed)nnnThe example is not the focus here so please try not to get sidetracked by it.  The focus is still trying to get O(1) complexity for finding items in a list.  How would I accomplish that pythonically?nn(As extra credit if you did want to show a better way of performing that operation in Python pseudocode or another language I'd be happy to read it).nnThank you!nnEdit:nnIn response to Ami Tavory's answer I learned you can't make lists faster than O(n) but the suggestion for collections.Counter() helped solve the application I was working on. I'm uploading my faster solution for Stack Overflow the performance was phenomenal! If I'm not mistaken (correct me if I'm wrong) it should be O(1) since it involves only hashable values and no loop iteration.nnfrom collections import Counternchars_available = 'h' 'e' 'l' 'o' 'o' 'z'nchars_needed = 'h' 'e' 'l' 'l' 'o'nndef foo(chars_available chars_needed):n    counter_available = Counter(chars_available)n    counter_needed = Counter(chars_needed)n    out = counter_needed - counter_availablen    if not list(out.elements()): return Truen    else: return Falsennfoo(chars_available chars_needed)nnnVery fast very pythonic! Thanks!n' 'In general it's impossible to find elements in a list in constant time. You could hypothetically maintain both a list and a set but updating operations will take linear time.nnYou mention that your motivation isnnn  a list and not a set is largely due to the need to account for duplicate items within the list. Sets do not allow for duplicates.nnnand ask not to focus on the example. If this is your motivation you might want to use instead of a set a dict mapping each element to the number of its occurrences. nnYou might find collections.Counter useful in particular:nnIn 1: from collections import CounternnIn 2: Counter('h' 'e' 'l' 'o' 'o' 'z')nOut2: Counter({'e': 1 'h': 1 'l': 1 'o': 2 'z': 1})nn',['python-3.x'],"['list', 'python-2.7']"
40064411,"'urls.py entry for django v1.10 mysite.com:8000/index.html' 'I'm having trouble getting the url entry in my app's urls.py file how I want it.nWhen a person enters mysite.com:8000/ I want it to use the same view as mysite.com:8000/index.html  I can use url(r'^index.html$' views.index name='index') and the view is properly displayed when I type mysite.com:8000/index.html into the chrome address bar or I can trim the .htmloff both the urls.py entry and the address bar and it's ok but I figured with regex I could get this to display for / or for index*nnlots of googling hasn't let me to an answer yet...nnEDIT:nupdate based on @moses:nnfrom django.conf import settingsnfrom django.conf.urls import urlnfrom django.conf.urls.static import staticnfrom . import viewsnnurlpatterns = n        url(r'^(index.?html{4})?$' views.index name='index')n#       url(r'^index$' views.index name='index')n + static(settings.STATIC_URL document_root=settings.STATIC_ROOT)nnnnow I get: ""Exception Value:index() takes exactly 1 argument (2 given)""n' 'You can use the following regex pattern that matches 0 or 1 repetitions of 'index.html' in the url i.e. either ^$ or r'^index.html$':nn>>> re.match(r'^(?:index.html)?$' 'index.html')n<_sre.SRE_Match object; span=(0 10) match='index.html'>n>>> re.match(r'^(?:index.html)?$' '')n<_sre.SRE_Match object; span=(0 0) match=''>n>>> re.match(r'^(?:index.html)?$' 'login')n>>>nnnAnd your Django url pattern becomes:nnurl(r'^(?:index.html)?$' views.index name='index')nnnSee demo: https://regex101.com/r/MVCPDN/2n'",['django'],"['django', 'regex']"
40064532,'Attempting to Create Vector Field Plot of Dipole using Matplotlib' 'I have been a long-time Mathematica user and I've been in the process of converting various notebooks into python (version 3). For plotting I've been using matplotlib. I've ran into a snag and I am not sure what's going wrong.nnI'm trying to convert the following Mathematica code:nn(* simple electric dipole *)nExx_ y_ := (x + 1)/((x + 1)^2 + y^2) - (x - 1)/((x - 1)^2 + y^2)nEyx_ y_ := y/((x + 1)^2 + y^2) - y/((x - 1)^2 + y^2)nStreamPlot{Exx y Eyx y} {x -3.5 3.5} {y -3.5 3.5}nnnThis produces the following figure:nnnnI want to reproduce this using Python code.nnfrom pylab import *nXY = meshgrid( arange(-44.2)arange(-44.2) )nEx = (X + 1)/((X+1)**2 + Y**2) - (X - 1)/((X-1)**2 + Y**2)nEy = Y/((X+1)**2 + Y**2) - Y/((X-1)**2 + Y**2)nfigure()nQ = quiver( Ex Ey)nlrbt = axis()ndx dy = r-l t-b naxis(l-0.05*dx r+0.05*dx b-0.05*dy t+0.05*dy)nshow()nnnProduces the following figure:nnnnI'm still learning how to do plotting in python and I'm a little unsure of how to create a vector field plot. Any insight would be appreciated.n' nan,"['python-3.x', 'matplotlib']",['matplotlib']
40064559,"'Python: Unable to remove spaces from list' ""I am trying to remove white spaces from a list of strings in Python.nI have tried almost every other method but still I am not able to remove the spaces.nHere is the list:nnnames=': A slundn' ': N Brenner and B Jessop and M Jones and G Macleodn' ': C Boonen' ': PB Evansn' ': F Neil utitle: uThe architecture of markets}n' ': PA Hall and D Soskicen' '' '' '' '' '' '' '' ': EBYP HIGONNET and DS LANDES and H ROSOVSKYn' '' '' '' '' '' '' ': DS Landesn' '' '' '' '' '' '' '' ': DC Northn' '' '' '' '' '' '' '' ': K Polyanin' '' '' '' '' '' ''nnnHere is my code:nnfor i in names:n    if len(i)== 0:   // i==''  // len(i)<=1n    names.remove(i)nprint namesnn"" ""With list comprehension.nnnames_without_space = name.replace(' ' '') for name in namesnprint(names_without_space:3)n# ':Aslundn' ':NBrennerandBJessopandMJonesandGMacleodn' ':CBoonen'nn""",['list'],"['list', 'python-2.7']"
40064565,"'Python search text file and count occurrences of a specified string' 'I am attempting to use python to search a text file and count the number of times a user defined word appears. But when I run my code below instead of getting a sum of the number of times that unique word appears in the file I am getting a count for the number lines within that file contain that word. nnExample: the word 'bob' exists 56 times in the text file appearing in 19 of the total 63 lines of text.  When I run my code the console prints '19'.nnI am guessing I need to do something different with my split method?  I am running Python 2.7.10.nnuser_search_value = raw_input(""Enter the value or string to search for: "")nncount = 0    nnwith open(file.txt 'r') as f:n    for word in f.readlines():n        words = word.lower().split()n        if user_search_value in words:n            count += 1n    print countnn' 'One way to do this would be to loop over the words after you split the line and increment count for each matching word:nnuser_search_value = raw_input(""Enter the value or string to search for: "")nncount = 0    nnwith open(file.txt 'r') as f:n    for line in f.readlines():n        words = line.lower().split()n        for word in words:n            if word == user_search_value:n                count += 1nprint countnn' 'As I mentioned in the comment above after playing with this for a (long) while I figured it out.  My code is below.nn#read filenf = open(filename ""r"")nlines = f.readlines()nf.close()n#looking for patternsnfor line in lines:n    line = line.strip().lower().split()n    for words in line:n        if words.find(user_search_value.lower()) != -1:n            count += 1nprint(""nYour search value of '%s' appears %s times in this file"" % (user_search_value count))nn'",['python-2.7'],['python-2.7']
40064587,"'Image display error after changing dtype of image matrix' 'I'm using opencv + python to process fundus(retinal images). There is a problem that im facing while converting a float64 image to uint8 image.nnFollowing is the python code:nnimport cv2nimport matplotlib.pyplot as pltnimport numpy as npnfrom tkFileDialog import askopenfilenamennfilename = askopenfilename()na = cv2.imread(filename)nheight width channel = a.shapenb Ago Aro = cv2.split(a)nmr = np.average(Aro)nsr = np.std(Aro)nnAr = Aro - np.mean(Aro)nAr = Ar - mr - srnnAg = Ago - np.mean(Ago)nAg = Ag - mr - srnn#Values of elements in Arn#    Ar = -179.17305527 -169.17305527 -176.17305527 ... -177.17305527 -177.17305527 -177.17305527n#           -178.17305527 -169.17305527 -172.17305527 ... -177.17305527 -177.17305527 -177.17305527n#           -179.17305527 -178.17305527 -179.17305527 ... -177.17305527 -177.17305527 -177.17305527n#           ...n#           -177.17305527 -177.17305527 -177.17305527 ... -177.17305527 -177.17305527 -177.17305527n#           -177.17305527 -177.17305527 -177.17305527 ... -177.17305527 -177.17305527 -177.17305527n#           -177.17305527 -177.17305527 -177.17305527 ... -177.17305527 -177.17305527 -177.17305527nnMr = np.mean(Ar)nSDr = np.std(Ar)nnprint ""MR = "" Mr ""SDr = "" SDrnnMg = np.mean(Ag)nSDg = np.std(Ag)nThg = np.mean(Ag) + 2 * np.std(Ag) + 50 + 12nnThr = 50 - 12 - np.std(Ar)nprint ""Thr = "" ThrnDd = np.zeros((height width))nDc = Ddnfor i in range(height):n    for j in range(width):nn        if Arij > Thr:n            Ddij = 255n        else:n            Ddij = 0nnTDd = np.uint8(Dd)nTDd2 = Ddnnfor i in range(height):n    for j in range(width):n        if Agij > Thg:n            Dcij = 1n        else:n            Dcij = 0nn#CALCULATING RATIOnratio = 500.0 / Dd.shape1ndim = (500 int(Dd.shape0 * ratio))n#n# #RESIZING TO-BE-DISPLAYED IMAGESnresized_TDd = cv2.resize(TDd dim interpolation=cv2.INTER_AREA)nresized_TDd2 = cv2.resize(TDd2 dim interpolation=cv2.INTER_AREA)nresized_original = cv2.resize(Aro dim interpolation=cv2.INTER_AREA)nncv2.imshow('TDd' resized_TDd)ncv2.imshow('TDd2' resized_TDd2)ncv2.imshow('Aro' resized_original)ncv2.waitKey(0)nnnAr has -ve as well as +ve values and Thr has a -ve value. Dd is the image which i want to display. The problem is that TDd displays a bizarre image (255s and 0s are being assigned to appropriate pixels i checked but the image being displayed is weird and not similar to TDdnnOriginal imagennnnRed channel image:nnnnTDd (uint8 of Dd):nnnnTDd2 (same as Dd)nnnnDd2 (declared uint8 dtype while initializing)nnnnWhy are the TDd and TDd2 images different? nSince the difference between the gray values of the pixels (as far as i understand and know) in these 2 images is only 255 0 (in TDd) and 255.0 0.0 (in TDd2).nnIt would be a great great help if someone could tell me.n' 'Usually when Images are represented with np float64 arrays RGB values are in range 0 to 1. So when converting to uint8 there is a possible precision loss when converting from float64 to uint8.nnI would directly create Dd as a:nnDd = np.zeros((height width) dtype=np.uint8)nnnThen it should work.n' 'Look I executed your code and there are the resultsnnThey seem pretty normal to me... this is the exact code I usednnAr is different from the others because when you imShow() it it puts white where values are > 0 black otherwise. The other matrices after tour code get white where > Thr which is less than 0 so more pixel get white obviously.nnupdatennYou assigned Dd to Dc when you should've done Dc = np.zeros((height width)).n'",['numpy'],['numpy']
40064589,"'Counting sub-element in string?' 'Say I have a string = ""Nobody will give me pancakes anymore""nnI want to count each word in the string. So I do string.split() to get a list in order to get 'Nobody' 'will' 'give' 'me' 'pancakes' 'anymore'.nnBut when I want to know the length of 'Nobody' by inputing len(string0) it only gives me 1 because it thinks that the 0th element is just 'N' and not 'Nobody'. nnWhat do I have to do to ensure I can find the length of the whole word rather than that single element?n' 'You took the first letter of string0 ignoring the result of the string.split() call.nnStore the split result; that's a list with individual words:nnwords = string.split()nfirst_worth_length = len(words0)nnnDemo:nn>>> string = ""Nobody will give me pancakes anymore""n>>> words = string.split()n>>> words0n'Nobody'n>>> len(words0)n6nn' 'Yup string0 is just 'N'nnRegarding your statement...nnn  I want to count each word in the stringnnn>>> s = ""Nobody will give me pancakes anymore""n>>> lens = map(lambda x: len(x) s.split())n>>> print lensn6 4 4 2 8 7nnnSo then you can do lens0n' ""words = s.split()   nd = {word : len(word) for word in words}nnornnwords = s.split()nd = {}nnfor word in words:n    if word not in d:n        dword=0n    dword+=len(word)nnIn 15: d  nOut15: {'me': 2 'anymore': 7 'give': 4 'pancakes': 8 'Nobody': 6   'will': 4}nIn 16: d'Nobody'nOut16: 6nn""",['list'],"['list', 'python-2.7']"
40064622,"'why is feedparser returning fewer results than there actually are?' 'I am using feed parser along with beautifulsoup. There is no key explicitly for the youtube embed code. Instead it is inside of the html via the 'content' key like thisnn'content': {'value': '<h4><strong>Video:</strong> cangel Ft De La  âx80x93 ose (Official Video)<span id=""more-125869""></span></h4>n<p>&nbsp;</p>n<div class=""lyte-wrapper""></div>n<p><span id=""more-2331""></span><iframe src=""https://www.youtube.com/embed/HFiDh_TcvNE"" width=""560"" height=""315"" frameborder=""0"" allowfullscreen=""allowfullscreen""></iframe></p>'}nnnso I created a function to get the src code and image code like thisnndef pan_task():n    url = 'http://example.net/feed/'n    name = 'elrealsonidodelakalle'n    live_leaks = i for i in feedparser.parse(url).entries:3n    the_count = len(live_leaks)n    ky = feedparser.parse(url).keys()n    oky = i.keys() for i in feedparser.parse(url).entries1 # shows what I can pullnn    def embed_image(html_doc):n        soup = BeautifulSoup(html_doc ""html5lib"")n        embed = soup.iframe.get('src')n        remove = 'https://www.youtube.com/embed/'n        remaining_pic_code = embed.replace(remove '')n        the_img = 'http://i1.ytimg.com/vi/' + remaining_pic_code + '/hqdefault.jpg'n        results = {'src': the_img 'embed': embed}n        return resultsnn    results = {n                'name': namen                'text': i.titlen                'url': i.idn                'comments': i.titlen                'src': embed_image(i.content0'value')'src'n                'embed': embed_image(i.content0'value')'embed'n                'author': Nonen                'video': Truen                'status': 'published'n               } for i in live_leaksnn    for entry in results:n        post = Post()  #n        post.title = entry'text' #n        title = post.title  #n        if not Post.objects.filter(title=title):n            post.title = entry'text'n            post.name = entry'name'n            post.url = entry'url'n            post.body = entry'comments'n            post.image_url = entry'src'n            post.video_path = entry'embed'n            post.author = entry'author'n            post.video = entry'video'n            post.status = entry'status'n            post.save()n            post.tags.add(""video"")nn    return print(results)nnnbut it only works when I do thisnnlive_leaks = i for i in feedparser.parse(url).entries:3nnnif i remove the three "":3"" I get this errornnTask blog.tasks.pan_task79707dd3-70ae-40e9-a97a-e5c36dee4004 raised unexpected: AttributeError(""'NoneType' object has no attribute 'get'"")nTraceback (most recent call last):n  File ""/Users/ray/Desktop/myheroku/practice/lib/python3.5/site-packages/celery/app/trace.py"" line 240 in trace_taskn    R = retval = fun(*args **kwargs)n  File ""/Users/ray/Desktop/myheroku/practice/lib/python3.5/site-packages/celery/app/trace.py"" line 438 in __protected_call__n    return self.run(*args **kwargs)n  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 126 in pan_taskn    } for i in live_leaksn  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 126 in <listcomp>n    } for i in live_leaksn  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 109 in embed_imagen    embed = soup.iframe.get('src')nAttributeError: 'NoneType' object has no attribute 'get'n2016-10-15 17:24:43560: ERROR/MainProcess Task blog.tasks.pan_task339ccc72-c87a-4323-948b-4db7afb4f619 raised unexpected: AttributeError(""'NoneType' object has no attribute 'get'"")nTraceback (most recent call last):n  File ""/Users/ray/Desktop/myheroku/practice/lib/python3.5/site-packages/celery/app/trace.py"" line 240 in trace_taskn    R = retval = fun(*args **kwargs)n  File ""/Users/ray/Desktop/myheroku/practice/lib/python3.5/site-packages/celery/app/trace.py"" line 438 in __protected_call__n    return self.run(*args **kwargs)n  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 126 in pan_taskn    } for i in live_leaksn  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 126 in <listcomp>n    } for i in live_leaksn  File ""/Users/ray/Desktop/myheroku/practice/src/blog/tasks.py"" line 109 in embed_imagen    embed = soup.iframe.get('src')nAttributeError: 'NoneType' object has no attribute 'get'. If I go to the feed page I can count eight items. any help with this would be great. I am new to programming all code is my own so if it seems sloppy or unprofessional that's whynn' nan",['django'],['python-3.x']
40064660,"'IndexError: list index of range. Python 3' ""I was just trying to create a Matrix filled with zeros like the function of numpy.nnBut it continues to give me that error. Here's the code:nndef zeros(ab):nn     for i in range(a):n        for j in range(b):  n            Rij=0n      return RnnnI tried with a=3 and b=2 so it would give me a 3x2 matrix filled with zeros. It is a part of the program to multiply matrixnnI'm new in this whole programming world thanks for the help.n"" 'You could do that:nn>>> def zeros(ab):n...     return 0 for _ in range(a) for _ in range(b)n...n>>> zeros(32)n0 0 0 0 0 0nnnOr something more close to your code:nndef zeros(ab):n    R = n    l = 0*an    for _ in range(b):n        R.append(l)n    return Rnn'",['python-3.x'],"['list', 'python-2.7']"
40064853,"""Testing C++ Math functions with Python's C Extension - Precision issues"" 'I wrote a C++ wrapper class to some functions in LAPACK. In order to test the class I use the Python C Extension where I call numpy and do the same operations and compare the results by taking the differencennFor example for the inverse of a matrix I generate a random matrix in C++ then pass it as a string (with many many digits like 30 digits) to Python's terminal using PyRun_SimpleString and assign the matrix as numpy.matrix(...dtype=numpy.double) (or numpy.complex128). Then I use numpy.linalg.inv() to calculate the inverse of the same matrix. Finally I take the difference between numpy's result and my result and use numpy.isclose with a specific relative tolerance to see whether the results are close enough.nnThe problem: The problem is that when I use C++ floats the relative precision I need to be able to compare is about 1e-2!!! And yet with this relative precision I get some statistical failures (with low probability).nnDoubles are fine... I can do 1e-10 and it's statistically safe.nnWhile I know that floats have intrinsic bit precision of about 1e-6 I'm wondering why I have to go so low to 1e-2 to be able to compare the results and it still fails some times!nnSo going so low down to 1e-2 got me wondering whether I'm thinking about this whole thing the wrong way. Is there something wrong with my approach?nnPlease ask for more details if you need it.nnnnUpdate 1: Eric requested example of Python calls. Here is an example:nn//create my matricesnMatrix<T> mat_d = RandomMatrix<T>(...);nauto mat_d_i = mat_d.getInverse();nn//I store everything in the dict 'data'nPyRun_SimpleString(std::string(""data={}"").c_str());nn//original matrixn//mat_d.asString(...) will return in the format 1234 where 32 is 32 digits per numbernPyRun_SimpleString(std::string(""data'a'=np.matrix("" + mat_d.asString(32'''''') + ""dtype=np.complex128)"").c_str());n//pass the inverted matrix to PythonnPyRun_SimpleString(std::string(""data'b_c'=np.matrix("" + mat_d_i.asString(32'''''') + ""dtype=np.complex128)"").c_str());n//inverse in numpynPyRun_SimpleString(std::string(""data'b_p'=np.linalg.inv(data'a')"").c_str());n//flatten the matrices to make comparing them easier (make them 1-dimensional)nPyRun_SimpleString(""data'fb_p'=((data'b_p').flatten().tolist())0"");nPyRun_SimpleString(""data'fb_c'=((data'b_c').flatten().tolist())0"");nn//make the comparison. The function compare_floats(f1f2t) calls numpy.isclose(f1f2rtol=t)n//prec is an integer that takes its value from a template function where I choose the precision I want based on typenPyRun_SimpleString(std::string(""res=list(set(compare_floats(data'fb_p'idata'fb_c'i1e-""+ std::to_string(prec) +"") for i in range(len(data'fb_p'))))0"").c_str());n//the set above eliminates repeated True and False. If all results are True we expect that res=True otherwise the test failed somewherenPyRun_SimpleString(std::string(""res = ((len(res) == 1) and res0)"").c_str());n//Now if res is True then successnnnComments in the code describe the procedure step-by-step. n' nan",['numpy'],['numpy']
40064867,"'Get list of variables from Jinja2 template (parent and child)' ""I'm trying to get a list of variables from a Jinja2 template.nntest1.j2:nnsome-non-relevant-contentn{{var1}}n{% include 'test2.j2' %}nnntest2.j2:nnanother-textn{{var2}}nnnI can get variables from test1 easily:nnenv = Environment(loader=FileSystemLoader(searchpath='./Templates'))nsrc_t = env.loader.get_source(env 'test1.j2')0nparsed_t = env.parse(source=src_t)nt_vars = meta.find_undeclared_variables(ast=parsed_t)nnnProblem is I can only get variables from the parent template with get_source.nObviously I can not feed class template object to parse method as well.nnIs there any way to build the full list? {'var1' 'var2'} in my case.nIdeally by using Jinja2 API. Minimum custom code.n"" ""Found a way to code that without a big pain.nmeta.find_referenced_templates helps to load all child templates when applied recursively. When done it's trivial to get variables from all templates in a single list.n""",['python-3.x'],['python-2.7']
40064875,"""While using Django : Command ''wkhtmltopdf' '--encoding' u'utf8' returned non-zero exit status 1"" ""In Django I get this error code while using wkhtmltopdf. It uses the default path(which has been set under windows) for the command.nThis is my url:nnurl(r'^marche/$' PDFTemplateView.as_view(template_name='hello.html'n                                        filename='my_pdf.pdf') name='pdf')nnnAny ideas? Thanksn"" nan",['django'],['django']
40064881,"'Splitting strings unhashable type' 'I have never split strings in Python before so I am not too sure what is going wrong here. nnimport pyowmnnowm = pyowm.OWM('####################')nnlocation = owm.weather_at_place('Leicester uk')nweather = location.get_weather()nweather.get_temperature('celsius')ntemperature = weather.get_temperature('celsius')nnprint(temperature5:10)nnnError received nnsudo python weather.pynTraceback (most recent call last):nFile ""weather.py"" line 10 in <module>nprint(temperature5:10)nTypeError: unhashable typenn' 'get_temperature returns a dictionary which you're then trying to index with a slice object which is not hashable. e.g.nn>>> hash(slice(5 10))                                                                         nTraceback (most recent call last):                                                             n  File ""<stdin>"" line 1 in <module>                                                          nTypeError: unhashable typennnTo get the temperature you need to get it from the dictionary like this:nntemperature'temp'nn'",['python-3.x'],"['python-3.x', 'dictionary', 'list']"
40064997,"'Working with strings in Python: Formatting the information in a very specific way' 'OBS: I am working on Python 3.5.2 and I use the standard Shell and IDLEnnHi everyone I think one of the most difficult tasks I have when programming with python is dealing with strings. Is there someone who can help?nnOne of the problems I face frequently is transforming the string so I can use it properly. For instance:nn#consider I have the following string I want to work with:nnnmy_input = 'insert 3 ""psyduck"" 30!!!insert 10 ""a nice day at the beach"" 100!!!find 3!!!find 10'nnHow can I transform this string in a  way that with the results I would be able to do the following:nn1 - Separate the following substrings into variables like this:nncommand = 'insert'nnnode = '3' #or the int 3nnlist = '""psyduck"" 30'nnn2 - Or any other solution that will somehow enable me to do this in the end:nnlistOfCommands = 'insert' '3' '""psyduck"" 30' 'insert' '10' '""a nice day at the beach"" 100' 'find' '3' 'find' '10'nnnI need this list in order to do the following:nnfor entry in listOfCommands:n    if entry0 == 'insert':n    #I will execute a part of the program    nn    elif entry0 == 'update':n    #execute something elsenn    elif entry0 == 'find':n    #execute something elsennnThe problem is that I do not know exaclty what is going to appear (the number of commands or the size of the information I will have to add) in the input. I just know that it will always obey these exact formats: nA command a 'node' where I have to store the information or update it the information I have to store or update or A command a 'node' I have to find or delete and the blocks will be separated by '!!!'nnI can work my way around the main program but in order to be able to make it run properly I need to have this input formatted in this really specific way.n' ""Maybe something like this will work:nncommands = my_input.split('!!!')nmy_commands = c.split(' ' 2) for c in commandsnnnThe second argument of the split methods tells it how many times you want it to split the string.n""",['python-3.x'],"['python-3.x', 'python-2.7']"
40065101,"'Sending Xbox One Controller Inputs to a Xbox One with Python' 'Is there any way to send Xbox one controller inputs e.x. ""d-pad up"" ""a button"" in python 2 or 3?nnI want to know so that i can do things like automate sending invites in games by having a loop that presses d-pad down and A over and over again.nnIf anyone needs more info please just ask in the comments.n' nan","['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40065108,"'Regex taking too long in python' 'I have used regex101 to test my regex and it works fine.What i am trying to is to detect these patternsnnnsection 1.2 random 2n1.2 random 2n1.2. random 2nrandom 2nrandom 2.nnnBut its just random it shouldn't match if the string is like thatnnnrandomnnnMy regex is this.nn  m = re.match(r""^(((section)s*|(d+.)|d+|(d+.d+)|a-zA-zs|a-zA-z.s)+((d+.$)|d+$|(d+.d+$)))""""random random random random random""flags = re.I)nnnIf i give in a long string it gets stuck.Any ideas?n' 'After some simplification this regular expression meets the requirements stated above and reproduced in the test cases below.nnimport rennregex = r'(?:section)*s*(?:0-9.)*s*randoms+(?!random)(?:0-9.)*'nnstrings = n   ""random random random random random""n   ""section 1.2 random 2""n   ""1.2 random 2""n   ""1.2. random 2""n   ""random 2""n   ""random 2.""n   ""random""nnnfor string in strings:n    m = re.match(regex string flags = re.I)n    if m:n        print ""match on"" stringn    else:n        print ""non match on"" stringnnnwhich gives an output of:nnnon match on random random random random randomnmatch on section 1.2 random 2nmatch on 1.2 random 2nmatch on 1.2. random 2nmatch on random 2nmatch on random 2.nnon match on randomnnnSee it in action at: https://eval.in/661183n'",['regex'],['regex']
40065313,'Creating an array of tensors in tensorflow?' 'Suppose I have two tensor variables each of size 2x4:nnv1 = tf.logical_and(a1 b1)nv2 = tf.logical_and(a2 b2)nnnInstead I want to store these in an array called v which is of size 2x2x4. How do I do this in Tensorflow? The idea would be something like this:nnfor i in range(2):n  vi = tf.logical_and(aibi)nnnHow do I initialize v? I tried initializing v as a numpy array which did not work. I also tried initializing it as a tensorflow variable ie. tf.Variable(tf.zeros(2)) but that does not work either.nnNote a and b are dynamic inputs ie. they are tf.placeholder variables.n' 'tf.pack() is probably what you are looking for.n',['numpy'],"['numpy', 'python-2.7']"
40065378,"'Python using custom color in plot' ""I'm having a problem that (I think) should have a fairly simple solution. I'm still a relative novice in Python so apologies if I'm doing something obviously wrong. I'm just trying to create a simple plot with multiple lines where each line is colored by its own specific user-defined color. When I run the following code as a test for one of the colors it ends up giving me a blank plot. What am I missing here? Thank you very much!nnimport numpy as npnimport matplotlib.pyplot as pltnfrom colour import Color nndbz53 = Color('#DD3044')nn*a bunch of arrays of data two of which are called x and mpt1* nnfig ax = plt.subplots()nax.plot(x mpt1 color='dbz53' label='53 dBz')nax.set_yscale('log')nnax.set_xlabel('Diameter (mm)')nax.set_ylabel('$N(D) (m^-4)$')nax.set_title('N(D) vs. D')n#ax.legend(loc='upper right')nnplt.show()nn"" ""In the plot command you could enter Hex colours. A much more simple way to beautify your plot would be to simply use matplotlib styles. For instance before any plot function just writenplt.style.use('ggplot')n"" ""The statementnax.plot(x mpt1 color='dbz53' label='53 dBz')nis wrong with quoted dbz53. Where python treated it as a string of unknown rgb value.nYou can simply put color='#DD3044' and it will work.nOr you can try ncolor=dbz53.get_hex()nwithout quote if you want to use the colour module you imported.n""","['numpy', 'matplotlib']",['matplotlib']
40065381,"'Finding and replacing a value in a Python dictionary' 'I'm a complete newbie to stackoverflow so please excuse me if I end up posting this in the wrong place (or any other newbie-related mitakes! Thanks!).nnMy question pertains to Python 3.x where I am trying to basically access a value in a very small dictionary (3 keys 1 value each). I have searched high and low on the web (and on here) but cannot seem to find anything pertaining to replacing a value in a dictionary. I have found the ""replace"" function but does not seem to work for dictionaries.nnSo here is my dictionary:nna1 = {""Green"": ""Tree"" ""Red"": ""Rose"" ""Yellow"": ""Sunflower""}nnnHow would I go about querying the value ""Rose"" to replace it with ""Tulip"" for example?nnAny help would be greatly appreciated even if it is just to point me in the right direction!nnThanks so much!n' 'You first must find the key that has the value ""Rose"":nnfor color flower in a1.items():n    if flower == ""Rose"":n        a1color = ""Tulip""nn'",['dictionary'],"['dictionary', 'python-3.x']"
40065479,"'Numpy repeat for 2d array' ""Given two arrays say nnarr = array(10 24 24 24  1 21  1 21  0  0 dtype=int32)nrep = array(3 2 2 0 0 0 0 0 0 0 dtype=int32)nnnnp.repeat(arr rep) returns nnarray(10 10 10 24 24 24 24 dtype=int32)nnnIs there any way to replicate this functionality for a set of 2D arrays?nnThat is given nnarr = array(10 24 24 24  1 21  1 21  0  0n            10 24 24  1 21  1 21 32  0  0 dtype=int32)nrep = array(3 2 2 0 0 0 0 0 0 0n            2 2 2 0 0 0 0 0 0 0 dtype=int32)nnnis it possible to create a function which vectorizes?nnPS: The number of repeats in each row need not be the same. I'm padding each result row to ensure that they are of same size.nndef repeat2d(arr rep):n    # Find the max length of repetitions in all the rows. n    max_len = rep.sum(axis=-1).max()  n    # Create a common array to hold all results. Since each repeated array will have n    # different sizes some of them are padded with zero.n    ret_val = np.empty((arr.shape0 maxlen))  n    for i in range(arr.shape0):n        # Repeated array will not have same num of cols as ret_val.n        temp = np.repeat(arri repi)n        ret_vali:temp.size = tempn    return ret_val nnnI do know about np.vectorize and I know that it does not give any performance benefits over the normal version.n"" ""So you have a different repeat array for each row?  But the total number of repeats per row is the same?nnJust do the repeat on the flattened arrays and reshape back to the correct number of rows.nnIn 529: np.repeat(arrrep.flat)nOut529: array(10 10 10 24 24 24 24 10 10 24 24 24 24  1)nIn 530: np.repeat(arrrep.flat).reshape(2-1)nOut530: narray(10 10 10 24 24 24 24n       10 10 24 24 24 24  1)nnnIf the repetitions per row vary we have the problem of padding variable length rows.  That's come up in other SO questions.  I don't recall all the details but I think the solution is along this line:nnChange rep so the numbers differ:nnIn 547: repnOut547: narray(3 2 2 0 0 0 0 0 0 0n       2 2 2 1 0 2 0 0 0 0)nIn 548: lens=rep.sum(axis=1)nIn 549: lensnOut549: array(7 9)nIn 550: m=np.max(lens)nIn 551: mnOut551: 9nnncreate the target:nnIn 552: res = np.zeros((arr.shape0m)arr.dtype)nnncreate an indexing array - details need to be worked out:nnIn 553: idx=np.r_0:7m:m+9nIn 554: idxnOut554: array( 0  1  2  3  4  5  6  9 10 11 12 13 14 15 16 17)nnnflat indexed assignment:nnIn 555: res.flatidx=np.repeat(arrrep.flat)nIn 556: resnOut556: narray(10 10 10 24 24 24 24  0  0n       10 10 24 24 24 24  1  1  1)nn"" ""Another solution similar to @hpaulj's solution:nndef repeat2dvect(arr rep):n    lens = rep.sum(axis=-1)n    maxlen = lens.max()n    ret_val = np.zeros((arr.shape0 maxlen))n    mask = (lens:None>np.arange(maxlen))n    ret_valmask = np.repeat(arr.ravel() rep.ravel())n    return ret_valnnnInstead of storing indices I'm creating a bool mask and using the mask to set the values.n""",['numpy'],['numpy']
40065495,"'Python - Removing 1 char from a series of nested lists' ""I've solved the problem with the code below but I'm trying to understand a better way to strip out the zeros at the end of the each string of numbers because they throw off the calculation. The solution I have seems heavy handed is there a more elegant way to solve this without a for loop removing the 0s?nnCoding Problem:nnDetermine the average of a series of numbers like this:nnn  97 143 3 149 1 181 195 76 0n  n  8042 4302 1273 3858 4019 8051 4831 7747 4887 768 6391 7817 2635 6203 0n  n  1783 218 154 360 409 929 1503 428 73 1505 1868 1625 64 1613 0nnnimport sysninp = sys.stdin.readlines()nlin = nnfor i in inp1::n    lin.append(map(inti.split()))nnn/---Crux----nnfor r in lin:n    del r-1nnn/-------------nnfor n in lin:nprint int(round((sum(n) / float(len(n)))))nnnAny other critiques and constructive criticisms are appreciated.n"" 'As far getting the job done I think looks okay. Why not just do:nnIf r-1 == 0:n    Del r-1nn' 'You can do it all in one go using slicing and list comprehension:nnlin = map(inti.split()):-1 for i in inp1:nn' 'Cant you just do:nnlin=nfor line in sys.stdin:n    lin.append(float(e) for e in line.split():-1)nnnSo that becomes a single line:nnlin=float(e) for e in line.split():-1 for line in sys.stdinnnnThen your averages become:nnavgs=sum(e)/len(e) for e in linn>>> avgsn105.625 5058.857142857143 895.1428571428571nn'",['list'],"['python-2.7', 'list']"
40065641,"'Python Pandas Concat ""WHERE"" a Condition is met' 'How can I ""concat"" a specific column from many Python Pandas dataframes WHERE another column in each of the many dataframes meets a certain condition (colloquially termed condition ""X"" here).nnIn SQL this would be simple using JOIN clause with WHERE df2.Col2 = ""X"" and df3.Col2 = ""X"" and df4.col2 = ""X""... etc (which can be run dynamically).nnIn my case I want to create a big dataframe with all the ""Col1""s from each of the many dataframes but only include the Col1 row values WHERE the corresponding Col2 row value is greater than ""0.8"". When this condition isn't met the Col1 value should be ""NaN"".nnAny ideas would be most helpful! Thanks in advance!n' ""consider the list dfs of pd.DataFramesnnimport pandas as pdnimport numpy as npnnnnp.random.seed(31415)ndfs = pd.DataFrame(np.random.rand(10 2)n                    columns='Col1' 'Col2') for _ in range(5)nnnI'll use pd.concat to joinnnraw concatnstack values without regard to where it came fromnnpd.concat(d.Col1.locd.Col2.gt(.8) for d in dfs ignore_index=True)nn0     0.850445n1     0.934829n2     0.879891n3     0.085823n4     0.739635n5     0.700566n6     0.542329n7     0.882029n8     0.496250n9     0.585309n10    0.883372nName: Col1 dtype: float64nnnjoin with source informationnuse the keys parameternnpd.concat(d.Col1.locd.Col2.gt(.8) for d in dfs keys=range(len(dfs)))nn0  3    0.850445n   5    0.934829n   6    0.879891n1  1    0.085823n   2    0.739635n   7    0.700566n2  4    0.542329n3  3    0.882029n   4    0.496250n   8    0.585309n4  0    0.883372nName: Col1 dtype: float64nnnanother approachnuse querynnpd.concat(d.query('Col2 > .8').Col1 for d in dfs keys=range(len(dfs)))nn0  3    0.850445n   5    0.934829n   6    0.879891n1  1    0.085823n   2    0.739635n   7    0.700566n2  4    0.542329n3  3    0.882029n   4    0.496250n   8    0.585309n4  0    0.883372nName: Col1 dtype: float64nn""",['pandas'],['pandas']
40065702,"""TypeError: 'float' object is not subscriptable in 3d array"" 'guys I'm trying to write a function which get a 3-D array and check how many of its cells are empty. nbut i will got the following errornnin checkpointnif mij0 == 0:nTypeError: 'float' object is not subscriptablennnmy function is as followingnndef checkpoint(m i j):n    c = 0n    if mij0 == 0:n        c += 1.0n    if mij1 == 0:n        c += 1.0n    if mij2 == 0:n        c += 1.0n    if mij3 == 0:n        c += 1.0nreturn cnnnits from a large module that I'm working with nhere is the function that work with it nndef check(m size):nflag = 2nfor i in range(size):n    for j in range(size):n        print(i j ""/n"")n        c = checkpoint(m i j)n        s = summ(m i j)n        if c == 2:n            if s == 2 or -2:n                flag = 1.0n                if mij0 == 0:n                    if mij1 == 0:n                        mij0 = mij1 = (-s/2)n                        fix(m i j 0 size)n                        fix(m i j 1 size)n                    elif mij2 == 0:n                        mij0 = mij2 = (-s/2)n                        fix(m i j 0 size)n                        fix(m i j 2 size)n                    else:n                        mij0 = mij3 = (-s/2)n                        fix(m i j 0 size)n                        fix(m i j 3 size)n                elif mij1 == 0:n                    if mij2 == 0:n                        mij1 = mij2 = (-s/2)n                        fix(m i j 1 size)n                        fix(m i j 2 size)n                    elif mij3 == 0:n                        mij1 = mij3 = (-s/2)n                        fix(m i j 1 size)n                        fix(m i j 3 size)n                else:n                    mij2 = mij3 = (-s/2)n        if c == 3:n            flag = 1.0n            if mij0 == 0:n                mij0 = -sn            elif mij1 == 0:n                mij1 = -sn            elif mij2 == 0:n                mij2 = -sn            else:n                mij3 = -snreturn m flagnnnany comment would be appreciatednnupdate:nni desperately run the function inside the module and i saw that there isn't any problem whit first iteration and second iteration of the i and j in check function. but after that will faced with the error.nnhere is my output:the output of the code that I'm trying to runnnas you can see it didn't have any problem in first iteration of the i in check function.nhere is my fix function. it changes some other cells with respect to the arrow that cell that just changed.nndef fix(m i j k size):nip = i - 1njp = j - 1niz = i + 1njz = j + 1nif ip < 0:n    ip = size - 1nif jp < 0:n    jp = size - 1nif iz > size - 1:n    iz = 0nif jz > size - 1:n    jz = 0nkp = (k+2) % 4nif k == 0:n    mijzkp = -1 * mijknif k == 1:n    mizjkp = -1 * mijknif k == 2:n    mijpkp = -1 * mijknif k == 3:n    mipjkp = -1 * mijknreturn mnnnhere you can find whole package:nmy coden' 'That means m is not actually 3d array the code is trying to do i or ij or ij0 on a float. nn""containers"" are ""scriptable"" as described heren'",['python-3.x'],"['python-3.x', 'python-2.7']"
40065703,"'Collecting Summary Statistics on Dataframe built by randomly sampling other dataframes' ""My goal is to build a dataframe by randomly sampling from other dataframes collecting summary statistics on the new dataframe and then append those statistics to a list. Ideally I can iterate through this process n number of times (e.g. bootstrap). nndfposlist = OFdf Firstdf Seconddf Thirddf CFdf RFdf Cdf SSdfnnOFdf.head()n    playerID    OPW         POS salaryn87  bondsba01   62.061290   OF  8541667n785 ramirma02   35.785630   OF  13050000n966 walkela01   30.644305   OF  6050000n859 sheffga01   29.090699   OF  9916667n357 gilesbr02   28.160054   OF  7666666nnnAll the dataframes in the list have the same headers. What I'm trying to do looks something like this:nnteamdist = nfor df in dfposlist:n    frames = df.sample(n=1)nteam = pd.concat(frames)nnteamopw = team'OPW'.sum()nteamsal = team'salary'.sum()nteamplayers = team'playerID'.tolist()nnteamdic = {'Salary':teamsal 'OPW':teamopw 'Players':teamplayers}nteamdist.append(teamdic)nnnThe output I'm looking for is something like this:nnteamdist = {'Salary':4900000 'OPW':78.452 'Players':bondsba01 etc etc}nnnBut for some reason all the sum actions like teamopw = team'OPW'.sum() do not work how I'd like and just returns the elements in team'OPW'nnprint(teamopw)n0.17118131814601256n38.10700006434629n1.5699939126695253n32.9068837019903n16.990760776263674n18.22428871113601n13.447706356730897nnnAny advice on how to get this working? Thanks!nnEdit: Working solution as follows. Not sure if it is the most pythonic way but it works. nnteamdist = nteam = pd.concat(df.sample(n=1) for df in dfposlist)nnteamopw = team'OPW'.values.sum()nteamsal = team'salary'.values.sum()nteamplayers = team'playerID'.tolist()nnteamdic = {'Salary':teamsal 'OPW':teamopw 'Players':teamplayers}nteamdist.append(teamdic)nn"" ""Here (with random data):nnimport pandas as pdnimport numpy as npnndfposlist = dict(zip(range(10)n                     pd.DataFrame(np.random.randn(10 5)n                                   columns=list('abcde'))n                     for i in range(10)))nfor df in dfposlist.values():n    df'f' = list('qrstuvwxyz')nnteamdist = nteam = pd.concat(df.sample(n=1) for df in dfposlist.values())nprint(team.info())nnteamdic = team'a' 'c' 'e'.sum().to_dict()nteamdic'f' = team'f'.tolist()nteamdist.append(teamdic)nprint(teamdist)nn# Output:n## team.info():n<class 'pandas.core.frame.DataFrame'>nInt64Index: 10 entries 1 to 6nData columns (total 6 columns):na    10 non-null float64nb    10 non-null float64nc    10 non-null float64nd    10 non-null float64ne    10 non-null float64nf    10 non-null objectndtypes: float64(5) object(1)nmemory usage: 560.0+ bytesnNonenn## teamdist:n{'a': -3.5380097363724601n  'c': 2.0951152809401776n  'e': 3.1439230427971863n  'f': 'r' 'w' 'z' 'v' 'x' 'q' 't' 'q' 'v' 'w'}nn""","['pandas', 'dictionary']",['pandas']
40065762,'Pandas plot mean values from corresponding unique id values' 'This is my csv file. I want to find the mean cost for each unique ids. nnso for example: id 1 mean cost should be 20.nnidcostn110 n120n130n240n250nnnI got the output right with:nndf.groupby('id')'cost'.mean()nidn1    20n2    45nName: cost dtype: int64nnnBut i dont know how to plot such that x-axis is the id (12) and y axis as the mean values (2045). nnThe below code made the mean to be the x-axis (should be on y-axis) while the y-axis is only until 1 (should be 2 and should be the x-axis). nndf.groupby('id')'cost'.mean().hist()nnnn' 'Piggybacking off of Psidom's comment...nndf.groupby('id').mean().plot(kind='bar')nnnnnnnIn 108: dfnOut108: n   id  costn0   1    10n1   1    20n2   1    30n3   2    40n4   2    50nn',"['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40065822,"'memcached fails after running for a while' ""I am using Django with memcached with somewhat high volume of requests.nAt first the memcached works fine however after a while it starts raising errors from time to time. The error messages are also inconsistent. After spending a lot of time I can't even find out what exactly the errors mean nor how to resolve it.  nnSetup:nnnDjango + default memcached backendnmemcached is started using Docker: ndocker up -d memcached -m 3072m -I 10m -c 4096nmemcached uses its own dedicated hostnHost spec: 4 CPU + 3.5GB ramnswappiness = 0nrunning on Google compute enginennnStatsnn statsn    STAT pid 1n    STAT uptime 38718n    STAT time 1476576775n    STAT version 1.4.31n    STAT libevent 2.0.21-stablen    STAT pointer_size 64n    STAT rusage_user 73.432000n    STAT rusage_system 565.536000n    STAT curr_connections 10n    STAT total_connections 346393n    STAT connection_structures 4070n    STAT reserved_fds 20n    STAT cmd_get 710031n    STAT cmd_set 373473n    STAT cmd_flush 0n    STAT cmd_touch 0n    STAT get_hits 681898n    STAT get_misses 28133n    STAT get_expired 1295n    STAT get_flushed 0n    STAT delete_misses 0n    STAT delete_hits 0n    STAT incr_misses 0n    STAT incr_hits 0n    STAT decr_misses 0n    STAT decr_hits 0n    STAT cas_misses 0n    STAT cas_hits 0n    STAT cas_badval 0n    STAT touch_hits 0n    STAT touch_misses 0n    STAT auth_cmds 0n    STAT auth_errors 0n    STAT bytes_read 294333584541n    STAT bytes_written 294114029877n    STAT limit_maxbytes 3221225472n    STAT accepting_conns 1n    STAT listen_disabled_num 8604n    STAT time_in_listen_disabled_us 207162898n    STAT threads 4n    STAT conn_yields 0n    STAT hash_power_level 16n    STAT hash_bytes 524288n    STAT hash_is_expanding 0n    STAT malloc_fails 0n    STAT log_worker_dropped 0n    STAT log_worker_written 0n    STAT log_watcher_skipped 0n    STAT log_watcher_sent 0n    STAT bytes 80025379n    STAT curr_items 4616n    STAT total_items 373473n    STAT expired_unfetched 20032n    STAT evicted_unfetched 0n    STAT evictions 0n    STAT reclaimed 21994n    STAT crawler_reclaimed 0n    STAT crawler_items_checked 0n    STAT lrutail_reflocked 1229n    ENDnnnDifferent Error MessagesnnException Value: error 31 from memcached_get(:1:a7735b06da00d2e6991920299c31): (14006136669712) A TIMEOUT OCCURRED host: 10.140.0.16:11211 -> libmemcached/get.cc:314nnerror 37 from memcached_set: SUCCESSnnerror 47 from memcached_get(:1:throttle_naive_9885206_None_): (140085126390144) SERVER HAS FAILED AND IS DISABLED UNTIL TIMED RETRY host: 10.140.0.16:11211 -> libmemcached/get.cc:314nnnNotennnIn all cases it seems the memcached docker is still functional asnstats still works and not all requests generates errornCPU usage for memcached host is around 1% onlynI used to have the same problem when having the memcached instance on the same host as my frontend service. However the same problem.nnnEDIT: As I was not able to solve this problem I switched to Redis on the same host. Although I didn't get it right at the first time Redis provides comprehensive error messages so I can easily resolve them. Now my cache is running stably.n"" nan",['django'],['django']
40065896,"'Disable tree view from filling the window after update' 'I have very simple grid layout with two columns where first column should display some text and the second to show tree view:nn#! python3nnfrom random import randintnimport tkinter as tknfrom tkinter import ttknfrom tkinter.constants import *nnnclass Application(ttk.Frame):nn    def __init__(self root):n        self.root = rootn        self.root.resizable(0 0)n        self.root.grid_columnconfigure(0 weight=1)n        self.root.grid_columnconfigure(1 weight=3)n        self.init_widgets()n        self.arrange_grid()nn    def init_widgets(self):n        self.text_frame = ttk.Labelframe(self.root text='Info')n        self.button = ttk.Button(self.root text='Process' command=self.on_button)n        self.tree = ttk.Treeview(self.root)n        self.scroll = ttk.Scrollbar(self.root orient=HORIZONTAL command=self.tree.xview)n        self.tree.configure(xscrollcommand=self.scroll.set)nn    def arrange_grid(self):n        self.text_frame.grid(row=0 sticky=NSEW)n        self.button.grid(row=0 sticky=N pady=32)n        self.tree.grid(row=0 column=1 sticky=NSEW)n        self.scroll.grid(row=0 column=1 sticky=(S W E))nn    def on_button(self):n        headers = list(range(20))n        rows = randint(0 100) * len(headers) for i in headersn        self.tree""columns"" = headersn        for i row in enumerate(rows):n            self.tree.insert("""" i values=row)nnnif __name__ == '__main__':n    root = tk.Tk()n    app = Application(root)n    root.mainloop()nnnWhen I click on a ""Process"" button tree view is populated with data but at the same time it resizes the root window and fills whole space.nnHow can I instruct ttk tree view to remain it's size after populating with data?n' 'The treeview will grow to fit all of its columns unless constrained by the window. The window will grow to fit all of it children unless you give it a fixed size. What is happening is that you're giving the treeview many columns causing it to grow. Because it grows the window grows because you haven't constraint its growth.nnThere are several solutions. Perhaps the simplest solution is to put the tree in a frame so that you can give it an explicit width and height. The key to this is to make the frame control the size of its children rather than the other way around. This is done by turning geometry propagation off. nnFirst start by creating a frame and then putting the tree in the frame. We can also put the scrollbar in the frame so that we can treat the tree and scrollbar as a single unit.nnself.tree_frame = tk.Frame(self.root width=400 height=200)nself.tree = ttk.Treeview(self.treeframe)nself.scroll = ttk.Scrollbar(self.tree_frame orient=HORIZONTAL command=self.tree.xview)nself.tree.configure(xscrollcommand=self.scroll.set)nnnNext add the treeview and scrollbar to the frame. You can use any of pack place or grid; I find pack superior for a top-to-bottom layout. We also use pack_propagate to turn off geometry propagation (meaning: the frame width and height are honored):nnself.tree_frame.pack_propagate(0)nself.scroll.pack(side=""bottom"" fill=""x"")nself.tree.pack(side=""top"" fill=""both"" expand=True)nnnWith that you need to modify your arrange_grid to put the frame in the root window and then ignore the scrollbar since it's already packed in the frame:nndef arrange_grid(self):n    self.text_frame.grid(row=0 sticky=NSEW)n    self.button.grid(row=0 sticky=N pady=32)n    self.tree_frame.grid(row=0 column=1 sticky=NSEW)nnnnnNote: you've turned off the ability for the user to resize the window. I recommend avoiding this -- the user usually knows better what size they want the window. Instead you should configure your GUI to properly resize when the user resizes the window.nnSince you're using grid all you have to do is tell tkinter which rows and columns get any extra space caused by the user resizing the window. Since everything is in a single row you merely need to give that row a weight:nnroot.grid_rowconfigure(0 weight=1)nn'",['tkinter'],['tkinter']
40065971,'Making subplots based on specific column in Pandas' 'I have a pandas data frame that contains polynomial approximations of various functions at given points with variable degrees to the polynomial approximation.  It is arranged so that the first column is the function name the second is the x value then columns 2-5 are the approximations with a polynomial of the corresponding degree.  I would like to make 1 plot for each function showing the convergence of the approximations to that function.  I know one way to do it is to break the data frame into separate data frames based on the first column name but wanted to know if there was a more elegant way to do it.nnEdit for clarification:nSo in the data frame there are two unrelated functions say a and b.  The second column contains the x values then third and fourth are functions of x.  So it might look like     nn   fnctn  x  y1  y2n0     a  1   2   3n1     a  2   3   2n2     a  3   4   3n3     a  4   3   4n4     a  5   2   3n5     b  1   1   2n6     b  2   4   6n7     b  3   9   12n8     b  4   16  20n9     b  5   25  30nnnI would want a plot of y1 and y2 where the first column is a on one plot and on another plot y1 and y2 where the first column is bn' 'import pandasnfrom matplotlib import pyplot as pltndf = pandas.DataFrame({'fnctn':'a''a''a''b''b''b''x':123123'y1':234322'y2':323432})nnIn 19: dfnOut19: n  fnctn  x  y1  y2n0     a  1   2   3n1     a  2   3   2n2     a  3   4   3n3     b  1   3   4n4     b  2   2   3n5     b  3   2   2nnfor f in set(df'fnctn'): n     dfdf'fnctn'==f.plot(x='x')nnnnn',['pandas'],"['pandas', 'matplotlib']"
40066019,"""django 1.10 Exception while resolving variable 'is_popup' in template 'admin/login.html'"" 'I create a new django project with python3.5 and django1.10.0I keep getting an error in the admin whenever I want access localhost:8000/admin He`re's the error:nnDEBUG- Exception while resolving variable 'is_popup' in template 'admin/login.html'.nTraceback (most recent call last):n  File ""C:PythonPython35libsite-packagesdjangotemplatebase.py"" line 885 in _resolve_lookupn    current = currentbitn  File ""C:PythonPython35libsite-packagesdjangotemplatecontext.py"" line 75 in __getitem__n    raise KeyError(key)nKeyError: 'is_popup'nnDuring handling of the above exception another exception occurred:nnTraceback (most recent call last):n  File ""C:PythonPython35libsite-packagesdjangotemplatebase.py"" line 891 in _resolve_lookupn    if isinstance(current BaseContext) and getattr(type(current) bit):nAttributeError: type object 'RequestContext' has no attribute 'is_popup'nnDuring handling of the above exception another exception occurred:nnTraceback (most recent call last):n  File ""C:PythonPython35libsite-packagesdjangotemplatebase.py"" line 900 in _resolve_lookupn    current = currentint(bit)nValueError: invalid literal for int() with base 10: 'is_popup'nnDuring handling of the above exception another exception occurred:nnTraceback (most recent call last):n  File ""C:PythonPython35libsite-packagesdjangotemplatebase.py"" line 907 in _resolve_lookupn    (bit current))  # missing attributendjango.template.base.VariableDoesNotExist: Failed lookup for key is_popup in ""{'True': True 'None': None 'False': False} {'perms': <django.contrib.auth.context_processors.PermWrapper object at 0x04A2D1D0> 'DEFAULT_MESSAGE_LEVELS': {'WARNING': 30 'SUCCESS': 25 'ERROR': 40 'INFO': 20 'DEBUG': 10} 'user': <SimpleLazyObject: <django.contrib.auth.models.AnonymousUser object at 0x04A0A590>> 'messages': <django.contrib.messages.storage.fallback.FallbackStorage object at 0x04A0A490> 'request': <WSGIRequest: GET '/admin/login/?next=/admin/'> 'csrf_token': <SimpleLazyObject: <function csrf.<locals>._get_val at 0x04581C90>>} {} {'has_permission': False 'username': '' 'site_title': <django.utils.functional.lazy.<locals>.__proxy__ object at 0x03CF82B0> 'next': '/admin/' 'site': <django.contrib.sites.requests.RequestSite object at 0x04A0A6D0> 'app_path': '/admin/login/?next=/admin/' 'site_url': '/' 'site_name': '127.0.0.1:8000' 'available_apps':  'LANGUAGE_BIDI': False 'LANGUAGE_CODE': 'en-us' 'form': <AdminAuthenticationForm bound=False valid=Unknown fields=(username;password)> 'site_header': <django.utils.functional.lazy.<locals>.__proxy__ object at 0x03CF8310> 'title': 'Log in'}""n2016-10-16 09:31:59199 Thread-7:11460 django.template:929 base:_resolve_lookup DEBUG- Exception while resolving variable 'is_popup' in template 'admin/login.html'.nTraceback (most recent call last):n  File ""C:PythonPython35libsite-packagesdjangotemplatebase.py"" line 885 in _resolve_lookupn    current = currentbitn  File ""C:PythonPython35libsite-packagesdjangotemplatecontext.py"" line 75 in __getitem__n    raise KeyError(key)nKeyError: 'is_popup'nnnAnyone can help methanks very much!n' nan",['django'],['django']
40066061,"'Check panadas dataframe for singular matrices' 'I am trying to use pandas scatter_matrix for displaying dataframe contents eg:nnscatter_matrix(df alpha=0.2 figsize=(6 6) diagonal='kde')nnnHowever I get a singular matrix error as the scatter_matrix with kde option code tries to invert a covariance matrix of the data where there is no covariance.nn#see pands.tools.plotting.scatter_matrixnn = df.columns.sizenmask = notnull(df)nfor i a in zip(range(n) df.columns):n    for j b in zip(range(n) df.columns):n        if i == j:n            values = dfa.valuesmaska.valuesn            from scipy.stats import gaussian_kden            y = valuesn            try:n                #the line below calls linalg.inv(self._data_covariance)n                #which throws the LinAlgErrorn                gkde = gaussian_kde(y)n            except LinAlgError as e:n                logger.debug(""Error data: {0}"".format(y))nnnIs there a way I could re-create the dataframe so that matrices combinations with no covariance are removed?n' nan",['pandas'],"['pandas', 'numpy']"
40066089,"'apply images to pyplot python bar graphs' 'So below is a snippet of my code and it all works fine. Just curious instead of display bars with specific colors can an image be applied to the bar such as a countries flag etc. (please ignore my inconsistent order of param passing)nnthanksnnl_images=""australia.png""""turkey.png"" # this is desirednl_colors=""pink""""blue""nnif (l_bar_dir==""vertical""):                             n plt.bar(xs2ystick_label=xscolor=l_colorsbottom=bottomswidth=bar_widthalign='center') # set plot to be a bar graphnelse:                           n plt.barh(bottom=xs2width=ystick_label=xsalign='center'color=l_colors) # set plot to be a bar graphnn' 'AFAIK there's no built-in way to do this although matplotlib does allow hatches in bar plots. See for example hatch_demo.nnBut it's not terribly difficult to put together several calls to plt.imshow in the form of a bar plot. Here is a rather crude function that could be used to make basic bar plots using images using your idea of flags as the images.nnimport numpy as npnimport matplotlib.pyplot as pltnfrom scipy.misc import imreadnndef image_plot(heights images spacing=0):n    # Iterate through images and data autoscaling the width ton    # the aspect ratio of the imagen    for i (height img) in enumerate(zip(heights images)):n        AR = img.shape1 / img.shape0n        width = height * ARn        left = width*i + spacing*in        right = left + widthn        plt.imshow(img extent=left right 0 height)n    # Set xy limits on plot windown    plt.xlim(0 right)n    plt.ylim(0 max(heights)*1.1)nn# Read in flag imagesnusa_flag = imread('american_flag.png')naussie_flag = imread('australian_flag.png').swapaxes(0 1)nturkish_flag = imread('turkish_flag.png').swapaxes(0 1)nn# Make up some data about each countrynusa_data = 33naussie_data = 36nturkish_data = 27nndata = usa_data aussie_data turkish_datanflags = usa_flag aussie_flag turkish_flagnnimage_plot(data flags spacing=2)nnnWithout doing anything fancy to the x and y axes returns this plot.nnn'",['matplotlib'],['matplotlib']
40066116,"'Remove IMG tag from HTML using Regex - Python 2.7' ""I have HTML and I want to remove IMG tag from it.nnI am not good at regex I have this function but it does not remove IMG tagnndef remove_img_tags(data):n    p = re.compile(r'<img.*?/>')n    return p.sub('' data)nnnWhat is the proper regex? I don't want to use any library.n"" ""Try this:nnimage_tag = re.compile(r'<img.*?/>').search(data).group()ndata.replace(image_tag '')nn"" 'All you need is to capture img tag and replace it with empty string.nnclean_data = re.sub(""(<img.*?>)"" """" data 0 re.IGNORECASE | re.DOTALL | re.MULTILINE)nnnYou'll be passing HTML content in data. Regex will remove all img tags their content and return clean data in clean_data variable.n'","['regex', 'python-2.7']",['regex']
40066130,"'How do I remove the circular dependency in my Organization-Owner-Member models?' ""Heyo I'm fairly new to this stuff so please pardon me if this is a stupid question. nI'm trying to create an app where users can create organizations and join already existing ones. My requirements are:nnnan organization may have only one user designated the owner (the user who creates it)nusers must be able to join several organizationsnusers must be able to create organizations and therefore be owners of multiple organizationsnnnSo far I've got the following models.py:nnfrom django.db import modelsnfrom django.utils.translation import ugettext_lazy as _nnfrom myapp.users.models import Usernnnclass TimeStampedModel(models.Model):nn    created = models.DateTimeField(auto_now_add=True)n    updated = models.DateTimeField(auto_now=True)nn    class Meta:n        abstract = Truennclass Org(TimeStampedModel):nn    name = models.CharField(n        _('Organization name')n        max_length=255n    )n    owner = models.OneToOneField('OrgOwner')n    members = models.ManyToManyField(n        'OrgMember'n        related_name='organization_members'n    )n    users = models.ManyToManyField(n        Usern        related_name='organization_users'n    )nn    def __str__(self):n        return self.namennnclass OrgMember(TimeStampedModel):nn    user = models.ForeignKey(n        Usern        related_name='user_profile'n    )n    organization = models.ForeignKey(n        Orgn        related_name='member_organization'n    )nn    def __str__(self):n        return self.user.usernamennnclass OrgOwner(TimeStampedModel):nn    member = models.OneToOneField(OrgMember)n    organization = models.OneToOneField(Org)nn    def __str__(self):n        return self.member.__str__()nnnMy issue is that the way I've designed the models so far I have a circular dependency. In order for a user to create an Org from scratch he needs to be an OrgMember of said not yet created Org. In other words I cannot instantiate an OrgMember without assigning it an Org but I cannot instantiate a new Org without an OrgOwner for which I also need an OrgMember. nnI'm sure there is just an error in my reasoning here. But perhaps there are some best practices for situations like this one you could share. There is probably a fairly simple solution to this but I haven't been able to find one in an hour of searching and reading the django docs. Any help is much appreciated!n"" 'I still can't see why you have so much looping information. Your OrgMember class has an organization field even though Org already has a ManyToMany with OrgMember. Same thing with OrgOwner - except that points to OrgMember which already points to an Org as well. Both of those classes only have two fields - the User associated with it and then the Org. Unless there are more fields they serve no purpose - the same thing can be accomplished in one model:nnclass Org(TimeStampedModel):n    name = models.CharField(_('Organization name') max_length=255)n    # Only one owner but each User can own more than one orgn    owner = models.ForeignKey('auth.User' related_name='owned_orgs')n    members = models.ManyToManyField('auth.User' related_name='organization_members')n    users = models.ManyToManyField(User related_name='organization_users')nn    def __str__(self):n        return self.namennnI'd recommend that you do some more reading about Django's relationship fieldsn'",['django'],['django']
40066186,"""ModuleNotFoundError: No module named 'appoauth2_provider'"" 'I followed all the directions in importing Facebook into my python django app. However when  I try to migrate  I get an error ""No module named'appoauth2_provider'nI am using Windows 10 Python 3.6.0.nn(app) C:UsersCorey ShawDesktopgoodrvirtualenvappScriptsapp>python manage.py migratenTraceback (most recent call last):n  File ""manage.py"" line 22 in <module>n    execute_from_command_line(sys.argv)n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibsite-packagesdjango-1.10-py3.6.eggdjangocoremanagement__init__.py"" line 367 in execute_from_command_linen    utility.execute()n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibsite-packagesdjango-1.10-py3.6.eggdjangocoremanagement__init__.py"" line 341 in executen    django.setup()n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibsite-packagesdjango-1.10-py3.6.eggdjango__init__.py"" line 27 in setupn    apps.populate(settings.INSTALLED_APPS)n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibsite-packagesdjango-1.10-py3.6.eggdjangoappsregistry.py"" line 85 in populaten    app_config = AppConfig.create(entry)n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibsite-packagesdjango-1.10-py3.6.eggdjangoappsconfig.py"" line 90 in createn    module = import_module(entry)n  File ""C:UsersCOREYS~1DesktopGOODRV~1applibimportlib__init__.py"" line 126 in import_modulen    return _bootstrap._gcd_import(namelevel: package level)n  File ""<frozen importlib._bootstrap>"" line 978 in _gcd_importn  File ""<frozen importlib._bootstrap>"" line 961 in _find_and_loadn  File ""<frozen importlib._bootstrap>"" line 948 in _find_and_load_unlockednModuleNotFoundError: No module named 'appoauth2_provider'nn' nan",['django'],['django']
40066199,"'Django FileNotFoundError in a view when returning HTML using codecs' 'I am creating a view in Django that returns a static HTML page and my code for that view is as follows:nnfrom django.shortcuts import rendernfrom django.http import HttpResponsenfrom django.shortcuts import render_to_responsenimport codecsnn# Basic HTTP response that returns my html indexn# To call this view map it to a URLconfnndef index(request):nn    # When a request is called return my index.htmlnn    html = codecs.open(""index.html"" ""r"")n    return HttpResponse(html.read())nnnWhen I fire up the Django dev. server and navigate to my app instead of the rendering of index.html that I expect I am confronted with a FileNotFoundError at /myapp/ as well as Errno 2 No such file or directory: 'index.html'. I know for a fact that index.html is a real file in the same directory as myviews.py and I have also tried debugging by opening a debug.txt in the same directory and returning that but with the same result. When I open the python shell in the same directory and try to open the same file it works without a hitch. Any insight would be appreciated as I am thouroughly stumped.n' 'If you want to open a file from the same directory as your view.py file use the following:nnhtml = open(os.path.dirname(os.path.realpath(__file__)) + 'index.html' ""r"")nn'",['django'],['django']
40066256,"'Printing a logo and boilerplate text to a PDF document using Python' ""I'm currently using matplotlib.backends.backend_pdf to build a PDF report consisting of several matplotlib plots.  Currently there are 9 pages of plots.  Each page consists of about 7 subplots (I'm using plt.subplot2grid).  nnIs there a way for me to do the following?nna) print a logo to the first page of the PDF document and then have the 9 pages of plots appears on pages 2 through 10nnb) print a disclaimer and some other boilerplate language underneath the logonnThanks!n"" nan",['matplotlib'],['matplotlib']
40066381,"'Print items from a list in an external .py file' 'I have a list in a external file and I'm able to access the file but I have a list in that file with the name of factswith some items on it but how can I read the items from that list? It goes something likennx = open(""Trivia""+""/fact.py"" ""r"")nf = x.read()nfact = f.? nnnWhat do I have to do there? If I run the code like that it just prints the whole list with the variable name and everything.n' 'open is for files containing data; files containing Python code are typically accessed with import.  See The Python Tutorial's section 6. Modules for the typical use cases.nnAssuming you'll always be running your script from the same directory:nnimport Trivia.factnndo_something_with(Trivia.fact.facts)nnnOr if you're only going to use that one value:nnfrom Trivia.fact import factsnndo_something_with(facts)nnnIf you want to install all of this as a package so you can run it from anywhere you will also have to learn about packages and maybe the import path but don't worry about that until it's clear you need it.nnnnAll this assumes there's some advantage to storing your data in a Python file --- like it's a list of objects that took a bit of work to initialize.  If it's just ""raw"" data like strings then a plain text file with one string per line might be the way to go... and you'd be back to using open and probably readlines or for line in ...:.nn""Nearly-raw"" data like tables dictionaries of numbers and strings or lists of lists can be read and written with either the json or csv modules depending on how complex your data is and which format you're more comfortable with.n'",['list'],"['list', 'python-2.7']"
40066439,"'How to calculate frequency of elements for pairwise comparisons of lists in Python?' 'I have the the sample stored in the following listnn sample = AAAACGCGTTTTAT-TCATCnnn.. To illustrate the problem I have denoted them as ""Sets"" belownnSet1 AAAAnSet2 CGCGnSet3 TTTTnSet4 AT-TnSet5 CATCnnnnEliminate all Sets where each every element in the set is identical to itself.nnnOutput:nn Set2 CGCGn Set4 AT-Tn Set5 CATCnnnnPerform pairwise comparison between the sets. (Set2 v Set4 Set 2v Set5 Set4 v Set5)nEach pairwise comparison can have only two types of combinations if not then those pairwise comparisons are eliminated. egnnSet2    Set5nC       CnG       AnC       T nG       CnnnnHere there are more than two types of pairs (CC) (GA) (CT) and (GC). So this pairwise comparison cannot occur. nnEvery comparison can have only 2 combinations out of (AA GGCCTT ATTAACCAAGGAGCCGGTTGCTTC) ... basically all possible combinations of ACGT where order matters. nnIn the given example more than 2 such combinations are found. nnHence Set2 and Set4; Set4 and Set5 cannot be considered.Thus the only pairs that remain are:nnOutputnSet2 CGCGnSet4 AT-TnnnnIn this pairwise comparison remove any the element with ""-"" and its corresponding element in the other pairnnOutput    nSet2 CGGnSet4 ATTnnCalculate frequency of elements in Set2 and Set4. Calculate frequency of occurrence of types of pairs across the Sets (CA and GT pairs)nnOutputnSet2 (C = 1/3 G = 2/3)nSet4 (A = 1/3 T = 2/3)nPairs (CA = 1/3 GT = 2/3)nnCalculate float(a) = (Pairs) - (Set2) * (Set4) for corresponding element (any one pair is sufficient)nneg. For CA pairs float (a) = (freq of CA pairs) - (freq of C) * (freq of A)nnnnNOTE: If the pair is AAAC and CCCA the freq of C would it be 1/4 i.e. it is the frequency of the base over one of the pairsnnnCalculate nnfloat (b) = float(a)/ (freq of C in CGG) * (freq G in CGG) * (freq A in ATT) * (ATT==> freq of T in ATT)nnRepeat this for all pairwise comparisonsnnneg. nnSet2 CGCGnSet4 AT-TnSet6 GCGCnnnSet2 v Set4 Set2 v Set6 Set4 v Set6nnMy half-baked code till now:n** I would prefer if all codes suggested would be in standard for-loop format and not comprehensions **nn#Step 1nfor i in sample: n    for j in range(i):n        if j = j+1    #This needs to be corrected to if all elements in i identical to each other i.e. if all ""j's"" are the samen                        del i n    #insert line of code where sample1 = new sample with deletions as abovenn#Step 2n    for ii+1 in enumerate(sample):n    #Step 3n    for j in range(i):n        for k in range (i+1):n        #insert line of code to say only two types of pairs can be included if yes continue else skipn            #Step 4n            if j = ""-"" or k = ""-"":n                #Delete j/k and the corresponding element in the other pairn                #Step 5n                count_dict = {}n                    square_dict = {}n                for base in list(i):n                    if base in count_dict:n                            count_dictbase += 1n                    else:n                            count_dictbase = 1n                    for allele in count_dict:n                    freq = (count_dictallele / len(i)) #frequencies of individual allelesn                    #Calculate frequency of pairs n                #Step 6n                No code yetnn' ""I think this is what you want:nnfrom collections import Counternn# Remove elements where all nucleobases are the same.nfor index in range(len(sample) - 1 -1 -1):n    if sampleindex:1 * len(sampleindex) == sampleindex:n        del sampleindexnnfor indexA setA in enumerate(sample):n    for indexB setB in enumerate(sample):n        # Don't compare samples with themselves nor compare same pair twice.n        if indexA <= indexB:n            continuenn        # Calculate number of unique pairsn        pair_count = Counter()n        for pair in zip(setA setB):n            if '-' not in pair:n                pair_countpair += 1nn        # Only analyse pairs of sets with 2 unique pairs.n        if len(pair_count) != 2:n            continuenn        # Count individual bases.n        base_counter = Counter()n        for pair count in pair_count.items():n            base_counterpair0 += countn            base_counterpair1 += countnn        # Get the length of one of each item in the pair.n        sequence_length = sum(pair_count.values())nn        # Convert counts to frequencies.n        base_freq = {}n        for base count in base_counter.items():n            base_freqbase = count / float(sequence_length)nn        # Examine a pair from the two unique pairs to calculate float_a.n        pair = list(pair_count)0n        float_a = (pair_countpair / float(sequence_length)) - base_freqpair0 * base_freqpair1nn        # Step 7!n        float_b = float_a / float(base_freq.get('A' 0) * base_freq.get('T' 0) * base_freq.get('C' 0) * base_freq.get('G' 0))nnnOr more Pythonically (with the list/dict comprehensions you don't want):nnfrom collections import CounternnBASES = 'ATCG'nn# Remove elements where all nucleobases are the same.nsample = item for item in sample if item:1 * len(item) != itemnnfor indexA setA in enumerate(sample):n    for indexB setB in enumerate(sample):n        # Don't compare samples with themselves nor compare same pair twice.n        if indexA <= indexB:n            continuenn        # Calculate number of unique pairsn        relevant_pairs = (elA elB) for (elA elB) in zip(setA setB) if elA != '-' and elB != '-'n        pair_count = Counter(relevant_pairs)nn        # Only analyse pairs of sets with 2 unique pairs.n        if len(pair_count) != 2:n            continuenn        # setA and setB as tuples with pairs involving '-' removed.n        setA setB = zip(*relevant_pairs)nn        # Get the total for each base.n        seq_length = len(setA)nn        # Convert counts to frequencies.n        base_freq = {base : count / float(seq_length) for (base count) in (Counter(setA) + Counter(setB)).items()}nn        # Examine a pair from the two unique pairs to calculate float_a.n        pair = list(pair_count)0n        float_a = (pair_countpair / float(seq_length)) - base_freqpair0 * base_freqpair1nn        # Step 7!n        denominator = 1n        for base in BASES:n            denominator *= base_freq.get(base 0)nn        float_b = float_a / denominatornn""","['list', 'dictionary']","['list', 'dictionary']"
40066532,"'Dictionary saving last result to every value using BeautifulSoup' 'I am currently in the process of making a web crawler using requests and BeautifulSoup. I am using a for loop to create a list of dictionaries with the values being the href of the a tags. I am having issues doing this however since all of the results will be the last href on that page. Here is the output when I print out the final result:nn{'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'} {'link': '/terms'}nnnI am unsure as to why it's doing the last value only. I assume it's because through the last loop it assigns all keys with the same name to that value. How can I go around fixing this? Here is the code.nnimport jsonnimport requestsnfrom bs4 import BeautifulSoupnntags_dict = {}ntags_list = nnr = requests.get(""http://chicosadventures.com/"")nnsoup = BeautifulSoup(r.content ""lxml"")nnnfor link in soup.find_all('a'):n    tags_dict'link' = link.get('href')n    tags_list.append(tags_dict)nndump = json.dumps(tags_list)nprint(dump)nn' 'Your issue is with tags_dict. You are just storing a reference to that one dictionary again and again in your list and since its a reference the last value gets reflected in all entries. I changed it to create a new dict object for each iteration now it works finennimport jsonnimport requestsnfrom bs4 import BeautifulSoupnntags_list = nr = requests.get(""http://chicosadventures.com/"")nsoup = BeautifulSoup(r.content ""lxml"")nnfor link in soup.find_all('a'):n    tags_list.append({""link"": link.get('href')})nndump = json.dumps(tags_list)nprint(dump)nnnOutput:nnn  {""link"": ""/""} {""link"": ""/about_chico""} {""link"":n  ""/about_the_author""} {""link"": ""/about_the_illustrator""} {""link"":n  ""/chico_in_the_news_""} {""link"": ""/order_your_copy""} {""link"":n  ""/contact_us""} {""link"": ""/about_chico""} {""link"":n  ""/about_the_author""} {""link"": ""/about_the_illustrator""} {""link"":n  ""/chico_in_the_news_""} {""link"": ""/order_your_copy""} {""link"":n  ""/contact_us""} {""link"": ""/privacy""} {""link"": ""javascript:print()""}n  {""link"": ""http://www.ebtech.net/""} {""link"": ""/terms""}nn'",['dictionary'],"['dictionary', 'python-2.7']"
40066533,"'Django: Slug in Vietnamese working not correctly' 'I begin to develop website online store using Django framework. I have faced with problem that I want to change the name in Vietnamese ""nhá»¯ng-viÃªn-káº¹o"" to ""nhung-vien-keo"". I have read this article: nDjango: Slug in Vietnamesennand I do something on model.py like this:nn# -*- coding: utf-8 -*-nfrom __future__ import unicode_literalsnnfrom django.db import modelsnfrom django.template.defaultfilters import slugifynnclass Category(models.Model):n    name = models.CharField(max_length=50)n    slug = models.CharField(max_length=50 unique=Truehelp_text = 'Unique value for product page URL created from name.')n    description = models.TextField()n    is_active = models.BooleanField(default=True)n    meta_keywords = models.CharField(""Meta Keywords"" max_length=255 help_text='Comma-delimited set of SEO keywords for meta tag')n    meta_description = models.CharField(""Meta Description"" max_length=255  help_text = 'Content for description meta tag')n    created_at = models.DateTimeField(auto_now_add=True)n    updated_at = models.DateTimeField(auto_now=True)nn    class Meta:  n        db_table = 'categories'n        ordering = '-created_at'n        verbose_name_plural = 'Categories'nn    def __unicode__ (self):n        return self.namenn    @models.permalinkn    def get_absolute_url(self):n        return ('catalog_category' () { 'category_slug': self.slug })nnnBut when I type ""nhá»¯ng-viÃªn-káº¹o"" in the Name field of Admin page the slug field appear ""nhng-vien-ko"". I don't know something wrong. nAnd when I run a test with:nn# -*- coding: utf-8 -*-nfrom __future__ import unicode_literalsnvietnamese_map = {n    ord(u'Æ°'): 'u'n    ord(u'Æ¡'): 'o'n    ord(u'Ã¡'): 'a'n    ord(u'n'): 'n'n    ord(u'h'): 'h'n    ord(u'á»¯'): 'u'n    ord(u'n'): 'n'n    ord(u'g'): 'g'n    ord(u'v'): 'v'n    ord(u'i'): 'i'n    ord(u'Ãª'): 'e'n    ord(u'n'): 'n'n    ord(u'k'): 'k'n    ord(u'áº¹'): 'e'n    ord(u'o'): 'o'n}nnprint unicode(""nhá»¯ng-viÃªn-káº¹o"").translate(vietnamese_map)nnnIt work correctly and return ""nhung-vien-keo""nnEDITnnI have try this on my form.pynnclass CategoryAdminForm(forms.ModelForm):nn    class Meta:n        model = Categoryn        exclude = ()nn    def clean_slug(self):n        slug = self.cleaned_data'slug'n        vietnamese_map = {n            ord(u'Æ°'): 'u'n            ord(u'Æ¡'): 'o'n            ord(u'Ã¡'): 'a'n            ord(u'n'): 'n'n            ord(u'h'): 'h'n            ord(u'á»¯'): 'u'n            ord(u'n'): 'n'n            ord(u'g'): 'g'n            ord(u'v'): 'v'n            ord(u'i'): 'i'n            ord(u'Ãª'): 'e'n            ord(u'n'): 'n'n            ord(u'k'): 'k'n            ord(u'áº¹'): 'e'n            ord(u'o'): 'o'n        }n        slug = slugify(unicode(slug).translate(vietnamese_map))n        return slugnnnAnd in admin.pynnclass CategoryAdmin(admin.ModelAdmin):nn    form = CategoryAdminFormn    # sets up values for how admin site lists categoriesn    list_display = ('name' 'created_at' 'updated_at')n    list_display_links = ('name')n    list_per_page = 20n    ordering = 'name'n    search_fields = 'name' 'description' 'meta_keywords' 'meta_description'n    exclude = ('created_at' 'updated_at')n    # sets up slug to be generated from category namen    prepopulated_fields = {'slug': ('name')}nnadmin.site.register(Category CategoryAdmin)nnnBut it still not work!n' 'if not self.slug:n    ...n    self.slug = slugify(unicode(self.slug).translate(vietnamese_map))nnnYour logic here is ""translate slug only if slug is empty"". Firstly try to remove this condition (because it doesn't make sense). Secondly try to make this work in forms instead because at the point of model saving your slug is already processed by slugify function of django. To do this:nnnCreate ModelForm for your class:    nnclass SomeModelForm(forms.ModelForm):nn    class Meta:n        model = SomeModeln        exclude = ()nn    def clean_slug(self):n        slug = self.cleaned_data'slug'n        # Consider adding vietnamese_map here n        slug = slugify(unicode(slug).translate(vietnamese_map))n        return slugnnIn your admin class: nnclass YourModelAdmin(admin.ModelAdmin):n    form = SomeModelFormnnnnYou may need to replace SlugField with regular CharField at the point.n'",['django'],['django']
40066648,"'Boxplot for list in pandas dataframe' ""I have the foll. dataframe:nn    Month(s)                                             Valsn0        Mar                             3.691756 3.59027575n1  Mar - Apr  4.75706325 3.138456625 1.90741175 3.019323n2  Mar - May  4.698454875 3.317812375 2.512695375 2.8096n3  Mar - Jun  4.70111125 3.474370375 2.53445075 2.926820n4  Mar - Jul  4.79324375 3.56983175 2.39309125 3.0682476n5  Mar - Aug  4.618898125 3.613308875 2.361248375 3.0536nnnI want to create a boxplot with x-axis using 'Month(s)' column and y-axis using the 'Vals' column. Simply doing df.plot() does not work. How do I fix it?n"" nan",['pandas'],['pandas']
40066837,"'pandas get average of a groupby' ""I am trying to find the average monthly cost per user_id but i am only able to get average cost per user or monthly cost per user. nnBecause i group by user and month there is no way to get the average of the second groupby (month) unless i transform the groupby output to something else.nnThis is my df:nn     df = { 'id' : pd.Series(11112222)n            'cost' : pd.Series(1020304050607080)n            'mth': pd.Series(33453445)}nn   cost  id  mthn0    10   1    3n1    20   1    3n2    30   1    4n3    40   1    5n4    50   2    3n5    60   2    4n6    70   2    4n7    80   2    5nnnI can get monthly sum but i want the average of the months for each user_id. nndf.groupby('id''mth')'cost'.sum()nnid  mthn1   3       30n    4       30n    5       40n2   3       50n    4      130n    5       80nnni want something like this:nnid average_monthlyn1 (30+30+40)/3n2 (50+130+80)/3nn"" ""Resetting the index should work. Try this:nnIn 19: df.groupby('id' 'mth').sum().reset_index().groupby('id').mean()  nOut19: n    mth       costnid                n1   4.0  33.333333n2   4.0  86.666667nnnYou can just drop mth if you want. The logic is that after the sum part you have this:nnIn 20: df.groupby('id' 'mth').sum()nOut20: n        costnid mth      n1  3      30n   4      30n   5      40n2  3      50n   4     130n   5      80nnnResetting the index at this point will give you unique months.nnIn 21: df.groupby('id' 'mth').sum().reset_index()nOut21: n   id  mth  costn0   1    3    30n1   1    4    30n2   1    5    40n3   2    3    50n4   2    4   130n5   2    5    80nnnIt's just a matter of grouping it again this time using mean instead of sum. This should give you the averages.nnLet us know if this helps.n""",['pandas'],['pandas']
40066840,"'DRF auth tokens fail in tests: django.template.response.ContentNotRenderedError: The response content must be rendered before it can be accessed' 'any time I try to read the response.content of hitting the usual /api-token-auth/ in my test I getnndjango.template.response.ContentNotRenderedError: The response content must be rendered before it can be accessed.nnnThis is not a template I am hitting the url using request factory. Using postman I get it each time:nnPOST: localhost:8000/api-token-auth/n{""username"": ""cchilders"" ""password"": ""blahblah""}nnBodyn{n  ""token"": ""4c3008f5130b94e15a52937b56a3cc0ae1e1ee79""n}nnncurl even works. tests do notnn$ http POST 127.0.0.1:8000/api-token-auth/ username='cchilders' password='blahblah'nHTTP/1.0 200 OKnAllow: POST OPTIONSnContent-Type: application/jsonnDate: Sun 16 Oct 2016 04:18:02 GMTnServer: WSGIServer/0.1 Jython/3.5.1nX-Frame-Options: SAMEORIGINnn{n    ""token"": ""4c3008f5130b94e15a522342j234234ae1e1ee79""n}nnntests:nnfrom django.contrib.auth.models import Usernfrom django.urls import reversennfrom model_mommy import mommynnfrom api.login.views import customer_loginnfrom api.mixins import AppUserViewsTestsnnnclass LoginViewTests(AppUserViewsTests):nn    def setUp(self):n        super().setUp()n        self.view = customer_loginn        self.token_url = reverse('auth-token')n        self.token_test_url = reverse('api:login:token-test')n        self.payload = {'username': 'cchilders' 'password': 'blahblah'}n        self.make_user()nn    def test_auth_token_works(self):n        response = self.run_assertion_test(self.token_url data=self.payload expected_status_code=200)n        import ipdb; ipdb.set_trace()n        # can't do response.content or response.METAnn    def test_protected_url_with_no_token_given_fails_400(self):n        self.run_assertion_test(self.token_test_url expected_status_code=400)nn    def test_protected_url_with_token_given_works(self):n        response = self.call_view(self.token_url data=self.payload)n        self.run_assertion_test(self.token_test_url expected_status_code=200)nn    def make_user(self):n        user = mommy.make(User **self.payload)nnnthe mixinnnfrom copy import copynnfrom django.contrib.auth.models import Usernfrom django.test import TransactionTestCasenfrom rest_framework.test import APIRequestFactorynnfrom users.models import AppUsernnnclass AppUserViewsTests(TransactionTestCase):nn    def setUp(self):n        self.factory = APIRequestFactory()n        self.test_email = ""fake@fake.com""n        self.phone_number = ""8135555555""n        self.base_data = {n            ""first_name"": ""John""n            ""last_name"": ""Doe""n            ""email"": self.test_emailn            ""password"": ""password""n        }nn    def tearDown(self):n        self.clear_test_user()nn    def run_assertion_test(self url=None method='post' data=None expected_status_code=None):n        response = self.call_view(url method=method data=data)n        self.assertEqual(response.status_code expected_status_code)n        return responsenn    def call_view(self url method='post' data=None):n        request = getattr(self.factory method)(url data=data content_type='application/json')# format='json')n        response = self.view(request)n        return responsenn    def create_user_and_app_user(self):n        new_user = User.objects.create(**self.user_creation_data)n        new_user.save()n        new_app_user = AppUser(user=new_user phone_number=self.phone_number)n        new_app_user.save()nn    def clear_test_user(self):n        try:n            app_user = AppUser.objects.get(user__username=self.test_email)n            app_user.delete()n        except:n            pass # all is wellnn    @propertyn    def request_data(self):n        this_data = copy(self.base_data)n        this_data.update({'phone_number': self.phone_number})n        return this_datann    @propertyn    def user_creation_data(self):n        this_data = copy(self.base_data)n        this_data.update({'username': self.test_email})n        return this_datannnwhy can't I test this auth-token endpoint and retrieve the token? Thank youn' nan",['django'],['django']
40066876,"'Subprocess not capturing the output of stdout storing it inside a variable in Python' 'I tried the below code to capture the output from screen using the sub-process but its not doing what I intended to do.nn#!/tools/bin/pythonnnimport subprocessnnresult = subprocess.check_output(""echo $USERNAME"" shell=True)nprint resultnnnexpected output is:nnvimo nvimo nnni.e. one for the echo process and one for printing the result output. nBut what I see is nnvimonnnBut when I try to print the result output its always empty.nnWhat am I missing in the above puzzle !! Help out !!n' ""Here you goes some greatly stripped (and altered for privacy reasons) raw dummy  piece of code grabbing both stdin and stdout from external script output.nnfrom subprocess import Popen PIPEnncmd = 'echo' 'foo'nnproc = Popen(cmd stdout=PIPE stderr=PIPE)ncomm = proc.communicate()nnif proc.returncode != 0:n    # code to handle / parse stderr (comm1)n    raise RuntimeError(n        ''%s': command has failed (%d):n%s'n        % ('some value' proc.returncode comm1))nnfor line in comm0.split('n'):n    if line.find('Wrote:') == 0:n        # some code to parse stdoutn        passnn""",['python-2.7'],['python-2.7']
40066877,'django stream json data that is created by request' 'how can we stream data in django i saw many tutorials but still can figure it out ni requested a data inside view.py and send it through the context to template.html but i want to update the data once it got changed so i need to keep sending request but how can i create that type of connection? nbasically some thing like this:nnwebserver ---------> Wsgi -----------> urls.py n      |                              |n      |                              |n      |     keep sending data        |        keep requesting datantemplat.html<--------------------- views.py -------------------------> requestnnni dont now if we need to use sockets or how to approach this problem.n' 'The most common use case of what you want to do is endless pagination when you have lots of data and you do not want to retrieve them in one request. Instead you request data multiple times and update your front end. nTry to use django-el-pagination django package it can help you with your problem. django-el-pagination on GitHub.n',['django'],['django']
40066882,"'How to transfer edit method of an ID to a button/links in Django?' 'This is the code in my ulrs.pynnurl(r'^viewguides/detail/(?P<id>d+)/edit/$' views.post_update name='update')nnnNow I want to make it look like this:nn<a href=""/detail/(?P<id>d+)/edit"" class=""btn btn-default btn-lg"" style=""background-color: transparent;""><font color=""Orange""> EDIT </font></a><hr>nnnSo that I can edit the certain ID that I want to. But it gives me an error. How do you do it? or is there any other way? I'm new to Django.n' 'You must use the url tag in your template something like this:nn<a href=""{% url update guide.id %}"">EDIT</a>nnnWhere ""update"" is the name found in urls.py and ""guide"" the instance you want to update.n' 'I just asked my colleagues who have some experience in Django. The answer is very simple.nnyou just need to create this function in ""models.py"" :nndef get_absolute_url(self):n    return ""/viewguides/detail/%s/"" %(self.id)nnnand then you can call it in the html by:nn<a href=""{{obj.get_absolute_url}}edit"" class=""btn"">EDIT</a>nnnEvery time you click the btn EDIT it will take you to the following edit page with the given id (id that contains the forms/models of the user).n'","['django', 'python-2.7']",['django']
40067081,"'How do I replace items in a file with items in a list' ""I have f1.txt a file in which I want to replace all occurrences of 999 with the consecutive elements of the list lst. I have the following code but it doesn't quite work. nnlst = '1' '2' '3' nf1 = open('f1.txt' 'r')nf2 = open('f2.txt' 'w')nfor no in lst:n  for line in f1:n    if 'some_text' in line:n      f2.write(line.replace('999' no))n      continuen    else:n      f2.write(line)nf1.close()nf2.close()nnnSample from f1.txt:nntags text somethingnsome_text blablabla 999nother text whatevernsome_text blablabla 999nnon interesting textnsome_text blablabla 999nnnThe result should be:nntags text somethingnsome_text blablabla 1nother text whatevernsome_text blablabla 2nnon interesting textnsome_text blablabla 3nnnCan you please help me?nnThank youn"" ""lst = '1' '2' '3' nf1 = open('f1.txt' 'r')nf2 = open('f2.txt' 'w')nidx = 0nfor line in f1:n    if ('some_text' in line) and ('999' in line):n      f2.write(line.replace('999' lstidx))n      idx += 1n    else:n      f2.write(line)nf1.close()nf2.close()nn""",['list'],"['python-2.7', 'list']"
40067128,"'Incorporate duplicates in a list of tuples into a dictionary summing the values' ""Hi I wish to convert this list of tuples into dictionary. As I am new to python I am figuring out ways to convert into dictionary. I could only convert into dictionary if there is only one value. In my case there are two values in it.I will demonstrate with more details below:nn    `List of tuples: ('Samsung' 'Handphone'10) ('Samsung' 'Handphone'-1)n('Samsung''Tablet'10)('Sony''Handphone'100)`nnnAs you can see above I wish to identify 'Samsung' as the key and 'Handphone' and '10' as the values with respect to the key.nnMy desired output would be:nn  `Output: {'Sony': 'Handphone'100 'Samsung': 'Tablet'10'Handphone' 9}`nnnAs you can see above the item 'handphone' and 'tablet' are group according to the key values which in my case is Sony and Samsung. The quantity of the item are are added / subtracted if they belong to the same item and same key (Samsung or Sony).nnI would really appreciate any suggestions and ideas that you guys have in order to achieve the above output. I really ran out of ideas. Thank you. n"" ""You can do this with a dictionary comprehensionnnWhat you really want are tuples for keys which will be the company and the device.nntuples = ('Samsung' 'Handphone'10) n          ('Samsung' 'Handphone'-1)n          ('Samsung''Tablet'10)n          ('Sony''Handphone'100)nnd = {}nfor company device n in tuples:n    key = (company device)n    dkey = d.get(key 0) + nnn"" ""Good opportunity for defaultdictnnfrom collections import defaultdictnnthe_list = n    ('Samsung' 'Handphone' 10) n    ('Samsung' 'Handphone' -1) n    ('Samsung' 'Tablet' 10)n    ('Sony' 'Handphone' 100)nnnd = defaultdict(lambda: defaultdict(int))nnfor brand thing quantity in the_list:n    dbrandthing += quantitynnnResult will benn{n    'Samsung': {n        'Handphone': 9 n        'Tablet': 10n    }n    'Sony': {n        'Handphone': 100n    }n}nn"" ""Your output has a problem that can be seen with proper identation:nn{n    'Sony': 'Handphone'100 n    'Samsung': 'Tablet'10n    'Handphone' 9n}nnnHandphone isn't a part of 'Samsung' you can do a list of lists to get:nn{n    'Sony': n        'Handphone'100n    n    'Samsung': n        'Tablet'10n        'Handphone' 9n    n}nnnWith:nnmy_list = ('Samsung' 'Handphone'10) ('Samsung' 'Handphone'-1) ('Samsung''Tablet'10)('Sony''Handphone'100)nnresult = {}nfor brand device value in my_list:n    # first verify if key is present to add list for the first timen    if not brand in result:n        resultbrand = n    # then add new list to already existent listn    resultbrand += device valuennnBut I think the best format would be a dict:nn{n    'Sony': {n        'Handphone': 100n    }n    'Samsung': {n        'Tablet': 10n        'Handphone': 9n    }n}nnnThat would be like:nnmy_list = ('Samsung' 'Handphone'10) ('Samsung' 'Handphone'-1) ('Samsung''Tablet'10)('Sony''Handphone'100)nnresult = {}nfor brand device value in my_list:n    # first verify if key is present to add dict for the first timen    if not brand in result:n        resultbrand = {}n    # then add new key/value to already existent dictn    resultbranddevice = valuenn""","['list', 'dictionary']","['dictionary', 'list', 'python-2.7']"
40067182,"'ImportError: No module named app.views django 1.10 python' 'I just have started learning django in its 1.10 version. In a project (called refugio) I have created an app called mascota.nnThis is my views.py file for my app:nnfrom __future__ import unicode_literals absolute_importnfrom django.shortcuts import rendernfrom django.http import HttpResponsenn# Create your views here.ndef index(request):n    return HttpResponse(""Index"")nnnAlso I already have written my urls.py file for it:nnfrom django.conf.urls import urlnfrom apps.mascota.views import indexnnurlpatterns = n    url(r'^$/' index)nnnnAnd I have modified the url.py file of my project:nnfrom django.conf.urls import url includenfrom django.contrib import adminnnurlpatterns = n    url(r'^admin/' admin.site.urls)n    url(r'^' include('apps.mascota.urls'))nnnnBut when I run the server of my project it sends me the next error message:nnnIf it helps My dir tree is the following:nnREFUGIOn    appsn        mascotan            views.pyn            urls.pyn    refugion        settings.pyn        urls.pyn    manage.pynnnI know this is a dummy question but I don't know what is wrong I have already checked my urls sentences but I see everything ok.nnI will appreciate your help.nnPs.: My app is located inside a folder called apps.nnRegards.n' 'Change your file structure into nnREFUGIOn    mascotan        views.pyn        urls.pyn    refugion        settings.pyn        urls.pyn    manage.pynnnand then change the line in urls.py nnfrom apps.mascota.views import indexnnninto nnform mascota.views import indexnnnHope this helps.n' 'Every Python package need __init__.py file (read this and this).nnREFUGIOn    appsn        mascotan            __init__.pyn            views.pyn            urls.pyn        __init__.pyn    refugion        __init__.pyn        settings.pyn        urls.pyn    manage.pynn'",['django'],['django']
40067243,"'matplotlib adding blue shade to an image' 'I am trying to use matplotlib for basic operations but I see that whenever I try to display an image using matplotlib a blue shade is added to the image. nnFor example nnCode:nn# import the necessary packagesnimport numpy as npnimport cv2nimport matplotlib.pyplot as pltnnimage = cv2.imread(""./data/images/cat_and_dog.jpg"")ncv2.imshow('image'image) # Display the picturennnplt.imshow(image)nplt.show()nncv2.waitKey(0) # wait for closingncv2.destroyAllWindows() # Ok destroy the windownnnAnd the images shown by opencv gui and matplotlib are different.nnnnEven the histogram is distorted and not just the displaynnnnHow do I avoid this blue shade on an imagen' 'see: http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html#using-matplotlibnnn  Warning: Color image loaded by OpenCV is in BGR mode. But Matplotlibn  displays in RGB mode. So color images will not be displayed correctlyn  in Matplotlib if image is read with OpenCV. Please see the exercisesn  for more details.nnnyou can replace your plt.imshow(image) line with the following lines:nnim2 = image.copy()nim2: : 0 = image: : 2nim2: : 2 = image: : 0nplt.imshow(im2)nn'",['matplotlib'],['matplotlib']
40067276,"'Optimization of iterating over long list of string' ""The below snippet of code executes in about 18s. EdgeList is estimated to be 330K in length. Is there a way to optimize it considering that I am calling it multiple times.nnI have tried optimizing the insertion into my MeanspeedDict. But I guess it's the best it can go already?     nn    EdgeList = traci.edge.getIDList() #Returns a list of Stringsn    for edge in EdgeList:n        meanspeed = traci.edge.getLastStepMeanSpeed(edge) #returns a float valuen        '''n        if edge in MeanspeedDict:n            MeanspeedDictedge.append(meanspeed)n            MeanspeedDictedge = MeanspeedDictedge-300: #Only keep the last 300 valuesn        else:n            MeanspeedDictedge = meanspeedn        '''n        try:n            MeanspeedDictedge.append(meanspeed)n            MeanspeedDictedge = MeanspeedDictedge-300: #Only keep the last 300 valuesn        except KeyError:n            MeanspeedDictedge = meanspeednnnProfile Data as per request. Running it 11 timesnn         252229348 function calls in 295.056 secondsnn   Ordered by: standard namenn   ncalls  tottime  percall  cumtime  percall filename:lineno(function)n        1    0.000    0.000  295.056  295.056 <string>:1(<module>)n        1    0.000    0.000   40.158   40.158 __init__.py:101(getVersion)n        1    0.000    0.000    4.908    4.908 __init__.py:105(close)n        1    0.000    0.000    0.000    0.000 __init__.py:111(switch)n        1    0.000    0.000    0.507    0.507 __init__.py:45(connect)n        1    0.000    0.000    0.000    0.000 __init__.py:49(normalize_encoding)n        1    0.000    0.000   40.665   40.665 __init__.py:64(init)n        1    0.000    0.000    0.008    0.008 __init__.py:71(search_function)n       11    0.000    0.000    1.646    0.150 __init__.py:92(simulationStep)n  3607912    2.785    0.000  221.939    0.000 _edge.py:151(getLastStepMeanSpeed)n        1    0.000    0.000    0.000    0.000 codecs.py:92(__new__)n  3607923    5.689    0.000   16.796    0.000 connection.py:119(_beginMessage)n  3607923    3.451    0.000  210.529    0.000 connection.py:128(_sendReadOneStringCmd)n  3607923    8.231    0.000  190.282    0.000 connection.py:152(_checkResult)n       11    0.000    0.000    1.646    0.150 connection.py:254(simulationStep)n        1    0.000    0.000   40.158   40.158 connection.py:273(getVersion)n        1    0.000    0.000    4.908    4.908 connection.py:285(close)n        1    0.000    0.000    0.507    0.507 connection.py:48(__init__)n  3607923    4.167    0.000    8.645    0.000 connection.py:64(_packString)n  3607936   19.808    0.000  108.622    0.000 connection.py:72(_recvExact)n  3607936   19.507    0.000  200.505    0.000 connection.py:91(_sendExact)n       15    0.000    0.000    0.000    0.000 copy.py:123(_copy_inst)n       15    0.000    0.000    0.000    0.000 copy.py:66(copy)n       15    0.000    0.000    0.000    0.000 domain.py:108(_setConnection)n  3607923    4.273    0.000  236.643    0.000 domain.py:111(_getUniversal)n       11    0.004    0.000   17.493    1.590 domain.py:116(getIDList)n       15    0.000    0.000    0.000    0.000 domain.py:37(__init__)n      495    0.000    0.000    0.000    0.000 domain.py:47(reset)n       15    0.000    0.000    0.000    0.000 domain.py:99(_register)n        1    0.000    0.000    0.000    0.000 latin_1.py:13(Codec)n        1    0.000    0.000    0.000    0.000 latin_1.py:20(IncrementalEncoder)n        1    0.000    0.000    0.000    0.000 latin_1.py:24(IncrementalDecoder)n        1    0.000    0.000    0.000    0.000 latin_1.py:28(StreamWriter)n        1    0.000    0.000    0.000    0.000 latin_1.py:31(StreamReader)n        1    0.000    0.000    0.000    0.000 latin_1.py:34(StreamConverter)n        1    0.000    0.000    0.000    0.000 latin_1.py:41(getregentry)n        1    0.000    0.000    0.000    0.000 latin_1.py:8(<module>)n        1    0.000    0.000    0.000    0.000 six.py:180(find_module)n        1    0.000    0.000    0.000    0.000 six.py:184(find_module)n        1    0.001    0.001    0.001    0.001 socket.py:189(__init__)n        1    0.000    0.000    0.000    0.000 socket.py:196(close)n        2    0.000    0.000    0.506    0.253 socket.py:227(meth)n  3607936    1.590    0.000    1.590    0.000 storage.py:32(__init__)n 39687197   29.658    0.000   39.432    0.000 storage.py:36(read)n       12    0.000    0.000    0.000    0.000 storage.py:41(readInt)n  3607912    1.564    0.000    5.345    0.000 storage.py:44(readDouble)n  3607924    1.712    0.000    5.389    0.000 storage.py:47(readLength)n 10823772   17.543    0.000   50.373    0.000 storage.py:53(readString)n       11    1.922    0.175   16.496    1.500 storage.py:57(readStringList)n        1    0.000    0.000    0.000    0.000 subprocess.py:458(_cleanup)n        1    0.000    0.000    0.000    0.000 subprocess.py:578(list2cmdline)n        1    0.000    0.000    0.045    0.045 subprocess.py:651(__init__)n        1    0.000    0.000    0.000    0.000 subprocess.py:811(_get_handles)n        3    0.000    0.000    0.000    0.000 subprocess.py:881(_make_inheritable)n        1    0.000    0.000    0.045    0.045 subprocess.py:905(_execute_child)n        3    0.000    0.000    0.000    0.000 subprocess.py:946(_close_in_parent)n        1    6.670    6.670  295.056  295.056 traciTest_meanspeed.py:45(runTraCI)n        1    0.007    0.007    0.007    0.007 {__import__}n 39687197    3.728    0.000    3.728    0.000 {_struct.calcsize}n 10823795    3.374    0.000    3.374    0.000 {_struct.pack}n 43295133    7.225    0.000    7.225    0.000 {_struct.unpack}n        1    0.045    0.045    0.045    0.045 {_subprocess.CreateProcess}n        3    0.000    0.000    0.000    0.000 {_subprocess.DuplicateHandle}n        6    0.000    0.000    0.000    0.000 {_subprocess.GetCurrentProcess}n        1    0.000    0.000    0.000    0.000 {_subprocess.GetStdHandle}n        4    0.000    0.000    0.000    0.000 {built-in method Close}n        1    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x1E22B4F8}n        8    0.000    0.000    0.000    0.000 {getattr}n       61    0.000    0.000    0.000    0.000 {hasattr}n        6    0.000    0.000    0.000    0.000 {isinstance}n 32471566    2.246    0.000    2.246    0.000 {len}n        3    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}n 10496061    2.479    0.000    2.479    0.000 {method 'append' of 'list' objects}n      990    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}n        1    0.506    0.506    0.506    0.506 {method 'connect' of '_socket.socket' objects}n 10823772   12.557    0.000   12.565    0.000 {method 'decode' of 'str' objects}n        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}n  3607923    3.371    0.000    3.371    0.000 {method 'encode' of 'str' objects}n        2    0.000    0.000    0.000    0.000 {method 'fileno' of 'file' objects}n       17    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}n        2    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}n  7215956   84.503    0.000   84.503    0.000 {method 'recv' of '_socket.socket' objects}n        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}n  3607936   46.414    0.000   46.414    0.000 {method 'send' of '_socket.socket' objects}n        1    0.000    0.000    0.000    0.000 {method 'setsockopt' of '_socket.socket' objects}n        1    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}n        1    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}n        1    0.000    0.000    0.000    0.000 {method 'translate' of 'str' objects}n       15    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}n       11    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}n        2    0.000    0.000    0.000    0.000 {msvcrt.get_osfhandle}n       12    0.023    0.002    0.023    0.002 {range}n       27    0.000    0.000    0.000    0.000 {setattr}n        1    0.000    0.000    0.000    0.000 {sys.exit}n       22    0.000    0.000    0.000    0.000 {time.clock}nn"" 'from collections import deque defaultdictnnMeanspeedDict = defaultdict(lambda: deque(maxlen=300))nnEdgeList = traci.edge.getIDList()nfor edge in EdgeList:n    MeanspeedDictedge.append(traci.edge.getLastStepMeanSpeed(edge))nn' 'It seems getLastStepMeanSpeed is too slow:nn3607912    2.785    0.000  221.939    0.000 _edge.py:151(getLastStepMeanSpeed)nnnThe script spend executing it 75% of the time (221/295)n'",['python-2.7'],['python-3.x']
40067293,'Pandas annotate dataframe hist' 'df = { 'id' : pd.Series(1111222233444)}nnnum_id = df'id'.value_counts().hist(bins=2)nnnI an get a nice histogram with the count of number of ids that fall into each bin. nnQuestion is how do i add annotations to each bar to show the count? It could be in the middle with white text. nnI know there is an ax parameter that we can specify in hist() but i am not sure how. nnn' 'Here you are (with the import statements just in case):nnimport pandas as pdnimport matplotlib.pyplot as pltnndf = pd.DataFrame({ 'id' : 1111222233444})nnfig ax = plt.subplots()nfreq bins _ = ax.hist(df'id'.value_counts() 2 facecolor='skyblue')nax.grid(True)nfor i n in enumerate(freq):n    ax.text(binsi+0.5 2 n)nax.set_xlabel('Bins')nax.set_ylabel('Freq')nplt.show()nnnn',"['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40067538,"'string input from Python list' 'i Want to make a very simple script that will do the following:nn1- I have a List Named tries = ""First"" ""Second"" ""Last""nn2- I want the user will make an input string for each trynnso I made script as below:nnprint(""You got 3 Guessing tries to guess What is My Name"")nntries = ""First"" ""Second"" ""Last""nnfor x in tries:n    Names = str(input(x""Guess ?""))nn    print(Names)nnnbut it seems that Python doesn't accept this line: Names = str(input(x""Guess ?""))nnso any suggestions how to make the Questions to be appearing to the user as:  ""First Guess?"" then ""Second Guess?"" then ""last guess?"" n' 'The input function takes only one arguments. Here you give two to it.nnI'm guessing that what you want to do isnnprint(""You got 3 Guessing tries to guess What is My Name"")nntries = ""First"" ""Second"" ""Last""nnfor x in tries:n    Names = str(input(""{} Guess ?"".format(x))) nn    print(Names)nnnIf you want more about format: on devdocsnnMattn' 'first off the str() is not needed because input always outputs a stringnnsecondly this is python 3.x not 2.7 (in the tagging)nnthird the issue you are having is you are trying to give input 2 parameters this works with print and that throws new python coders off but other functions won't allow it. you can fix it by simply adding the two strings together like this input(x+""Guess ?"")n'","['python-2.7', 'python-3.x']","['python-3.x', 'python-2.7']"
40067586,'Matplotlib combine polar and cartesian axis' 'I want to combine polar and cartesian axis in matplotlib. I want color bar outside the square box.nnnimport numpy as npnimport matplotlib.pyplot as pltn#-- Generate Data -----------------------------------------nazimuths = np.radians(np.linspace(0 360 20))nzeniths = np.arange(0 91 10)nr theta = np.meshgrid(zeniths azimuths)nvalues = np.random.random((azimuths.size zeniths.size))nn#-- Plot... ------------------------------------------------nfig=plt.figure()nrect=0.10.10.80.8nax_cartesian=fig.add_axes(rect)nax_cartesian.axis(-22-22)nax_polar=fig.add_axes(rectprojection='polar' polar=False frameon=True)nax_polar.axis('off')ns=ax_polar.contourf(theta r values100)nplt.gca().set_rmin(0.0)nfig.colorbar(s)nplt.show()nn' nan,['matplotlib'],['matplotlib']
40067593,"'How to assign variables to numpy matrix' 'I want to make a function to generate rotational matrix R. Here is my code:nnimport numpy as npndef R(theta):n    a = np.cos(theta)n    b = -1*np.sin(theta)n    c = np.sin(theta)n    d = np.cos(theta)n    return np.matrix('a b; c d')nnnBut it has error like thisnnraise TypeError(""Invalid data string supplied: "" + astr)nTypeError: Invalid data string supplied: annnAny suggestions?n' 'use .format to put the variables into string form nnreturn np.matrix('{} {};{} {}'.format(abcd))nn' ""That matrix notation:nna = np.matrix('1 2; 3 4')nnnonly works for literals not variables; with scalar variables you'd use the bracket notationnnnp.matrix(1 2 3 4)nnp.matrix(a b c d)nnnThis part a b c d is an ordinary Python list (of lists).  np.matrix(...) then takes this list and turns it into a numpy matrix.nnBut really you should be usingnnnp.array(...)nnnnp.matrix was written to make things familiar to MATLAB visitors.  Most numpy work is the array not matrix.nnAnother point - a = np.cos(theta) works with theta is scalar or an array.  But if an array than a itself will be an array not a scalar.  You should be aware of that when constructing this rotation matrix.n""",['numpy'],['numpy']
40067790,"""Trying to Solve Numerical Diff Eq Using Euler's Method Invalid Value Error"" 'I am trying to learn it from this website: http://nbviewer.jupyter.org/github/numerical-mooc/numerical-mooc/blob/master/lessons/01_phugoid/01_03_PhugoidFullModel.ipynbnnI was trying to code it with as little help as possible but I kept getting this error:nnC:Users""My Real Name""Anaconda2libsite-packagesipykernel__main__.py:29: RuntimeWarning: invalid value encountered in double_scalarsnnWith no data points on my plot. So I literally pasted all the code in directly from the website and I still get there error! I give up can someone help a python newbie?nnimport numpy as npnfrom matplotlib import pyplotnfrom math import sin cos log ceiln%matplotlib inlinenfrom matplotlib import rcParamsnrcParams'font.family' = 'serif'nrcParams'font.size' = 16nn# model parameters:ng = 9.8      # gravity in m s^{-2}nv_t = 30.0   # trim velocity in m s^{-1}   nC_D = 1/40  # drag coefficient --- or D/L if C_L=1nC_L = 1   # for convenience use C_L = 1nn### set initial conditions ###nv0 = v_t     # start at the trim velocity (or add a delta)ntheta0 = 0 # initial angle of trajectorynx0 = 0     # horizotal position is arbitraryny0 = 1000  # initial altitudennnndef f(u):nn    v = u0n    theta = u1n    x = u2n    y = u3n    return np.array(-g*sin(theta) - C_D/C_L*g/v_t**2*v**2 -g*cos(theta)/v + g/v_t**2*v v*cos(theta) v*sin(theta))nndef euler_step(u f dt):n    u + dt * f(u)nnT = 100                          # final timendt = 0.1                           # time incrementnN = int(T/dt) + 1                  # number of time-stepsnt = np.linspace(0 T N)      # time discretizationnn# initialize the array containing the solution for each time-stepnu = np.empty((N 4))nu0 = np.array(v0 theta0 x0 y0)# fill 1st element with initial valuesnn# time loop - Euler methodnfor n in range(N-1):n    un+1 = euler_step(un f dt)nnnnnnx = u:2ny = u:3nnnpyplot.figure(figsize=(86))npyplot.grid(True)npyplot.xlabel(r'x' fontsize=18)npyplot.ylabel(r'y' fontsize=18)npyplot.title('Glider trajectory flight time = %.2f' % T fontsize=18)npyplot.plot(xy 'k-' lw=2);nn' 'The solution is very simple. You forgot the return statement in euler_step.nChangenndef euler_step(u f dt):n    u + dt * f(u)nnntonndef euler_step(u f dt):n    return u + dt * f(u)nnnand it will workn'","['numpy', 'matplotlib']","['matplotlib', 'numpy']"
40067806,"'Switching database backend in Mezzanine' ""I am trying to script a series of examples where the reader incrementally builds a web application. The first stage takes place with Mezzanine's default configuration using built-in SQLlite:nnsudo pip install mezzaninensudo -u mezzanine python manage.py createdb nnnAfter the initial examples are complete I want to switch the existing setup to a mysql backend. If that is too complex I at least want to re-create the built-in examples that come with Mezzanine on the new backend but Mezzanine won't allow re-running createdbnnCommandError: Database already created you probably want the migrate commandnnnThis seems like something that should be incredibly simple yet I can't seem to get it quite right (and migrate alone does not do the trick). Google and official docs not helping either.nnSteps I am taking: first I create a MySQL database on Amazon RDS. Then I set appropriate configuration for it in myapp/local_settings (I am sure these steps are correct). Then:nnsudo apt install python-mysqldbnsudo -u mezzanine python /srv/mezzanine/manage.py migratennnbut then:nnRunning migrations:n   No migrations to apply.nnnWhat am I missing?n"" 'The Mezzanine project is based on Django the Python framework.nUnless you encounter a Mezzanine specific problem most issues can be solved by figuring out how its done the Django way.nnMigrations is just Django's way of refering to alterations & amendments within the DB ie the schema (because apps evolve & databases are metamorphic).nnIn order to actually migrate the data however you could:nnnExport the contents from the current database eg:nn./manage.py dumpdata > db-dump-in-json.jsonn./manage.py --format=xml > db-dump-in-xml.xmlnnnThis may crash if there is too much data or not enough memory. Then the thing would be to use native DB tools to get the dump.nnnCreate and add the settings for the new DB in settings.py:nCreate the tables and set them up (based on your models) on the newly defined DB:nn./manage.py makemigrationsn./manage.py migratennncreatedb = syncdb (create) + migrate (set) combined nnnAnd reload the exported data there:nn./manage.py loaddata db-dump-in-json.jsonnn'",['django'],['django']
40067814,"'How to save a dictionary as a value of another dictionary in pymongo for flask?' 'I have a Json request that looks like this:nn{""name"":""jane"" ""family"": ""doe""n""address"":{""country"":""Iran"" ""State"": ""Ilam"" ""city"": ""ilam""}n""age"": ""25"" }nnnand i can get the values into a variable using:nnname = request.json'name'nfamily = requst.json'family'nage = requst.json'age'nnnbut how do i get the address field and save it to a variable?n' 'If you have the following dictionary 'address' is a dictionary that is nested in another dictionary:nn{""name"":""jane"" ""family"": ""doe""n""address"":{""country"":""Iran"" ""State"": ""Ilam"" ""city"": ""ilam""}n""age"": ""25"" }nnnExtracting the address is done in the following way:nnaddress = request.json'address'nn>>> addressn{'country': 'Iran' 'State': 'Ilam' 'city': 'ilam'}nnnAddress that you extracted is now a new dictionary and you need to extract values from it like this:nnstate = address'State'ncity = address'city'ncountry = address'country'nn'",['dictionary'],"['dictionary', 'python-2.7']"
40067822,"'Remove numbers from list which contains some particular numbers in python' 'Given List:nnl = 13252333613525nnnI am having a number 23 as an output of some particular function.nnNow nnI want to remove all the numbers from list which contains either 2 or 3 or both 2 and 3.nnOutput should be:1nnnI want to write some cool one liner code.nnPlease help!nnMy approach was :nn1.) Convert list of int into list of string.nn2.) then use for loop to check for either character 2 or character 3 like this:nA=x for x in l if ""2"" not in x (not sure for how to include 3 also in this line)nn3.) Convert A list into integer list using :nnB= int(numeric_string) for numeric_string in AnnThis process is quiet tedious as it involves conversion to string of the number 23 as well as all the numbers of list.I want to do in integer list straight away.n' 'You could convert the numbers to sets of characters:nn>>> values = 1 32 523 336 13525n>>> number = 23n>>> value for value in valuesn...  if set(str(number)).isdisjoint(set(str(value)))n1nn' ""You're looking for the filter function.  Say you have a list of ints and you want the odd ones only:nndef is_odd(val):n   return val % 2 == 1nnfilter(is_odd range(100))nnnor a list comprehensionnnx for x in range(100) if x % 2 == 1nnnThe list comprehension in particular is perfectly Pythonic.  All you need now is a function that returns a boolean for your particular needs.n""","['list', 'python-2.7', 'python-3.x']","['list', 'python-2.7']"
40067900,"'How do you define a function during dynamic Python type creation' '(This is in Python 3 btw)nnOkay so say we use type() as a class constructor:nnX = type('X' () {})nnWhat I'm trying to find is how would type() accept a function as an argument and allow it to be callable? nnI'm looking for an example of how this could be accomplished. Something along the lines of:nn>>> X = type('X' () {'name':'World' 'greet':print(""Hello {0}!"".format(name))}n>>> X.greet()nHello World!nn' 'You need to pass the function.  In your code you call the function and pass the result.nnTry:nndef print_hello(self):n    print(""Hello {0}!"".format(self.name))nnX = type('X' () {'name':'World' 'greet': print_hello})nn'",['python-3.x'],['python-3.x']
40068295,"""Django inlineformset - 'CapForm' object has no attribute 'cleaned_data'"" ""I am facing attribute errornn'CapForm' object has no attribute 'cleaned_data'nnnThis is my post methodnndef post(selfrequest*args**kwargs):n        user = request.user.idn        form = SesForm(request.POSTrequest.FILESuser=request.user)n        if form.is_valid():n            frm = form.save(commit=False)n            frm.user = request.usern            frm.status = Falsen            obj = frm.save()nn            cap_formset = CapFormSet(request.POST)n            cap_formset.instance = frm    # Tried obj also it throws - 'NoneType' object has no attribute '_state'n            cap_formset.save()nnnMy Formnnclass CapForm(forms.ModelForm):n    title = forms.CharField(label=_('Cap'))n    class Meta:n        model = Capn        fields = ('title')n    def __init__(self*args**kwargs):n        super(CapFormself).__init__(*args**kwargs)n        for name field in self.fields.iteritems():n            field.widget.attrs.update({'class': 'form-control' 'placeholder': field.label})nnnFormset declarationnnCapFormSet = inlineformset_factory(Ses Cap form=CapForm extra=1 can_delete=True)nnnCan any one help me pointing where the issue isn"" ""You've called is_valid on SesForm but not on CapFormSet.n""",['django'],['django']
40068308,"'How can I gradually free memory from a numpy array?' ""I'm in a situation where I'm constantly hitting my memory limit(I have 20G of RAM). Somehow I managed to get the huge array into memory and carry on my processes. Now the data needs to be saved onto the disk. I need to save it in leveldb format.nThis is the code snippet responsible for saving the normalized data onto the disk:nnprint 'Outputting training data'nnleveldb_file = dir_des + 'svhn_train_leveldb_normalized'nbatch_size = size_trainnn# create the leveldb filendb = leveldb.LevelDB(leveldb_file)nbatch = leveldb.WriteBatch()ndatum = caffe_pb2.Datum()nnfor i in range(size_train):n    if i % 1000 == 0:n        print inn    # save in datumn    datum = caffe.io.array_to_datum(data_traini label_traini)n    keystr = '{:0>5d}'.format(i)n    batch.Put( keystr datum.SerializeToString() )nn    # write batchn    if(i + 1) % batch_size == 0:n        db.Write(batch sync=True)n        batch = leveldb.WriteBatch()n        print (i + 1)nn# write last batchnif (i+1) % batch_size != 0:n    db.Write(batch sync=True)n    print 'last batch'n    print (i + 1)nnnNow my problem is I hit my limit pretty much at the very end (495k out of 604k items that need to be saved to the disk) when saving to the disk.  nnto get around this issue I thought after writing each batch I release the corresponding memory from the numpy array (data_train) since it seems leveldb writes the data in a transaction manner and until all the data are written they are not flushed to the disk!nMy second thought is to somehow make the write non-transactional and when each batch is written using the db.Write it actually saves the content to the disk. nnI dont know if any of these ideas are applicable so any help is greatly appreciated . n"" nan",['numpy'],['numpy']
40068572,"'Python: String slice in pandas DataFrame is a series? I need it to be convertible to int' 'I have a problem that has kept me up for hours. I need to slice a string variable in a pandas DataFrame and extract an he numerical value (so I can perform a merge). (as a way to provide context the variables is the result of .groupby ... and now am trying to merge in additional information. nnGetting the number out of a string should be easy. nnBasically I am doing the following: nnstring = x_1 nnumber = string2:nnumber == 2net voila! nnnTo that goal let's build up codennIn 32: import pandas as pdn    ...: d = {'id' : 1 2 3 4n    ...:     'str_id' : 'x_2' 'x_4' 'x_8' 'x_1'}n    ...: nnIn 33: df= pd.DataFrame(d)nnIn 34: df.head()nOut34: n   id str_idn0   1    x_2n1   2    x_4n2   3    x_8n3   4    x_1nnIn 35: df'num_id'=df.str_id.str2:nnIn 36: df.head()nOut36: n   id str_id num_idn0   1    x_2      2n1   2    x_4      4n2   3    x_8      8n3   4    p_1      1nnIn 37: df.dtypesnOut37: nid         int64nstr_id    objectnnum_id    objectndtype: objectnnnThe result LOOKS good -- we have an object so we'll just convert to int and be golden right? Sadly not so much. nnIn 38: df'num_id3' = int(df'num_id')nTraceback (most recent call last):nn  File ""<ipython-input-38-50312cced30b>"" line 1 in <module>n    df'num_id3' = int(df'num_id')nn  File ""/Users/igor/anaconda/lib/python2.7/site-packages/pandas/core/series.py"" line 92 in wrappern    ""{0}"".format(str(converter)))nnTypeError: cannot convert the series to <type 'int'>nnnok let's try something simpler ---stripping leading and trailing blanks nn In 39: df'num_id3' = (df'num_id').strip()nTraceback (most recent call last):nn  File ""<ipython-input-39-0af6d5f8bb8c>"" line 1 in <module>n    df'num_id3' = (df'num_id').strip()nn  File ""/Users/igor/anaconda/lib/python2.7/site-packages/pandas/core/generic.py"" line 2744 in __getattr__n    return object.__getattribute__(self name)nnAttributeError: 'Series' object has no attribute 'strip'nnnSo .. somehow I have a series object ... with a single item in it ... I have not been able to get the series object to convert to anything usablennPlease will you help?!nThanks!n' 'You can't use int(Series) construction (it's similar to int('1''2''3') which also won't work) you should use Series.astype(int) or better pd.to_numeric(Series) instead:nnIn 32: dfnOut32:n   id str_idn0   1    x_2n1   2    x_4n2   3    x_8n3   4    x_1n4   5  x_AAAnnIn 33: df'num_id' = pd.to_numeric(df.str_id.str.extract(r'_(d+)' expand=False))nnIn 34: dfnOut34:n   id str_id  num_idn0   1    x_2     2.0n1   2    x_4     4.0n2   3    x_8     8.0n3   4    x_1     1.0n4   5  x_AAA     NaNnn'",['pandas'],['pandas']
40068605,"'Scatter and Hist in one subplot in Python' 'Here is codenn    df = pd.DataFrame(3 * np.random.rand(4 2) columns='a' 'b')n    plt.subplot(121)n    df""a"".plot.box()n    plt.subplot(122)n    df.plot.scatter(x=""a"" y=""b"")n    plt.show()nnnOutput comes in two different windows as follows:-nnFigure 1nnnFigure 2nnnAlthough both should come in one window. Any advice where is mistaken' 'You need to specify which axis to draw on when you call scatter. This can be done by passing an ax = argument to the plotting function:nndf = pd.DataFrame(3 * np.random.rand(4 2) columns='a' 'b')nplt.subplot(121)ndf""a"".plot.box()nax = plt.subplot(122)ndf.plot.scatter(x=""a"" y=""b"" ax = ax)nplt.show()nn'","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40068655,'How to create factory boy with several child' 'I have two Django models like:  nnclass Country(models.Model):n    country_name = models.CharField(max_length=10)nnclass Resident(models.Model):n    country = models.ForeignKey('Country')n    name = models.CharField(max_length=10)n    age = models.PositiveSmallInteger()nnnand I want to Factory Boy create a Country with two children which have different attribute(s).nnFor example somefactory.create() creates FooCountry and FooCountry has two residents: nnname=Paul country=foo age=33nname=Jamse country=foo age=34nnnHow to do it?n' 'First write down CountryFactory and ResidentFactory (as described in FactoryBoy documentation). Then write your function:nndef create_country_with_residents():n    country = CountryFactory.create()n    ResidentFactory.create(country=country name=Paul age=33)n    ResidentFactory.create(country=country name=James age=34)n    return countrynn',['django'],['django']
40068842,"'What is proper workflow for insuring ""transactional procedures"" in case of exceptions' 'In programming web applications Django in particular sometimes we have a set of actions that must all succeed or all fail (in order to insure a predictable state of some sort). Now obviously when we are working with the database we can use transactions.nnBut in some circumstances these (all or nothing) constraints are needed outside of a database contextnn(e.g. If payment is a success we must send the product activation code or else risk customer complaints etc)nnBut lets say on some fateful day the send_code() function just failed time and again due to some temporary network error (that lasted for 1+ hours)nnShould I log the error and manually fix the problem e.g. send the mail manually  nnShould I set up some kind of work queue where when things fail they just go back onto the end of the queue for future retry?nnWhat if the logging/queueing systems also fail? (am I worrying too much at this point?)n' 'We use microservices in our company and at least once a month we have one of our microservices down for a while. We have Transaction model for the payment process and statuses for every step that go before we send a product to the user. If something goes wrong or one of the connected microservices is down we mark it like status=error and save to the database. Then we use cron job to find and finish those processes. You need to try something for the beginning and if does not fit your needs try something else.n'",['django'],['django']
40069001,"""Pandas and GGPlot 'Could not compare __index__ with block values' even after df.fillna(0)"" 'I am new to Pandas and GGPlot in Python. I am currently trying to plot something through nnggplot.ggplot(train_data'Survived' 'Pclass' ggplot.aes(x = pclass fill = survived)) + nggplot.geom_histogram(width=0.5) + nggplot.xlab(""Pclass"") + nggplot.ylab(""Total Count"") + nggplot.labs(fill = ""Survived"")nnnas shown in David Langer's Titanic tutorial.nHowever whenever I try this I get an (skip this paragraph if you think this is unnecessary)nnTypeError                                 Traceback (most recent call last)n<ipython-input-16-6fd52cf2ca6c> in <module>()n----> 1 ggplot.ggplot(train_data'Survived' 'Pclass' ggplot.aes(x = pclass fill = survived)) + ggplot.geom_histogram(width=0.5) + ggplot.xlab(""Pclass"") + ggplot.ylab(""Total Count"") + ggplot.labs(fill = ""Survived"")nn/Users/davidal/anaconda/envs/py27/lib/python2.7/site-packages/ggplot/ggplot.pyc in __init__(self aesthetics data)n 53         self._aes = aestheticsn 54         self.data = data.copy()n---> 55         self._handle_index()n 56         self.data = self._aes._evaluate_expressions(self.data)n 57         self.data = self._aes.handle_identity_values(self.data)nn/Users/davidal/anaconda/envs/py27/lib/python2.7/site-packages/ggplot/ggplot.pyc in _handle_index(self)n132 n133     def _handle_index(self):n--> 134         if '__index__' in self._aes.values():n135             self.data'__index__' = self.data.indexn136 nn/usr/local/lib/python2.7/site-packages/pandas/core/ops.pyc in f(self other)n1182             # straight boolean comparisions we want to allow all columnsn1183             # (regardless of dtype to pass thru) See #4537 for discussion.n-> 1184             res = self._combine_const(other func raise_on_error=False)n1185             return res.fillna(True).astype(bool)n1186 nn/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc in _combine_const(self other func raise_on_error)n3553 n3554         new_data = self._data.eval(func=func other=othern-> 3555                                    raise_on_error=raise_on_error)n3556         return self._constructor(new_data)n3557 nn/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc in eval(self **kwargs)n2909 n2910     def eval(self **kwargs):n-> 2911         return self.apply('eval' **kwargs)n2912 n2913     def quantile(self **kwargs):nn/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc in apply(self f axes filter do_integrity_check consolidate raw **kwargs)n2888 n2889             kwargs'mgr' = selfn-> 2890             applied = getattr(b f)(**kwargs)n2891             result_blocks = _extend_blocks(applied result_blocks)n2892 nn/usr/local/lib/python2.7/site-packages/pandas/core/internals.pyc in eval(self func other raise_on_error try_cast mgr)n1151 n1152                 raise TypeError('Could not compare %s with block values' %n-> 1153                                 repr(other))n1154 n1155         # transpose if needednnnand finallynnTypeError: Could not compare u'__index__' with block valuesnnnI had assumed that the problem arises because there are 'None' values within the dataset but applyingnntrain_data.fillna(0)nnnleads in the same error message...nAny ideas what could have gone wrong and how I can overcome this problem? nnAny ideas are greatly appreciated! Thank you so much in advance!n' nan",['pandas'],"['pandas', 'matplotlib']"
40069059,"""Fastest way to merge 2 dictionaries if one dict's key equals to the other dict's values?"" ""Suppose I have 2 dictionariesnndict1 = {(111) : ('abc') (222) : ('def')} ndict2 = {('abc') : (123) ('def') : (456)}nnnWhat is the fastest way to produce a dict 3 such thatnndict3 = {(111):(123) (222):(456)}?n"" ""You can use a dictionary comprehension:nndict1 = {(111) : ('abc') (222) : ('def')} ndict2 = {('abc') : (123) ('def') : (456)}ndict3 = {k: dict2dict1k for k in dict1}nn>>> print dict3n{(2 2 2): (4 5 6) (1 1 1): (1 2 3)}nnnThis iterates over the keys of dict1 and using the corresponding value from dict1 as a key looks up the value in dict2. The key from dict1 and the value from dict2 are then combined to produce a new dictionary.nnNote that in Python 2 this should be slightly faster then using dict1.items() because that will build a temporary list. Similarly iterating over dict1.iteritems() returns an iterator which has to be created but that is neglible. Iterating directly over a dictionary's keys also incurs minimal overhead.n""",['dictionary'],"['dictionary', 'python-2.7', 'list']"
40069151,"'count the number of groups of consecutive digits in a series of strings' ""consider the pd.Series snnimport pandas as pdnimport numpy as npnnnp.random.seed(31415)np = (.35 .35 .1 .1 .1)ns = pd.DataFrame(np.random.choice('' 1 + list('abc') (10 20) p=p)).sum(1)nnsnn0    11111bbaacbbca1n1    1bab111aaaaca1an2    11aaa1b11a11a11n3     1ca11bb1b1a1b1n4        bb1111b1111n5       b1111c1aa111n6     1b1a111b11b1abn7        1bc111ab1ban8      a11b1b1b11111n9        1cc1ab1acc1ndtype: objectnnnnnI'm looking to count the number of groups of consecutive digits in each element of s.  Or how many integers are in each string.nnI'd expec the result to look likenn0    2n1    3n2    5n3    6n4    2n5    3n6    5n7    3n8    4n9    4ndtype: int64nnnI'm looking for efficiency though elegance is important too.n"" 'UPDATE: the idea is first to replace all consecutive groups of digist with single 1 and then delete everything which is not 1 and finally get the length of the changed string:nnIn 159: s.replace('d+' '^1+' '1' '' regex=True).str.len()nOut159:n0    2n1    3n2    5n3    6n4    2n5    3n6    5n7    3n8    4n9    4ndtype: int64nnnTiming against 100K Series:nnIn 160: %timeit big.replace('d+' '^1+' '1' '' regex=True).str.len()n1 loop best of 3: 1 s per loopnnIn 161: %timeit big.apply(lambda x: len(re.sub('D+' ' ' x).strip().split()))n1 loop best of 3: 1.18 s per loopnnIn 162: %timeit big.str.replace(r'D+' ' ').str.strip().str.split().str.len()n1 loop best of 3: 1.25 s per loopnnIn 163: big.shapenOut163: (100000)nnnTiming against 1M Series:nnIn 164: big = pd.concat(s * 10**5 ignore_index=True)nnIn 165: %timeit big.replace('d+' '^1+' '1' '' regex=True).str.len()n1 loop best of 3: 9.98 s per loopnnIn 166: %timeit big.apply(lambda x: len(re.sub('D+' ' ' x).strip().split()))n1 loop best of 3: 11.7 s per loopnnIn 167: %timeit big.str.replace(r'D+' ' ').str.strip().str.split().str.len()n1 loop best of 3: 12.6 s per loopnnIn 168: big.shapenOut168: (1000000)nnnExplanation:nnIn 169: s.replace('d+' '^1+' '1' '' regex=True)nOut169:n0        11n1       111n2     11111n3    111111n4        11n5       111n6     11111n7       111n8      1111n9      1111ndtype: objectnnnOLD (slow) answer:nnWhat about using .str.extractall() in conjunction with .groupby(level=0)?nnIn 130: s.str.extractall('(d+)').groupby(level=0).count()nOut130:n   0n0  2n1  3n2  5n3  6n4  2n5  3n6  5n7  3n8  4n9  4nnnExplanation:nnIn 131: s.str.extractall('(d+)')nOut131:n             0n  matchn0 0      11111n  1          1n1 0          1n  1        111n  2          1n2 0         11n  1          1n  2         11n  3         11n  4         11n3 0          1n  1         11n  2          1n  3          1n  4          1n  5          1n4 0       1111n  1       1111n5 0       1111n  1          1n  2        111n6 0          1n  1          1n  2        111n  3         11n  4          1n7 0          1n  1        111n  2          1n8 0         11n  1          1n  2          1n  3      11111n9 0          1n  1          1n  2          1n  3          1nn' 'This was my solutionnns.str.replace(r'D+' ' ').str.strip().str.split().str.len()nnn100000 rowsnnnp.random.seed(31415)np = (.35 .35 .1 .1 .1)ns = pd.DataFrame(np.random.choice('' 1 + list('abc') (100000 20) p=p)).sum(1)nnnn' ""PiRSquared and MaxU solutions are great.nnHowever I noticed apply is usually a bit faster than using multiple string methods.nnIn 142: %timeit s.apply(lambda x: len(re.sub('D+' ' ' x).strip().split()))n1 loop best of 3: 367 ms per loopnnIn 143: %timeit s.str.replace(r'D+' ' ').str.strip().str.split().str.len()n1 loop best of 3: 403 ms per loopnnIn 145: s.shapenOut145: (100000L)nn""",['pandas'],"['pandas', 'regex']"
40069199,"'Convert str bytes to bytes' 'I have a bluetooth controller which returns the data of a event in received_data where the 3 & 4 byte together are a 16 bit signed little-endian int value. nnWith python2 where a str is also a byte I just exctract it with struct.unpactnnrotation_value = struct.unpack(""<h"" received_data3 + received_data4)0nnnThis doesn't work with python3 because str and byte are not the same thingnnrotation_value = struct.unpack(""<h"" received_data3 + received_data4)0nTypeError: 'str' does not support the buffer interfacennnSo my approach was to just convert the str to bytes.nnhere are things I triednnprint((received_data3+received_data3).encode('utf_16_le'))nprint(received_data3.encode('ISO-8859-1') + received_data4.encode('ISO-8859-1'))nprint(int.from_bytes(bytes(ord(c) for c in (received_data3+received_data3)) byteorder='little' signed=True))nnprint(struct.unpack(""<h"" bytearray(received_data3 + received_data4 'cp1252'))0)nnnBut no matter how I do it I have allays error messages like these:nnUnicodeDecodeError: 'utf-8' codec can't decode byte 0xef in position 3: invalid continuation bytennnAs @PM 2Ring proposed to use latin1nnprint(received_data3.encode('latin1'))nnnWhich didn't work nnUnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 3: invalid continuation bytenUnicodeDecodeError: 'utf-8' codec can't decode byte 0xb6 in position 3: invalid start bytennnSo what exactly is the correct way to convert these fake str in bytes preferably a solution which works on python2 & 3. n' nan","['python-2.7', 'python-3.x']","['python-3.x', 'python-2.7']"
40069220,"'Is there a more Pythonic/elegant way to expand the dimensions of a Numpy Array?' 'What I am trying to do right now is:nnx = x: None  None  None  None  None  None  None  None  NonennnBasically I want to expand my Numpy array by 9 dimensions. Or some N number of dimensions where N might not be known in advance!nnIs there a better way to do this?n' ""One alternative approach could be with reshaping -nnx.reshape((-1) + (1)*N)  # N is no. of dims to be appendednnnSo basically for the None's that correspond to singleton dimensions we are using a shape of length 1 along those dims. For the first axis we are using a shape of -1 to push all elements into it.nnSample run -nnIn 119: x = np.array(2564)nnIn 120: x.reshape((-1) + (1)*9).shapenOut120: (4 1 1 1 1 1 1 1 1 1)nn""",['numpy'],['numpy']
40069307,"""Pandas: sep in read_csv doesn't work"" 'I try to read_csv nne29bea24f74b7fb26cb9c14ef8c3b10bozon.ru/context/detail/id/338495622016-03-27 01:08:4316Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦ne29bea24f74b7fb26cb9c14ef8c3b10bozon.ru/context/detail/id/247443472016-03-27 01:08:5944Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦ne29bea24f74b7fb26cb9c14ef8c3b10bozon.ru/context/detail/id/1351684382016-03-27 01:11:396Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦ne29bea24f74b7fb26cb9c14ef8c3b10bozon.ru/context/detail/id/332906892016-03-27 01:12:378Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦ne29bea24f74b7fb26cb9c14ef8c3b10bozon.ru/context/detail/id/316425442016-03-27 01:13:0714Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦n1cf378e0ba824651d9d80b076514bfe7citilink.ru2016-03-27 01:54:2212Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦n1cf378e0ba824651d9d80b076514bfe7citilink.ru/catalog/computers_and_notebooks/net_equipment/netcards/905202016-03-27 01:55:2620Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦n1cf378e0ba824651d9d80b076514bfe7citilink.ru/catalog/computers_and_notebooks/net_equipment/netcards/8968352016-03-27 01:55:5810Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦n1cf378e0ba824651d9d80b076514bfe7citilink.ru/catalog/computers_and_notebooks/net_equipment/netcards/8968402016-03-27 01:57:4852Ðxa0Âxa0Ð¡âx80ºÐxa0Âxa0Ðxa0âx80¦Ðxa0Âxa0Ðx92Â»Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð²âx80x9eâx80x93Ðxa0Âxa0Ðxa0âx80¦-Ðxa0Âxa0Ð¡Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ð¡âx80x93Ðxa0Âxa0Ðx92Â°Ðxa0Âxa0Ðx92Â·Ðxa0Âxa0Ð¡âx80x98Ðxa0Âxa0Ðxa0âx80¦nnnI usennnames = 'ID' 'url' 'date' 'duration' 'request' 'category'ndf = pd.read_csv('pv-lena11.csv' sep="""" header=None names=names)nnnbut it doesn't separate that.n' ""It works on my laptop.nnWhat's your pandas version? Is your file encoded as UTF-8? Can you try if this work?nndf = pd.read_csv(n    'pv-lena11.csv' sep='' header=None names=names n    quoting=0 encoding='utf8')nn""",['pandas'],['pandas']
40069358,"'I can not parse html using xpath and lxml library' 'I`m using Python 3.5.nI want to get a list of synonyms from the site with the help of XPATH but I do not get the required html code and get """".nnimport lxml.htmlnword=input(""Input your word: "")nurl = ""http://www.thesaurus.com/browse/{word}?s=t.html"".format(word=word)nhtml = lxml.html.parse(url)nsyn = html.xpath(""//DIV@id='filters-0'"")nprint(syn)nnnIf you are good at python then tell me how to do such a task more concise and simple.nBig thanks!n' 'Just imagining you need Synonyms extracted :nnimport requestsnfrom lxml import htmlnnsource = html.fromstring(((requests.get('http://www.thesaurus.com/browse/wordy?s=t.html')).text).encode('utf-8'))nprint (source.xpath('//div@class=""synonym-description""//text()')3.strip())nn' 'The xpath-syntax is case sensitive:nnsyn = html.xpath(""//div@id='filters-0'"")nprint(syn)nn'",['python-3.x'],['python-3.x']
40069551,"'How to save split data in panda in reverse order?' 'You can use this to create the dataframe:nnxyz = pd.DataFrame({'release' : '7 June 2013' '2012' '31 January 2013'n                                 'February 2008' '17 June 2014' '2013'})nnnI am trying to split the data and save them into 3 columns named ""day month and year"" using this command: nndataframe'day''month''year' = dataframe'release'.str.rsplit(expand=True) nnnThe resulting dataframe is :ndataframennAs you can see that it works perfectly when it gets 3 strings but whenever it is getting less then 3 strings it saves the data at the wrong place. nnI have tried split and rsplit both are giving the same result.nAny solution to get the data at the right place?nnThe last one is year and it is present in every condition  it should be the first one to be saved and then month if it is present otherwise nothing and same way the day should be stored.n' ""Try reversing the result. nndataframe'year''month''day' = dataframe'release'.str.rsplit(expand=True).reverse()nn"" ""You could nnIn 17: dataframe'year' 'month' 'day' = dataframe'release'.apply(n                                                    lambda x: pd.Series(x.split()::-1))nIn 18: dataframenOut18:n           release  year     month  dayn0      7 June 2013  2013      June    7n1             2012  2012       NaN  NaNn2  31 January 2013  2013   January   31n3    February 2008  2008  February  NaNn4     17 June 2014  2014      June   17n5             2013  2013       NaN  NaNnn""",['pandas'],['pandas']
40069562,"'Pickle: file or directory not found' ""When i execute below code I get the errornnimport picklenimport numpy as npnfrom random import gaussnnpath ='/flash/data/'na = gauss(1.5 2) for i in range(1000)npkl_file = open(path +'data.pkl' 'w')nn%time pickle.dump(a pkl_file)nnnI get the following error (even though i created /flash/data/)nnIOError Traceback (most recent call last)nn<ipython-input-4-ac470dd231a6> in <module>()nn      1 import picklenn----> 2 pkl_file = open (path + 'data.pkl''w')nn      3 get_ipython().magic(u'time pickle.dump(apkl_file)')nnIOError: Errno 2 No such file or directory: '/flash/data/data.pkl'nn"" nan",['numpy'],"['numpy', 'python-2.7']"
40069585,"""how can i fix AttributeError: 'dict_values' object has no attribute 'count'?"" 'here is my code and the text file is herennimport networkx as nxnimport pylab as pltnnwebg = nx.read_edgelist('web-graph.txt'create_using=nx.DiGraph()nodetype=int)nin_degrees = webg.in_degree()nin_values = sorted(set(in_degrees.values()))nin_hist = in_degrees.values().count(x)for x in in_valuesnnnI want to plot degree distribution web graph nhow can i change dict to solve?n' 'The error is obvious dict_values object has no attribute count. If you want to count the number of unique values the best way to go is using a collections.Counternnfrom collections import Counternin_hist = Counter(in_degrees.values())nn' 'If you want to count dictionary values you can do it like this:nnlen(list(dict.values()))nnnsame method works for keysnnlen(list(dict.keys()))nnnAlso keep in mind if you want to get all keys or values in list just use list(dict.values())n'",['python-3.x'],"['dictionary', 'matplotlib']"
40069621,"'One Character ""lag"" in Python 3 Curses Program' 'I'm attempting to create a roguelike using Python3 and curses. I've got everything displaying the way I want it to but I've come across a strange bug in the code. There is a 1 key stroke delay in processing the commands. So assuming traditional roguelike commands pressing ""k"" should move you 1 square to the right. The first time you press it it does nothing. The second time it will move. If you then press ""g"" you don't move back to the left instead the 2nd ""k"" gets processed and the ""g"" ends up ""on deck"". Here's the loop that's supposed to be processing the moves.nn  def main_loop(self):n#This will catch and handle all keystrokes. Not too happy with ifelifelif or case. Use a dict lookup eventuallyn    while 1:n      self.render_all()nn      c = self.main.getch()n      try:n        self.keybindingsc""function""(**self.keybindingsc""args"")n      except KeyError:n        continuennnAnd here is the dictionary lookup I promised myself I'd use in that commentnn    self.keybindings = {ord(""h""): {""function"":self.move_object n                               ""args"":{""thing"":self.things0 ""direction"":""North""}}n                        ord('j'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""South""}}n                        ord('g'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""West""}}n                        ord('k'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""East""}}n                        ord('y'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""NorthWest""}}n                        ord('u'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""NorthEast""}}n                        ord('b'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""SouthWest""}}n                        ord('n'): {""function"":self.move_objectn                               ""args"":{""thing"":self.things0 ""direction"":""SouthEast""}}n                        ord('l'): {""function"":self.look ""args"":{""origin_thing"":self.things0}}n                        ord('q'): {""function"":self.save_gamen                               ""args"":{""placeholder"":0}}}nnnFinally here is the move_object function that's supposed to be called:nn  def move_object(self thing direction): n""""""I chose to let the Game class handle redraws instead of objects.nI did this because it will make it easier should I ever attempt to rewritenthis with libtcod pygcurses or even some sort of browser-based thing.nDisplay is cleanly separated from obects and map data.nObjects use the variable name ""thing"" to avoid namespace collision.""""""n    curx = thing.xn    cury = thing.yn    newy = thing.y + directionsdirection0n    newx = thing.x + directionsdirection1n    if not self.is_blocked(newx newy):n      logging.info(""Not blocked"")n      thing.x = newxn      thing.y = newynnnEdited to cleanup code formatting.n' ""I found the problem and it wasn't in the code I posted. It was inside my render_all() function. I needed to add call to the window's refresh() function after making the changes I was making. I must say I really don't like curses!n""",['python-3.x'],['python-3.x']
40069683,'Matplotlib specific representation' 'I am studying the influence of diverse factors on the distribution of bikes throughout a bike- sharing system called Velib in paris. I have 1222 bike stations with their occupation rate their latitude and their longitude. I would like to make a map like this : n(http://images.google.fr/imgres?imgurl=http%3A%2F%2Fscipy-cookbook.readthedocs.org%2F_images%2Fgriddataexample1.png&imgrefurl=https%3A%2F%2Fwizardforcel.gitbooks.io%2Fscipy-cookbook-en%2Fcontent%2F37.html&h=288&w=432&tbnid=j0EtJS7s1utbYM%3A&docid=KQV-DInQ9QIq2M&ei=L2ADWJqUJ8L9aemiiYAJ&tbm=isch&client=safari&iact=rc&uact=3&dur=1229&page=13&start=324&ndsp=31&ved=0ahUKEwja57uTmN_PAhXCfhoKHWlRApA4rAIQMwg0KDEwMQ&bih=739&biw=1438) However i can't figure out a way to do it using marplotlib. For now i have this code but it is irrelevant to what i am trying to show: nnfor k in range(number gf bike stations):nnnT(k)/Tt is (occupation rate/average occupation rate) and R_0 is a list with all the data   nnif T(k)/Tt>1.5:      (if the occupation ratio is >1.5 i scatter a green dot and so on)n    ax.scatter(R_0k'position''lng'R_0k'position''lat' color='g' s=10)       nelif T(k)/Tt>1:      (yellow dot)n    ax.scatter(R_0k'position''lng'R_0k'position''lat' color='y' s=10)nelif T(k)/Tt>0.5:    (red dot)n    ax.scatter(R_0k'position''lng'R_0k'position''lat' color='r' s=10)nn' 'It seems like you need:nnmatplotlib.pyplot.contour(x y z)nmatplotlib.pyplot.contourf(x y z)nnnwith arguments x - latitude y - longitude and z - occupation rate. n',['matplotlib'],['matplotlib']
40069689,'âx80x8bHelp me! I would like to find split where the split sums are close to each other?' 'I have a list isnnn  test = 102030405060708090100nnnâx80x8band I would like to find split where the split sums are close to each other by number of splits = 3 that âx80x8ball possible combinations and select the split where the sum differences are smallest.nnplease example code or simple code Python.nnThank you very muchnnK.ademarusn' 'This first script uses a double for loop to split the input list into all possible triplets of lists. For each triplet it calculates the sum of each list in the triplet then creates a sorted list named diffs of the absolute differences of those sums. It saves a tuple consisting of diffs followed by the triplet into a list named all_splits. Finally it sorts all_splits and because each item in all_splits begins with diffs the saved tuples are sorted in order of their diffs from lowest to highest.nndef split_list_test(lst):n    all_splits = n    for i in range(1 len(lst) - 1):n        for j in range(i + 1 len(lst)):n            splits = lst:i lsti:j lstj:n            a b c = map(sum splits)n            diffs = sorted((abs(c-a) abs(c-b) abs(b-a)) reverse=True)n            all_splits.append((diffs splits))n    all_splits.sort()n    return all_splitsnntest = 10 20 30 40 50 60 70 80 90 100nnfor row in split_list_test(test):n    print(row)nnnoutputnn(60 40 20 10 20 30 40 50 60 70 80 90 100)n(60 40 20 10 20 30 40 50 60 70 80 90 100)n(140 110 30 10 20 30 40 50 60 70 80 90 100)n(140 120 20 10 20 30 40 50 60 70 80 90 100)n(160 90 70 10 20 30 40 50 60 70 80 90 100)n(170 90 80 10 20 30 40 50 60 70 80 90 100)n(180 110 70 10 20 30 40 50 60 70 80 90 100)n(200 110 90 10 20 30 40 50 60 70 80 90 100)n(200 140 60 10 20 30 40 50 60 70 80 90 100)n(200 150 50 10 20 30 40 50 60 70 80 90 100)n(210 160 50 10 20 30 40 50 60 70 80 90 100)n(240 130 110 10 20 30 40 50 60 70 80 90 100)n(240 220 20 10 20 30 40 50 60 70 80 90 100)n(240 230 10 10 20 30 40 50 60 70 80 90 100)n(250 250 0 10 20 30 40 50 60 70 80 90 100)n(260 260 0 10 20 30 40 50 60 70 80 90 100)n(270 260 10 10 20 30 40 50 60 70 80 90 100)n(280 190 90 10 20 30 40 50 60 70 80 90 100)n(280 190 90 10 20 30 40 50 60 70 80 90 100)n(300 160 140 10 20 30 40 50 60 70 80 90 100)n(310 160 150 10 20 30 40 50 60 70 80 90 100)n(330 190 140 10 20 30 40 50 60 70 80 90 100)n(330 290 40 10 20 30 40 50 60 70 80 90 100)n(340 180 160 10 20 30 40 50 60 70 80 90 100)n(340 310 30 10 20 30 40 50 60 70 80 90 100)n(350 300 50 10 20 30 40 50 60 70 80 90 100)n(370 280 90 10 20 30 40 50 60 70 80 90 100)n(390 260 130 10 20 30 40 50 60 70 80 90 100)n(390 320 70 10 20 30 40 50 60 70 80 90 100)n(410 390 20 10 20 30 40 50 60 70 80 90 100)n(420 380 40 10 20 30 40 50 60 70 80 90 100)n(430 340 90 10 20 30 40 50 60 70 80 90 100)n(440 360 80 10 20 30 40 50 60 70 80 90 100)n(460 460 0 10 20 30 40 50 60 70 80 90 100)n(480 440 40 10 20 30 40 50 60 70 80 90 100)n(510 500 10 10 20 30 40 50 60 70 80 90 100)nnnnnThe next script is a little more compact and it only returns a single solution. It uses a different rule to decide on the minimal split. If (a b c) are the sums of the lists in a triplet sorted from lowest to highest then the absolute differences of those sums are c-a c-b and b-a. The sum of the differences is c-a + c-b + b-a which is equal to 2*(c-a) so we can find the minimal split (using this rule) by looking for the split with the minimal value of c-a.nndef keyfunc(seq):n    sums = sorted(sum(u) for u in seq)n    return sums2 - sums0nndef split_list(lst):n    gen = (lst:i lsti:j lstj:n        for i in range(1 len(lst) - 1)n            for j in range(i + 1 len(lst)))n    return min(gen key=keyfunc)nntest = 10 20 30 40 50 60 70 80 90 100nprint(split_list(test))nnnoutputnn10 20 30 40 50 60 70 80 90 100nnnAs you can see for this test list this version gives the same solution as one of the minimal solutions found above.n',"['python-2.7', 'python-3.x']",['list']
40069694,"'Changing the value of groups with few members in a pandas data frame' ""I have a data frame which represent different classes with their values. for example:nndf=pd.DataFrame(n {'label':'a''a''b''a''b''b''a''c''c''d''e''c'n'date':123437121811253'value':np.random.randn(12)})nnnI want to choose the labels with values_counts less than a specific threshold and then put them into one class i.e. label them as for example 'zero'. nnThis is my attemp:nnvalue_count=df.label.value_counts()nthreshold = 3nfor index in value_countvalue_count.values<=threshold.index:n    df.labeldf.label==index='zero'nnnIs there a better way to do this?n"" ""You can use groupby.transform to get the value counts aligned with the original index then use it as a boolean index:nndf.locdf.groupby('label')'label'.transform('count') <= threshold 'label' = 'zero'nndfnOut: n    date label     valuen0      1     a -0.587957n1      2     a  0.341551n2      3  zero  0.516933n3      4     a  0.234042n4      3  zero -0.206185n5      7  zero  0.840724n6     12     a -0.728868n7     18  zero  0.111260n8     11  zero -0.471337n9      2  zero  0.030803n10     5  zero  1.012638n11     3  zero -1.233750nnnHere are my timings:nndf = pd.concat(df*10**4)nn%timeit df.groupby('label')'label'.transform('count') <= thresholdn100 loops best of 3: 7.86 ms per loopnn%%timeit nvalue_count=df.label.value_counts()ndf'label'.isin(value_countvalue_count.values<=threshold.index)n100 loops best of 3: 9.24 ms per loopnn"" ""You could donnIn 59: df.locdf'label'.isin(value_countvalue_count.values<=threshold.index)n 'label' = 'zero'nnIn 60: dfnOut60:n    date label     valuen0      1     a -0.132887n1      2     a -1.306601n2      3  zero -1.431952n3      4     a  0.928743n4      3  zero  0.278955n5      7  zero  0.128430n6     12     a  0.200825n7     18  zero -0.560548n8     11  zero -2.925706n9      2  zero -0.061373n10     5  zero -0.632036n11     3  zero -1.061894nnnTimingsnnIn 87: df = pd.concat(df*10**4 ignore_index=True)nnIn 88: %timeit df'label'.isin(value_countvalue_count.values<=threshold.index)n100 loops best of 3: 7.1 ms per loopnnIn 89: %timeit df.groupby('label')'label'.transform('count') <= thresholdn100 loops best of 3: 11.7 ms per loopnnIn 90: df.shapenOut90: (120000 3)nnnYou may want to benchmark with larger dataset. And this may not be aaccurate to compare since you're precomuting value_countn""",['pandas'],['pandas']
40069845,"'Plot each unique element of a column in a dataframe with partially overlapping y-Values' 'I hope I can explain this properly as I am new to pandas. I have the following dataframe in pandas.nnimport numpy as npnplant1 = {'Date' : pd.date_range('1/1/2011' periods=10 freq='D')n     'Plant' : pd.Series(""Plant1""*10)n     'Output' : pd.Series(abs(np.random.randn(10)))}nnplant2 = {'Date' : pd.date_range('1/3/2011' periods=10 freq='D')n     'Plant' : pd.Series(""Plant2""*10)n     'Output' : pd.Series(abs(np.random.randn(10)))}nnplant3 = {'Date' : pd.date_range('1/5/2011' periods=10 freq='D')n     'Plant' : pd.Series(""Plant3""*10)n     'Output' : pd.Series(abs(np.random.randn(10)))}     nnnndf_plant_1 = pd.DataFrame(plant1)ndf_plant_2 = pd.DataFrame(plant2)ndf_plant_3 = pd.DataFrame(plant3)nnsample = pd.concat(df_plant_1df_plant_2df_plant_3)nnnMy output is meant to be an area plot with each individual plant and the respective y-Value (Output) and x-value (Date). Notice that ""Dates"" are only partially overlapping.nnI am stuck at finding a way to meaningful organize my data. The first challenge is to merge the data for duplicate ""Date""-Values. The next step would be to fill the resulting holes in the series with .fillna(). The final step would be to plot for each unique ""Plant""-value.nnHowever I am already stuck at the first step. I am aware of the .merge function but don't know how to apply it to this case.nnThank you for your time and consideration.n' 'A user in the chat made me aware of the pivot-function.nntest = pd.pivot_table(sample index='Date' columns='Plant' values='Output')ntest = test.fillna(method='pad')                            ntest = test.fillna(method='bfill')        nnplt.figure(); test.plot(kind='area')nnnn'",['pandas'],['pandas']
40069922,'Retrieve word count from PDF with exclusion rules' 'I am in search of a module which can retrieve word count from a PDF document with the possibility to add exclusion rules (such as appendix content page front page and so forth).nnI have found the following module : PyPDF2. I could use it to create the functionality I want. Not sure how to handle exclusion rules properly though.nnHere is a code snippet (from the following eBook) for reading words from a specific page :nnimport PyPDF2nFile = open('somefile.pdf' 'rb')nread = PyPDF2.PdfFileReader(File)npage = pdfReader.getPage(0) # I.e front pagenpage.extractText() # contains a list of stringsnnnFor word count obvious exceptions are n and t.nnAn option could be to instead do word count on the .tex file which generates the PDF (not always possible unless you actually have the .tex file). Problem with this approach lies in knowing which keywords to ignore during count.nnFinally the easiest approach is to copy all the words in the PDF file and paste them in an online word counter like wordcounter.net.nnRegardless I hope I do not have to implement this and instead just use a module which does this already. That way I can run a script and append e.g. .tex file and add the count automatically. Which comes in handy.nnEdit: I found a good site which lists different modules for manipulating PDF's with Python. Still nothing related to the functionality I have posted here.n' nan,['regex'],['python-2.7']
40069930,'Regex for matching only legitimate tokens and discarding characters on the first indication of a bad token' 'I have a regular expression like so:nn(?x)n^(?:^S*)n(?:Sn    (?:n        (?:(PING|PONG)E)                  # match and capture a tokenn        |n        (?!P).+                           # match and discard all that don't start with any prefix of the tokensn        |n        .+(?<!PING|PONG|PIN|PON|PI|PO|P)$ # match and discard all that don't end properly (if there's garbage at the end)n    )n)?nnnA demonstration of this regex is here: https://regex101.com/r/IGCnLE/4nnI'm attempting to experiment with regex as a simple lexer. Basically there's a character stream with messages like SPINGE and SPONGE. But there could be other stuff in it. I use the above regex to do 2 things. One to find all the characters that should be discarded because they cannot result in an legitimate capture and two to capture the first legitimate token that appears.nnThe above regex works for all cases except in these 2:nnSPINGPnSPINGPINPINGPINGnnnThe above 2 are partially completely messages with no ending frame of E. But because they have some garbage after the PING that means these are not legitimate tokens to capture. The entire string should be matched and discarded. But I can't figure it out.nnNote that the discard operation is not in the regex itself I make use of the match index in order to know how much of the character stream to discard.nnThe other test cases are on the website: https://regex101.com/r/IGCnLE/4 and copied down here:nnSnSPnSPInSPINnSPINGnSPONGnSPOnSPINGPnSPINGPINPINGPINGnSPINGESPONGEnabcSPINGEabcnSPINGEabcnabcSnabcS   nSabc...nSP   nSPINGGnnS   nabcnSPONGenSOPnSNIPOnSabcPINGEnSPINGabcEnSabcEnnnWhile I could do this without regex since I came this far with writing it I'd like to see how it could be done in regex.n' nan,['regex'],['regex']
40069960,"'Python. Best way to match dictionary value if condition true' 'I'm trying to build a parser now part of my code is looks like this:nn    azeri_nums      = {k:v for kv in zip(range(110)(""bir""""iki""""uc""""dord""""beÅx9f""""altÄ±""""yeddi""""sÉx99kkiz""""doqquz""))}nrussian_nums    = {k:v for kv in zip(range(110)(""Ð¾Ð´Ð¸Ð½""""Ð´Ð²Ð°""""Ñx82Ñx80Ð¸""""Ñx87ÐµÑx82Ñx8bÑx80Ðµ""""Ð¿Ñx8fÑx82Ñx8c""""Ñx88ÐµÑx81Ñx82Ñx8c""""Ñx81ÐµÐ¼Ñx8c""""Ð²Ð¾Ñx81ÐµÐ¼Ñx8c""""Ð´ÐµÐ²Ñx8fÑx82Ñx8c""))}nnnImagine that I should find the digit if roomnum =""Ð¾Ð´Ð½Ð°""nHere is how I trying to match this:nn    if roomnum.isalpha():n    for keyvalue in azeri_nums.items():n        if value.startswith(roomnum.lower()):n            roomnum = str(key)n            breaknnif roomnum.isalpha():n    for keyvalue in russian_nums.items():n        if value.startswith(roomnum.lower()):n            roomnum = str(key)n            breaknnnis there any other method to do that that will work faster or some best practices for this situation?nnThank you in advance!nnP.S.nthe reason that this code works that module ""re"" capture from ""Ð¾Ð´Ð½Ð°"" only ""Ð¾Ð´"" and that is why ""Ð¾Ð´Ð¸Ð½"".startswith(""Ð¾Ð´"") returns true.n' 'Change your dict to bennazeri_nums = {v.lower():k for kv in zip(range(110)(""bir""""iki""""uc""""dord""""beÅx9f""""altÄ±""""yeddi""""sÉx99kkiz""""doqquz""))}nrussian_nums  = {v.lower():k for kv in zip(range(110)(""Ð¾Ð´Ð¸Ð½""""Ð´Ð²Ð°""""Ñx82Ñx80Ð¸""""Ñx87ÐµÑx82Ñx8bÑx80Ðµ""""Ð¿Ñx8fÑx82Ñx8c""""Ñx88ÐµÑx81Ñx82Ñx8c""""Ñx81ÐµÐ¼Ñx8c""""Ð²Ð¾Ñx81ÐµÐ¼Ñx8c""""Ð´ÐµÐ²Ñx8fÑx82Ñx8c""))}nnnAnd once you've names mapped to digits just use:nnkey = None # By defaultnroomnum_lower = roomnum.lower()nif roomnum_lower in azeri_nums:n    key = azeri_numsroomnum_lowernelif roomnum_lower in russian_nums:n    key = russian_numsroomnum_lowernnnDictionary is based on keysearch not valuesearch. The first one is O(1) and allows u to use key in dict when the 2nd one is O(n) and requires looping.nnEDIT TO COMMENT:nnif you want to map one word to others create another dict that will handle it.nn string_map = {'Ð¾Ð´Ð½Ð°': 'Ð¾Ð´Ð¸Ð½'} # map single string to many others if u wantnnnAnd then all u need to do is:nnkey = None # By defaultnroomnum_lower = roomnum.lower()nif roomnum_lower in azeri_nums:n    key = azeri_numsroomnum_lowernelif roomnum_lower in russian_nums:n    key = russian_numsroomnum_lower nif key is None:n    # At this point you know that the single string is not in any dictn    # so u start to check if any other string that u assigned to it is in dictn    for optional_string in string_map.get(roomnum_lower ):n        opt_str_low = optional_string.lower()n        key = azeri_nums.get(opt_str_low None)n        key = russian_nums.get(opt_str_low None) if key is None else keynn'",['dictionary'],"['dictionary', 'python-2.7']"
40070006,"'Url argument with Django' ""I'm having some problem with my url in Django (1.9)nnTried many way to solve it but still the same type of errornnReverse for 'elus' with arguments '()' and keyword arguments '{u'council': u'CFVU'}' not found. 1 pattern(s) tried: 'elus/(?P<council>A-B+)$'nnnThe actual code is this : nnView : nnclass RepresentativeView(ListView):n    model = Representativen    template_name= 'lea/elus.html'n    context_object_name = 'represents'nn    def get_queryset(self council):nn        return Representative.objects.filter(active=True).filter(council=council).order_by(order)nnnurl : nnurl(r'^elus/(?P<council>A-B+)$' views.RepresentativeView.as_view() name='elus')nnnTemplate :nn{% url 'elus' council='CFVU' %}nnnI've tried with **kwargs and other things. It work with **kwargs in another function with <pk> in url and my query is based on the id. But here with a string I can't find the solution.n"" ""You have A-B will only match the letters A and B. nnIf you only want to match uppercase letters you could do:nnurl(r'^elus/(?P<council>A-Z+)$nnnOr a common approach is to use w-+ which will match upper case A-Z lowercase a-z digits 0-9 underscores and hyphens:nnurl(r'^elus/(?P<council>w-+)$nn""",['django'],['django']
40070037,'Add a legend (like a matplotlib legend) to an image' 'Problem : Add a legend (like a matplotlib legend) to an imagennDescription:nnI have an image as a numpy array uint8.nI want to add a legend to it exactly as matplotlib does with its plots.nnMy image has  basically this shape :nnoutput_image = np.empty(shape=(xx 4) dtype=np.uint8)n    # B-G-R-Anblue = 255 0 0 255ngreen = 0 255 0 255nred = 0 0 255 255norange = 0 128 255 255nblack = 0 0 0 255n    ...nnnThe colors above are added.nThen the image is returned. And when it is returned by the method i would like to add a graphic to it.nnExample Below. Instead of the graphic i would have an imagennnnExtra InformationnnThe output is a numpy array with values ranging from 0 to 255.nEach pixel value in the array is formed by a 4-D array ( Blue-Green-Red-Alpha)nnThe legend should be added in the bottom right of the image.nnThe reason is because i have to do it i guess.nnBasically the current output is the numpy array which i later use for other purposes.n' 'Your question itself makes it clear that you know how to make an image in a numpy array. Now make your legend using the same techniques in a smaller numpy array.nnFinally use the facilities in numpy to replace part of the plot array with the legend array as discussed in this answern',"['numpy', 'matplotlib']","['matplotlib', 'numpy']"
40070051,"'How to import Pandas library in Python?' ""I've downloaded Anaconda package but Pandas seems to not work in both Spyder and PyCharm.nI'm very new to Python can somebody gives me a breakthrough please?n"" nan","['python-3.x', 'pandas']",['pandas']
40070093,"'GridSpec on Seaborn Subplots' 'I currently have 2 subplots using seaborn:nnimport matplotlib.pyplot as pltnimport seaborn.apionly as snsnnf (ax1 ax2) = plt.subplots(2 sharex=True)nnsns.distplot(df'Difference'.values ax=ax1) #array top subplotnnsns.boxplot(df'Difference'.values ax=ax2 width=.4) #bottom subplotnsns.stripplot(cimin cimax color='r' marker='d') #overlay confidence intervals over boxplotnnax1.set_ylabel('Relative Frequency') #label only the top subplotnnplt.xlabel('Difference')nnplt.show()nnnHere is the output:nnnnI am rather stumped on how to make ax2 (the bottom figure) to become shorter relative to ax1 (the top figure). I was looking over the GridSpec (http://matplotlib.org/users/gridspec.html) documentation but I can't figure out how to apply it to seaborn objects.nnQuestion:nnnHow do I make the bottom subplot shorter compared to the topnsubplot? nIncidentally how do I move the plot's title ""Distrubition of Difference"" to  go above the topnsubplot?nnnThank you for your time.n' 'As @dnalow mentioned seaborn has no impact on GridSpec as you pass a reference to the Axes object to the function. Like so:nnimport matplotlib.pyplot as pltnimport seaborn.apionly as snsnimport matplotlib.gridspec as gridspecnntips = sns.load_dataset(""tips"")nngridkw = dict(height_ratios=5 1)nfig (ax1 ax2) = plt.subplots(2 1 gridspec_kw=gridkw)nnsns.distplot(tips.loc:'total_bill' ax=ax1) #array top subplotnsns.boxplot(tips.loc:'total_bill' ax=ax2 width=.4) #bottom subplotnnplt.show()nnnn'",['matplotlib'],['matplotlib']
40070229,"'OpenCV preprocess image for better thresholding results' 'In OpenCV how can I preprocess images for better thresholding results? My input image is nnbase imagennI am using a variety of thresholding methods like:nnEDITnnApplying CLAHE (Contrast Limited Adaptive Histogram Equalization) significantly decreases the amount of noise but the text extracted is still kind of blurry. Is there a way I can make the text more ""crisp""?nnclahe = cv2.createCLAHE(clipLimit=1.0 tileGridSize=(33))ninputImage = clahe.apply(inputImage)nnnEND OF EDITnninvertRet invertColors = cv2.threshold(inputImage127255cv2.THRESH_BINARY_INV)nngaussianThreshold = cv2.adaptiveThreshold(inputImage 255 cv2.ADAPTIVE_THRESH_GAUSSIAN_C cv2.THRESH_BINARY_INV 11 2)nnadaptiveMean = cv2.adaptiveThreshold(inputImage 255 cv2.ADAPTIVE_THRESH_MEAN_C cv2.THRESH_BINARY_INV 11 2)nnotsuRet otsu = cv2.threshold(inputImage0255cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)nnnbut they all display lots of noise like:nngaussian thresholdingn' nan",['python-2.7'],['python-2.7']
40070289,"'Python itertools.product freezes with higher numbers' ""I have 6 variables with different ranges. I want to create possibilities pool with my code. In this example i gave 10 range for every variable but i have to give them about 200 range. But whenever i'm trying to exceed 20 range (for example 30 range) Python kills itself and sometimes it freezes computer. Is there anyway to make it faster and stable?nnThanks.nnimport itertoolsnna = x for x in range(400411)nb = x for x in range(400411)nc = x for x in range(400411)nd = x for x in range(400411)ne = x for x in range(400411)nf = x for x in range(400411)nnfl = lambda x: xnnit = filter(fl itertools.product(abcdef))nnposslist = x for x in itnnprint(len(posslist))nn"" 'Use the cartesian_product function from hereÂxa0 for an almost 60x speed up from itertools.product()nndef cartesian_product2(arrays):nn    la = len(arrays)n    arr = np.empty(len(a) for a in arrays + la)n    for i a in enumerate(np.ix_(*arrays)):n        arr...i = ann    return arr.reshape(-1 la)nn' 'There are 6 lists of 11 elements each: 400 401 402 403 404 405 406 407 408 409 410.nnA cartesian product of 6 such lists is a list of 116 tuples of 6 integers each (the first tuple is: (400 400 400 400 400 400)).nnThe size of each tuple is 6*8 bytes in 64-bit Python*.nnSo the total size of posslist is 6 * 8 * 116 = 81 GB!nnDo you have enough RAM for that? Probably not so the OS is going to start swapping RAM which is extremely slow. Therefore in addition to calculating 81 GB of data thecomputer will have to constantly swap data from RAM to HDD and back so it will do the job even slower.nnnn* Note that while it is half that size in a 32-bit Python a 32-bit Python cannot address enough memory at all n' 'Maybe instead of doing all of it one-go you can try doing the product in successive steps. For examplennimport itertools as ittnna = 1 2 3nb = 4 5 6nc = 7 8 9nnfl = lambda x: xnns1 = filter(fl itt.product(a b))ns2 = filter(fl itt.product(s1 c))nnprint(list(s2))nnnBut then the result would look like the following. You just have to unpack the tuple of tuple to a single tuple.nn((1 4) 7)n ((1 4) 8)n ((1 4) 9)n ((1 5) 7)n ((1 5) 8)n ((1 5) 9)n ((1 6) 7)n ((1 6) 8)n ((1 6) 9)n ((2 4) 7)n ((2 4) 8)n ((2 4) 9)n ((2 5) 7)n ((2 5) 8)n ((2 5) 9)n ((2 6) 7)n ((2 6) 8)n ((2 6) 9)n ((3 4) 7)n ((3 4) 8)n ((3 4) 9)n ((3 5) 7)n ((3 5) 8)n ((3 5) 9)n ((3 6) 7)n ((3 6) 8)n ((3 6) 9)nnnI also think that this can be made parallelizable where you can do the product of the lists in parallel.nnFor lists L1 L2 L3 L4 do something like:nnth1_res = itertools.product(L1 L2)nth2_res = itertools.product(L3 L4)nnthread_final = itertools.product(th1_res th2_res)nn' 'Thanks everyone for your answers. While searching for a better solution i found an answer on Python documentation. There is an example on documentation for using itertools.product as generator instead of list. Yet i still can't find any good idea to make it faster. This will help you too if your going to use product with high values.nnProduct generator for Python 2nProduct generator for Python 3n'",['python-3.x'],"['list', 'python-2.7', 'python-3.x']"
40070357,"'Searching Elements of a List' 'I am trying to search a array of previous usernames used in a game for the username currently used by the gamer (allowing all the previous game scores under the username to be displayed). This list has been imported from an external text file.nnfor x in range(0 len(lis)):n    if username == lisx:n        print ""yes""n    print lisxnnnHere for example the username could be ""Jack"". Even though multiple elements in lis have the value ""Jack"" (verified by printing all the values of the list through 'print lisx') ""yes"" is never printed to show this.nnWhat's going wrong?n' 'if username in lis:nnnShould do the trick of searching through a listnnIf the code you have written is not working check if the strings are formatted the same waynnif username.strip().lower() == lisx.strip().lower():nn' 'Try this:nnfor usernameTest in lis:n   if username == usernameTest.strip():n        print ""yes""n    print lisxnn' 'I'm not sure if it is what you meant but at least this prints yes:nnlis = ""Jack""""Rose"" ""Joe"" ""Franz""nusername = ""Joe""nfor x in range(0 len(lis)):nif username == lisx:n    print (""yes"")nn'",['list'],"['list', 'python-2.7']"
40070364,"'Get distance to non-empty item in two-dimensional list column' 'I am trying to make a game of scrabble. I have a board defined below.nnself.board = "" "" ""A "" ""B "" ""C "" ""D "" ""E "" ""F "" ""G "" ""H "" ""I "" ""J "" ""K "" ""L "" ""M "" ""N "" ""O ""n    '01' 'TWS' ' ' ' ' 'DLS' ' ' ' ' ' ' 'TWS' ' ' ' ' ' ' 'DLS' ' ' ' ' 'TWS'n    '02' ' ' 'DWS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'DWS' ' 'n    '03' ' ' ' ' 'DWS' ' ' ' ' ' ' 'DLS' ' ' 'DLS' ' ' ' ' ' ' 'DWS' ' ' ' 'n    '04' 'DLS' ' ' ' ' 'DWS' ' ' ' ' ' ' 'DLS' ' ' ' ' ' ' 'DWS' ' ' ' ' 'DLS'n    '05' ' ' ' ' ' ' ' ' 'DWS' ' ' ' ' ' ' ' ' ' ' 'DWS' ' ' ' ' ' ' ' 'n    '06' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' 'n    '07' ' ' ' ' 'DLS' ' ' ' ' ' ' 'DLS' ' ' 'DLS' ' ' ' ' ' ' 'DLS' ' ' ' 'n    '08' 'TWS' ' ' ' ' 'DLS' ' ' ' ' ' ' 'B' 'O' 'G' ' ' 'DLS' ' ' ' ' 'TWS'n    '09' ' ' ' ' 'DLS' ' ' ' ' ' ' 'DLS' ' ' 'DLS' ' ' ' ' ' ' 'DLS' ' ' ' 'n    '10' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' 'n    '11' ' ' ' ' ' ' ' ' 'DWS' ' ' ' ' ' ' ' ' ' ' 'DWS' ' ' ' ' ' ' ' 'n    '12' 'DLS' ' ' ' ' 'DWS' ' ' ' ' ' ' 'DLS' ' ' ' ' ' ' 'DWS' ' ' ' ' 'DLS'n    '13' ' ' ' ' 'DWS' ' ' ' ' ' ' 'DLS' ' ' 'DLS' ' ' ' ' ' ' 'DWS' ' ' ' 'n    '14' ' ' 'DWS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'TLS' ' ' ' ' ' ' 'DWS' ' 'n    '15' 'TWS' ' ' ' ' 'DLS' ' ' ' ' ' ' 'TWS' ' ' ' ' ' ' 'DLS' ' ' ' ' 'TWS'        nnnMy goal is to find the distance to the nearest letter from any letter. For example if I called the function on B it would returnnn{""up"" : 7 ""down"" : 7 ""left"" : 7 ""right"" : 0}nnnI have experimented with the built-in next function but I guess my question is is there an easy way to get the column of a two-dimensional list?nnI also have a list of things that should be considered as empty:nnemptyList = ""TWS"" ""DWS"" ""TLS"" ""DLS""nnnPlease help. Thank you so much!n' 'You could use next and extract the column with rowcol_num for row in board like this:nndef distances(row_num col_num):n    letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'n    if not col_num.isdigit():n        col_num = ord(col_num.upper()) - ord('A') + 1n    col = rowcol_num for row in boardn    row = boardrow_numn    return {n        'right': next((i for i c in enumerate(rowcol_num+1:) if c in letters) 15-col_num)n        'left': next((i for i c in enumerate(rowcol_num-1:0:-1) if c in letters) col_num-1)n        'down': next((i for i c in enumerate(colrow_num+1:) if c in letters) 15-row_num)n        'up': next((i for i c in enumerate(colrow_num-1:0:-1) if c in letters) row_num-1)n    }nnprint (distances(8 'H'))nnnThe arguments to the function should be the row number (8) and column number (8) or the corresponding letter H.nnTo check that a square is empty the function checks whether the contents are not a single letter (A-Z).nnSee it run on repl.itn'",['python-3.x'],['list']
40070475,"""Can't change tkinter label text constantly in loop"" 'I'm trying to make simple Quiz program. I want labels to change their text for every question in range of 10 questions. So when you are on 1st question one label should show 'Question 1'. But it immediately shows 'Question 10' and I'm unable to play quiz.nnIn dictionary there's only one question but it should not be problem it should repeat that question 10 times.nnHere's piece of my code (It's in class):nn    self.label = tk.Label(self text=""This is page 1"")n    self.label.pack(side=""top"" fill=""x"" pady=10)n    self.label1 = tk.Label(self text='')n    self.label1.pack()n    self.label2 = tk.Label(self text='')n    self.label2.pack()n    self.entry1 = tk.Entry(self)n    self.entry1.pack()n    self.label3 = tk.Label(self text='')n    self.label3.pack()n    self.entry2 = tk.Entry(self)n    self.entry2.pack()nn    my_dict = {n        ""Base-2 number system"": ""binary""n    }nn    score = 0nn    for i in range(10):n        question = (random.choice(list(my_dict.keys())))n        answer = my_dictquestionn        self.label1.config(text=(""Question "" + str(i + 1)))n        self.label2.config(text=(question + ""?""))nn        guess = self.entry1.get()nn        if guess.lower() == answer.lower():n                score += 1n        else:n                score += 0nn    self.label3.config(text=(""Your final score was "" + str(score)))nn' 'You need to wait for the user to enter their answer into the Entry widget. The code you posted doesn't do that. You have to organize your logic a little differently in GUI programss  compared to command-line programs because you need to wait for events generated by user actions and then respond to them.nnThe code below doesn't do everything you want but it does run. :) It displays a question waits for the user to type their answer into the self.entry1 widget and when they hit the Enter key in that widget it calls the .get_answer method which processes their answer and then calls the .ask method to ask a new question. After 10 questions the program exits.nnimport tkinter as tknimport randomnnclass Quiz(tk.Frame):n    def __init__(self root):n        super().__init__(root)n        self.root = rootn        self.pack()nn        self.label = tk.Label(self text=""This is page 1"")n        self.label.pack(side=""top"" fill=""x"" pady=10)n        self.label1 = tk.Label(self text='')n        self.label1.pack()n        self.label2 = tk.Label(self text='')n        self.label2.pack()n        self.entry1 = tk.Entry(self)n        self.entry1.bind(""<Return>"" self.get_answer)n        self.entry1.pack()n        self.label3 = tk.Label(self text='')n        self.label3.pack()n        self.entry2 = tk.Entry(self)n        self.entry2.pack()nn        self.start_quiz()n        root.mainloop()nn    def start_quiz(self):n        self.qdict = {n            ""Base-2 number system"": ""binary""n            ""Base-8 number system"": ""octal""n            ""Base-16 number system"": ""hexadecimal""n        }n        self.qkeys = list(self.qdict.keys())n        self.score = 0n        self.count = 1n        self.ask()nn    def ask(self):n        self.question = random.choice(self.qkeys)n        self.label1.config(text=""Question {}"".format(self.count))n        self.label2.config(text=self.question + ""?"")nn    def get_answer(self event):n        widget = event.widgetn        guess = widget.get()n        answer = self.qdictself.questionn        if guess.lower() == answer.lower():n            self.score += 1n        self.label3.config(text=""Score: {}"".format(self.score))nn        self.count += 1n        if self.count <= 10:n            self.ask()n        else:n            self.root.destroy()nnQuiz(tk.Tk())nn'",['tkinter'],['tkinter']
40070584,"'Python using while loop with a list name' 'I am a beginner to python so this might be easy but I am not sure of what the following code means.nnq=startn    while q:nnnDoes this mean when there is at least one element in the list q execute it and q becomes false when it is empty?nEdit:I cannot execute it at the moment and I need to find it quickly.n' ""The line q = start means create a variable called q and assign the value start to it. In this case it will create a list with one element: the value of the variable start. It's the exact same syntax as q = 1 2 but it uses a variable instead of a constant value.nnAfter this the line while q: is a use (or abuse) of Python's type conversion system. While loops require a boolean condition to know whether they should repeat so your code is equivalent to while bool(q):. To understand how this works let's examine the possible cases:nnbool(1) == True # This applies for any non-empty listnbool() == False # This applies to any empty listnnnTherefore the meaning of while q: is actually 'while q is non-empty'.n""",['list'],"['list', 'python-2.7']"
40070615,"'How to unpack a tuple for looping without being dimension specific' ""I'd like to do something like this:nn    if dim==2:n        ab=grid_shapen        for i in range(a):n            for j in range(b):n                Aij = ...things...nnnwhere dim is simply the number of elements in my tuple grid_shape. A is a numpy array of dimension dim.nIs there a way to do it without being dimension specific? nWithout having to write ugly code like nn    if dim==2:n        ab=grid_shapen        for i in range(a):n            for j in range(b):n                Aij = ...things...n    if dim==3:n        abc=grid_shapen        for i in range(a):n            for j in range(b):n                for k in range(c):n                    Aijk = ...things...nn"" 'Using itertools you can do it like this:nnfor index in itertools.product(*(range(x) for x in grid_shape)):n    Aindex = ...things...nnnThis relies on a couple of tricks.  First itertools.product() is a function which generates tuples from iterables.nnfor i in range(a):n    for j in range(b):n        index = ijn        do_something_with(index)nnncan be reduced tonnfor index in itertools.product(range(a)range(b)):n    do_something_with(index)nnnThis works for any number of arguments to itertools.product() so you can effectively create nested loops of arbitrary depth.nnThe other trick is to convert your grid shape into the arguments for itertools.product:nn(range(x) for x in grid_shape)nnnis equivalent tonn(range(grid_shape0)range(grid_shape1)...)nnnThat is it is a tuple of ranges for each grid_shape dimension.  Using * then expands this into the arguments.nnitertools.product(*(range(x1)range(x2)...))nnnis equivalent tonnitertools.product(range(x1)range(x2)...)nnnAlso since Aijk is equivalent to A(ijk) we can just use Aindex directly.nnAs DSM points out since you are using numpy you can reducennitertools.product(*(for range(x) for x in grid_shape))nnntonnnumpy.ndindex(grid_shape)nnnSo the final loop becomesnnfor index in numpy.ndindex(grid_shape):n    Aindex = ...things...nn' 'You can catch the rest of the tuple by putting a star in front of the last variable and make a an array by putting parentheses around it.nn>>> tupl = ((1 2) 3 4 5 6)n>>> a *b = tupln>>> an(1 2)n>>> bn3 4 5 6n>>> nnnAnd then you can loop through b. So it would look something likenna*b=grid_shapenfor i in a:n    for j in range(i):n        for k in b:n            for l in range(k):n                Aj l = ...things...nn'",['numpy'],"['numpy', 'python-2.7']"
40070659,"""Django calendar widget doesn't work with ModelForm and Form Media"" 'I found one blog. It explains how apply calendar widget with form media. It is what I exactly want to make. so I followed instructions.nnbut js and css files doesn't work in widget. I tried to figure out this problem. I spent quite much time by searching and reading stuffs. But I can't get what's wrong in my situation exactly. Well It could be very easy question but I will appreciate if you can give me any hint to figure out this!nnmodel.pynnclass Birthday(models.Model):n    birthday = models.DateField(null=True)nnnviews.pynndef register_birthday(request):n    if request.method == 'POST':n        form = BirthdayForm(request.POST)n        if form.is_valid():n            form.save()n            return HttpResponseRedirect('/success')n    else:n        form = BirthdayForm()n    return render(request 'sale/registerbirthday.html' {'form':form})nnnforms.pynnclass DateUIWidget(forms.TextInput):n    def _media(self):n        return forms.Media(css = {n            ""all"": (""tiny-date-picker.css"")n        }n        js = (""tiny-date-picker.js"" ""date-init.js""))n    media = property(_media)nnnclass BirthdayForm(forms.ModelForm):n    class Meta:n        model = Birthdayn        fields = ('birthday')n        widgets = {n            ""birthday"" : DateUIWidget(attrs={'class':'dateuiwidget' 'id':'id_birthday'})n        }nnnactually I wrote at first like below. but I changed to check if it works when I use media as a dynamic property.nnclass DateUIWidget(forms.TextInput):n    class Media:n        css = {n            ""all"": (""tiny-date-picker.css"")n        }n        js = (""tiny-date-picker.js"" ""date-init.js"")nnnforms.py firstnn<form action=""."" method=""post"">n{% csrf_token %}n{{ form.as_p }}n<input type=""submit"">n</form>n{{ form.medai}}nnnI changed it because I read that I should read this when I changed.nAs we have already seen the string representation of a Media object is the HTML required to include the relevant files in the  block of your HTML page.nn<html>nn<head>n{{ form.media }}n</head>nn<body>n<form action=""."" method=""post"">n{% csrf_token %}n{{ form.as_p }}n<input type=""submit"">n</form>n</body>nn</html>nnnunder myapp/static/date-init.jsnn$("".dateuiwidget"").each(function(){n    return TinyDatePicker(this);n});nnnI copied two files(tiny-date-picker.jstiny-date-picker.css) under myapp/static/.ni got two files from herennit shows widget in a form without error. I assume that somehow js css file didn't apply to this widget.nnhtml source coden<html>nn<head>n<link href=""/static/tiny-date-picker.css"" type=""text/css"" media=""all"" rel=""stylesheet"" />n<script type=""text/javascript"" src=""/static/tiny-date-picker.js""></script>n<script type=""text/javascript"" src=""/static/date-init.js""></script>n</head>nn<body>n<form action=""."" method=""post"">n<input type='hidden' name='csrfmiddlewaretoken' value='VC8ahwDLBOsy4IlAzf1iIiukK7ZvTcGDQjL9RxywlauCOX3c8rG7DVJ1ClozHEEW' />n<p><label for=""id_birthday"">Birthday:</label> <input class=""dateuiwidget"" id=""id_birthday"" name=""birthday"" type=""text"" required /></p>n<input type=""submit"">n</form>n</body>nnnThanks for reading!nn</html>nn' nan",['django'],['django']
40070758,"'Best Way to launch an asynchronous function in django?' ""I am using tweepy library to collect tweets from twitter streaming API and store them in an Elasticsearch server. Overall I am writing a simple Django application to display the tweets in real time over a map. However for that I need the ElasticSearch database to be populated in realtime constantly by the Django Server i.e it should preferably start doing it as soon as the Django Server is launched. What will be a good way to go about it ?nnThe calls look as followin:nnstreamer = tweepy.Stream(twitter_api.auth listener=stream_listener)nstreamer.filter(locations=-180 -90 180 90 languages='en' async=True)nn"" 'Use celery along with celery-haystack (hopefully you are already using django-haystack to interact with Elasticsearch). Its not a straight forward solution but with some effort it is the best solution.n' 'I use supervisor + custom django command. Inside the command you decide when to run that asynchronous function.n'",['django'],['django']
40070909,"'Python pandas group by two columns' ""I have a pandas dataframe:nn       code   typenindex  n  312   11     21n  312   11     41 n  312   11     21n  313   23     22n  313   11     21n  ...   ...    nnnSo I need to group it by count of pairs 'code' and 'type' columns for each index item:nn        11_21   11_41  23_22nindex  n  312       2      1      0n  313       1      0      1n  ...   ...   nnnHow implement it with python and pandas?n"" 'Here's one way using pd.crosstab and then rename column names using levels information.nnIn 136: dff = pd.crosstab(df'index' df'code' df'type')nnIn 137: dffnOut137:ncode  11    23ntype  21 41 22nindexn312    2  1  0n313    1  0  1nnIn 138: dff.columns = '%s_%s' % c for c in dff.columnsnnIn 139: dffnOut139:n       11_21  11_41  23_22nindexn312        2      1      0n313        1      0      1nnnAlternatively less elegantly create another column and use crosstab.nnIn 140: df'ct' = df.code.astype(str) + '_' + df.type.astype(str)nnIn 141: dfnOut141:n   index  code  type     ctn0    312    11    21  11_21n1    312    11    41  11_41n2    312    11    21  11_21n3    313    23    22  23_22n4    313    11    21  11_21nnIn 142: pd.crosstab(df'index' df'ct')nOut142:nct     11_21  11_41  23_22nindexn312        2      1      0n313        1      0      1nn'",['pandas'],['pandas']
40071006,"'Python 2.7: Print a dictionary without brackets and quotation marks' 'myDict = {""Harambe"" : ""Gorilla"" ""Restaurant"" : ""Place"" ""Codeacademy"" : ""Place to learn""}nnnSo I want to print out a dictionary. But I want to do it like it looks like an actual list of things. I can't just do print myDict as it will leave all the ugly stuff in. I want the output to look like Harambe : Gorilla Restaurant : Place etcnnSo what do I do? I haven't found a post meeting what I want. Thanks in advance.n' 'You could try something like this.nnfor (i j) in myDict.items():n    print ""{0} : {1}"".format(i j) end = "" "" nnnNote that since dictionaries don't care about order the output will most likely be more like Restaurant : Place Harambe : Gorilla Codeacademy : Place to learn. n' ""My solution:nnprint ' '.join('%s : %s' % (kmyDictk) for k in myDict.keys())nn"" 'Using the items dictionary method:nnprint('n'.join(""{}: {}"".format(k v) for k v in myDict.items()))nnnOutput: nnRestaurant: PlacenCodeacademy: Place to learnnHarambe: GorillannnExpanded: nnfor key value in myDict.items():n    print(""{}: {}"".format(key value))nn'","['python-2.7', 'dictionary']","['dictionary', 'python-2.7']"
40071026,"'how to split a string with whitespace but ignore specific whitespace (that includes comma) in python' 'I want split a string with whitespace but ignore specific whitespace (that includes comma).nnExample: nnstr = ""abc de45+ Pas hfa underak (333)""nnnRequired split:nnItem 1: abcnItem 2: de45+nItem 3: Pas hfa underaknItem 4: (333)nn' 'If you want to split only at a space then simply use split()nna = ""abc de45+ Pas hfa underak (333)""nsplit_str = a.split(' ')    #Splits only at spacennnIf you want to split at spaces but not period as suggested by @Beloo use regexnnimport renna = ""abc de45+ Pas hfa underak (333)""nsplit_str = re.split(' '  a)    #Splits just at spacesnsplit_str = re.split(' .:' a)    #Splits at spaces periods and colonsnsplit_str = re.split('(?<!) '  a)    #Splits at spaces excluding commasnnnAs you might have guessd if you want to exclude a character simply put it in between the (?<! and )n' 'You should split by (?<!)snCheck here : https://regex101.com/r/9VXO49/1n'",['regex'],"['regex', 'python-2.7']"
40071074,"'How to split a column data into other columns which is stored in a dataframe?' 'The df is the dataframe which contain the following information.nn In 61: df.head()n    Out61: n       id  movie_id                  infon    0   1         1   Italy:1 January 1994n    1   2         2   USA:22 January 2006n    2   3         3   USA:12 February 2006n    3   4         4   USA:February 2006n    4   5         5   USA:2006nnnI want output like below:nnIn 61: df.head()    nOut61: n   id  movie_id    country Date    Month   Yearn0   1         1    Italy    1     January  1994n1   2         2    USA      22    January  2006n2   3         3    USA      12    February 2006n3   4         4    USA      None  February 2006n4   5         5    USA      None  None     2006nnnThe data is stored in dataframe and it must be overwrite into the dataframe.n' 'You can use regex :|s+ to split the column on either semicolon or white spaces and specify the expand parameter to be true so that the result will expand to columns:nndf""country""""Date""""Month""""Year"" = df'info'.str.split(':|s+' expand = True)nnnnnUpdate:nnTo handle optional missing dates and months you could try extract with regular expression:nn(df""country""""Date""""Month""""Year"" = n     df'info'.str.extract('^(A-Za-z+):(d{12})? ?(A-Za-z+)? ?(d{4})$'))nnnn^(A-Za-z+):(d{12})? ?(A-Za-z+)? ?(d{4})$' contains four capture groups corresponding to country Date Month Year respectively;n^ and $ denote the start and end of the string;n(A-Za-z+) captures the country which is before : and consists of letters; n(d{12}) captures Date which consists of one or two digits but optional(with ? after the group) i.e could be missing;n(A-Za-z+) captures Month which consists of letters and it's marked as optional with ?;n(d{4}) captures the year which consists of four digits;nnnn' 'Using split string method.nnIn 163: df'country' 'date' 'month' 'year' = df'info'.str.split('W+' expand=True)nnIn 164: dfnOut164:n   id  movie_id                  info country date     month  yearn0   1         1  Italy:1 January 1994   Italy    1   January  1994n1   2         2   USA:22 January 2006     USA   22   January  2006n2   3         3  USA:12 February 2006     USA   12  February  2006n3   4         4  USA:19 February 2006     USA   19  February  2006n4   5         5   USA:22 January 2006     USA   22   January  2006nn'",['pandas'],"['pandas', 'regex']"
40071096,"'How to plot multiple lines in one figure in Pandas Python based on data from multiple columns?' 'I have a dataframe with 3 columns like this:nndf'year' = '2005 2005 2005 2015 2015 2015 2030 2030 2030'ndf'name' = 'A' 'B' 'C' 'A' 'B' 'C' 'A' 'B' 'C'ndf'weight' = 80 65 88 65 60 70 60 55 65nnnhow can I plot a line for A B and  C where it shows how their weight develops through the years. So I tried this: nndf.groupby(""euro"").plot(x=""year"" y=""MKM"")nnnHowever I get multiple plots and that is not what I want. I want all those plots in one figure. n' 'Does this produce what you're looking for?nnimport matplotlib.pyplot as pltnfigax = plt.subplots()nnfor name in 'A''B''C':n    ax.plot(dfdf.name==name.yeardfdf.name==name.weightlabel=name)nnax.set_xlabel(""year"")nax.set_ylabel(""weight"")nax.legend(loc='best')nnnn'","['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40071153,"'Django - trouble with separating objects by user and date' 'So I have these models: nnexcercises_choices = (('Bench Press' 'Bench press')('Overhead Press' 'Overhead Press') ('Squat' 'Squat')n                ('Deadlift' 'Deadlift'))nnunit_choices = (('kg''kg') ('lbs' 'lbs'))nnnclass Lifts(models.Model):nn user = models.ForeignKey('auth.User' null=True)n excercises = models.CharField(max_length=200 choices=excercises_choices)n sets = models.IntegerField(null=True blank=True)n reps = models.IntegerField(null=True blank=True)n weight = models.FloatField()n unit = models.CharField(max_length=3 choices=unit_choices)n created_date = models.ForeignKey('Dates')n amrap_set = models.BooleanField(default=False)n amrap_rep = models.IntegerField(null=True blank=True)nndef __str__(self):n    return self.excercisesnnnclass Dates(models.Model):n created_date = models.DateField(unique=True)nndef __str__(self):n    return str(self.created_date)nnnLet's say I have few lifts at different dates for admin and few lifts at different for xx user. nI want multiple lifts matching one date that's why I've made foreign key. (eg. 3 lifts to 2016-10-10 and 2 lifts to 2016-10-11).nnHere is a view for showing it:nn @login_requiredn def entries(request):n  date = Dates.objects.all().order_by('-created_date')n  lifts_by_user = Lifts.objects.filter(user=request.user)n  return render(request 'lift/entries.html' {'date': daten                                             'lifts_by_user': lifts_by_user})nnnAnd template: nn{% extends 'lift/base.html' %}nn{% block content %}n{{ user }}nnn{% if user.is_authenticated %}nn{% for date in date %}n    <p><strong><a href=""{% url 'lift_date' pk=date.pk %}"">{{ date }}</a></strong>n    {% for i in date.lifts_set.all %}n        {{ i }}nn    {% endfor %}nn<a href=""{% url 'new_lifts' %}"">add new lift</a></p>n{% endfor %}n{% endif %}n<p>n<a href=""{% url 'entries_delete' %}"">Delete lifts or dates </a>n</p>n{% endblock %}nnnThe problem is that I dont know how to separate it by dates AND by user.nThis is how it looks like How do i keep this pattern date - lifts_to_that_date but for separate users? I dont want to see admin's entries while I am on test usern' 'Have a look at the regroup template tag it does exactly what you need.nnYou can do something like this in your view:nn@login_requiredndef entries(request):n    lifts_by_user = (Lifts.objects.filter(user=request.user)n        .order_by('-created_date__created_date'))n    return render(n        requestn        'lift/entries.html'n        {'lifts_by_user': lifts_by_user}n    )nnnAnd replace the for date in dates loop in your template with something like:nn{% regroup lifts_by_user by created_date.created_date as lifts %}n<ul>n    {% for day in lifts %}n        <li>Date: {{ day.grouper }}n            <ul>n                {% for lift in day.list %}n                    <li>{{ lift }}</li>n                {% endfor %}n            </ul>n        </li>n    {% endfor %}n</ul>nnnI've used a ul here so that it's easier to compare to the example in the docs but obviously you can change the markup to whatever you need. It's important to know that regroup doesn't order its input so you need to order by created_date in your view.nnIf you're using Django's dev version you can use this instead:nn{% regroup lifts_by_user by created_date.created_date as lift_list %}n<ul>n    {% for day lifts in lift_list %}n        <li>Date: {{ day }}n            <ul>n                {% for lift in lifts %}n                    <li>{{ lift }}</li>n                {% endfor %}n            </ul>n        </li>n    {% endfor %}n</ul>nnnWhich I think is a little clearer.nnAs an aside none of this relies on having dates stored as a foreign key but that's up to you.nnQuestions from comments:nnnorder_by('-created_date__created_date') is joining Lifts to Dates through the Lifts.created_date foreign key and ordering by the Dates.created_date field. Have a look at https://docs.djangoproject.com/en/dev/topics/db/queries/#lookups-that-span-relationships for details.nfor day lifts in lift_list is using tuple unpacking.nAs a quick example:nnt = (1 2 3)n# first second third will have values 1 2 3 respectivelynfirst second third = tnnn{% regroup lifts_by_user by created_date.created_date as lifts_list %} produces a list of namedtuples (again only in the dev version if you're using 1.10 or earlier it's a list of dicts so you can't use this trick) so as you're iterating through lift_list you can unpack the date and list of lifts into separate variables.nIf you have a Lift instance called lift you can get the pk for its date by using lift.created_date_id. Accessing it where you have the date URL in your example template is a little trickier because you have to get a lift out of the regrouped date's list. Something like this:nn{% regroup lifts_by_user by created_date.created_date as lifts %}n<ul>n    {% for day in lifts %}n        <li>Date: {{ day.grouper }}n            {# day.list.0 gets the first lift for this day #}n            Date PK: {{ day.list.0.created_date_id }}n            <ul>n                {% for lift in day.list %}n                    <li>{{ lift }}</li>n                {% endfor %}n            </ul>n        </li>n    {% endfor %}n</ul>nnn'",['django'],['django']
40071295,"'Adding a new Unique Field in an existing database table with existing values- Django1.7/MySql' 'I have an existing database table.nI want to add a new (Char)field to it. This field will have unique values.nnWhen I try to do so:nnid = models.CharField(max_length=100 Unique=True)nnnI get integrity error.nnSome of the other things I have tried :nnid = models.CharField(max_length=100 Unique=Truendefault="""".join(random.random() random.random())))nnnandnnid = models.CharField(max_length=100ndefault="""".join(random.random() random.random())))nnnSame error.nnIs there a way around this? n' ""I will show the following with the new column being an INT not a CHAR. Same difference. nncreate table t1n(   id int auto_increment primary keyn    col1 varchar(100) not nulln);nninsert t1(col1) values ('fish')('apple')('frog');nalter table t1 add column col2 int; -- OK (all of col2 is now NULL)nALTER TABLE t1 ADD UNIQUE (col2); -- OK (now a UNIQUE constraint on col2)nnshow create table t1;nCREATE TABLE `t1` (n   `id` int(11) NOT NULL AUTO_INCREMENTn   `col1` varchar(100) NOT NULLn   `col2` int(11) DEFAULT NULLn   PRIMARY KEY (`id`)n   UNIQUE KEY `col2` (`col2`)n) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;nnnNow let's start over and see it blow up.nndrop table t1;ncreate table t1n(   id int auto_increment primary keyn    col1 varchar(100) not nulln);ninsert t1(col1) values ('fish')('apple')('frog');nalter table t1 add column col2 int not null; -- OK (at the moment)n-- note: (all of col2 is now 0)nALTER TABLE t1 ADD UNIQUE (col2); -- error 1062 duplicate entry '0' for key 'col2'nnnThe reason the above blew up was because the NOT NULL on the col2 add column made all that data a 0. Then the UNIQUE constraint attempt failed.nnNow below let's continue the thought:nndrop table t1;ncreate table t1n(   id int auto_increment primary keyn    col1 varchar(100) not nulln);ninsert t1(col1) values ('fish')('apple')('frog');nalter table t1 add column col2 int; -- OK (all of col2 is now NULL)nALTER TABLE t1 ADD UNIQUE (col2); -- OKnselect * from t1; -- col2 is NULL for all 3 rowsnupdate t1 set col2=7 where id=1; -- OKnupdate t1 set col2=7 where id=2; -- error 1062 duplicate entry '7' for key 'col2'nnnThe moral of the story is that if you add a column to a table with data pre-existing and want that new column to be unique you need to have it nullable to start. Then create the unique constraint. Now all data is NULL so the unique constraint is forgiving. But once you tweak the data to be non-NULL it better be unique. Tweak meaning UPDATE or INSERT. So col2 needs to remain NULL or UNIQUE thereafter.n""",['django'],['django']
40071311,"'How to change 1 bit from a string python?' 'I generate a 64 bits random string using os.urandom(8). Next I want to randomly change the value of one bit of the string getting the bit to change first x = random.getrandbits(6) and doing the XOR operation for that bit like this rand_string ^= 1 << x but this last operation gives me the following error: TypeError: unsupported operand type(s) for ^=: 'str' and 'long'nnIt's important to me to generate a random binary string because I want to cipher it cipher.encrypt(rand_string) and only takes plain-text for parameters. I don't use random.getrandbits(64) because it returns a long but it doesn't match the 64 bits size block that I want.nnBesides I want to measure the hamming distance between the strings (should give me 1 because I only changed one bit) but I'm afraid that the algorithm I found is not valid to me because it compares the characters representations instead of comparing bit-level:nndef hamming_distance(s1 s2):n    # Return the Hamming distance between equal-length sequencesn    if len(s1) != len(s2):n        raise ValueError(""Undefined for sequences of unequal length"")n    return sum(ch1 != ch2 for ch1 ch2 in zip(s1 s2))nnnSo there are two questions:nnHow could I change randomly a bit of my binary string?nnIs the above algorithm valid for my purposes? If it is not how could I measure the Hamming Distance at bit-level?n' 'I do not see the point in getting random bits and than lshifting. A randInt should do just right. Also if you want to change a single bit try to xor a character instead of the string. If that does not work ...=chr(ord(char)^x)n' 'I assume there's a typo in your question. As Jonas Wielicki says os.random doesn't exist; presumably you meant os.urandom. Yes it's a Good Idea to use the system's random source for crypto work but using os.urandom directly isn't so convenient. Fortunately the random module provides an interface toos.urandom: the SystemRandom class.nnDoing bit-twiddling of multi-byte byte objects is possible in Python although it is somewhat fiddly (especially in Python 2). It's much easier to do this sort of thing with Python integers. You can certainly get 64 random bits using the getrandbits method although of course it's possible that some of those leading bits are zero bits.nnHere's some code that runs on Python 2 or Python 3 that generates a random 64 bit number flips one of its bits and then computes the Hamming distance between the original number & the number with the flipped bit (which is of course 1). nnimport randomnn# SystemRandom uses os.urandom() nsysrandom = random.SystemRandom()nndef bincount(n):n    return bin(n).count(""1"")nnfor _ in range(5):n    bits0 = sysrandom.getrandbits(64)n    print('bits0: {:016x}'.format(bits0))nn    bitnum = sysrandom.randint(0 64)n    print('bitnum: {}'.format(bitnum))nn    bits1 = bits0 ^ (1 << bitnum)n    print('bits1: {:016x}'.format(bits1))nn    hamming = bincount(bits0 ^ bits1)n    print('Hamming distance: {}n'.format(hamming))nnntypical outputnnbits0: a508c77693a0e7d7nbitnum: 32nbits1: a508c77793a0e7d7nHamming distance: 1nnbits0: 9608e25db458a350nbitnum: 3nbits1: 9608e25db458a358nHamming distance: 1nnbits0: f485bd53af91e2dcnbitnum: 62nbits1: b485bd53af91e2dcnHamming distance: 1nnbits0: 18f6749bc260fcd1nbitnum: 17nbits1: 18f6749bc262fcd1nHamming distance: 1nnbits0: 51b35142c99b6814nbitnum: 54nbits1: 51f35142c99b6814nHamming distance: 1nnnThere are faster ways to compute the number of 1 bits in a Python integer but bincount is reasonably fast (and faster than a Python implementation of the well-known algorithm by Kernighan); see fast way of counting non-zero bits in python for other methods.nnIf you need to convert bits0 to a bytes object that's easy in Python 3: just use the .to_bytes method egnnbytes0 = bits0.to_bytes(8 'big')    nnnIf you need to use Python 2 converting an integer to a string and converting a string to an integer takes a little more work. Here's a demo using a modified version of the above code.nnfrom __future__ import print_functionnimport randomnfrom binascii import hexlifynn# SystemRandom uses os.urandom() nsysrandom = random.SystemRandom()nndef bincount(n):n    return bin(n).count(""1"")nndef int_to_bytes(n size):n    result = n    for _ in range(size):n        result.append(chr(n & 0xff))n        n >>= 8n    return ''.join(result::-1)nndef bytes_to_int(bs):n    n = 0n    for b in bs:n        n = (n << 8) | ord(b)n    return nnnfor _ in range(4):n    bits0 = sysrandom.getrandbits(64)n    print('bits0: {0:016x}'.format(bits0))nn    bs = int_to_bytes(bits0 8)n    print('bytes:' repr(bs))n    print('hex:  ' hexlify(bs))nn    n = bytes_to_int(bs)n    print('int:   {0:016x} {1}n'.format(n n == bits0))nnntypical outputnnbits0: 69831968a1b0aff8nbytes: 'ix83x19hxa1xb0xafxf8'nhex:   69831968a1b0aff8nint:   69831968a1b0aff8 Truennbits0: c2c77e02969d3ebcnbytes: 'xc2xc7~x02x96x9d>xbc'nhex:   c2c77e02969d3ebcnint:   c2c77e02969d3ebc Truennbits0: e87c78eb3929a76fnbytes: 'xe8|xxeb9)xa7o'nhex:   e87c78eb3929a76fnint:   e87c78eb3929a76f Truennbits0: 0d5d796c986ba329nbytes: 'rylx98kxa3)'nhex:   0d5d796c986ba329nint:   0d5d796c986ba329 Truenn'",['python-2.7'],"['python-3.x', 'python-2.7']"
40071344,"'Error when using heroku-toolbelt: 3.43.12 on windows 7 cant run any command' 'Whenever I run any command it gives me the following errornnpanic: mkdir U:: The specified network name is no longer available.nngoroutine 1 running:npanic(0x67d400 0x12ab2800)n        /usr/local/go/src/runtime/panic.go:500 +0x331nmain.must(0x7be130 0x12ab2800)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/io.go:189 +0x44nmain.configHome(0x0 0x0)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:66 +0nx157nmain.init()n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:27 +0nx2c6npanic: mkdir U:: The specified network name is no longer available.nngoroutine 1 running:npanic(0x67d400 0x12cb2800)n        /usr/local/go/src/runtime/panic.go:500 +0x331nmain.must(0x7be130 0x12cb2800)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/io.go:189 +0x44nmain.configHome(0x0 0x0)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:66 +0nx157nmain.init()n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:27 +0nx2c6npanic: mkdir U:: The specified network name is no longer available.nngoroutine 1 running:npanic(0x67d400 0x12c527e0)n        /usr/local/go/src/runtime/panic.go:500 +0x331nmain.must(0x7be130 0x12c527e0)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/io.go:189 +0x44nmain.configHome(0x0 0x0)n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:66 +0nx157nmain.init()n        /home/ubuntu/.go_workspace/src/github.com/heroku/cli/filesystem.go:27 +0nx2c6n !    error getting commands pid 18844 exit 2nnnI dont get it I downloaded the windows toolbet why is this using addresses of ubuntu I even uninstalled it and reinstalled it again....nnEDIT:nnI have another git bash installed separately and when I tried to login from there it asked me to login from the cmd.exe when I typed ""start cmd"" in this other git bash (which is MINGW32) it opened a new cmd and I tried the heroku commands there and it worked.......what sorcery is this!!!nnSO if I start cmd.exe from normal methods hereoku commands gives me the above error but if I start it from the mingw32 shell and type heroku it works...n' nan",['django'],['django']
40071398,"'scatter plot and line in python' 'I have a question about how to place scatter plot and line into one graph correctly.nnHere is the code:nnimport numpy as npnimport matplotlib.pyplot as pltnnt= np.linspace(60 180100)nax= plt.subplot()nax.plot(data.Weight data.Height  color = 'red')nax.plot(t 60+ 0.05*t label=r""$Height = 60+ 0.05*Weight$"")nax.plot(t 50+ 0.16*t label=r""$Height = 50+ 0.16*Weight$"")nax.set_xlabel(r'$Weight$' fontsize=12)nax.set_ylabel(r'$Height$' fontsize=12)nax.set_title('Dependence')nnplt.show()nnnenter image description herennAs it can be seen scatter plot reflecting is not correct(it displays as lines)nnThank you!n' ""Assuming you want the variable data to be displayed in the scatter plotnnax.scatter(data.Weight data.Height  color = 'red')nn"" ""To scatter data.Weight against data.Height:nnax.plot(data.Weight data.Height  'o' markerfacecolor = 'red')nn""","['numpy', 'matplotlib']",['matplotlib']
40071425,"'Writing large amounts of numbers to a HDF5 file in Python' 'I currently have a data-set with a million rows and each around 10000 columns (variable length).nnNow I want to write this data to a HDF5 file so I can use it later on.nI got this to work but it's incredibly slow. Even a 1000 values take up to a few minutes just to get stored in the HDF5 file.nnI've been looking everywhere including SO and the H5Py docs but I really can't find anything that describes my use-case yet I know it can be done.nnBelow I have made a demo-source code describing what I'm doing right now:nnimport h5pynimport numpy as npnn# I am using just random values heren# I know I can use h5py broadcasts and I have seen it being used before.n# But the issue I have is that I need to save around a million rows with each 10000 valuesn# so I can't keep the entire array in memory.nrandom_ints = np.random.random(size = (500010000))nn# See http://stackoverflow.com/a/36902906/3991199 for ""libver='latest'""nwith h5py.File('my.data.hdf5' ""w"" libver='latest') as f:n    X = f.create_dataset(""X"" (500010000))n    for i1 in range(0 5000):n        for i2 in range(0 10000):n            Xi1i2 = random_intsi1i2nn        if i1 != 0 and i1 % 1000 == 0:n            print ""Done %d values..."" % i1nnnThis data comes from a database it's not a pre-generated np array as being seen in the source code.nnIf you run this code you can see it takes a long time before it prints out ""Done 1000 values"".nnI'm on a laptop with 8GB ram Ubuntu 16.04 LTS and Intel Core M (which performs similar to Core i5) and SSD that must be enough to perform a bit faster than this.nnI've read about broadcasting here: http://docs.h5py.org/en/latest/high/dataset.htmlnnWhen I use it like this:nnfor i1 in range(0 5000):n        Xi1: = random_intsi1nnnIt already goes a magnitude faster (done is a few secs). But I don't know how to get that to work with a variable-length dataset (the collumns are variable-length). It would be nice to get a bit of insights in how this should be done as I think I'm not having a good idea of the concept of HDF5 right now :) Thanks a lot!n' 'Following http://docs.h5py.org/en/latest/special.htmlnnand using an open h5 file f I tried:nndt = h5py.special_dtype(vlen=np.dtype('int32'))nvset=f.create_dataset('vset' (100) dtype=dt)nnnSetting the elements one by one:nnvset0=np.random.randint(01001000)    # set just one elementnfor i in range(100):    # set all arrays of varying lengthn    vseti=np.random.randint(0100i)nvset:      # view the datasetnnnOr making an object array:nnD=np.empty((100)dtype=object)nfor i in range(100):   # setting that in same wayn    Di=np.random.randint(0100i)nnvset:=D    # write it to the filennvset:=D::-1   # or write it in reverse ordernnnA portion of the last write:nnIn 587: vset-10:nOut587: narray(array(52 52 46 80  5 89  6 63 21)n       array(38 95 51 35 66 44 29 26)n       array(51 96  3 64 55 31 18)n       array(85 96 30 82 33 45) array(28 37 61 57 88)n       array(76 65  5 29) array(78 29 72) array(77 32)n       array(5) array( dtype=int32) dtype=object)nnnI can view portions of an element with:nnIn 593: vset3:10nOut593: array(86 26  2 79 90 67 66  5 63 68)nnnbut I can't treat it as a 2d array: vset3:10.  It's an array of arrays.n'",['numpy'],['numpy']
40071461,"'Swapping characters in string inputted from user in python' ""I'm a beginner in Python. I have already taken an input from the user for string and turned it into a list so I can manipulate the individual characters. I know how to switch say the first and last letter etc. but I am confused on what code to use because I don't know how many characters the user will input. Someone told me to think about it in terms of l0 with the end of len(l) l1 with len(l)-1... but there are n number of characters I am dealing with. Do I need to use a loop? Thank you.n"" 'In python reversing the order of a list is as simple as list::-1nnSo saynna='my_string'na=a::-1nprint(a)nnnYour output will be nngnirts_ymnnnFor more information on how this works have a look at slicing in python. Note however that strings in python are immutable meaning you cannot change a portion of them using slicing (for instance a2:4='yo' ).n'",['python-3.x'],"['list', 'python-2.7']"
40071582,"'In-game save feature (in tkinter game)' ""I'm working on a text-based game in Python using Tkinter. All the time the window contains a Label and a few Buttons (mostly 3). If it didn't have GUI I could just use Pickle or even Python i/o (.txt file) to save data and later retrieve it.  But what is the best way to tell the program to load the exact widgets without losing bindings buttons' commands classes etc.?  P.S.: Buttons lead to cleaning the frame of widgets and summoning new widgets. I'm thinking of assigning a lambda (button's command) to a variable and then saving it (Pickle?) to be able to load it in the future and get the right point in the plot. Should I go for it or is there a better alternative way to accomplish the thing? (If using lambda may work I'd still be grateful to see your way of doing that.)n"" ""You need to save stuff in some kind of config file. In generel I'd recommend JSON and YAML as file formats also ini for ease of parsing.nnAlso do not forget about the windows registry (portability lost then though).n"" 'My understanding was that you need a widget manager to put them where you want and it is easy to pick up values.nnCreate a new class called Manager make two functions _setNewWidget _deleteWidget like this:nnclass Manager():n    def __init__(self *args **kwargs):n        objects = {}nn    def _createButton(self frame id function etc):n        # objectid = frame.Button(function etc ...) i dnt' know sintaxes but this is the waynn    def _deleteWidget(self id):n        # objectid = None or del(objectid) same herennnTo get just:nnmanager = Manager()nmanager._createWidget(""button_fase_one"" frameTk etc etc)nmanager.objects""button_fase_one"".changeFrame() # examplenprint(manager.objects""button_fase_one"".text)nnnIn this way u can create objects and blit where u want.nnTo save data just make another function and save as json.n'",['tkinter'],['tkinter']
40071628,"'How to look up rows in certain condition' ""I have a dataframe and I would like to search strange rows like below :nnãx80x80ãx80x80monthn0  201605ãx80x80ãx80x80ãx80x80ãx80x80n1  201606n2  201607n3      08n4     nann5  201610nnnFor instance I would like to extract rows with elements that is not 6 digits like below :nn   monthn3   08n4  nannnnI have searched but couldn't figure out how to extract rows.nHow can I get this result?n"" 'Suppose your month column is of str type you can use .str.len() to get the number of digits for each element and use the result for subsetting:nndfdf.month.str.len() != 6nn# monthn#3   08n#4  NaNnn'",['pandas'],['pandas']
40071919,"""Python Regex sub doesn't replace line breaks"" 'I have a robot that brings me an html code like this:nn<div class=""std"">n  <p>CAR:n    <span>Onix</span>n  </p>n  <p>MODEL: LTZ</p>n  <p>n    <span>COLOR:n    <span>Black</span>n  </p>n  <p>ACESSORIES:n    <span>ABS</span>n  </p>n  <p>n    <span>DESCRIPTION:</span>n    <span>The Chevrolet Onix is a subcompact car launched by American automaker Chevrolet in Brazil at the 2012 SÃ£o Paulo International Motor Show1 to succeed some versions of Chevrolet Celta. Offered initially as a five-door hatchback a four-door sedan was launched in 2013 and called the Chevrolet Prisma.2 The Onix is currently only sold in some South American countries part of Mercosur including Brazil Argentina Colombia Paraguay and Uruguay.</span>n  </p>n  <p>TECHNICAL DETAIL:n    <span>The Onix is available in three trim levels (LS LT and LTZ) with two 4-cylinder engines the 1.0-litre producing 78 PS (57 kW; 77 bhp) (petrol)/ 80 PS (59 kW; 79 bhp) (ethanol) and 1.4-litre 98 PS (72 kW; 97 bhp) (petrol)/106 PS (78 kW; 105 bhp) (ethanol) offering automatic or five-speed manual transmission..</span>n  </p>n</div>nnnI applied the code below to remove the HTML tags:nncleanr    = re.compile('<.*?>')ncleantext = re.sub(cleanr'n' html_code).strip()nnnIt returns to me:nnCAR: OnixnnnMODEL: LTZnnnCOLOR:nBlacknnnnACESSORIES:nABSnnnnDESCRIPTION:nnnThe Chevrolet Onix is a subcompact car launched by American automaker Chevrolet in Brazil at the 2012 SÃ£o Paulo International Motor Show1 to succeed some versions of Chevrolet Celta. Offered initially as a five-door hatchback a four-door sedan was launched in 2013 and called the Chevrolet Prisma.2 The Onix is currently only sold in some South American countries part of Mercosur including Brazil Argentina Colombia Paraguay and Uruguay.nnnnTECHNICAL DETAIL:nThe Onix is available in three trim levels (LS LT and LTZ) with two 4-cylinder engines the 1.0-litre producing 78 PS (57 kW; 77 bhp) (petrol)/ 80 PS (59 kW; 79 bhp) (ethanol) and 1.4-litre 98 PS (72 kW; 97 bhp) (petrol)/106 PS (78 kW; 105 bhp) (ethanol) offering automatic or five-speed manual transmission..nnnNow I need to remove the line breaks to have something like this:nnCAR: OnixnMODEL: LTZnCOLOR: BlacknACESSORIES: ABSnDESCRIPTION: The Chevrolet Onix is a subcompact car launched by American automaker Chevrolet in Brazil at the 2012 SÃ£o Paulo International Motor Show1 to succeed some versions of Chevrolet Celta. Offered initially as a five-door hatchback a four-door sedan was launched in 2013 and called the Chevrolet Prisma.2 The Onix is currently only sold in some South American countries part of Mercosur including Brazil Argentina Colombia Paraguay and Uruguay.nTECHNICAL DETAIL: The Onix is available in three trim levels (LS LT and LTZ) with two 4-cylinder engines the 1.0-litre producing 78 PS (57 kW; 77 bhp) (petrol)/ 80 PS (59 kW; 79 bhp) (ethanol) and 1.4-litre 98 PS (72 kW; 97 bhp) (petrol)/106 PS (78 kW; 105 bhp) (ethanol) offering automatic or five-speed manual transmission..nnnI tried this code below but it doesn't match the line breaks correctly:nncleantext = re.sub(r':s*rn*' ': ' cleantext)nnnI tried this another code also:nncleantext = cleantext.replace(': n' ': ')nnnIt doesn't work also. How can I manage this?n' 'I think this should work for you nn>>> string = """"""nCAR: OnixnnnMODEL: LTZnnnCOLOR:nBlacknnnnACESSORIES:nABSnnnnDESCRIPTION:nnnThe Chevrolet Onix is a subcompact car launched by American automaker Chevrolet in Brazil at the 2012 SÃ£o Paulo International Motor Show1 to succeed some versions of Chevrolet Celta. Offered initially as a five-door hatchback a four-door sedan was launched in 2013 and called the Chevrolet Prisma.2 The Onix is currently only sold in some South American countries part of Mercosur including Brazil Argentina Colombia Paraguay and Uruguay.nnnnTECHNICAL DETAIL:nThe Onix is available in three trim levels (LS LT and LTZ) with two 4-cylinder engines the 1.0-litre producing 78 PS (57 kW; 77 bhp) (petrol)/ 80 PS (59 kW; 79 bhp) (ethanol) and 1.4-litre 98 PS (72 kW; 97 bhp) (petrol)/106 PS (78 kW; 105 bhp) (ethanol) offering automatic or five-speed manual transmission..n""""""n>>> list_string = string.split(""nnn"")n>>> for each in list_string:n    print each.replace(""n"""""").strip()nnnCAR: OnixnMODEL: LTZnCOLOR:BlacknACESSORIES:ABSnDESCRIPTION:nThe Chevrolet Onix is a subcompact car launched by American automaker Chevrolet in Brazil at the 2012 SÃ£o Paulo International Motor Show1 to succeed some versions of Chevrolet Celta. Offered initially as a five-door hatchback a four-door sedan was launched in 2013 and called the Chevrolet Prisma.2 The Onix is currently only sold in some South American countries part of Mercosur including Brazil Argentina Colombia Paraguay and Uruguay.nTECHNICAL DETAIL:The Onix is available in three trim levels (LS LT and LTZ) with two 4-cylinder engines the 1.0-litre producing 78 PS (57 kW; 77 bhp) (petrol)/ 80 PS (59 kW; 79 bhp) (ethanol) and 1.4-litre 98 PS (72 kW; 97 bhp) (petrol)/106 PS (78 kW; 105 bhp) (ethanol) offering automatic or five-speed manual transmission..nn' 'I think there are two parts to your problem nFirst is to Join the string in two lines like belownCOLOR:nBlacknntonCOLOR: blacknnand then remove all empty linesnnFor first part you could use replace your re.sub with followingncleantext = re.sub(r'(.*):s*rn(.*)' 'g<1>: g<2>' cleantext)nnAnd for removing empty lines it would be tricky to do it via re.sub so I would suggest to usencleantext = ""n"".join(line for line in cleantext.split('n') if line.strip() != '')nnThis would give you answer as expectedn'",['regex'],['regex']
40072050,"'python get class object instance from another python file' 'I'm pretty new to python and classes so please excuse me if this is obvious!nnI have a class object that I run at start up however I would like to access that instance of the running class from another .py filennHow would I go about this?nnhere is an example of my code:nnclass testclass(xml):n    instanceobject = 0nn    def __new__(cls):n        return super(testclass cls).__new__(cls 'xmlfile' dir1 dir2)nn    def __init__(self):n        super(testclass self).__init__()n        testclass.instanceobject = selfn        print ""print from class init"" testclass.instanceobjectnnnthen from my other .py file I try do the following:nnfrom py1file import testclassnnprint ""print from other py file"" testclass.instanceobjectnnnand I'm getting the following:nnprint from class initn<py1file.testclass object at 0x22F7FA80>nnprint from other py filen0nnnBasically I want to call a function from the instance of the running class but I need to pass the instance object so I'm trying to get that so I can pass the instance.nnThank you in advanced!n' nan",['python-2.7'],['python-2.7']
40072058,"'How can i display my data in database and export it to pdf -Django' 'my x variable is getting all the data in my database i guess? someone help me how can i display all data and export it to pdf file.nnresponse = HttpResponse(content_type='application/pdf')nresponse'Content-Disposition' = 'attachment; filename=""WishList.pdf""'nnbuffer = BytesIO()nn# Create the PDF object using the BytesIO object as its ""file.""np = canvas.Canvas(buffer)nx = Item.objects.all()nnp.drawString(100 100x)nnp.drawString(200300""sad"")nn# Close the PDF object cleanly.np.showPage()np.save()nn# Get the value of the BytesIO buffer and write it to the response.npdf = buffer.getvalue()nbuffer.close()nresponse.write(pdf)nreturn responsenn' 'Your Variable x won't return anything you can print into the PDF because its a querryset and not a couple strings attached to each other. I just started working with Django and getting the values works something like this:nnx = Item.objects.all0.namennnThis Code snippet will asigne the vale of the row name of the first entry in your Item table to the variable x.nFor more Information I can only recommend reading the n   Tutorial about making queries on the django website.n'",['django'],['django']
40072104,"'Multi-color text in one Gtk.Label' 'I'm using a css file for theming my interface. So I have currently this:nn    style_file = Gio.File.new_for_path('interface.css')n    style_provider = Gtk.CssProvider()n    style_provider.load_from_file(style_file)nn    Gtk.StyleContext.add_provider_for_screen(n        Gdk.Screen.get_default()n        style_providern        Gtk.STYLE_PROVIDER_PRIORITY_APPLICATIONn    )nn    self.label = Gtk.Label()n    self.label.set_name('foobar_label')n    self.label.set_markup(""<span color='blue'>foo </span>""n                          ""<span color='green'>{} </span>""n                          ""<span color='red'>""n                          ""bar</span>"".format(baz))nnnI want to get rid of set_markup call and use the css for style it. I really must create three separated labels just for color it?n' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40072151,"'Installing matplotlib using pip gives error' 'I am new to python and is using pip to download and install packages. I ran the following code on my command window and it throws an errornnpip install matplotlibnnnAnd the process starts as nnCollecting matplotlibn  Using cached matplotlib-1.5.3-cp27-cp27m-win32.whlnCollecting numpy>=1.6 (from matplotlib)n  Using cached numpy-1.11.2-cp27-none-win32.whlnCollecting python-dateutil (from matplotlib)n  Using cached python_dateutil-2.5.3-py2.py3-none-any.whlnCollecting cycler (from matplotlib)n  Using cached cycler-0.10.0-py2.py3-none-any.whlnCollecting pyparsing!=2.0.4!=2.1.2>=1.5.6 (from matplotlib)n  Using cached pyparsing-2.1.10-py2.py3-none-any.whlnCollecting pytz (from matplotlib)n  Using cached pytz-2016.7-py2.py3-none-any.whlnCollecting six>=1.5 (from python-dateutil->matplotlib)n  Using cached six-1.10.0-py2.py3-none-any.whlnInstalling collected packages: numpy six python-dateutil cycler pyparsing pytz matplotlibnException:nTraceback (most recent call last):n  File ""c:python27libsite-packagespipbasecommand.py"" line 215 in mainn    status = self.run(options args)n  File ""c:python27libsite-packagespipcommandsinstall.py"" line 317 in runn    prefix=options.prefix_pathn  File ""c:python27libsite-packagespipreqreq_set.py"" line 742 in installn    **kwargsn  File ""c:python27libsite-packagespipreqreq_install.py"" line 831 in installn    self.move_wheel_files(self.source_dir root=root prefix=prefix)n  File ""c:python27libsite-packagespipreqreq_install.py"" line 1032 in move_wheel_filesn    isolated=self.isolatedn  File ""c:python27libsite-packagespipwheel.py"" line 346 in move_wheel_filesn    clobber(source lib_dir True)n  File ""c:python27libsite-packagespipwheel.py"" line 324 in clobbern    shutil.copyfile(srcfile destfile)n  File ""c:python27libshutil.py"" line 83 in copyfilen    with open(dst 'wb') as fdst:nIOError: Errno 13 Permission denied: 'c:python27Libsite-packagesnumpycoremultiarray.pyd'nnnAnd it gives these traceback errors. I'm unable to figure out what these errors are and how to solve them. Please help. It works perfectly till collecting the packages but at the time of installing it throws errors.n' 'Try python -m pip install matplotlib.nnornnnOpen the cmd as administrator nthen python -m pip install matplotlibnn'",['matplotlib'],['matplotlib']
40072224,"'Python 2.7: Add 2 list items in a function' 'I want to be able to add multiple items to my code with a function. But I want to be able to still add one single item or none. Here is and example.nnlistX = ""a"" ""b"" ""c""nndef addList(add):n    if add != ""null"":n        listX.append(add)nnaddList(""d"")nnnAdds d at the end. Simple.nnprint listXnnaddList(""e"" + ""f"")nnprint listXnnnNow it's 'a' 'b' 'c' 'd' 'ef'. I want it to be 'a' 'b' 'c' 'd' 'e' f. Also I also want to have only one argument for adding an item the (add) one.nnHow do I do this? Please help. And as always thanks in advance.n' 'Your Function addList expects only 1 argument when you saynnaddList(""e"" + ""f"") # it passes it as addList(""ef"")nnnTo solve your problem simply use * to get multiple arguments and extend to add to it easily:nnlistX = 'a' 'b' 'c'nndef addList(*args):n  listX.extend(args)nnaddList('d' 'e' 'f')nprint (listX)nnnreturns:nn'a' 'b' 'c' 'd' 'e' 'f'nn' ""The problem is breaking down the 'e' + 'f' thing you have there.nnAs long as your parameter is an interable this should worknndef addList(iterable):n   for item in iterable:n       listX.append(item)nn""",['python-2.7'],"['python-2.7', 'list']"
40072263,"'How setuptools builds extensions where to add a compiler option?' 'I was trying to build numpy on Cygwin but I got a error with xlocale.h which is defined in X11/xlocale.h. My naive patch was to add this: nn#ifdef __CYGWIN__ n   #include ""X11/Xlocale.h""n#elsen   #include ""xlocale.h""n#endifnnnAlternatively I could have added -I/usr/include/X11 to the Makefile but there is no Makefiles in setuptools and I am trying to understand how it works. nnWhen I type python setup.py build_ext how Python builds the extensions?n' nan",['numpy'],['numpy']
40072312,'TypeError: return arrays must be of ArrayType' 'epsData is a two-dimensional array consisting of Dates and StockID.nnI took out some of the code in order to make it simple. nnThe code calls the functions Generate and neweps epsData is passed by the engine. I am not sure why it gives an error when I try to pass the array epsss to the SUE() function. nnI tried to remove the extra bracket in array (if any) by using flatten function but that does not help.nnSUE() is supposed to loop through the array and find the 4th last different value and then store these in an array.nnI get this error:nnTypeError: return arrays must be of ArrayTypennnwith the three lines marked below:nndef lastdifferentvalue(valsdatasi):n  sizes=len(datas)n  j=sizes-1n  values=0n  while (i>0) and (j>=0):n    if logical_and((vals-datasj!=0)(datasj!=0)(datasj-1!=0)): # !! HERE !!n      i=i-1n      values=datasj-1n    j=j-1n  return j valuesnndef SUE(datas):n  sizes=len(datas)n  j=sizes-1n  values=0n  sues=zeros(8)n  eps1=datasjn  i=7n  while (j>0) and (i>=0) :n    counts eps2=lastdifferentvalue(eps1array(datas0:j)4)n    if eps2!=0:n      suesi=eps1-eps2n      i=i-1n      jeps1=lastdifferentvalue(eps1datas0:j1) # !! HERE !!nn  stddev=std(SUE)n  sue7=SUE7n  return stddevsue7          nndef Generate(dialpha):      nn    #the code below loops through the data. neweps is a two dimensional array of floats dates stockid                     n    for ii in range(0len(alpha)):n      if (epss2ii-epss1ii!=0) and (epss2ii!=0) and (epss1ii!=0):n        predata=0n        epsss= newepsdi-delay-250:di-delay+1iin        stddevssuedata= SUE(array(epsss.flatten())) # !! HERE !!nn' nan,['numpy'],['python-2.7']
40072316,"'Appending to a list from a for loop (to read a text file)' ""How do I append to an undetermined list from a for loop?nThe purpose is to first slice each line by '-'. Then I would like to append these slices to an array without a determined size. I have the following code and am loosing hair because of how simple this seems! nnEach line in the text file looks like the following: n2014-06-1342.7-73.827nnprogram so far:nnf = open('Lightning.txt')nnlightning =list()nnfor templine in f:nn    if not templine.startswith('2014'): continuenn    templine = templine.rstrip('-')nn    line = templine.split()nn    print line2nnnThank you communityn"" 'Do this: for templine in f.read():  nYou forgot the read() methidn' 'Try something like that if you want to get list of formated strings.nnf = open('Lightning.txt')nlightning =list()nfor templine in f:n    if not templine.startswith('2014'): continuen    # We are splitting the line by '' to get 2014-06-13 42.7-73.8 27n    templine = templine.split('')n    # After splitting is done we know that at the 1st place is the date n    # and at the last one is the number of video recordings.nn    #Here we asign the first item to ""data"" and the last one to ""num_of_strikes""n    date num_of_strikes = templine0 templine-1n    # After that is done we create the output string with placeholders n    # {data} and {num} waiting for data to be passedn    output = '{date} : {num} lightning strikes were recorded.'n    # Here we are appending the formated string passing our data to placeholdersn    # And yes they work like a dictionary so u can write (key = value)n    lightning.append(output.format(date= date num= num_of_strikes))nn' 'This is an ideal job for the csv lib:nnimport csvnnwith open('Lightning.txt') as f:n    data = n    # unpack the elements from each line/rown    for dte _ _ i in csv.reader(f):n        # if the date starts with 2014 add the date string and the last element in        if dte.startswith('2014'):n            data.append((dte i))nnnWhich can all be done using a list comp:nnimport csvnnwith open('Lightning.txt') as f:n    data = (dte i) for dte _ _ i in csv.reader(f) if dte.startswith('2014')nn'",['list'],"['list', 'python-2.7']"
40072329,'Converting Complex-Valued Angles from Radians to Degrees in Python?' 'After using cmath to compute the asin of 1.47 which returns a complex angle measured in radians;nnn  cmath.asin(1.47)n  n  (1.5707963267948966+0.9350931316301407j)nnnIs there a way in which can I convert this value to degrees? math.degrees does not work since it cannot compute with complex values.nnThanks!n' 'Degrees make little sense in complex numbers. But if you must use them just use the same math formula as for real numbers:nncmath.asin(1.47) * 180 / math.pinnnYou get the resultnn(90+53.576889894078214j)nnnNote the 90 degrees in the real part.nnThe usefulness of this depends on the context. For example when taking a complex logarithm only the imaginary part of the result is an angle and thus can be expressed in degrees. The real part is the logarithm of the modulus of the parameter and has nothing to do with an angle. In that case use the above conversion only on the imaginary part. In your arcsine example usually only the real part is considered an angle which is why you got the simple 90 for the real part but a mess for the imaginary part.nnLet us know just what you are doing with this and we can help you determine the best way to use degrees.n' 'To use math.degrees() you need to get the real part of the complex number first.nnimport cmathnimport mathnrad = cmath.asin( 1.47 )nmath.degrees( rad.real )nn',['python-2.7'],['python-2.7']
40072420,"'Interpolate without having negative values in python' 'I've been trying to create a smooth line from these values but I can't have negative values in my result. So far all the methods I tried do give negative values. Would love some help.nnimport matplotlib.pyplot as pltnfrom scipy.interpolate import UnivariateSplinenimport numpy as npny = np.asarray(05801011040308050)nx = np.arange(len(y))nnplt.plot(x y 'r' ms=5)nspl = UnivariateSpline(x y)nxs = np.linspace(0len(y)-1 1000)nspl.set_smoothing_factor(2)nnplt.plot(xs spl(xs) 'g' lw=3)nplt.show()nnnn' 'This does it albeit in some sections better than others.nnimport matplotlib.pyplot as pltnfrom scipy.interpolate import UnivariateSplinenimport numpy as npnny = np.asarray(05801011040308050)nx = np.arange(len(y))nnplt.plot(x y 'r' ms=5)nspl = UnivariateSpline(x y)nxs = np.linspace(0len(y)-1 1000)nspl.set_smoothing_factor(2)nn#new codenny = spl(xs).clip(0max(spl(x)))nspl2 = UnivariateSpline(xs ny)nnplt.plot(xs spl(xs)  'g' lw=2label=""original"")nplt.plot(xs spl2(xs) 'b' lw=2label=""stack mod"")nnplt.legend()nplt.show()nnnn' 'Spline fitting is known to overshoot. You seem to be looking for one of the so-called monotonic interpolators. For instancennIn 10: from scipy.interpolate import pchipnnIn 11: pch = pchip(x y)nnnproducesnnIn 12: xx = np.linspace(x0 x-1 101)nnIn 13: plt.plot(x y 'ro' label='points')nOut13: <matplotlib.lines.Line2D at 0x7fce0a7fe390>nnIn 14: plt.plot(xx pch(xx) 'g-' label='pchip')nOut14: <matplotlib.lines.Line2D at 0x7fce0a834b10>nnnn'","['numpy', 'matplotlib']",['matplotlib']
40072528,"'Print part of String with matching Index' 'I'm trying to make a Program that takes a given text checks to see at which indexes ("") is located throughout the text and prints anything in-between the quotation marks ("") i.e. ""xyz"" blablabla ""abc"". In this case xyz between 0 and 4 and abc between 16 and 20 would be printed. I've got the indexes part to work but can't seem to find a way to print whatever's within the range of these indexes. Here's my code:nntext = '""bleed"" seed ""deed""'nnindex = 0nna = 0nnfind = int(input(""Would you like to find all the links in the file?n If yes enter 1:  ""))nndef Link_Finder(a):nn    index = 0nn    if find == 1:nn        while index < len(text):nn            index = text.find('""' index)nn            if index == -1:nn                breaknnn            print('"" found at' index)nnn            index = index + 2nn    return indexnnLink_Finder(a)nnprint(textindex:)nnnI'm only printing the Indexes for my own reference. I'm quite new to Python so I'm not really familiar with complex stuff yet.nnOne way to do this in my opinion would be to return the Index values and then use the returned values to print the required text.nnThanks.n' 'If you don't mind using regular expressions I think this is an easier solution:nnimport renprint(re.findall(r'""(^""*)""' text))nnnIf not you can use your link_finder function:nndef link_finder(s):n    index = 0n    while index < len(s):n        index = s.find('""' index)n        if index == -1:n            breakn        yield indexn        index = index + 2nnnAnd then iterate through the results in pairsnnresults = list(link_finder(text))nnfor start end in zip(results::2 results1::2):n    print textstart+1:endnn'",['python-3.x'],"['regex', 'python-2.7', 'python-3.x']"
40072568,"'How to iterate through instances in a tree?' 'I have a problem with a self-written tree class in python:nnclass Tree:n    def __init__(self parent=0 value=0):n        self.value = valuen        self.parent = parentn    def __iter__(self): return selfn    def next(self):n        tmp = self.valuen        try:n            self.parent = self.parent.parentn            self.value = self.parent.valuen        except AttributeError:n            raise StopIterationn        return tmpn    def sum(self):n        list_ = item for item in selfn        print list_n        return sum(list_)nnnActually the ""tree"" is not fully written but the current problem blocks further progress.nThe structure has only two instance variables (value parent).nI would like to sum values from the current instance to the first parent with iterators (if it is all together possible). The sum method is used for that (additional list_ variable is unnecessary but helps further to explain the problem). nnWhen running a test casennparent = Tree()nchild = Tree(parent=parent value=8)nchild2 = Tree(parent=childvalue=10)nprint child2.sum()nnnI obtain the following:nn10n10nnnPlease could anybody explain why the list of values contains only one number though it should look like 108? Seems the problem is in the implementation of iter and next but I can't understand how to repair the solution.nnThank you in advance.n' ""Here you go:nnclass Tree:n    def __init__(self parent=None value=0):n        self.value = valuen        self.parent = parentnn    def __iter__(self): n        yield self.valuen        root = selfn        while root.parent is not None:n            yield root.parent.valuen            root = root.parentn        raise StopIterationnnn    def tree_sum(self):n        return sum(list(self))nnnparent = Tree()nchild = Tree(parent=parent value=8)nchild2 = Tree(parent=childvalue=10)nnnI've changed the default parent value to None.nnfor i in child2:n    print(i)nn10n8n0 # 0 is here because the parent value is 0 by default.nn"" 'I'm not sure you can call this a Tree. One would expect parent node(s) and   multiple leaf nodes and not just a linear connection of objects.nnSee: a general tree implementation in pythonnnOn another note if you want to implement a linkedlist suggestions made in the comment to your question by Barny should be considered and as well you can give an eye to: Python Linked ListnnComing to your current implementation you'll need some sort of loop to walk from the current child node up until the head parent node. And when the next parent attribute is not found stop the iteration. The following puts the logic in the __iter__ method of the class which is now a generator function:nnclass Tree:n    def __init__(self parent=None value=0):n        self.value = valuen        self.parent = parentnn    def __iter__(self): n        _parent = self.parentn        yield self.valuen        while True:n            try:               n                yield _parent.value n                _parent = _parent.parentn            except AttributeError:n                break  nn    def sum_from_node(self):n        list_ = item for item in selfn        print list_n        return sum(list_)nnnDemo:nnparent = Tree()nchild = Tree(parent=parent value=8)nchild2 = Tree(parent=childvalue=10)nchild3 = Tree(parent=child2value=4)nprint child3.sum_from_node()n# 4 10 8 0n# 22nn'",['python-2.7'],"['python-2.7', 'list']"
40072572,"'Cython numpy array indexer speed improvement' 'I wrote the following code in pure python the description of what it does is in the docstrings:nnimport numpy as npnfrom scipy.ndimage.measurements import find_objectsnimport itertoolsnndef alt_indexer(arr):nn    """"""n    Returns a dictionary with the elements of arr as keyn    and the corresponding slice as value.nn    Note:nn        This function assumes arr is sorted.nn    Example:nn        >>> arr = 0032123n        >>> loc = _indexer(arr)n        >>> locn        {0: (slice(0L 2L None))n        1: (slice(2L 3L None))n        2: (slice(3L 5L None))n        3: (slice(5L 7L None))}n        >>> arr = sorted(arr)n        >>> arrloc30n        3 3n        >>> arrloc20n        2 2nn    """"""nn    unique counts = np.unique(arr return_counts=True)n    labels = np.arange(1len(unique)+1)n    labels = np.repeat(labelscounts)nn    slicearr = find_objects(labels)n    index_dict = dict(itertools.izip(uniqueslicearr))nn    return index_dictnnnSince i will be indexing very large arrays i wanted to speed up the operations by using cython here is the equivalent implementation:nnimport numpy as npncimport numpy as npnndef _indexer(arr):nn    cdef tuple unique_counts = np.unique(arr return_counts=True)n    cdef np.ndarraynp.int32_tndim=1 unique = unique_counts0n    cdef np.ndarraynp.int32_tndim=1 counts = unique_counts1.astype(int)nn    cdef int start=0n    cdef int endn    cdef int in    cdef dict d ={}nn    for i in xrange(len(counts)):n        if i>0:n            start = countsi-1+startn        end=countsi+startn        duniquei=slice(startend)n    return dnnnBenchmarksnnI compared the time it took to complete both operations:nnIn 26: import numpy as npnnIn 27: rr=np.random.randint(010001000000)nnIn 28: %timeit _indexer(rr)n10 loops best of 3: 40.5 ms per loopnnIn 29: %timeit alt_indexer(rr) #pure pythonn10 loops best of 3: 51.4 ms per loopnnnAs you can see the speed improvements are minimal. I do realize that my code was already partly optimized since i used numpy.nnIs there a bottleneck that i am not aware of?nShould i not use np.unique and write my own implementation instead?nnThanks.n' 'With arr having non-negative not very large and many repeated int numbers here's an alternative approach using np.bincount to simulate the same behavior as np.unique(arr return_counts=True) -nndef unique_counts(arr):n    counts = np.bincount(arr)n    mask = counts!=0n    unique = np.nonzero(mask)0n    return unique countsmask nnnRuntime testnnCase #1 :nnIn 83: arr = np.random.randint(0100(1000)) # Input arraynnIn 84: unique counts = np.unique(arr return_counts=True)n    ...: unique1 counts1 = unique_counts(arr)n    ...: nnIn 85: np.allclose(uniqueunique1)nOut85: TruennIn 86: np.allclose(countscounts1)nOut86: TruennIn 87: %timeit np.unique(arr return_counts=True)n10000 loops best of 3: 53.2 Âµs per loopnnIn 88: %timeit unique_counts(arr)n100000 loops best of 3: 10.2 Âµs per loopnnnCase #2:nnIn 89: arr = np.random.randint(01000(10000)) # Input arraynnIn 90: %timeit np.unique(arr return_counts=True)n1000 loops best of 3: 713 Âµs per loopnnIn 91: %timeit unique_counts(arr)n10000 loops best of 3: 39.1 Âµs per loopnnnCase #3: Let's run a case with unique having some missing numbers in the min to max range and verify the results against np.unique version as a sanity check. We won't have a lot of repeated numbers in this case and as such isn't expected to be better on performance.nnIn 98: arr = np.random.randint(010000(1000)) # Input arraynnIn 99: unique counts = np.unique(arr return_counts=True)n    ...: unique1 counts1 = unique_counts(arr)n    ...: nnIn 100: np.allclose(uniqueunique1)nOut100: TruennIn 101: np.allclose(countscounts1)nOut101: TruennIn 102: %timeit np.unique(arr return_counts=True)n10000 loops best of 3: 61.9 Âµs per loopnnIn 103: %timeit unique_counts(arr)n10000 loops best of 3: 71.8 Âµs per loopnn'",['numpy'],['numpy']
40072623,"'Issues deploying Django project' ""Okay I am new to the Django framework but I have a basic site that I want live. I have a droplet up on Digital Ocean and my files have been moved over to there.nnI get this error:nnImportError at /nncannot import name patternsnnRequest Method:     GETnRequest URL:    http://188.166.147.202/nDjango Version:     1.10.2nException Type:     ImportErrornException Value:    nncannot import name patternsnnException Location:     /home/django/django_project/django_project/urls.py in <module> line 1nPython Executable:  /usr/bin/pythonnPython Version:     2.7.6nPython Path:    nn'/home/django/django_project'n '/home/django'n '/usr/bin'n '/usr/lib/python2.7'n '/usr/lib/python2.7/plat-x86_64-linux-gnu'n '/usr/lib/python2.7/lib-tk'n '/usr/lib/python2.7/lib-old'n '/usr/lib/python2.7/lib-dynload'n '/usr/local/lib/python2.7/dist-packages'n '/usr/lib/python2.7/dist-packages'n '/usr/lib/python2.7/dist-packages/gtk-2.0'nnServer time:    Sun 16 Oct 2016 16:26:46 +0000nnnurls.py looks like:nnfrom django.conf.urls import patterns include urlnnfrom django.contrib import adminnadmin.autodiscover()nnurlpatterns = n    url(r'^admin/' include(admin.site.urls))n    url(r'^' include('personal.urls'))n    url(r'^blog/' include('blog.urls'))nnnnThe doplet is currently using python 2.7 but I used python3 while developing so how can I upgrade the version of python on my droplet?n"" 'patterns was deprecated in Django 1.8 and removed in Django 1.10. nnYour urlpatterns is already as it should be a list of url() instances. Simply change your import to:nnfrom django.conf.urls import include urlnn'",['django'],['django']
40072913,"'AttributeError in a pygame.sprite.Sprite subclass' ""I am currently developing a 2D platformer game with pygame and I have discovered an issue. I usually handled sprite rendering with a single sprite group declared inside of the main function. Now that I need to have some specific sprites over others/under sprites having a single group won't cut it and having multiple groups just laying about is a mess. So I decided to add groups into my Entity class:nnclass Entity(pygame.sprite.Sprite):n    entitiesTop = pygame.sprite.Group()n    entitiesMid = pygame.sprite.Group()n    entitiesBot = pygame.sprite.Group()n    entities = entitiesBot entitiesMid entitiesTopnn    def __init__(self force = None):n        pygame.sprite.Sprite.__init__(self)n        if force is None:n            if isinstance(self Platform):n                Entity.entitiesTop.add(self)n            elif isinstance(self (Bullet Gun)):n                Entity.entitiesMid.add(self)n            else:n                Entity.entitiesBot.add(self)n        else:n            Entity.entitiesforce.add(self)nnnand I made all the other subclasses of Entity automatically get added to a group using its __init__ method. I think it was working fine with the classes since the error didn't show when I initialized the entities themselves rather when I tried to run this codenn     for group in Entity.entities:nnnan AttributeError appearednnAttributeError: type object 'Entity' has no attribute 'entities'nnnI am relatively new to python OOP so I don't quite get what I am missing here. Does anyone know the solution to this?n"" 'furas at the comments has solved the mystery. I just forgot to remove the old definition of the class! Silly me. Its all working fine now. n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40072950,"'Concatenating pandas DataFrames keeping only rows with matching values in a column?' 'I am trying to ""merge-concatenate"" two pandas DataFrames. Basically I want to stack the two DataFrames but only keep the rows from each DataFrame which matching values in the other DataFrame. So for example:nndata1:nn+---+------------+-----------+-------+n|   | first_name | last_name | class |n+---+------------+-----------+-------+n| 0 | Alex       | Anderson  |     1 |n| 1 | Amy        | Ackerman  |     2 |n| 2 | Allen      | Ali       |     3 |n| 3 | Alice      | Aoni      |     4 |n| 4 | Andrew     | Andrews   |     4 |n| 5 | Ayoung     | Atiches   |     5 |n+---+------------+-----------+-------+nndata2:nn+---+------------+-----------+-------+n|   | first_name | last_name | class |n+---+------------+-----------+-------+n| 0 | Billy      | Bonder    |     4 |n| 1 | Brian      | Black     |     5 |n| 2 | Bran       | Balwner   |     6 |n| 3 | Bryce      | Brice     |     7 |n| 4 | Betty      | Btisan    |     8 |n| 5 | Bruce      | Bronson   |     8 |n+---+------------+-----------+-------+nnnThen the resulting data frame after performing this operation on data1 and data2 should look like:nnresult:nn+---+------------+-----------+-------+n|   | first_name | last_name | class |n+---+------------+-----------+-------+n| 3 | Alice      | Aoni      |     4 |n| 4 | Andrew     | Andrews   |     4 |n| 5 | Ayoung     | Atiches   |     5 |n| 0 | Billy      | Bonder    |     4 |n| 1 | Brian      | Black     |     5 |n+---+------------+-----------+-------+nnnBasically I'm trying to merge the two data sets and then stack the columns. I can think of a couple ways to do this but they're all sort of hack-y. I could merge data1 and data2 and then stack up the columns or use a map like:nnmap1 = data1'subject_id'.map(lambda x: x in list(data2'subject_id'))nmap2 = data2'subject_id'.map(lambda x: x in list(data1'subject_id'))npd.concat(data1map1 data2map2)nnnBut is there a more elegant solution to this?n' ""How about this?nnIn 335: cls = np.intersect1d(data1'class' data2'class')nnIn 336: clsnOut336: array(4 5 dtype=int64)nnIn 337: pd.concat(data1.ixdata1'class'.isin(cls) data2.ixdata2'class'.isin(cls))nOut337:n  first_name last_name  classn3      Alice      Aoni      4n4     Andrew   Andrews      4n5     Ayoung   Atiches      5n0      Billy    Bonder      4n1      Brian     Black      5nnnor:nnIn 338: data1.ixdata1'class'.isin(cls).append(data2.ixdata2'class'.isin(cls))nOut338:n  first_name last_name  classn3      Alice      Aoni      4n4     Andrew   Andrews      4n5     Ayoung   Atiches      5n0      Billy    Bonder      4n1      Brian     Black      5nn""",['pandas'],['pandas']
40072960,"'Trying to split string with regex' 'I'm trying to split a string in Python using a regex pattern but its not working correctly.nnExample text:nn""The quick {brown fox} jumped over the {lazy} dog""nnCode:nn""The quick {brown fox} jumped over the {lazy} dog"".split(r'({.*?}))nnI'm using a capture group so that the split delimiters are retained in the array.nnDesired result:nn'The quick' '{brown fox}' 'jumped over the' '{lazy}' 'dog'nnActual result:nn'The quick {brown fox} jumped over the {lazy} dog'nnAs you can see there is clearly not a match as it doesn't split the string. Can anyone let me know where I'm going wrong? Thanks.n' 'You're calling the strings' split method not re'snn>>> re.split(r'({.*?})' ""The quick {brown fox} jumped over the {lazy} dog"")n'The quick ' '{brown fox}' ' jumped over the ' '{lazy}' ' dog'nn'",['regex'],['regex']
40073003,"'Create Image Histogram Manually and Efficiently in Python' 'I want to write codes that can show the histogram of an image without using built in Matplotlib hist function.nnHere is my codes:nnimport cv2 as cvnimport numpy as npnfrom matplotlib import pyplot as pltnndef manHist(img):n   row col = img.shape # img is a grayscale imagen   y = np.zeros((256) np.uint64)n   for i in range(0row):n      for j in range(0col):n         yimgij += 1n   x = np.arange(0256)n   plt.bar(xycolor=""gray""align=""center"")n   plt.show()nndef main():n   img = cv.imread(""C:/Users/Kadek/Documents/MATLAB/2GS.jpg"")n   manHist(img)nnmain()nnnMy question is is there a more efficent way to make an array of pixel value frequency without using for loop?n' 'A NumPy based vectorized solution would be with np.bincount -nnout = np.bincount(img.ravel()minlength=256)nnnAnother vectorized approach based on .sum() -nnout = (img.ravel() == np.arange(256):None).sum(1)nnnSample run to verify results -nnIn 155: # Input image (512x512) as arrayn     ...: img = np.random.randint(0255(512512))n     ...: n     ...: # Original coden     ...: row col = img.shapen     ...: y = np.zeros((256) np.uint64)n     ...: for i in range(0row):n     ...:     for j in range(0col):n     ...:         yimgij += 1n     ...:         nnIn 156: out1 = np.bincount(img.ravel()minlength=256)nnIn 157: out2 = (img.ravel() == np.arange(256):None).sum(1)nnIn 158: np.allclose(yout1)nOut158: TruennIn 159: np.allclose(yout2)nOut159: Truenn'","['numpy', 'matplotlib']","['numpy', 'matplotlib']"
40073023,'spyder: Running without the SUID sandbox' 'I install spyder by:nnsudo pip3 install spydernnnWhen I run it:nn~$ spydernnnIt shows the following error:nn    1016/190710:ERROR:browser_main_loop.cc(217) Running without the SUID sandbox! nSee https://chromium.googlesource.com/chromium/src/+/master/docs/linux_suid_sandbox_development.md for more information on developing with the sandbox on.n    Segmentation fault (core dumped)nnnHow to fix this error? My ubuntu version is 16.10n' nan,['python-3.x'],['python-2.7']
40073167,"'How to remove a character from element and the corresponding character in another element in a list (Python)?' 'sample = 'A$$N''BBBC''$$AA'nnnI need to compare every element to every other element in the list. So compare sample0 and sample1 sample0 and sample2 sample1 and sample2.nanIf any pair in the comparison has ""$"" then ""$"" and the corresponding element needs to be eliminated. nEg. in nnsample0 and sample1    Output1 : 'AN''BC'nsample0 and sample2    Output2 : 'N' 'A'nsample1 and sample2    Output3 : 'BC''AA'nnnfor i in range(len(sample1)):n    for j in range(i + 1 len(sample1)):n        if i == ""$"" or j == ""$"":n            #Need to remove ""$"" and the corresponding element in the other listnn   #Print the pairsnn' ""This may not be the most beautiful code but will do the job.nnfrom itertools import combinationsnsample = 'A$$N''BBBC''$$AA'noutput = nfor i j in combinations(range(len(sample)) 2):n    out = '' ''n    for pair in zip(samplei samplej):n        if '$' not in pair:n            out0 += pair0n            out1 += pair1n    output.append(out)nprint(output)nn""",['list'],"['python-2.7', 'list']"
40073192,"'GLib.io_add_watch behaves differently Windows/Linux' 'I want to use GLib.io_add_watch in my Application.nnIn Ubuntu this works and i can send to the Server my START message and immediately receive an answer.nnOn Windows i never receive something.nni suspect this is because socket is different on Windows and Unix but i would like to know how i can use io_add_watch on Windows to communicate over a longer time with a xmpp server.nnimport socketnimport ginimport sysngi.require_version('Gtk' '3.0')nfrom gi.repository import GLib Gtk Gionimport signalnimport tracebacknnnFLAG_READ_WRITE = GLib.IOCondition.OUT | GLib.IOCondition.IN | n    GLib.IOCondition.PRI | GLib.IOCondition.HUP | GLib.IOCondition.ERRnnSTART = ""<?xml version='1.0'?><stream:stream to='jabber.at' xmlns='jabber:client' xmlns:stream='http://etherx.jabber.org/streams' version='1.0'>""nTLS = ""<starttls xmlns='urn:ietf:params:xml:ns:xmpp-tls'/>""nnclass Classtest():nn    def __init__(self):nn        w = Gtk.Window()n        w.set_border_width(1)n        msg = '''n        Play with resizing the window...n        '''n        w.add(Gtk.Label(msg))n        w.connect('delete-event' self.delete)n        w.show_all()n        self.connected = self.received_features = self.sent_tls = Falsen        self.sock = self.get_sock()n        print(self.sock)nn        self.SOURCEID = GLib.io_add_watch(self.sock GLib.PRIORITY_LOWn                                          FLAG_READ_WRITE self.handle_data)nnn    def get_sock(self):n        sock = socket.socket(socket.AF_INET socket.SOCK_STREAM)n        sock.setblocking(False)n        try:n            sock.connect(('xmpp.jabber.at' 5222))n        except:n            traceback.print_exc()n        return socknnn    def handle_data(self source condition):n        if condition & GLib.IOCondition.OUT:n            print(condition)n            if self.received_features and not self.sent_tls:n                print(TLS)n                source.send(TLS.encode('utf-8'))n                self.sent_tls = Truen            elif not self.connected:n                print(START)n                source.send(START.encode('utf-8'))n                self.connected = Truen        if condition & GLib.IOCondition.IN:n            print(condition)n            recv = source.recv(1024)n            if recv:n                if b'stream:features' in recv and b'starttls' in recv:n                    self.received_features = Truen                print('IN EVENT')n                print(recv.decode('utf-8'))n        if condition & GLib.IOCondition.HUP:n            print(condition)n            self.delete()n        if condition & GLib.IOCondition.PRI:n            print(condition)n        return Truenn    def delete(self w event):n        GLib.source_remove(self.SOURCEID)n        Gtk.main_quit()nnnbla = Classtest()nsignal.signal(signal.SIGINT signal.SIG_DFL)  # ^C exits the applicationnGtk.main()nnnOUTPUT UBUNTUnnTraceback (most recent call last):n  File ""lovetox-socket.py"" line 47 in get_sockn    sock.connect(('xmpp.jabber.at' 5222))nBlockingIOError: Errno 115 Vorgang ist jetzt in Bearbeitungn<socket.socket fd=11 family=AddressFamily.AF_INET type=2049 proto=0 laddr=('192.168.186.129' 44148)>n<?xml version='1.0'?><stream:stream to='jabber.at' xmlns='jabber:client' xmlns:stream='http://etherx.jabber.org/streams' version='1.0'>nIN EVENTn<?xml version='1.0'?><stream:stream xmlns='jabber:client' xmlns:stream='http://etherx.jabber.org/streams' id='10045261113578581524' from='jabber.at' version='1.0' xml:lang='en'><stream:features><c xmlns='http://jabber.org/protocol/caps' hash='sha-1' node='http://www.process-one.net/en/ejabberd/' ver='z0FZ24Izum3FsTWrHpsaAsIfp78='/><starttls xmlns='urn:ietf:params:xml:ns:xmpp-tls'><required/></starttls><compression xmlns='http://jabber.org/features/compress'><method>zlib</method></compression></stream:features>n<starttls xmlns='urn:ietf:params:xml:ns:xmpp-tls'/>nIN EVENTn<proceed xmlns='urn:ietf:params:xml:ns:xmpp-tls'/>nnnOUTPUT WINDOWSnnTraceback (most recent call last):n  File ""C:UsersPhilippDesktoplovetox-socket.py"" line 47 in get_sockn    sock.connect(('xmpp.jabber.at' 5222))nBlockingIOError: WinError 10035 Ein nicht blockierender Socketvorgang konnte nicht sofort ausgefÃ¼hrt werdenn<socket.socket fd=780 family=AddressFamily.AF_INET type=SocketKind.SOCK_STREAM proto=0 laddr=('0.0.0.0' 50968) raddr=('128.130.95.40' 5222)>n<?xml version='1.0'?><stream:stream to='jabber.at' xmlns='jabber:client' xmlns:stream='http://etherx.jabber.org/streams' version='1.0'>nnnI cant get an IN EVENT/read on the socket in Windowsn' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40073205,"'django.core.exceptions.ImproperlyConfigured: Could not resolve URL for hyperlinked relationship using view name ""user-detail""' 'TL;DR: I am getting this error and don't know why:nnn  django.core.exceptions.ImproperlyConfigured: Could not resolve URL for hyperlinked relationship using view name ""user-detail"". You may have failed to include the related model in your API or incorrectly configured the 'lookup_field' attribute on this field.nnnI am going through the django-rest-framework tutorial and am currently at a point where function based views (FBV) were switched to class mixin and generic based views (CBV MBV GBV respectively). After switching to GBV when I went to test my API I received this error AssertionError: Expected view SnippetDetail to be called with a URL keyword argument named ""pk"". Fix your URL conf or set the '.lookup_field' attribute on the view correctly.. I did some research and found that lookup_field needs to be set to the in the urlpatterns. Currently my urls.py look like this:nnfrom django.conf.urls import url includenfrom rest_framework.urlpatterns import format_suffix_patternsnfrom snippets import viewsnn# API endpointsnurlpatterns = format_suffix_patterns(n    url(r'^$' views.api_root)n    url(r'^snippets/$'n        views.SnippetList.as_view()n        name='snippet-list')n    url(r'^snippets/(?P<id>0-9+)/$'n        views.SnippetDetail.as_view()n        name='snippet-detail')n    url(r'^users/$'n        views.UserList.as_view()n        name='user-list')n    url(r'^users/(?P<id>0-9+)/$'n        views.UserDetail.as_view()n        name='user-detail')n)nn# Login and logout views for the browsable APInurlpatterns += n    url(r'^auth/' include('rest_framework.urls'n                           namespace='rest_framework'))nnnnand my views.py look like so:nnfrom snippets.models import Snippetnfrom snippets.serializers import SnippetSerializer UserSerializernfrom snippets.permissions import IsOwnerOrReadOnlynnfrom rest_framework import genericsnfrom rest_framework import permissionsnfrom rest_framework.decorators import api_viewnfrom rest_framework.response import Responsenfrom rest_framework.reverse import reversennfrom django.contrib.auth.models import Usernnn@api_view('GET')ndef api_root(request format=None):n    return Response({n        'users': reverse('user-list' request=request format=format)n        'snippets': reverse('snippet-list' request=request format=format)n    })nnnclass UserList(generics.ListAPIView):n    queryset = User.objects.all()n    serializer_class = UserSerializernnnclass UserDetail(generics.RetrieveAPIView):n    queryset = User.objects.all()n    serializer_class = UserSerializernnnclass SnippetList(generics.ListCreateAPIView):n    queryset = Snippet.objects.all()n    serializer_class = SnippetSerializern    permission_classes = (permissions.IsAuthenticatedOrReadOnly IsOwnerOrReadOnly )nn    def perform_create(self serializer):n        serializer.save(owner=self.request.user)nnnclass SnippetDetail(generics.RetrieveUpdateDestroyAPIView):n    queryset = Snippet.objects.all()n    serializer_class = SnippetSerializern    permission_classes = (permissions.IsAuthenticatedOrReadOnly IsOwnerOrReadOnly )nnnwhen I add lookup_field = 'id' in both UserDetail and SnippetDetail the exception resolves itself. (Yay!). But when I visit http://127.0.0.1/users/1/ ImproperlyConfigured: Could not resolve URL for hyperlinked relationship using view name ""user-detail"". You may have failed to include the related model in your API or incorrectly configured the 'lookup_field' attribute on this field. is thrown. When I check the console however there is a second exception: nnn  django.urls.exceptions.NoReverseMatch: Reverse for 'user-detail' withn  arguments '()' and keyword arguments '{'pk': 1}' not found. 2n  pattern(s) tried: 'users/(?P0-9+).(?Pa-z0-9+)/?$'n  'users/(?P0-9+)/$'n  n  During handling of the above exception another exception occurred:n  n  django.core.exceptions.ImproperlyConfigured: Could not resolve URL forn  hyperlinked relationship using view name ""user-detail"". You may haven  failed to include the related model in your API or incorrectlyn  configured the 'lookup_field' attribute on this field.nnnWhat I find interesting is that the kwargs for the first exception is {'pk': 1} not {'id':1}. After some help from chat someone pointed me to this piece of information:nnn  Note that when using hyperlinked APIs you'll need to ensure that both the API views and the serializer classes set the lookup fields if you need to use a custom value.nnnThis is useful as User serializer extends HyperlinkedModelSerializer:nnfrom rest_framework import serializersnnfrom django.contrib.auth.models import Usernnfrom snippets.models import Snippetnnclass UserSerializer(serializers.HyperlinkedModelSerializer):n    snippets = serializers.HyperlinkedRelatedField(many=True view_name='snippet-detail' read_only=True)nn    class Meta:n        model = Usern        fields = ('url' 'id' 'username' 'snippets')nnnthe User model and serializer has a reverse relationship with Snippet. Now when I add lookup_field='id' to snippets attribute of UserSerializer (snippets = serializers.HyperlinkedRelatedField(many=True view_name='snippet-detail' read_only=True lookup_field='id')) like it asks me to do so here the error is persistent.nnWhat am I doing incorrectly? What can I do to fix this? Is it not having anything to do with lookup_id?nnI understand that I could replace <id> with <pk> in my urlpatterns but I would like to understand why this is happening. Thank you for any help.n' ""I eventually fixed my second exception by printing the serializer in the Django shell/python interactive console. The result I got was this:nn>>> from snippets.serializers import UserSerializern>>> print(UserSerializer())nUserSerializer():n    url = HyperlinkedIdentityField(view_name='user-detail')n    id = IntegerField(label='ID' read_only=True)n    username = CharField(help_text='Required. 150 characters or fewer. Letters digits and @/./+/-/_ only.' max_length=150 validators=<django.contrib.auth.validators.UnicodeUsernameValidator object> <UniqueValidator(queryset=User.objects.all())>)n    snippets = HyperlinkedRelatedField(lookup_field='id' many=True read_only=True view_name='snippet-detail')nnnIt turns out that to change <pk> to <id> in urlspatterns you need to add url = HyperlinkedIdentityField(view_name='user-detail' lookup_field='id') in the UserSerializer class. n""",['django'],['django']
40073276,"'Invalid literal for int()' 'I am learning python and I am trying to code a calculator that compares prices of butter calculates percentage differences and which one has the lowest price for 100 grams.nndef procenta(xy):n vysledek = (y-x)/x * 100            # (b-a) : a * 100n return round(vysledek 2)ntesco = float(input(""Zadejte cenu masla v Tescu: ""))ntesco_g = int(input(""Zadejte gramaz v Tescu: ""))nlidl = float(input(""Zadejte cenu masla v Lidlu: ""))nlidl_g = int(input(""Zadejte gramaz v Lidlu: ""))nkaufland = float(input(""Zadejte cenu masla v Kauflandu: ""))nkaufland_g = int(input(""Zadejte gramaz v Kauflandu: ""))nncena_tesco = int(tesco)/(tesco_g:2/10)ncena_lidl = int(lidl)/(lidl_g:2/10)ncena_kaufland = int(kaufland)/(kaufland_g:2/10)nnnTraceback:nnTraceback (most recent call last):n File ""python"" line 6 in <module>nValueError: invalid literal for int() with base 10: ''nnnDonÂ´t worry about what does the other text means it's my native language can translate it eventually. However if I change it to:nncena_tesco = float(tesco/(tesco_g:2/10))nnI get TypeError float object is not subscriptable.n' ""You've defined tesco_g to be an integer by casting it with your 5th line.  Your TypeError is telling you that the varname:2 syntax doesn't work because your type doesn't have indices.  To reframe what the interpreter is doing:n1. It reads tesco_g:2n2. It checks: does the type of tesco_g have a method for indexing up to the second element?n3. It doesn't find that method and throws an error.nnWhat is the cena_tesco line supposed to do?n"" 'If I will get it to work  it will be printed :nnprint(""Tesco is the cheapest shop with price of""*cena_tesco*""for 100 grams of butter."")nnnIts supposed to calculate price of butter for 100g.nWhat should I do with tesco_g:2 so it take first two digits from tesco_g and use them to calculate the price ?n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40073279,"'Cross join time series dataset applying asof criteria on time while limiting number of rows' ""I have a unique requirement around time-series analysis. Below I have presented my requirements along with a simple working solution. I have also worked out sample example to help understand my requirements.nnI am seeking help with regards to making this code efficient in terms of (a) reducing time & space complexity (b) reducing lines of code if any of these can be achieved by using in-built functions in Pandas or other python libraries.nnConsider following time-series data for example:nnimport pandas as pdnndf1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock': {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:14.05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: '09:13:46.867'1: '10:06:26.452' 2: '12:34:23.569' 3: '11:24:23.533' 4: '18:55:23.903' 5: '14:51:08.756'}})ndf2 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'} 'Stock': {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC'} 'Volume': {0: 100 1: 300 2: 600 3: 1500 4: 200} 'Price': {0: 10.05 1: 10.10 2: 10.40 3:10.50 4: 10.45} 'time': {0: '08:00:00.242' 1: '09:00:10.534' 2: '10:08:36.658' 3: '11:45:43.654' 4: '12:34:23.563'}})nnprint df1nprint df2nn         Date       EndTime     StartTime Stockn0  2016-10-11  09:13:46.867  08:00:00.241   ABCn1  2016-10-11  10:06:26.452  08:00:00.243   ABCn2  2016-10-11  12:34:23.569  12:34:23.563   ABCn3  2016-10-11  11:24:23.533  08:14:05.908   ABCn4  2016-10-11  18:55:23.903  18:54:50.100   ABCn5  2016-10-11  14:51:08.756  10:08:36.657   XYZnn         Date   Price Stock  Volume          timen0  2016-10-11   10.05   ABC     100  08:00:00.242n1  2016-10-11   10.10   ABC     300  09:00:10.534n2  2016-10-11   10.40   ABC     600  10:08:36.658n3  2016-10-11   10.50   ABC    1500  11:45:43.654n4  2016-10-11   10.45   ABC     200  12:34:23.563nnnI am looking to write following two functions in python in most efficient manner which takes following inputs:nndef do_asof(df1 df2 left_time='StartTime' right_time='time' left_on='Date''Stock' right_on='Date''Stock' uptoCols=2)ndef do_onafter(df1 df2 left_time='StartTime' right_time='time' left_on='Date''Stock' right_on='Date''Stock' uptoCols=2)nnnThe first function do_asof does following:n    1. Performs an exact match between df1 and df2 on left_on and right_on columns. In this case an inner join on 'Date' and 'Stock' columns as follows: df3 = df1.merge(df2 on = 'Date''Stock')n    2. Now in df3n        (a)  Get rid of all the rows where 'time' > 'StartTime'. Do something like df3 = df3.locdf3'time' <= df3'StartTime'n        (b)  Limit maximum of uptoCols = 2 entries for each row in original df1. Do something like df3 = df3.sort_values('time' ascending =True).groupby('Date''Stock''StartTime''EndTime').tail(2)n        (c)  Outer Join to original df1 as follows to get the desired output df4 = df1.merge(df3 on ='Date''Stock''StartTime''EndTime'how = 'outer')nnprint df4nn         Date       EndTime     StartTime Stock  Price  Volume          Timen0  2016-10-11  09:13:46.867  08:00:00.241   ABC    NaN     NaN           NaNn1  2016-10-11  10:06:26.452  08:00:00.243   ABC  10.05     100  08:00:00.242n2  2016-10-11  12:34:23.569  12:34:23.563   ABC  10.50    1500  11:45:43.654n3  2016-10-11  12:34:23.569  12:34:23.563   ABC  10.45     200  12:34:23.563n4  2016-10-11  11:24:23.533  08:14.05.908   ABC  10.05     100  08:00:00.242n5  2016-10-11  18:55:23.903  18:54:50.100   ABC  10.50    1500  11:45:43.654n6  2016-10-11  18:55:23.903  18:54:50.100   ABC  10.45     200  12:34:23.563n7  2016-10-11  14:51:08.756  10:08:36.657   XYZ    NaN     NaN           NaNnnnThe second function do_onafter does following:n    1. Performs a similar exact match between df1 and df2 on left_on and right_on columns. In this case an inner join on 'Date' and 'Stock' columns as follows: df3 = df1.merge(df2 on = 'Date''Stock')n    2. Now in df3n        (a)  Get rid of all the rows where 'time' < 'StartTime'. Do something like df3 = df3.locdf3'time' >= df3'StartTime'n        (b)  Limit maximum of uptoCols = 2 entries for each row in original df1. Do something like df3 = df3.sort_values('time' ascending =True).groupby('Date''Stock''StartTime''EndTime').head(2)n        (c)  Outer Join to original df1 as follows to get the desired output df4 = df1.merge(df3 on ='Date''Stock''StartTime''EndTime'how = 'outer')nnprint df4nn         Date       EndTime     StartTime Stock  Price  Volume          Timen0  2016-10-11  09:13:46.867  08:00:00.241   ABC  10.05     100  08:00:00.242n1  2016-10-11  09:13:46.867  08:00:00.241   ABC  10.10     300  09:00:10.534n2  2016-10-11  10:06:26.452  08:00:00.243   ABC  10.10     300  09:00:10.534n3  2016-10-11  10:06:26.452  08:00:00.243   ABC  10.40     600  10:08:36.658n4  2016-10-11  12:34:23.569  12:34:23.563   ABC  10.45     200  12:34:23.563n5  2016-10-11  11:24:23.533  08:14.05.908   ABC  10.10     300  09:00:10.534n6  2016-10-11  11:24:23.533  08:14.05.908   ABC  10.40     600  10:08:36.658n7  2016-10-11  18:55:23.903  18:54:50.100   ABC    NaN     NaN           NaNn8  2016-10-11  14:51:08.756  10:08:36.657   XYZ    NaN     NaN           NaNnn"" nan",['pandas'],['pandas']
40073322,"'Plotting list of lists in a same graph in Python' ""I am trying to plot (xy) where as y = 123456789. nnSay len(x) = len(y1) = len(y2)..nThe length of the y is decided by the User input. I want to plot multiple plots of y in the same graph i.e (x y1y2y3...). When I tried using loop it says dimension error.nnI also tried: plt.plot(xyi for i in range(1len(y))) nnHow do I plot ? Please help.nnfor i in range(1len(y)):nplt.plot(xyilabel = 'id %s'%i)nplt.legend()nplt.show()nn"" 'Assuming some sample values for x below is the code that could give you the desired output.nnimport matplotlib.pyplot as pltnx = 123ny = 123456789nplt.xlabel(""X-axis"")nplt.ylabel(""Y-axis"")nplt.title(""A test graph"")nfor i in range(len(y)):n    plt.plot(xpti for pt in ylabel = 'id %s'%i)nplt.legend()nplt.show()nnnAssumptions: x and any element in y are of the same length.nThe idea is reading element by element so as to construct the list (xy0's) (xy1's) and (xyn'snnBelow is the plot I get for this case:nn'",['matplotlib'],['matplotlib']
40073348,"'Python Django Queryset' ""I'm playing with querysets in django.nnWhat I'm looking it's to save a new foreign product or item but I can not achieve it.nnshellnnfrom applaboratorio.models import Datos_empresa_DB Datos_equipo_DBnndetalle = Datos_empresa_DB.objects.filter(pk=58)nnresp = Datos_equipo_DB(equipo='dell-labtop'marca='dell' modelo='432423'Foraneo_Datos_empresa_DB = detalle)nnnmodels.pynnclass Datos_empresa_DB(models.Model):n    nombre = models.CharField(max_length=150)n    empresa = models.CharField(max_length=150)nnclass Datos_equipo_DB(models.Model):n    Foraneo_Datos_empresa_DB = models.ForeignKey(Datos_empresa_DB)n    equipo = models.CharField(max_length=300)n    marca = models.CharField(max_length=300)n    modelo = models.CharField(max_length=300)nnnWhat am I doing bad?nnI'm trying to create a new product for a client that already exist in db.n"" ""I think you're nearly there. You need to call the save method of the new product to save to the DB and to retrieve the related client object you should get not filter so you have the object itself and not a list of objects (or QuerySet):nndetalle = Datos_empresa_DB.objects.get(pk=58)n#                                  ^^^nresp = Datos_equipo_DB(equipo='dell-labtop'marca='dell' modelo='432423'Foraneo_Datos_empresa_DB =detalle)n#                                          Save on model's related field <-^^^^^^^nresp.save()nn""",['django'],['django']
40073381,"'what type iswhen I use web crawler to download the information from web?' 'import requestsnfrom bs4 import BeautifulSoupnfrom pandas import SeriesDataFramenndef name1():n    url='''https://www.agoda.com/zh-tw/pages/agoda/default/DestinationSearchResult.aspx?asq=%2bZePx52sg5H8gZw3pGCybdmU7lFjoXS%2ban    xz%2bUoF4%2bbAw3oLIKgWQqUpZ91GacaGdIGlJ%2bfxiotUg7cHef4W8WIrREFyK%2bHWl%2ftRKlV7J5kUcPb7NK6DnLacMaVs1qlGagsx8liTdosF5by%2n    fmvF3ZvJvZqOWnEqFCm0staf3OvDRiEYy%2bVBJyLXucnzzqZp%2fcBP3%2bKCFNOTA%2br9ARInL665pxj%2fA%2bylTfAGs1qJCjm9nxgYafyEWBFMPjt2sn    g351B&city=18343&cid=1732641&tag=41460a09-3e65-d173-1233-629e2428d88e&gclid=Cj0KEQjwvve_BRDmg9Kt9ufO15EBEiQAKoc6qlyYthgdt9n    CgZ7a6g6yijP42n6DsCUSZXvtfEJdYqiAaAvdW8P8HAQ&tick=636119092231&isdym=true&searchterm=%E5%A2%BE%E4%B8%81&pagetypeid=1&origin    n=TW&cid=1732641&htmlLanguage=zh-tw&checkIn=2016-10-20&checkOut=2016-10-21&los=1&rooms=1&adults=2&children=0&isFromSearchBn    ox=true&ckuid=1b070b17-86c2-4376-a4f5-d3b98fc9cf45'''n    #æx8cx87å®x9aç¶²åx9dx80n    source_code=requests.get(url)                                         n    #åx8fx96å¾x97ç¶²åx9dx80çx9ax84source coden    plain_text=source_code.text                                           n    #æx8ax8asource codeåxadx98æx88x90textn    soup=BeautifulSoup(plain_text""lxml"")                                        n    #çx94¨BSåx8e»è§£ç¢¼n    for a in soup.find_all(""h3""{""class"":""hotel-name""}):n        print (list(a))nname1()nnnI want to sort the data craw from Agoda. It seems that I download the many list but a one list. I wonder a list about hotel-name but it has too much things I don't need ex: blanktag(<h3>...</h3>). nnPlease tell me how to clean the data downloaded from web with python.n' 'Use .text to get without tags. And .strip() to remove wihtespacesnnfor a in soup.find_all(""h3""{""class"":""hotel-name""}):n    print(a.text.strip())nn'",['python-3.x'],['python-2.7']
40073504,"'function value is returned as null' 'I try to run this piece of code I get the dimension not same issue. Also when i try to print the values of Strikes and option_value_seqs I get no return for ""option_value_seqs""nnimport numpy as npndef bsm_mcs_valuation(strike):n    s0=100;T=1.0;r=0.05;vol=0.2;M=50;I=200n    dt=T/Mn    rand= np.random.standard_normal((M+1I))n    s=np.zeros((M+1I));s0=100n    for t in range(1M+1):n        st= st-1*np.exp((r - 0.5 * vol **2 ) * dt n                        + vol *  np.sqrt(dt) * randt)nn    value = (np.exp(-r*t)*np.sum(np.maximum(s-1-strike0))/I)n    return valuenndef seq_value(n):n    strikes = np.linspace(80120n)n    print strikesn    option_values = n    for strike in strikes:n        print striken        print ""option value is ""; n        option_values.append(bsm_mcs_valuation(strike))n    return strikes option_valuesnnn=100n%time strikesoption_values_seq=seq_value(n)nnnimport matplotlib.pyplot as pltn%matplotlib inlinenplt.figure(figsize=(84))nplt.plot(strikesoption_values_seq'b')nplt.plot(strikesoption_values_seq'r')nnnI get the following errornn221         y = _check_1d(y)n222         if x.shape0 != y.shape0:n223             raise ValueError(""x and y must have same first dimension"")nnnValueError: x and y must have same first dimensionnn' nan",['numpy'],"['matplotlib', 'numpy']"
40073642,"'Removing negative values and printing the original and the new list' 'To start of I am telling you this is for school as I am learning to code with Python. Please do explain why I should do something :)! I am looking to learn not just getting the answer.nnI am trying to get rid of the negative items in the list. I want to print the list Before (including the negative items) and after ( without the negative items of course). nMy problem is that it prints out the original list and the new list without negative items on the Before print and the original one on After. nLike this: nnBefore: 2 7 -3 -3 13 -14 13 5 11 -4 10 5 0 -5 -14n-2 -9 -14 2 -10 -5 8 7n2 7 13 13 5 11 10 5 0 2 8 7nAfter: 2 7 -3 -3 13 -14 13 5 11 -4 10 5 0 -5 -14 -2 -9n-14 2 -10 -5 8 7 nnnThis is what I've done and I just can't seem to figure out what I should do...nnimport randomnndef removeNegatives(listOfIntegers):n    l = listOfIntegers:           #takes a copy of the listn    for item in listOfIntegers:     n        if item < 0:                #checks if it is lower than 0n           l.remove(item)n    print lnnnnl = nfor i in xrange(0 random.randint(1525)): #gives me the random numbersn  l.append(random.randint(-1515))nnprint ""Before:"" l #should only print out the original list of numbersnremoveNegatives(l)nprint ""After:"" l #should only print out the new list without the numbers that are <0nn' 'You aren't modifying global variable l in your function.nnI propose this code in Python which should work correctly:nnimport randomnndef removeNegatives(listOfIntegers):n    return x for x in listOfIntegers if not x < 0nnl = nfor i in xrange(0 random.randint(1525)): #gives me the random numbersn    l.append(random.randint(-1515))nnprint ""Before:"" l #should only print out the original list of numbersnl = removeNegatives(l)nprint ""After:"" l #should only print out the new list without the numbers that are <0nnnIt's way shorter. What do you think about it?n' 'Just saw your comment relative to not being able to modify the code below l = nnIn that case you need to reassign to listOfIntegers coming out of your functionnndef removeNegatives(listOfIntegers):n    global ln    k = listOfIntegers:           #takes a copy of the listn    for item in listOfIntegers:     n        if item < 0:                #checks if it is lower than 0n           k.remove(item)n    print kn    l = knnnYou make a copy of the global as you come in the function you just need to repoint it to the modified copy as you leave.nnEdit: other comments relative to modifying a list while you iterate it are not accurate as you are not modifying the list you are iterating on you are modifying the ""copy"" of the list.  While others have offered good suggestions on improving the conciseness of the method your original method was perfectly valid with the above tweaks. nnEdit2: volcano's 'comment' relative to the global is correct the global statement should be added inside the def to perform it this way. reference volcano's answer for the best approach but I'll leave this around for the discussion point. n' 'The ""cleanest"" way to modify external list will be to change its contents without reassigning - which changes list object reference. You can't remove elements when looping over list and removing each non-compliant element while iterating over copy is very ineffective. nnBut you may reassign contents of list without re-assigning list object reference - using slice on the left side of the assignmentnndef removeNegatives(listOfIntegers):n    listOfIntegers: = filter(lambda x: x >= 0 listOfIntegers)nnnThis code creates new list of non-negative values and replaces whole content of the external-scope list.n' 'Since you're studying Python this is a good place to learn list comprehension:nn$ cat /tmp/tmp.pyn_list = 2 7 -3 -3 13 -14 13 5 11 -4 10 5 0 -5 -14n        -2 -9 -14 2 -10 -5 8 7nnprint(""Before:""_list)nprint(""After:""a for a in _list if a >= 0)nn$ python3 /tmp/tmp.pynBefore: 2 7 -3 -3 13 -14 13 5 11 -4 10 5 0 -5 -14 -2 -9 -14 2 -10 -5 8 7nAfter: 2 7 13 13 5 11 10 5 0 2 8 7nnnAs you can see the elimination of the negative number in the list comprehension stage is concise clear and if you test it you'd find it's faster than the comparable solution using loops.n'",['python-2.7'],"['list', 'python-2.7']"
40073691,"'Problems while trying to generate pandas dataframe columns from regulars expressions?' 'I am working with a number of .txt files allocated in a directory. From all this files how should I extract specific words or chunks of text (i.e. sentences paragraphs and tokens defined by a regex) and place them into a pandas dataframe (i.e. tabular format) preserving a column with the name of each file?. So far I created this function that do this task (I know... it ain't perfect):nnIn:nnimport glob os renimport pandas as pdnregex = r'<the regex>b'nind = 'path/dir'nout = 'path/dir'nf ='path/redirected/output/'nnndef foo(ind reg out):n    for filename in glob.glob(os.path.join(in_directory '*.txt')):n        with open(filename 'r') as file:n            stuff = re.findall(a_regex file.read() re.M)n            #my_list = str(j.split()0 for j in i) for i in stuffnn            lis = t::2 for t in stuffn            cont = ' '.join(map(str lis))n            print(cont)n            with open(out 'a') as f:n                print(filename.split('/')-1 + 't' + cont file = f)nnnfoo(directory regex out)nnnThen the output is redirected to third file:nnOut:nnfileName1.txt       nfileName2.txt       stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunknfileName3.txt       stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunk stringOrChunkn....nfileNameN.txt       stringOrChunknnnThen this is how I create the dataframe from the previous file (yeah I know its awful):nnimport pandas as pdndf = pd.read_csv(/path/of/f/ sep='t' names = 'file_names''col1')ndf.to_csv('/pathOfNewCSV.csv' index=False sep='t')nnnAnd Finally:nn    file_names  col1n0   fileName1.txt   NaNn1   fileName2.txt   stringOrChunk stringOrChunk stringOrChunk...n2   fileName3.txt   stringOrChunk stringOrChunk stringOrChunk...n3   fileName4.txt   stringOrChunkn.....nN   fileNameN.txt   stringOrChunknnnSo any idea of do this in a more pythonic and efficient way?.nnUpdatennI uploaded a .zip with some docs as data so if we want to extract all the adverbs from the documents we should do:nna_regex = r""w+ly""ndirectory = '/Users/user/Desktop/Docs/'noutput_dir = '/Users/user/Desktop/'nnfoo(ind reg out)nnnThen it should create a table with all the adverbs of the documents:nnFiles            wordsndoc1.txt    ndoc2.txt    ndoc3.txt     DIRECTLY PROBABLY EARLY ndoc4.txt    nnnAny idea of how to enhance the above function?. Additionally I don't know if this is the best way to do this information extraction task (i.e. just using regex). What about using an string indexer like woosh project or what about nltk?.n' nan","['regex', 'python-3.x', 'pandas']","['pandas', 'regex']"
40073874,"'Strange Bug in creating Co-occurrence Matrix in Python' ""I am trying to create a co-occurrence matrix in Python that outputs the number which words in L1 appear in pears (cat dog cat house cat tree e.t.c.) in L2 my code so far is:nnco = np.zeros((55)) #the matrixnL1 = 'cat' 'dog' 'house' 'tree' 'car' #tagsnL2 = 'cat car dog' 'cat house dog' 'cat car' 'cat dog' #photo textnnn=0 # will hold the sum of each occurancennfor i in range(len(L1)):n    for j in range(len(L1)):n        for s in range(len(L2)):n            #find occurrence but not on same wordsn            if L1i in L2s and L1j in L2s and L1i != L1j: n                n+=1  # sum the number of occurances            n                #output = L1i L1j # L2sn                #print outputn                coij = s #add to the matrixnnprint connnThe output should be nn 0.  3.  1.  0.  2.n  3.  0.  1.  0.  1.n  1.  1.  0.  0.  0.n  0.  0.  0.  0.  0.n  2.  1.  0.  0.  0.nnnBut instead:nn 0.  3.  1.  0.  2.n  3.  0.  1.  0.  0.n  1.  1.  0.  0.  0.n  0.  0.  0.  0.  0.n  2.  0.  0.  0.  0.nnnEvery second row there is an error... The if part works well I have checked the output:nnoutput = L1i L1j # L2snprint outputn    ('cat' 'dog')n    ('cat' 'dog')n    ('cat' 'dog')n    ('cat' 'house')n    ('cat' 'car')n    ('cat' 'car')n    ('dog' 'cat')n    ('dog' 'cat')n    ('dog' 'cat')n    ('dog' 'house')n    ('dog' 'car')n    ('house' 'cat')n    ('house' 'dog')n    ('car' 'cat')n    ('car' 'cat')n    ('car' 'dog')nnnSo I guess there is something going on when filing the matrix?:nncoij = snnnAny suggestions???n"" ""It's giving a correct result because you have car and dog in first item of L2 which is 0 index.nnHere is a more pythonic approach that get the index based on first occurrence of the pairs in L2:nnIn 158: L2 = 'cat car dog' 'cat house dog' 'cat car' 'cat dog'nnIn 159: L2 = s.split() for s in L2nnIn 160: combinations = np.column_stack((np.repeat(L1 5) np.tile(L1 5))).reshape(5 5 2)n# with 0 as the start of the indicesnIn 162: next((i for i sub in enumerate(L2) if x in sub and y in sub) 0) for x y in row for row in combinationsnOut162: n0 0 1 0 0n 0 0 1 0 0n 1 1 1 0 0n 0 0 0 0 0n 0 0 0 0 0n# with 1 as the start of the indicesnIn 163: next((i for i sub in enumerate(L2 1) if x in sub and y in sub) 0) for x y in row for row in combinationsnOut163: n1 1 2 0 1n 1 1 2 0 1n 2 2 2 0 0n 0 0 0 0 0n 1 1 0 0 1nn""",['numpy'],"['numpy', 'python-2.7']"
40073942,"""Regex doesn't filter out the right text on datatime"" 'I have a string below:nnsenton = ""Sent:                               Friday June 18 2010 12:57 PM""nnnI created a regex to filter out the datetime portion:nnreg_datetime = ""(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) (January|February|March|April|May|June|July|August|September|October|November|December) d{12} d{4} d{2}:d{2} (AM|PM)""nnnI tested the regex in regex101.com and it works as expected however when running it in my python test script it fails to give me the right text can anyone help me fix it?nnUsing it this way:nnreal_senton = re.findall(reg_datetime senton)nprint real_sentonnnnProduces this result (here is the screenshot):nn('Friday' 'June' 'PM')nnnThank you very much.n' 'If you want regex to return the all those values you have to make sure that they're in separate groups like so:nnreg_datetime = ""(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) (January|February|March|April|May|June|July|August|September|October|November|December) (d{12}) (d{4}) (d{2}):(d{2}) (AM|PM)""nn' 'The problem is that the match results that are returned to you are the ones between '(' ')' which are called group match.nThus your regex should look like this to return all the data:  nnreg_datetime = ""(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) (January|February|March|April|May|June|July|August|September|October|November|December) (d{12}) (d{4}) (d{2}:d{2}) (AM|PM)""nnnYou can see here the demo. Or if you want all the date in one single string just add all the regex between '(' ')' n' 'Function re.findall does the following:nnn  Return all non-overlapping matches of pattern in string as a list of strings. The string is scanned left-to-right and matches are returned in the order found. If one or more groups are present in the pattern return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result unless they touch the beginning of another match.nnnSo if there are groups it returns the groups. A group is anything in the regular expression enclosed in parenthesis.nnsolution 1nnTo get every item separately put everything into parentesis:nnreg_datetime = ""(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) ""n ""(January|February|March|April|May|June|July|August|September|October|November|December)""n "" (d{12}) (d{4}) (d{2}):(d{2}) (AM|PM)""nnnThen will re.findall(reg_datetime senton) return:nn('Friday' 'June' '18' '2010' '12' '57' 'PM')nnnsolution 2nnAlternatively put everything into one big group:nnreg_datetime = ""((Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) ""n ""(January|February|March|April|May|June|July|August|September|October|November|December)""n "" d{12} d{4} d{2}:d{2} (AM|PM))""nnnNow the big group is returned as well:nn('Friday June 18 2010 12:57 PM' 'Friday' 'June' 'PM')nnnsolution 3nnOr change the existing grops into non-capturing groups (syntax (?:...))nnreg_datetime = ""(?:Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) ""n ""(?:January|February|March|April|May|June|July|August|September|October|November|December)""n "" d{12} d{4} d{2}:d{2} (?:AM|PM)""nnnResult:nn'Friday June 18 2010 12:57 PM'nnnsolution 4nnOr don't use findall at all. Use re.search. It returns a Match object which gives you more options. With the original reg_datetime it works this way:nn>>> m = re.search(reg_datetime senton)n>>> m.group(0)n'Friday June 18 2010 12:57 PM'n>>> m.group(1)n'Friday'n>>> m.group(2)n'June'n>>> m.group(3)n'PM'nn' 'without change reg_datetime and only use search nnimport rensenton = ""Sent:                               Friday June 18 2010 12:57 PM""nreg_datetime = ""(Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday) (January|February|March|April|May|June|July|August|September|October|November|December) d{12} d{4} d{2}:d{2} (AM|PM)""nl = re.search(reg_datetimesentonre.M|re.I)nprint l.group()nnnand run:nn$ python file.pynFriday June 18 2010 12:57 PMn$nn'",['regex'],['regex']
40073984,"'Models in Python Django not working for Many to Many relationships' ""I am trying to create the proper Django model that could fit the following reqs:nnPerson Class has 1 to many relations with the Address ClassnnPerson Class has many to many relations with the Group ClassnnBook Class contains the collections of the Persons and the GroupsnnThis is my code:nnclass Person(models.Model):n    first_name = models.CharField(max_length=15)n    last_name = models.CharField(max_length=20)nn    def __str__(self):n        return  self.first_name+ ' - ' + self.last_namennnclass Address(models.Model):n    person = models.ForeignKey(Person)  n    address_line = models.CharField(max_length=200)nn    def __str__(self):n        return self.address_linennnclass Group(models.Model):n    group_name = models.CharField(max_length=12)n    persons = models.ManyToManyField(Person)nn    def __str__(self):n        return self.group_namennclass Book(models.Model):n     record_name = models.CharField(max_length=12)n     person = models.ForeignKey(Person )  n     group = models.ForeignKey(Group )  nn     def __str__(self):n         return self.record_namennnHowever it's not correct:n1) A Group can now contain multiple Persons but the Persons do not contain any Group. nI am not sure if I should add to the Person class the following code:nngroups = models.ManyToManyField(Group)nnn2) The Book class now contains only 1 record of Person & Group per Book record. nn3) When I added the Foreign Keys to the models I removed non_delete tag:nnperson = models.ForeignKey(Person on_delete=models.CASCADE())nnnbecause it does not compile it asking for some params.nnI know how to make all this for C# but I am a kinda stucked with this simple task in Python/Django.n"" ""1) The ManyToMany field should appear only in one of the models and by looks of things you probably want it in the Person model.nIts important to understand that the data about the ManyToMany field is saved in a differant table. Django only allows this field to be visable through buth models (so basiclly choose where it is move convinient).nn2)By the look of your structure I will suggest you use a ManyToMany field through a different table. here is an example:nnclass Activity(models.Model):n    name = models.CharField(max_length=140)n    description = models.TextField(blank=True null=True)nnclass Route(models.Model):n    title = models.CharField(max_length=140)n    description = models.TextField()n    activities_meta = models.ManyToManyField(Activity through = 'RouteOrdering')nnclass RouteOrdering(models.Model):n    route = models.ForeignKey(Route on_delete=models.CASCADE)n    activity = models.ForeignKey(Activity on_delete=models.CASCADE related_name='activita')n    day = models.IntegerField()n    order = models.IntegerField(default=0)nnnthat way the data is binded to the ManyToMany fieldn""",['django'],['django']
40073995,"'Why this for loop in Python3 return dictionary value split in letters?' 'I am lerning Python from a book and there is this example. I rewrote example as it is shown in book but the result differs from books.nnThis is the codennfavorite_languages = {n   'jen': 'python''ruby'n   'bil': 'c'n   'edward': 'ruby''haskell'n   'phil': 'python'n   'marcis': 'octave''python''mysql'n   }nnfor name languages in favorite_languages.items():n    print(""n"" +name.title()+""'s favorite language(s) are:"")n    for language in languages:n        print(""t"" + language.title())nnnThis is the consoles printed result. Problem as you see are in the way console prints value 'python' for Phil's sentence.nnnnI have tried other IDLE and the same result!nWhy does name python is spelled by letters in each line for Phil's example? Is it an some sort of Python language or my code problem?n' ""Because line:nnfor language in languages:nnnis iterating over string 'python' and giving you single letters if you write it as 'python' it'll iterate over list and write it as one wordn""","['python-3.x', 'dictionary']",['python-3.x']
40074004,"'Access kivy popup parent' ""The way popups are implemented in kivy the popup seems to get attached to the window and not the parent object which created the popup.  Popup comes with self.dismiss() to close the popup but I can't figure out any way to access the 'parent' object since despite creating the popup it seems to exist outside of it.nnExample snippets:nnclass StartButton(ActionButton)n    def on_release(self):n        self.popup = StartPop(id='popid')n        self.popup.open()nnclass StartPop(Popup):n    def close(self):n        self.dismiss()n    def start(self):n        print(self)n        print(self.parent)nnnThe result of the print commands isnn<__main__.StartPop object at 0x00000000037BBCE0>nn<kivy.core.window.window_sdl2.WindowSDL object at 0x000000000373B0B0>nnnSo rather than the parent being StartButton whose parent I would also expect to access etc. the parent is the Window.  nnI don't see how I could bind any function that thus interact with the widget I used to create the popup from.  I need to be able to get the parent object and its parents to do things based on what I click within the popup but I can't figure out how this could be implemented.nnIn the .kv filenn<StartPop>:n    title: 'Popup'n    auto_dismiss: Truen    size_hint: NoneNonen    size: 400250n    BoxLayout:n        orientation: 'vertical'n        Label:n            text: 'sample text here'n            text_size: self.sizen            halign: 'center'n            valign: 'middle'n        BoxLayout:n            orientation: 'horizontal'n            Button:n                size_hint: 10.5n                text: 'Cancel'n                on_release: root.close()n            Button:n                size_hint: 10.5n                text: 'Start Testing'n                on_release: root.start()nn"" ""It's implemented like that because it needs to be hidden most of the time yet still active so that open() could be called. Kivy doesn't seem to handle hiding of the widgets other way that actually removing it and keeping a reference somewhere (there's no hide property) so maybe even because of that. Or because it was easier to implement it this way. It's not bad implementation however and the way OO programming works you can do some fancy stuff with it too. The thing you want can be handled simply with kwargs in __init__:nnInherit from Popup and get a custom keyword argument:nnclass StartPop(Popup):n    def __init__(self **kwargs):n        self.caller = kwargs.get('caller')n        super(StartPop self).__init__(**kwargs)n        print self.callernnnThen create an instance of that custom Popup and set the parent:nnpop = StartPop(caller=self)npop.open()nnnThe caller keyword isn't limited only to Kivy widgets. Put there any object you want to do stuff with and you can then access it inside the StartPop object via self.callern""",['python-2.7'],"['python-2.7', 'python-3.x']"
40074088,"'Target WSGI script cannot be loaded as Python module + no module named Django' 'I know that the question has already been asked here. I've read tons of answers but nothing helped.nnI'm using virtualenv (/root/eb-virt); my Django project is called mediar. All public files are stored in /var/www/html/xxx.com/public_html/nnFrom error log:nnSun Oct 16 18:40:11.737747 2016 :error pid 27659 client 128.75.240.205:60486 mod_wsgi (pid=27659): Target WSGI script '/var/www/html/xxx.com/django.wsgi' cannot be loaded as Python module.nSun Oct 16 18:40:11.737808 2016 :error pid 27659 client 128.75.240.205:60486 mod_wsgi (pid=27659): Exception occurred processing WSGI script '/var/www/html/xxx.com/django.wsgi'.nSun Oct 16 18:40:11.745983 2016 :error pid 27659 client 128.75.240.205:60486 Traceback (most recent call last):nSun Oct 16 18:40:11.746153 2016 :error pid 27659 client 128.75.240.205:60486   File ""/var/www/html/xxx.com/django.wsgi"" line 9 in <module>nSun Oct 16 18:40:11.746165 2016 :error pid 27659 client 128.75.240.205:60486     import django.core.handlers.wsginSun Oct 16 18:40:11.746191 2016 :error pid 27659 client 128.75.240.205:60486 ImportError: No module named 'django'nnnMy apache2.conf:nnMutex file:${APACHE_LOCK_DIR} defaultnnPidFile ${APACHE_PID_FILE}nnTimeout 300nnKeepAlive OffnnMaxKeepAliveRequests 100nnKeepAliveTimeout 5nnUser ${APACHE_RUN_USER}nGroup ${APACHE_RUN_GROUP}nnHostnameLookups OffnnErrorLog ${APACHE_LOG_DIR}/error.lognnLogLevel warnnnIncludeOptional mods-enabled/*.loadnIncludeOptional mods-enabled/*.confnnInclude ports.confnn<Directory />n    Options FollowSymLinksn    AllowOverride Nonen    Require all deniedn</Directory>nn<Directory /usr/share>n    AllowOverride Nonen    Require all grantedn</Directory>nn<Directory /var/www/>n    Options Indexes FollowSymLinksn    AllowOverride Nonen    Require all grantedn</Directory>nn#<Directory /srv/>n#   Options Indexes FollowSymLinksn#   AllowOverride Nonen#   Require all grantedn#</Directory>nnAccessFileName .htaccessnn<FilesMatch ""^.ht"">n    Require all deniedn</FilesMatch>nnLogFormat ""%v:%p %h %l %u %t ""%r"" %>s %O ""%{Referer}i"" ""%{User-Agent}i"""" vhost_combinednLogFormat ""%h %l %u %t ""%r"" %>s %O ""%{Referer}i"" ""%{User-Agent}i"""" combinednLogFormat ""%h %l %u %t ""%r"" %>s %O"" commonnLogFormat ""%{Referer}i -> %U"" referernLogFormat ""%{User-agent}i"" agentnnIncludeOptional conf-enabled/*.confnnIncludeOptional sites-enabled/*.confnn<IfModule mpm_prefork_module>n    StartServers 4n    MinSpareServers 20n    MaxSpareServers 40n    MaxClients 200n    MaxRequestsPerChild 4500n</IfModule>nnnLoadModule wsgi_module /usr/lib/apache2/modules/mod_wsgi.sonnWSGIScriptAlias / /var/www/html/xxx.com/public_html/mediar/mediar/wsgi.pynWSGIPythonPath /var/www/html/xxx.com/public_html:/root/eb-virt/lib/python3.4/site-packages/nn<Directory /var/www/html/xxx.com/public_html/mediar/mediar/>n<Files wsgi.py>nRequire all grantedn</Files>n</Directory>nnnMy xxx.com.conf:nn<VirtualHost *:80>n  ServerAdmin xxx@xxx.comn  ServerName  xxx.comn  ServerAlias www.xxx.comnn  # Index file and Document Root (where the public files are located)n  DirectoryIndex index.html index.phpn  DocumentRoot /var/www/html/xxx.com/public_htmln  # Log file locationsn  LogLevel warnn  ErrorLog  /var/www/html/xxx.com/log/error.logn  CustomLog /var/www/html/xxx.com/log/access.log combinednWSGIScriptAlias / /var/www/html/xxx.com/django.wsgin</VirtualHost>nnnAnd finally my django.wsgi:nn#!/usr/bin/python nimport os sys nnPROJECT_ROOT = '/var/www/html/xxx.com/' nsys.path.append(PROJECT_ROOT) nnos.environ'DJANGO_SETTINGS_MODULE' = 'mediar.settings' nnimport django.core.handlers.wsgi napplication = django.core.handlers.wsgi.WSGIHandler()nnnI've tried nn$ sudo apt-get remove libapache2-mod-python libapache2-mod-wsgin$ sudo apt-get install libapache2-mod-wsgi-py3nnn it didn't help. nnWhat should I do?n' ""I would first try using the right python shebang in your wsgi file.  Shouldnâx80x99t it be something like the following?nn#!/root/eb-virt/bin/pythonnnnAnd then the second thing would be to explicitly add the virtualenv to the sys.path append in the wsgi filennsys.path.append('/root/eb-virt/lib/python3.4/site-packages')nn""",['django'],['django']
40074290,"'Python How can i thread a client and server at same time?' 'Hello i make a code like this but it dont works well im trying to do a server and client server.i want this program makes sending and receiving either.nnimport socket              nimport sysnimport threadingnfrom threading import Threadn#making a serverndef server():               n    while True:n       # can someone say me what is that c's work?n       c addr = s.accept()n       #converting bytes(?)    n       data = c.recv(512)n       print addr  'is saying: '  datan       c.close()              n#making a clientndef client():  n    sock = socket.socket(socket.AF_INET socket.SOCK_STREAM) n    sock.connect(server_address)n    #sending messagesn    x = raw_input(""Message:"")n    sock.sendall(str(x))nn#defining threadsndef th():n    if __name__ == '__main__':n        Thread(target = server).start()n        Thread(target = client).start()nnnsock = socket.socket(socket.AF_INET socket.SOCK_STREAM)nserver_address = ('hostname' 6667)nprint >>sys.stderr 'Server running  %s port %s' % server_addressn#handle errorsntry:n    s = socket.socket()         n    host = socket.gethostname() n    port = 6667                n    s.bind((host port))       n    s.listen(5)n    server_address = ('hostname' 6667)n    print >>sys.stderr 'connecting to %s port %s' % server_addressn    while True:n        th()nexcept socket.error:n    print "" no connection""nnnif i try without while True: it works but if i try with it it gives a bunch of this errors nn#the errornException in thread Thread-14555:nTraceback (most recent call last):n  File ""/usr/lib/python2.7/threading.py"" line 801 in __bootstrap_innern  File ""/usr/lib/python2.7/threading.py"" line 754 in runn  File ""serverchat.py"" line 8 in servern  File ""/usr/lib/python2.7/socket.py"" line 206 in acceptnerror: Errno 24 Too many open filesnn' nan",['python-2.7'],['python-2.7']
40074315,"'""TypeError: 'str' does not support the buffer interface"" when writing to a socket' 'import socketnndef Main():n   host = '127.0.0.1'n   port = 5000nns = socket.socket()ns.connect((host port))nnfilename = input(""Filename? -> "")nif filename != 'q':n    s.send(filename)n    data = s.recv(1024)n    if data:6 == 'EXISTS':n        filesize = long(data6:)n        message = input(""File Exists "" + str(filesize) +n                        ""Bytes download? (Y/N) -> "")n        if message == 'Y':n            s.send('OK')n            f = open('new_' + filename 'wb')n            data = s.recv(1024)n            totalRecv = len(data)n            f.write(data)n            while totalRecv < filesize:n                data = s.recv(1024)n                totalRecv += len(data)n                f.write(data)n                print(""{0:.2f}"".format((totalRecv/float(filesize))*100)+n                      ""% Done"")n                print(""Download complete!"")n    else:n        print(""File doedn't exist!"")nns.close()nnif __name__ == '__main__':n   Main()nnnThe above python code is giving me this error: nnFile ""C:/Users/Mario/Networking/File Trasfering/fileClient.py"" line 12 in Mainnns.send(filename)nTypeError: 'str' does not support the buffer interfacenn' 'Python 3 makes a clean distinction between text strings (in the unicode character set but conceptually independent of any encoding) and sequences of bytes. To write text to a file or socket it must be ""encoded"" using a suitable encoding. In your case you could use nns.send(bytes(filename encoding=""...""))nnnor the equivalentnns.send(filename.encode(encoding=""...""))nnnLiteral strings can simply be written as byte strings e.g.nns.send(b'OK')nn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40074376,'Custom Python interpreter version in zc.buildout?' 'I have a zc.buildout project which I'd like to use Python 3.5 for. I'd like to avoid using the system Python as on RHEL7 the latest Python 3 package is Python 3.4.nnIs there a way to tell Buildout in buildout.cfg that bin/python should be Python 3.5? I'm currently doing something like this which does not seem to be working.n' nan,['python-3.x'],['python-3.x']
40074425,"""Zipline Error: AttributeError: 'NoneType' object has no attribute 'fetch_csv'"" 'I just installed Zipline on Windows 10 Python 2.7 system using conda. When I tried to use a function fetch_csv from zipline.api I get an errornnAttributeError: 'NoneType' object has no attribute 'fetch_csv'nnnWhy can't I load the function fetch_csv?nnfrom zipline.api import fetch_csvnnfetch_csv('./test.csv')nn' 'The Zipline API reference says that this methods is to ""Fetch a csv from a remote url"". For local files I would suggest pandas:nnpandas.read_csv('./test.csv')nn'",['python-2.7'],['python-2.7']
40074474,"'Python: Select particular characters from a file and add them to a new variable' 'I'm fairly new to python and I'm not sure why what I'm doing is wrong.nnnumberOfOrders = 0nnumberOfProducts = 0nnallOrders = open(""file.txt"" ""r"") #A .txt file in the same directory as the .py file.n#file.txt: n#(A->a:20a:20b:10c:25c:25)n#(B->d:100e:70)n#(C->f:10000g:200000)nnwhile True:n        theline = allOrders.readline()n        for theline in allOrders:n            for char in theline: #Iterate over each character of a line.n                listProducts = """" #Empty string will be the concatenation of the wanted characters.n                if char == """": #Wanted character.n                    listProducts = listProducts + """"n                elif char == "":"": #To keep count of no. of products in a list.n                    numberOfProducts += 1n                elif is_number(char) == True: #Function that checks whether char is a number.n                    listProducts = listProducts + str(char) #Add to the string ""listProducts"".n                elif char == """": #Wanted character.n                    listProducts = listProducts + str(char)n                elif char == """":#Wanted character to end the string.n                    listProducts = listProducts +str(char)n                    breakn            numberOfOrders += 1 #To keep track of no. of orders. Each line of file is an order. n        if len(theline) == 0:n            breaknn    allOrders.close()nn    print(numberOfProducts)n    print(numberOfOrders)n    print(listProducts)nnnI basically only want the numbers and commas within brackets. That's my biggest issue here.nThe output I get fornn print(listProducts)nnnisnn nnnThank you.n' ""You can keep the digits and commas by stripping everything else out using a regular expression. Then you have a string of decimals and commas that you can split to give a list of products in each order line.nnimport rennwith open('file.txt') as all_orders:n    # substitute '' for all non-digit non-comma then splitn    orders = re.sub(r'^d' '' line).split('')n        for line in all_ordersnnnumber_of_orders = len(orders)nnumber_of_products = sum(map(len orders))nprint('orders' number_of_orders 'products' number_of_products)nn"" 'Regarding your code the solution is to:nnnRemoving the ""for theline in allOrders"" which is not coherentnMoving the initialization of listProducts before the while loop  nnnOf course this can be widely optimized using regex for example as suggested by tdelaney.n'",['python-3.x'],"['regex', 'python-2.7']"
40074556,"'Numpy error in mtrand.pyx file' 'I was running a keras model in my desktop which was running smoothly in my laptop. But in desktop it's giving me the following error nn  File ""mtrand.pyx"" line 1252 in mtrand.RandomState.uniform (numpy/random/mtrand/mtrand.c:12988)nnnOverflowError: Range exceeds valid boundsnnMy editor showing that the error is occuring in this line nnmodel.add(Dense(128 activation='relu'))nn' nan",['numpy'],['numpy']
40074739,"""How to get mean of rows selected with another column's values in pandas"" 'I am trying to get calculate the mean for Score 1 only if column Dates is equal to Oct-16:nnnnWhat I originally tried was:nn import pandas as pdn import numpy as npn import osnn dataFrame = pd.read_csv(""test.csv"")nn for date in dataFrame""Dates"":n    if date == ""Oct-16"":n        print(date)##Just checkingn        print(dataFrame""Score 1"".mean())nnnBut my results are the mean for the whole column Score 1nnAnother thing I tried was manually telling it which indices to calculate the mean for:nndataFrame""Score 1"".iloc0:2.mean()nnnBut ideally I would like to find a way to do it if Dates == ""Oct-16"".n' 'Iterating through the rows doesn't take advantage of Pandas' strengths.  If you want to do something with a column based on values of another column you can use .loc:nndataFrame.locdataFrame'Dates' == 'Oct-16' 'Score 1'nnnThe first part of .loc selects the rows you want using your specified criteria (dataFrame'Dates' == 'Oct-16').  The second part specifies the column you want (Score 1).  Then if you want to get the mean you can just put .mean() on the end:nndataFrame.locdataFrame'Dates' == 'Oct-16' 'Score 1'.mean()nn' 'import pandas as pdnimport numpy as npnimport osnndataFrame = pd.read_csv(""test.csv"")nndates = dataFrame""Dates""nscore1s = dataFrame""Score 1""nresult = nnfor i in range(0len(dates)):n    if datesi == ""Oct-16"":n        result.append(score1si)nnprint(result.mean())nn' ""How about the mean for all datesnndataframe.groupby('Dates').'Score 1'.mean()nn""","['pandas', 'numpy']",['pandas']
40074749,"'One TIme Pad KeyGen using random.shuffle' ""I'm having issues attempting to generate 100kb random key. I'm trying to create a one time pad keygen but the constraints are it has to be random.nnc = 1250 ** 100nnf = bin(c)nnr = random.shuffle(1f)nnnso my thoughts are 1250 ** 100 the size is 100kb then I convert it to bits size:nnso it should be nnprint f = 110100101010 nnnbut if I pass it to shuffle would it shuffle the order of the bits?nn01010010101nn"" nan",['python-2.7'],"['python-2.7', 'python-3.x']"
40074768,"'Adding new values to empty nested lists' 'This is related to How to append to the end of an empty list? but I don't have enough reputation yet to comment there so I posted a new question here.nnI need to append terms onto an empty list of lists. I start with:nnTalkseachFilenameTermVectors=n      'paragraph''1''text'n       'paragraph''2''text'n       'paragraph''3''text'nnnI want to end with nnTalkseachFilenameSomeTermsRemoved=n      'paragraph''text'n       'paragraph''2'n       'paragraph'nnnTalkseachFilenameSomeTermsRemoved starts empty. I can't specify that I want: nnTalkseachFilenameSomeTermsRemoved00='paragraph'nTalkseachFilenameSomeTermsRemoved01='text'nTalkseachFilenameSomeTermsRemoved10='paragraph'nnnetc... (IndexError: list index out of range).  If I force populate the string  and then try to change it I get a strings are immutable error.nnSo how do I specify that I want TalkseachFilenameSomeTermsRemoved0 to be 'paragraph''text' and TalkseachFilenameSomeTermsRemoved1 to be 'paragraph''2' etc?nn.append works but only generates a single long column not a set of lists.nnTo be more specific I have a number of lists that are initialized inside a dictnnTalks = {}nTalkseachFilename= {}nTalkseachFilename'StartingText'=nTalkseachFilename'TermVectors'=nTalkseachFilename'TermVectorsNoStops'=nnneachFilename gets populated from a list of text files e.g.:nnTalkseachFilename='filename1''filename2'nnnStartingText has several long lines of text (individual paragraphs)nnTalksfilename1StartingText='This is paragraph one''paragraph two'nnnTermVectors are populated by the NLTK package with a list of terms still grouped in the original paragraphs:nnTalksfilename1TermVectors=n     'This''is''paragraph''one'n      'paragraph''two'nnnI want to further manipulate the TermVectors but keep the original paragraph list structure. This creates a list with 1 term per line:nnfor eachFilename in Talks:n    for eachTerm in range( 0 len( TalkseachFilename'TermVectors' ) ):n        for term in TalkseachFilename'TermVectors' eachTerm :n            if unicode(term) not in stop_words:n                TalkseachFilename'TermVectorsNoStops'.append( term )nnnResult (I lose my paragraph structure):nnTalksfilename1TermVectorsNoStops=n     'This'n      'is'n      'paragraph'n      'one'n      'paragraph'n      'two'nn' 'The errors you are reporting (strings immutable?) don't make any sense unless your list is actually not empty but already populated with strings. In any event if you start with an empty list then the simplest way to populate it is by appending:nn>>> talks = {}n>>> talks'each_file_name' = {}n>>> talks'each_file_name''terms_removed' = n>>> talks'each_file_name''terms_removed'.append('paragraph''text')n>>> talks'each_file_name''terms_removed'.append('paragraph''2')n>>> talks'each_file_name''terms_removed'.append('paragraph')n>>> talksn{'each_file_name': {'terms_removed': 'paragraph' 'text' 'paragraph' '2' 'paragraph'}}n>>> from pprint import pprintn>>> pprint(talks)n{'each_file_name': {'terms_removed': 'paragraph' 'text'n                                      'paragraph' '2'n                                      'paragraph'}}nnnIf you have an empty list and try to assign to it by using indexing it will throw an error:nn>>> empty_list = n>>> empty_list0 = 10nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>nIndexError: list assignment index out of rangennnAs an aside code like this:nnfor eachFilename in Talks:n    for eachTerm in range( 0 len( TalkseachFilename'TermVectors' ) ):n        for term in TalkseachFilename'TermVectors' eachTerm :n            if unicode(term) not in stop_words:n                TalkseachFilename'TermVectorsNoStops'.append( term )nnnIs very far from proper Python style. Don't use camelCase use snake_case. Don't capitalize variables. Also in your mid-level for-loop you use for eachTerm in range(0 len(TalkseachFilename'TermVectors' but eachTerm is an int so it makes more sense to use the standard i j or k. Even idx.nnAnyway there is no reason why that code should be turning this:nnTalksfilename1TermVectors =n     'This''is''paragraph''one'n      'paragraph''two' nnnInto this:nnTalksfilename1TermVectors =n     'This'n      'is'n      'paragraph'n      'one'n      'paragraph'n      'two'nnnHere is a reproducible example (I've made this for you BUT YOU SHOULD DO THIS YOURSELF BEFORE POSTING A QUESTION):nn>>> pprint(talks)n{'file1': {'no_stops': n           'term_vectors': 'This' 'is' 'paragraph' 'one'n                            'paragraph' 'two'}n 'file2': {'no_stops': n           'term_vectors': 'This' 'is' 'paragraph' 'three'n                            'paragraph' 'four'}}n>>> for file in talks:n...   for i in range(len(talksfile'term_vectors')):n...     for term in talksfile'term_vectors'i:n...       if term not in stop_words:n...         talksfile'no_stops'.append(term)n... n>>> pprint(file)n'file2'n>>> pprint(talks)n{'file1': {'no_stops': 'This' 'paragraph' 'one' 'paragraph'n           'term_vectors': 'This' 'is' 'paragraph' 'one'n                            'paragraph' 'two'}n 'file2': {'no_stops': 'This' 'paragraph' 'paragraph' 'four'n           'term_vectors': 'This' 'is' 'paragraph' 'three'n                            'paragraph' 'four'}}n>>> nnnThe more pythonic approach would be something like the following:nn>>> pprint(talks)n{'file1': {'no_stops': n           'term_vectors': 'This' 'is' 'paragraph' 'one'n                            'paragraph' 'two'}n 'file2': {'no_stops': n           'term_vectors': 'This' 'is' 'paragraph' 'three'n                            'paragraph' 'four'}}n>>> for file in talks.values():n...   file'no_stops' = term for term in sub if term not in stop_words for sub in file'term_vectors'n... n>>> pprint(talks)n{'file1': {'no_stops': 'This' 'paragraph' 'one' 'paragraph'n           'term_vectors': 'This' 'is' 'paragraph' 'one'n                            'paragraph' 'two'}n 'file2': {'no_stops': 'This' 'paragraph' 'paragraph' 'four'n           'term_vectors': 'This' 'is' 'paragraph' 'three'n                            'paragraph' 'four'}}n>>> nn' ""Some continued experimentation along with the comments got me moving towards a solution. Rather than appending each individual term which generates a single long list I accumulated the terms into a list and then appended each list as follows:nnfor eachFilename in Talks:n    for eachTerm in range( 0 len( TalkseachFilename'TermVectors' ) ):n        term_list =  n        for term in TalkseachFilename'TermVectors' eachTerm :n            if unicode(term) not in stop_words:n                term_list.append(term)n        TalkseachFilename'TermVectorsNoStops'.append( term )nnnThanks everyone!n""",['list'],"['list', 'python-2.7']"
40074769,"'Syntax error in python2 script using ldap module' 'Learning python (was chosen for its ldap module) for a new script that has been tossed my way. I'm getting a sytntax error when I try using a ldif. I was getting Syntax errors on the attrs I was trying to assign until I moved it further up the script to near the search fields. I'm not exactly sure why I am getting the syntax error:nn  File ""UserGroupModify.py"" line 66n    attrs = {}n        ^nSyntaxError: invalid syntaxnn~/Scripts/Termination-Script$ python2 UserGroupModify.pyn  File ""UserGroupModify.py"" line 69n    ldif = modlist.addModlist(attrs)n       ^nSyntaxError: invalid syntaxnnnThe code currently looks like the following (including previous things I had tried all with syntax errors of their own when I tried to use them). Getting it to log in and search for the user was easy enough but modifying the user is where I am having a hard time. The current code is uncommented and is from an example I found online.nn#!/usr/bin/env python2nnimport ldapnimport getpassnimport ldap.modlist as modlistnn## first you must open a connection to the serverntry:nn#Ignore self signed certsn    ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT ldap.OPT_X_TLS_NEVER)nn    username = raw_input(""LDAP Login: "")n    passwd = getpass.getpass()n    userlook = raw_input(""User to lookup: "")    nn    l = ldap.initialize(""ldaps://ldap.example.com:636/"")nn    # Bind/authenticate with a user with apropriate rights to add objectsn    l.simple_bind_s(""uid=""+username+""ou=peopledc=exampledc=com"" """"+passwd+"""")nexcept ldap.LDAPError e:n    print(e)nnn# The dn of our existing entry/objectndn = ""ou=Peopledc=exampledc=com""nnsearchScope = ldap.SCOPE_SUBTREEnsearchAttribute = ""uid""n#retrieveAttributes = ""ou=Group""nretrieveAttributes = ""ou""n#searchFilter = ""uid=*""nsearchFilter = ""(uid=""+userlook+"")""n#mod_attrs = (ldap.MOD_REPLACE 'ou' 'former-people' )nattrs = {}nattrs'member' = 'uid=""+userlook+""ou=former-peopledc=exampledc=com'nntry:n    #ldap_result_id = l.search(dn searchScope searchFilter retrieveAttributes)n    ldap_result_id = l.search(dn searchScope searchFilter retrieveAttributes)n    while 1:n        result_type result_data = l.result(ldap_result_id 0)n        if (result_data == ):n            breakn        else:n            ## here you don't have to append to a listn            ## you could do whatever you want with the individual entryn            ## The appending to list is just for illustration. n            if result_type == ldap.RES_SEARCH_ENTRY:n                print(result_data)n# Some place-holders for old and new valuesn#old={'Group':'l.result(ldap_result_id 0)'}n#new={'Group':'uid=""+userlook+""ou=former-peopledc=exampledc=com'}n#newsetting = {'description':'I could easily forgive his pride if he had not mortified mine.'}n#print(old)n#print(new)nn# Convert place-holders for modify-operation using modlist-modulen#ldif = modlist.modifyModlist(oldnew)nn# Do the actual modification n#l.modify_s(dnldif)nnn#l.modify_s('uid=""+userlook+ou=Peopledc=exampledc=com' mod_attrs)n#l.modify_s('uid=""+userlook+""ou=People' mod_attrs)nn#moved up due to SyntaxErrorn#attrs = {}n#attrs'member' = 'uid=""+userlook+""ou=former-peopledc=exampledc=com'nn# Convert our dict to nice syntax for the add-function using modlist-modulenldif = modlist.addModlist(attrs)nn# Do the actual synchronous add-operation to the ldapservernl.add_s(dnldif)nn# Its nice to the server to disconnect and free resources when donenl.unbind_s()nnexcept ldap.LDAPError e:n    print(e)nnnAny direction pointing on what's causing the error would be greatly appreciated. Thanksn' ""It's a syntax error to have try without except. Because there's a whole lot of unindented code before the except Python doesn't see it as part of the try. Make sure everything between try and except is indented.n"" ""You haven't ended your try block by the time you reach this linennldif = modlist.addModlist(attrs)nnnsince the accompanying except is below. However you reduced the indentation level and this is causing the syntax error since things in the same block should have the same indentation.n""",['python-2.7'],['python-2.7']
40074825,"'If a string contains a suffix from a list how do I strip that specific suffix from the string?' 'I have a list of strings and a list of suffixes. If a string contains one of the suffixes how do I strip that specific one from the string? nnb = ""food"" ""stuffing"" ""hobbitses""ny = ""ing"" ""es"" ""s"" ""ly""nnndef stemming():n    for i in range(len(b)):n        if bi.endswith(tuple(y)):n            bi = bi - #???nprint bnn' ""I'd recommend separating out the stem removal into its own function and then using a list comprehension or a separate function for the whole list.  Here's one way of doing itnndef remove_stems(word stems):n    for stem in stems:n        if word.endswith(stem):n            return word:-len(stem)n        else: n            return wordnnb_without_stems = remove_stem(word stems) for word in bnn"" 'You need to know which ending has been found so you need to check them one at a time instead of trying to check them all at once. Once you have found an ending you can chop it off using a slice.nndef stemming():n    for i word in enumerate(b):n        for suffix in y:n            if word.endswith(suffix):n                bi = word:-len(suffix)n                breaknnnA better approach would use a regular expression:nnimport rensuffix = re.compile(""(%s)$"" % ""|"".join(y))nndef stemming():n    for i word in enumerate(b):n        bi = suffix.sub("""" word)nnnThen you can easily do the stemming using a list comprehension:nnb = suffix.sub("""" w) for w in bnn' 'assuming you want to strip the first suffix found this will do itnndef stemming(strings endings):n    for i string in enumerate(strings):n        for ending in endings:n            if string.endswith(ending):n                stringsi = string:-len(ending)n                continuenn'",['python-2.7'],"['list', 'python-2.7']"
40074884,"'How to filter the list by selecting for unique combinations of characters in the elements (Python)?' 'I have the the following pairs stored in the following listnn sample = CGCGATATCGCGCATCATATTATAnnnEach pairwise comparison can have only two unique combinations of characters if not then those pairwise comparisons are eliminated. egnn   In sample1n    C       Cn    G       An    C       T n    G       CnnnLook a the corresponding elements in both sub-lists CC GA CT GC.nnHere there are more than two types of pairs (CC) (GA) (CT) and (GC). So this pairwise comparison cannot occur. nnEvery comparison can have only 2 combinations out of (AA GGCCTT ATTAACCAAGGAGCCGGTTGCTTC) ... basically all possible combinations of ACGT where order matters.nnIn the above example more than 2 such combinations are found.nnHowever nn   In sample0n    C       An    G       Tn    C       A n    G       TnnnThere are only 2 unique combinations: CA and GTnnThus the only pairs that remain are:nnoutput = CGCGATATATATTATAnnnI would prefer if the code was in traditional for-loop format and not comprehensionsnnThis is a small part of the question listed here. This portion of the question is re-asked as the answer provided earlier provided incorrect output.n' ""The core of this task is extracting the pairs from your sublists and counting the number of unique pairs.  Assuming your samples actually contain strings you can use zip(*sub_list) to get the pairs.  Then you can use set() to remove duplicate entries.nnsample = 'CGCG''ATAT''CGCG''CATC''ATAT''CATC'nndef filter(sub_list n_pairs):n    pairs = zip(*sub_list)n    return len(set(pairs)) == n_pairsnnnThen you can use a for loop or a list comprehension to apply this function to your main list.nnnew_sample = sub_list for sub_list in sample if filter(sub_list 2)nnn...or as a for loop...nnnew_sample = nfor sub_list in sample:n    if filter(sub_list 2):n        new_sample.append(sub_list)nn"" 'sample = CGCGATATCGCGCATCATATCATCnresult = nfor s in sample:n    first = s0n    second = s1n    combinations = n    for i in range(0len(first)):n        comb = firstisecondin        if comb not in combinations:n            combinations.append(comb)n    if len(combinations) == 2:n        result.append(s)nnprint resultnn' 'def filter_sample(sample):n    filtered_sample = nn    for s1 s2 in sample:n        pairs = {pair for pair in zip(s1 s2)}n        if len(pairs) <= 2:n            filtered_sample.append(s1 s2)nn    return filtered_samplennnRunning thisnnsample = ""CGCG""""ATAT""""CGCG""""CATC""""ATAT""""TATA""nfilter_sample(sample)nnnReturns thisnn'CGCG' 'ATAT' 'ATAT' 'TATA'nn'",['list'],"['list', 'python-2.7']"
40074994,"'Numerology with certain rules' ""The challenge is to :nCreate a function name_numerology(name) which takes input and turns this input into single digit value and then returns it.nnThe rules are:nnnfunction must ignore all kind of characters that are not in the listnof letters above treat them as something that matches value 0nfunction must be able to handle the case where input is not stringnfunction must do it's job despite that input might consist of bothnlower or upper case letters nif sum of letters is too big (over 10) then the sum the digitsnof the sum until the value is number between 0 and 10. Ex: totalnis 99 => 9 + 9 => 18 => 1 + 8 = 9. 9 is validnnnCan't figure out the rest. I am stuck help please.nnletters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'n    numbers = '12345678912345678912345678'n    def name_numerology(name):n            if isinstance(name str):n                name = str(name)n                name = name.upper()n                summed = 0n                for i in name:n                        if i not in letters:n                                i = 0n                        else:n                                a = letters.index(i)n                                summed += int(numbersa)n                                ha hu = divmod(summed 10)n                return ha+hun            else:n                   return 'Please enter a name'nn"" ""I think the purpose is that you start adding digits only after you have processed all input characters:nnletters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'nnumbers = '12345678912345678912345678'ndef name_numerology(name):n    if not isinstance(name str):n       return 'Please enter a name'n    summed = 0n    for c in name.upper():n        a = letters.find(c)n        if a > -1:n            summed += int(numbersa)n    while summed > 9:n        temp = summedn        summed = 0n        while temp > 0:n            temp digit = divmod(temp 10)n            summed += digitn    return summednnresult = name_numerology('JackTheRipper')nprint(result)nn""",['python-3.x'],"['python-2.7', 'python-3.x']"
40075055,"'Error in the 2nd last code for accuracy' 'if __name__ == ""__main__"":n    """"""nn    """"""     n    predictionEngine = Engine(""semeval2016-task6-trainingdata.txt"")n    if(predictionEngine.readFile()):n        predictionEngine.featureExtractor(predictionEngine.Tweet)n        testTweet = ""EU migrants: We're not Brexit 'bargaining chips': Read full story for latest details.""n        predictedStance = predictionEngine.NBClassifier(testTweet False)n        predictionEngine.logFile(testTweet predictedStance.upper())n        print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(NBClassifier training_set))) n        print ""Predicted Sentiment: "" + predictedStance.upper()nnn2nd last code for accuracy doesn't work.n' nan",['python-2.7'],['python-2.7']
40075106,'Replace values in pandas Series with dictionary' 'I want to replace values in a pandas Series using a dictionary. I'm following @DSM's accepted answer like so:nns = Series('abc' 'abe' 'abg')nd = {'b': 'B'}ns.replace(d)nnnBut this has no affect:nn0    abcn1    aben2    abgndtype: objectnnnThe documentation explains the required format of the dict for DataFrames (i.e. nested dicts with top level keys corresponding to column names) but I can't see anything specific for Series.n' 'You can do it using regex=True parameter:nnIn 37: s.replace(d regex=True)nOut37:n0    aBcn1    aBen2    aBgndtype: objectnnnAs you have already found out yourself - it's a RegEx replacement and it won't work as you expected:nnIn 36: s.replace(d)nOut36:n0    abcn1    aben2    abgndtype: objectnnnthis is working as expected:nnIn 38: s.replace({'abc':'ABC'})nOut38:n0    ABCn1    aben2    abgndtype: objectnn',"['pandas', 'dictionary']",['pandas']
40075164,"'Determine mean value of âx80x98dataâx80x99 where the highest number of CONTINUOUS cond=True' ""I have a pandas Dataframe with a 'data' and 'cond'(-ition) column. I need the mean value (of the data column) of the rows with the highest number of CONTINUOUS True objects in 'cond'.  nn    Example DataFrame:nn        cond  datan    0   True  0.20n    1  False  0.30n    2   True  0.90n    3   True  1.20n    4   True  2.30n    5  False  0.75n    6   True  0.80nn    Result = 1.466 which is the mean value of row-indexes 2:4 with 3 TruennnI was not able to find a âx80x9evectorizedâx80x9c solution with a groupby or pivot method. So I wrote a func that loops the rows. Unfortunately this takes about an hour for 1 Million lines which is way to long. Unfortunately the @jit decoration does not reduce the duration measurably. nnThe data I want to analyze is from a monitoring project over one year and I have every 3 hours a DataFrame with one Million rows. Thus about 3000 such files. nnAn efficient solution would be very important. I am also very grateful for a solution in numpy.  n"" ""Here's a NumPy based approach -nn# Extract the relevant cond column as a 1D NumPy array and pad with False atn# either ends as later on we would try to find the start (rising edge) n# and stop (falling edge) for each interval of True valuesnarr = np.concatenate((Falsedf.cond.valuesFalse))nn# Determine the rising and falling edges as start and stop nstart = np.nonzero(arr1: > arr:-1)0nstop = np.nonzero(arr1: < arr:-1)0nn# Get the interval lengths and determine the largest interval IDnmaxID = (stop - start).argmax()nn# With maxID get max interval range and thus get mean on the second colnout = df.data.ilocstartmaxID:stopmaxID.mean()nnnRuntime testnnApproaches as functions -nndef pandas_based(df): # @ayhan's solnn    res = df'data'.groupby((df'cond' != df'cond'.shift()).n                                cumsum()).agg('count' 'mean')n    return resres'count' == res'count'.max()nndef numpy_based(df):n    arr = np.concatenate((Falsedf.cond.valuesFalse))n    start = np.nonzero(arr1: > arr:-1)0n    stop = np.nonzero(arr1: < arr:-1)0n    maxID = (stop - start).argmax()n    return df.data.ilocstartmaxID:stopmaxID.mean()nnnTimings -nnIn 208: # Setup dataframen     ...: N = 1000  # Datasizen     ...: df = pd.DataFrame(np.random.rand(N)columns='data')n     ...: df'cond' = np.random.rand(N)>0.3 # To have 70% True valuesn     ...: nnIn 209: %timeit pandas_based(df)n100 loops best of 3: 2.61 ms per loopnnIn 210: %timeit numpy_based(df)n1000 loops best of 3: 215 Âµs per loopnnIn 211: # Setup dataframen     ...: N = 10000  # Datasizen     ...: df = pd.DataFrame(np.random.rand(N)columns='data')n     ...: df'cond' = np.random.rand(N)>0.3 # To have 70% True valuesn     ...: nnIn 212: %timeit pandas_based(df)n100 loops best of 3: 4.12 ms per loopnnIn 213: %timeit numpy_based(df)n1000 loops best of 3: 331 Âµs per loopnn"" 'Using the approach from Calculating the number of specific consecutive equal values in a vectorized way in pandas:nndf'data'.groupby((df'cond' != df'cond'.shift()).cumsum()).agg('count' 'mean')lambda x: x'count'==x'count'.max()nOut: n      count      meanncond                 n3         3  1.466667nnnIndexing by a callable requires 0.18.0 for earlier versions you can do:nnres = df'data'.groupby((df'cond' != df'cond'.shift()).cumsum()).agg('count' 'mean')nnresres'count' == res'count'.max()nOut: n      count      meanncond                 n3         3  1.466667nnnHow it works:nnThe first part df'cond' != df'cond'.shift() returns a boolean array:nndf'cond' != df'cond'.shift()nOut: n0     Truen1     Truen2     Truen3    Falsen4    Falsen5     Truen6     TruenName: cond dtype: boolnnnSo the value is False whenever the row is the same as the above. That means that if you take the cumulative sum these rows (consecutive ones) will have the same number:nn(df'cond' != df'cond'.shift()).cumsum()nOut: n0    1n1    2n2    3n3    3n4    3n5    4n6    5nName: cond dtype: int32nnnSince groupby accepts any Series to group on (it is not necessary to pass a column you can pass an arbitrary list) this can be used to group the results. .agg('count' 'mean' part just gives the respective counts and means for each group and at the end it selects the one with the highest count.nnNote that this would group consecutive False's together too. If you want to only consider consecutive True's you can change the grouping Series to:nn((df'cond' != df'cond'.shift()) | (df'cond' != True)).cumsum()nnnSince we want False's when the condition is True the condition became 'not equal to the row below OR not True'. So the original line would change to:nndf'data'.groupby(((df'cond' != df'cond'.shift()) | (df'cond' != True)).cumsum()).agg('count' 'mean')lambda x: x'count'==x'count'.max()nn'","['pandas', 'numpy']","['pandas', 'numpy']"
40075189,"'Django admin dashboard not able to ""select all"" records' 'I have a weird issue were I am not able to ""select all"" records for any model in my Django admin dashboard.nnnnThis is using Django 1.10.1nnIt is a small issue but I still rather have it solved. Appreciate any help!n' ""I think you'll need to run nnpython manage.py collectstaticnnnso your js will function on the page.n""",['django'],['django']
40075230,"'KeyError: numpy.datetime64 after changing only the month of a datetime (Zipline)' 'I am encountering a very strange error when creating a data bundle for Zipline. When using minuteDataB.csv CSV file to create the bundle everything works out OK. Script is taken from here.nnProblem: However when using minuteDataA.csv where only the months are changed the script throws an errornnKeyError: numpy.datetime64('2016-10-01T13:35:00.000000000-0400')nnnAny ideas what is happening?nnminuteDataA.csv (no error)nntimesopenhighlowclosenumEventsvolumevaluen16/1/2016 13:3060.8260.8960.6760.74199416802534707n26/1/2016 13:3160.738960.860.7360.786610359629549.4375n36/1/2016 13:3260.7660.769960.6260.63133189201148061n46/1/2016 13:3360.6160.6260.5260.61189355022150747.5n56/1/2016 13:3460.6160.6560.5860.618813968846745.375n66/1/2016 13:3560.660.6360.4260.4568261470562848120.5nnnminuteDataB.csv (causes error)nntimesopenhighlowclosenumEventsvolumevaluen110/1/2016 13:3060.8260.8960.6760.74199416802534707n210/1/2016 13:3160.738960.860.7360.786610359629549.4375n310/1/2016 13:3260.7660.769960.6260.63133189201148061n410/1/2016 13:3360.6160.6260.5260.61189355022150747.5n510/1/2016 13:3460.6160.6560.5860.618813968846745.375n610/1/2016 13:3560.660.6360.4260.4568261470562848120.5nnnErrornnread_csv dfData <class 'pandas.core.frame.DataFrame'> length 6nnstart_date <class 'pandas.tslib.Timestamp'> 2016-10-14 21:11:00 Nonenend_date <class 'pandas.tslib.Timestamp'> 2016-10-14 21:16:00 Nonenac_date <class 'pandas.tslib.Timestamp'> 2016-10-15 21:16:00 NonenliData <type 'list'> length 1nNow calling minute_bar_writernMerging minute equity files:  ####################################  100%  0nTraceback (most recent call last):n  File ""C:Usersmy-PcAnaconda2envstestEnvScriptszipline-script.py"" line 11 in <module>n    load_entry_point('zipline==1.0.2' 'console_scripts' 'zipline')()n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesclickcore.py"" line 716 in __call__n    return self.main(*args **kwargs)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesclickcore.py"" line 696 in mainn    rv = self.invoke(ctx)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesclickcore.py"" line 1060 in invoken    return _process_result(sub_ctx.command.invoke(sub_ctx))n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesclickcore.py"" line 889 in invoken    return ctx.invoke(self.callback **ctx.params)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesclickcore.py"" line 534 in invoken    return callback(*args **kwargs)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packageszipline__main__.py"" line 306 in ingestn    show_progressn  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesziplinedatabundlescore.py"" line 443 in ingestn    pth.data_path(name timestr environ=environ)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesziplinedatabundlescustomBundle.py"" line 116 in ingestn    minute_bar_writer.write(liData show_progress=True)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesziplinedataminute_bars.py"" line 686 in writen    write_sid(*e)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesziplinedataminute_bars.py"" line 719 in write_sidn    self._write_cols(sid dts cols)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagesziplinedataminute_bars.py"" line 799 in _write_colsn    latest_min_count = all_minutes.get_loc(last_minute_to_write)n  File ""C:Usersmy-PcAnaconda2envstestEnvlibsite-packagespandastseriesindex.py"" line 1352 in get_locn    raise KeyError(key)nKeyError: numpy.datetime64('2016-10-01T13:35:00.000000000-0400')nnnzipline/data/bundle/customBundle.pynn#n# Ingest stock csv files to create a zipline data bundlennnimport osnnimport numpy  as npnimport pandas as pdnimport datetimenfrom pytz import timezonennboDebug=True # Set True to get trace messagesnnfrom zipline.utils.cli import maybe_show_progressnndef customBundle(symbolsstart=Noneend=None):nn    # strict this in memory so that we can reiterate over it.n    # (Because it could be a generator and they live only once)n    tuSymbols = tuple(symbols)nn    if boDebug:n        print ""entering machina.  tuSymbols=""tuSymbolsnn    # Define our custom ingest functionn    def ingest(environn               asset_db_writern               minute_bar_writern               daily_bar_writern               adjustment_writern               calendarn               cachen               show_progressn               output_dirn               # pass these as defaults to make them 'nonlocal' in py2n               start=startn               end=end):nn        if boDebug:n            print ""entering ingest and creating blank dfMetadata""nn        dfMetadata = pd.DataFrame(np.empty(len(tuSymbols) dtype=n            ('start_date' 'datetime64ns')n            ('end_date' 'datetime64ns')n            ('auto_close_date' 'datetime64ns')n            ('symbol' 'object')n        ))nn        if boDebug:n            print ""dfMetadata""type(dfMetadata)n            print dfMetadata.describen            printnn        # We need to feed something that is iterable - like a list or a generator -n        # that is a tuple with an integer for sid and a DataFrame for the data ton        # daily_bar_writernn        liData=n        iSid=0n        for S in tuSymbols:n            IFIL=""~/minuteData.csv""n            if boDebug:n               print ""S=""S""IFIL=""IFILn            dfData=pd.read_csv(IFILindex_col='times'parse_dates=True).sort_index()n            # csv time stamp is in EST but pandas doesnt know that yet so tell itn            dfData.index=dfData.index.tz_localize('US/Eastern')n            # zipline needs data in UTC format so lets convert itn            dfData.index=dfData.index.tz_convert('UTC')n            # But zipline ingest function wants data in Naive date formatn            # so remove the tzinfo.n            dfData.index=dfData.index.tz_convert(None)n            if boDebug:n               print ""read_csv dfData""type(dfData)""length""len(dfData)n               dfData.index0n               printn            dfData.rename(n                columns={n                    'open': 'open'n                    'high': 'high'n                    'low': 'low'n                    'close': 'close'n                    'volume': 'volume'n                }n                inplace=Truen            )n            liData.append((iSiddfData))nn            # the start date is the date of the first trade andn            start_date = dfData.index0n            if boDebug:n                print ""start_date""type(start_date)start_datestart_date.tzinfonn            # the end date is the date of the last traden            end_date = dfData.index-1n            if boDebug:n                print ""end_date""type(end_date)end_dateend_date.tzinfonn            # The auto_close date is the day after the last trade.n            ac_date = end_date + pd.Timedelta(days=1)n            if boDebug:n                print ""ac_date""type(ac_date)ac_dateend_date.tzinfonn            # Update our meta datan            dfMetadata.ilociSid = start_date end_date ac_date Snn            iSid += 1nn        if boDebug:n            print ""liData""type(liData)""length""len(liData)n            print ""Now calling minute_bar_writer""nn        # daily_bar_writer.write(liData show_progress=False)n        minute_bar_writer.write(liData show_progress=True)nn        # Hardcode the exchange to ""YAHOO"" for all assets and (elsewhere)n        # register ""YAHOO"" to resolve to the NYSE calendar because these aren        # all equities and thus can use the NYSE calendar.n        dfMetadata'exchange' = ""YAHOO""nn        if boDebug:n            print ""returned from minute_bar_writer""n            print ""calling asset_db_writer""n            print ""dfMetadata""type(dfMetadata)n            print dfMetadatan            printnn        # Not sure why symbol_map is neededn        symbol_map = pd.Series(dfMetadata.symbol.index dfMetadata.symbol)n        if boDebug:n            print ""symbol_map""type(symbol_map)n            print symbol_mapn            printnn        asset_db_writer.write(equities=dfMetadata)nn        if boDebug:n            print ""returned from asset_db_writer""n            print ""calling adjustment_writer""nn        adjustment_writer.write()nn        if boDebug:n            print ""returned from adjustment_writer""n            print ""now leaving ingest function""nnn    if boDebug:n       print ""about to return ingest function""n    return ingestnn' nan","['python-2.7', 'pandas', 'numpy']","['numpy', 'pandas', 'python-2.7']"
40075277,"'Luhn Algorithm in Python giving incorrect results' 'First I get input from creditNumber than I apply Luhn algorithm only to get incorrect results.nncreditNumber = input( ""Enter your credit number: "" )nndef checkValid(creditNumber):n    creditNumber = creditNumber::-1n    total = 0n    numberLength = len(creditNumber)n    oddOrEven = numberLength & 1nn    for counter in range(numberLength):n        digit = int(creditNumbercounter)n        if not ((counter & 1) ^ oddOrEven):n            digit = digit * 2n            if digit > 9:n                digit = digit - 9n        total = digit + totaln    return (total % 10 == 0)nnif checkValid(creditNumber) == 0:n    print( ""Number is valid"" )nelse:n    print( ""Number is invalid"" )nn' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40075497,"'CountVectorizer: transform method returns multidimensional array on a single text line' ""Firstly I fit it on the corpus of sms:nnfrom sklearn.feature_extraction.text import CountVectorizernclf = CountVectorizer()nX_desc = clf.fit_transform(X).toarray()nnnSeems to works fine:nnX.shape = (5574)nX_desc.shape = (5574 8713)nnnBut then I applied transform method to the textline as we know it should have ( 8713) shape as a result but what we see:nnstr2 = 'Have you visited the last lecture on physics?'nprint len(str2) clf.transform(str2).toarray().shapennnn  52          (52 8713)nnnWhat is going on here? One more thing - all numbers are zerosn"" 'You always need to pass an array or vector to transform; if you just want to transform a single element you need to pass a singleton array and then extract its contents:nnclf.transform(str1)0nnnIncidentally the reason that you are getting a 2-dimensional array as output is that the a string is actually stored as a list of characters and so the vectoriser is treating your string as an array where each character is being considered as a single document.n'",['python-2.7'],"['numpy', 'python-2.7']"
40075615,"'Undefined symbol with compiled package' 'I'm trying to use the pip module swigibpy. I installed it once before on a different system and it was fine but for some reason it's no longer working.nnI'm running on Ubuntu 16.04 with Anaconda Python 3.5. I've installed ubuntu packages python-dev and g++.nnI don't understand the nature of the error below. If you could give me any insight that would help me track it down that would be a great help.nn>>> import swigibpynTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""/home/chris/anaconda3/lib/python3.5/site-packages/swigibpy.py"" line 34 in <module>n    _swigibpy = swig_import_helper()n  File ""/home/chris/anaconda3/lib/python3.5/site-packages/swigibpy.py"" line 30 in swig_import_helpern    _mod = imp.load_module('_swigibpy' fp pathname description)n  File ""/home/chris/anaconda3/lib/python3.5/imp.py"" line 242 in load_modulen    return load_dynamic(name filename file)n  File ""/home/chris/anaconda3/lib/python3.5/imp.py"" line 342 in load_dynamicn    return _load(spec)nImportError: /home/chris/anaconda3/lib/python3.5/site-packages/_swigibpy.cpython-35m-x86_64-linux-gnu.so: undefined symbol: _ZTVNSt7__cxx1115basic_stringbufIcSt11char_traitsIcESaIcEEEnn' nan",['python-3.x'],['python-3.x']
40075696,"'Python: Use specific parts of a string (that looks like a list)' 'I have a text file (file.txt):nn(A->a:5a:5a:5b:50c:10c:10)n(B->e:120g:50)n(C->a:5f:20)nnnand I want to extract and sum the values paired with 'a' (or 'b' or 'c' or ...) so that:nntotalValue = 20 # of 'a'n#ORntotalValue = 50 # of 'b'n#ORntotalValue = 20 # of 'c'nnnNote: text file is obviously not a list even though it looks like it.nnmyFile = open(""file.txt"" ""r"")nnwhile True:n    theline = myFile.readline()n    if ""a"" in theline:     #Just used 'a' here as an example.n        for char in theline:n            ...        nnmyFile.close()nnnThat's roughly the code I have to read the file and check each line for 'a' (for example).nnThank you.n' 'First parse the couples using a regular expression which extracts them all.nnThen use the nice itertools.groupby to gather the values using keys as the abc... letter (first item of the regex tuple).nnFinally create tuples with variable sum of values as integernnimport reitertoolsnnwith open(""file.txt"" ""r"") as myFile:nn    r = re.compile(""(w+):(-?d+)"")nn    for l in myFile:n        tuples = r.findall(l)n        sums = n        for variablevalues in itertools.groupby(tupleslambda t: t0):n            sums.append((variablesum(int(x1) for x in values)))n        print(lsums)nnnoutput:nn(A->a:5a:5a:5b:50c:10c:10) ('a' 15) ('b' 50) ('c' 20)n(B->e:120g:50) ('e' 120) ('g' 50)n(C->a:5f:20) ('a' 5) ('f' 20)nnnIf you want the total sum for all lines small changes. First accumulate all tuples in a list (source line is not important) then apply groupby on the sorted list (or grouping won't work properly)nnimport reitertoolsnnwith open(""file.txt"" ""r"") as myFile:nn  r = re.compile(""(w+):(-?d+)"")nn  tuples = n  for l in myFile:n      tuples += r.findall(l)nn  sums = n  for variablevalues in itertools.groupby(sorted(tuples)lambda t: t0):n      sums.append((variablesum(int(x1) for x in values)))n  print(sums)nnnresult:nn('a' 20) ('b' 50) ('c' 20) ('e' 120) ('f' 20) ('g' 50)nn' 'def find(s ch):n    return i for i ltr in enumerate(s) if ltr == chnnmyFile = open(""file.txt"" ""r"")ncontent = myFile.read()ntotalValue = 0nnall_colon_indexes = find(content':')nnfor i in range(0len(content)):n    if contenti==':':n        if contenti-1=='a':  #THIS IS WHERE YOU SPECIFY 'a' or 'b' or 'c' etcn            value=''n            index = i+1n            while True:n                if contentindex.isdigit()==True:n                    value=value+contentindexn                    index=index+1n                else:n                    breakn            _value = int(value)n            totalValue = totalValue + _valuennprint totalValuennnresult:nn20nn' 'Parse the file using regular expressions:nnnw stands for a word characternd stands for a digitn+ specifies that you want to match one or more of the preceding match groupsn? specifies that you want to match zero or one of the preceding match groups (to account for a minus character)nparentheses specify that what is matched inside them should be extracted as a group of characters so we have two groups (one for the letter one for the number)nnnThen use a defaultdict to hold the name -> sum mapping. A defaultdict is like an ordinary dict but when the key is missing it creates it with a default value obtained by calling the callable you supplied when creating it. In this case this is int which returns 0 when called.nnimport renfrom collections import defaultdictnnvalue_pattern = re.compile(""(w+):(-?d+)"")ntotals = defaultdict(int)nnwith open(""file.txt"" ""r"") as myFile:n    for line in myFile.readlines():n        values = value_pattern.findall(line)n        for name value in values:n            totalsname += int(value)nn        print(totals.items())n        totals.clear()nnnThis givesnndict_items(('c' 20) ('a' 15) ('b' 50))ndict_items(('g' 50) ('e' 120))ndict_items(('f' 20) ('a' 5))nnnwhen run on your file.n' 'If I may suggest a somehow more compact solution that sums up every ""key"" in the text file and outputs a dictionary:nnimport renfrom collections import defaultdictnnwith open('a.txt') as f:n    lines = f.read()nntups = re.findall(r'(w+):(d+)' lines)nprint(tups)n# tups is a list of tuples in the form (key value) ie ('a': '5') ...nnsums = defaultdict(int)nfor tup in tups:n    sumstup0 += int(tup1)nnprint(sums)nnnWill output:nn('a' '5') ('a' '5') ('a' '5') ('b' '50') ('c' '10') ('c' '10') ('e' '120') ('g' '50') ('a' '5') ('f' '20')ndefaultdict(<class 'int'> {'f': 20 'b': 50 'e': 120 'a': 20 'c': 20 'g': 50})nnnAnd more specifically:nnprint(sums'a')n>> 20nprint(sums'b')n>> 50nn' 'No intention on stepping on Jean-Francois's toes :-) - I would suggest using Counter for count.nnimport collectionsnwith open(""file.txt"" ""r"") as myFile:nn    r = re.compile(""(w+):(-?d+)"")n    res = collections.Counter()n    for l in myFile:n        for key cnt in r.findall(l):n            res.update({key: int(cnt)})nnnresult: res is now:nnCounter({'e': 120 'b': 50 'g': 50 'c': 20 'f': 20 'a': 20})nnnyou can access it like a dictionary: ex:nnres""a"" => 20nn'",['python-3.x'],"['regex', 'python-2.7']"
40075860,"'Unable to access modified value of imported variable' 'I am new to python and have some problem understanding the scope here.nnI have a python module A with three global variables :nnXYZ = ""val1""nABC = {""k1"" : ""v1"" ""k2"" : ""v2""}nPQR = 1nnclass Cls_A() :n    def sm_fn_A(self) :n        global XYZn        global ABCn        global PQRnn        XYZ = ""val2""n        ABC""k1"" = ""z1""n        ABC""k3"" = ""v3""n        PQR += 1nnnAnd another module B :nnfrom A import Cls_A XYZ ABC PQRnnclass Cls_B():n    def sm_fn_B(self) :n        Cls_A().sm_fn_A()n        print XYZn        print ABCn        print PQRnnCls_B().sm_fn_B()nnnThis gives me the following output :nnval1n{'k3': 'v3' 'k2': 'v2' 'k1': 'z1'}n1nnnSince these are all global variables why do I not get updated values of all the global variables printed ? n' 'ExplanationnnThree global variables are defined in module A in this code:nnXYZ = ""val1""nABC = {""k1"" : ""v1"" ""k2"" : ""v2""}nPQR = 1nnnThen new global variables XYZ ABC PQR are defined in module B in this code:nnfrom A import Cls_A XYZ ABC PQRnnnThis line of code creates new variables just as if the following was written:nnimport AnXYZ = A.XYZnABC = A.ABCnPQR = A.PQRnnnIt is important to understand that A.XYZ and B.XYZ are two variables which point to the same object. They are not the same variable.nnThen a new object is assigned to A.XYZ:nn    XYZ = ""val2""nnnThis modified A.XYZ but did not modify B.XYZ. The two used to be two variables which pointed to the same object but now A.XYZ points to a different object.nnOn the other hand A.ABC is not assiciated with a different object. Instead the object itself is modified. When the object is modified both A.ABC and B.ABC still point to the same object:nn    ABC""k1"" = ""z1""n    ABC""k3"" = ""v3""nnnThe third case is also not a case of object modification but rather reassignment:nn    PQR += 1nnnThe value was incremented. That created a new object and than thet new object was assigned to A.PQR. B.PQR is unchanged. This is equivalent to:nn    PQR = PQR + 1nnnA thing which may not be obvious is that both strings and integers are immutable objects in Python (there is no way to change number to 2 to become 3 - one can only assign a different int object to a variable not change the existing one). Because of that there is actually no way to change A.XYZ in a way that affects B.XYZ.nnThe dictionary could behave the same waynnThe reason why with the dictionary it ""worked"" is that the object was modified. If a new dictioanry was assigned to A.ABC that would not work. E.g.nn    ABC = {'k3': 'v3' 'k2': 'v2' 'k1': 'z1'}nnnNow it would not affect B.ABC because the object in A.ABC was not changed. Another object was assigned to A.ABC instead.nnNot related to modulesnnThe same behaviour can be seen without any modules:nnA_XYZ = ""val1""nA_ABC = {""k1"" : ""v1"" ""k2"" : ""v2""}nA_PQR = 1nnB_XYZ = A_XYZnB_ABC = A_ABCnB_PQR = A_PQRnnA_XYZ = ""val2""nA_ABC""k1"" = ""z1""nA_ABC""k3"" = ""v3""nA_PQR += 1nnprint B_XYZnprint B_ABCnprint B_PQRnnnPrints:nnval1n{'k3': 'v3' 'k2': 'v2' 'k1': 'z1'}n1nnnSolutionnnWell don't keep reference to the temporary object. Use the variable which has the correct value.nnFor example in module B:nnimport Annclass Cls_B():n    def sm_fn_B(self) :n        A.Cls_A().sm_fn_A()n        print A.XYZn        print A.ABCn        print A.PQRnnCls_B().sm_fn_B()nnnNow there is actually no B.XYZ variable which could be wrong. A.XYZ is always used.n'",['python-2.7'],"['python-2.7', 'dictionary']"
40075924,"'How to transform a slice of dataframe into a new data frame' 'I'm new to python and I'm confused sometimes with some operationsnI have a dataframe called ro and I also have filtered this dataframe using a specific column PN 3D for a specific value 921 and I assigned the results into a new data frame called headlamp by using the following code:nn headlamp = roro'PN 3D'==""921""nnnDoes my headlamp is also a dataframe or is just a slice?nThe reason I'm asking this is because I'm getting some strange warnings and results later on my script.nnSuch as I create a new column called word and I assigned to headlampnn headlamp'word' = """"nnnI got the following warning:nn A value is trying to be set on a copy of a slice from a DataFramennnAfter that I used the following script to assign the results to headlamp'word'nn i = 0n for row in headlamp'Comment'.astype(list):n     headlamp'word'i = Counter(str(row).split())n i+=1n print headlamp'word'nnnThe same warning appeared and it has impacted on my results because when I used the headlamp.tail() The last rows of headlamp'word' were empty.nnDoes anyone has an idea what is the problem and how to fix?nnAny help will be highly appreciatedn' 'Use .locnnheadlamp = ro.locro'PN 3D'==""921""nnnnnAs for the rest and your comments... I'm very confused.  But this is my best guessnnsetup nnimport pandas as pdnfrom string import ascii_lowercasennchars = ascii_lowercase + ' 'nprobs = 0.03 * 26 + .22nnheadlamp = pd.DataFrame(np.random.choice(list(chars) (10 100) p=probs)).sum(1).to_frame('comment')nheadlampnnnnnheadlamp'word' = headlamp.comment.str.split().apply(lambda x: pd.value_counts(x).to_dict())nheadlampnnnn'",['pandas'],['pandas']
40076046,"'Passing request (user) to a class based view' 'As someone who is a bit new to class based views I have decided to use them to drive some charts in an application I am working on.nnHowever I would like to make this chart dynamic and would like it to change based on who is seeing it. nnHow can one pass a request (to get the user from) to a class based view?nnBelow is my non-working implementation (working with dummy data but no request being passed):nnView:nnclass LineChartJSONView(BaseLineChartView request):nn    user = request.usernn    def get_labels(self):n        labels = n        items = Item.objects.filter(user = user)n        for i in items:n            labels.add(i.name)n        return labelsnn    def get_data(self):n        prices = n        items = Item.objects.filter(user = user)n        for i in items:n            prices.add(i.price)n        return pricesnnline_chart = TemplateView.as_view(template_name='dashboard/test_chart.html')nnline_chart_json = LineChartJSONView.as_view()nnnURL:nnurl(r'^chart_data/$' LineChartJSONView.as_view() name='line_chart_json')  nurl(r'^chart/$' views.ViewBaseChart name='basic_chart')nnnHTML:nn{% load staticfiles %}n<html>n    <head>n        <title>test chart</title>n    </head>n    <body>n        <canvas id = ""myChart"" width=""500"" height=""200""></canvas>n        <!-- jQuery 2.2.3 -->n        <script src=""{% static 'plugins/jQuery/jquery-2.2.3.min.js' %}""></script>n        <!-- Bootstrap 3.3.6 -->n        <script src=""{% static 'bootstrap/js/bootstrap.min.js' %}""></script>n        <!-- ChartJS 1.0.1 -->n        <script src=""{% static 'plugins/chartjs/Chart.min.js' %}""></script>n        <!-- FastClick -->n        <script src=""{% static 'plugins/fastclick/fastclick.js' %}""></script>n        <!-- AdminLTE App -->n        <script src=""{% static 'dist/js/app.min.js' %}""></script>n        <!-- AdminLTE for demo purposes -->n        <script src=""{% static 'dist/js/demo.js' %}""></script>n        <!-- page script -->n        <script type=""text/javascript"">n            $.get('{% url ""line_chart_json"" %}' function(data)n            {n                var ctx =n                $(""#myChart"").get(0).getContext(""2d"");n                new Chart(ctx).Line(data);n            });n        </script>n    </body>n</html>nnnView (for static above - non classbasedview):nndef ViewBaseChart(request):nn    context = {}n    template = ""dashboard/test_chart.html""nn    return render(requesttemplatecontext) nnnI am not sure I am using the class based view concept correctly here however have found this to be the only way to implement charts thus far.n' ""Your class definition is incorrect. A CBV shouldn't inherit from HttpRequest (and I am not even sure if that's what you mean by request)n. The correct definition isnnclass LineChartJSONView(BaseLineChartView):nnnThis assumes of course that BaseLineChartView has been defined correctly. The following line should also be removed since it defines a global user and secondly because there isn't a request object there!nnuser = request.usernnnNow to get hold of a user instance you need to override the get post methods.nndef get(self request):n    user = request.usernn"" 'You do not need to pass request to class based views it is already there for you if you inherit them from Django's generic views. Generic class based views have methods for handling requests (GET POST etc). nnFor example:nnclass LineChartJSONView(generic.View):n    def get(self request *args **kwargs):n        """"""Handle GET request and return response""""""nn    def post(self request *args **kwargs):n        """"""Handle POST request and return response""""""nnnRead about Django's generic class based views. They are full of ready to use functionalities. Here is the link to the doc Django class based views introductionn'",['django'],['django']
40076092,'Getting Django PROD ready best practice on Heroku' 'I have recently run into some problems flipping off Debug mode on my Heroku instance of Django (filled from the Heroku Django template).nnI have begun diving through the specific Heroku logs. However was wondering if anyone has already made a checklist for things one should do after turning off Debug mode on Heroku (allowed hosts email services etc)?n' 'Not specific to Heroku but I've made the following checklist. You may want to checkout the original list which expands on static files and links the settings to the Django documentation.nnnDatabases. Set DATABASES to your production database.nAllowed hosts. Set ALLOWED_HOSTS to the list of domain names to be served by this Django installation. It should be the same list as that listed in nginxâx80x99s server_name or in apacheâx80x99s ServerName and ServerAlias.nStatic files. Set STATIC_ROOT to the directory where the static files should be stored and STATIC_URL to the URL where they will be found (commonly /static/). Donâx80x99t forget to run collectstatic.nMedia files. Same thing as static files but also make sure that the user Django is running as has permission to write to MEDIA_ROOT.nEmail. Regardless whether your project uses email or not it is very important to set this up so that it can send you information about internal server errors. So you need to use EMAIL_HOST EMAIL_PORT EMAIL_HOST_USER EMAIL_HOST_PASSWORD EMAIL_USE_TLS DEFAULT_FROM_EMAIL and SERVER_EMAIL. Also set up ADMINS and MANAGERS.nMiscellaneous. Other settings you probably need to set different from development are SECRET_KEY LOGGING CACHES. Finally set DEBUG to False.nn',['django'],['django']
40076093,"'Annotate graph using data from Array' 'I have a matplotlib graph that I have created using data from arrays. I want to annotate this graph at certain points. The x axis is populated with dates (14/06/12 15/06/12) etc.. The y axis is price (6500 6624) etc... I would like to annotate at point: for example (xy) (14/06/12 6500). This is my code so far:nnDate = ""14/06/12"" ""15/06/12""nOpen = 6500 6544nHigh = 5434 5234nLow = 5342 5325nClose = 4523 2342nohlc = ni = 0nwhile i < 2:n    Prices = Datei Openi Highi lowi Closein    ohlc.append(Prices)n    i += 1nncandlestick_ohlc(ax ohlc width=0.8 colorup='g' colordown='r')nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))nax.annotate('Here!' xy=(Date1 Price1))nplt.show()nnnThis is the current graph and I want the annotation on it where i put it:nhttp://imgur.com/a/mv945n' 'Here's a quick example using the matplotlib.pyplot text command to add text to a plot at a specified location:nnimport numpy as npnimport matplotlib.pyplot as pltnnplt.figure()nx = np.arange(-5 5 0.1)nplt.plot(x np.cos(x))nplt.text(x=-4 y=0.5 s=""Cosine"" fontsize=20)nplt.show()nnnThere are lots of additional formatting options available for text (alignment font etc.).  Full documentation is available here:nnhttp://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.textn'",['matplotlib'],['matplotlib']
40076108,"'Removing duplicate mpatches from a list' ""I startet to work with buttons in my plots (from matplotlib.widgets import Button). By pressing the buttons different plots will show up. For that reason my legends do change. I handle this by putting the mpatches in a list:nnred_patch = mpatches.Patch(color='red' label='Numerical average')nhandlelist.append(red_patch)nax.legend(handles=handlelist numpoints=1)nnnNow if I press the same button twice the red_patch will also be displayed twice. Because of that I want to delete duplicates but this won't work. So far I tried:nnlist(set(handelist))nnnand also:nnif red_patch not in handelist:n    handlelist.append(red_patch)nnnBut both won't work and I don't understand why. Hope you have an idea :) n"" ""The problem is that:nnred_patch = mpatches.Patch(color='red' label='Numerical average')nnncreates an instance of red_patch every time. The __eq__ operator seems to be unimplemented for this particular type so the set only compares references of the object which are not equal.nnI would suggest the following code instead:nn# declare as ordered dict (so order of creation matters) not listnimport collectionsnhandlelist = collections.OrderedDict()nncolor = 'red'nlabel = 'Numerical average'nnif (colorlabel) not in handlelist:n    handlelist(colorlabel) = mpatches.Patch(color=color label=label)nn# pass the values of the dict as list (legend expects a list)nax.legend(handles=list(handlelist.values()) numpoints=1)nnnThe key of your dictionary is the couple (colorlabel) and when you call the legend method you only get one red_patch because if the entry already exists no extra Patch will be created.nnOf course you have to do the same in other parts of your code where you update handlelist. A shared method would be handy:nndef create_patch(colorlabel):n   if (colorlabel) not in handlelist:n       handlelist(colorlabel) = mpatches.Patch(color=color label=label)nnnEDIT: if you have only 1 patch total you could do even simpler:nnp = mpatches.Patch(color='red' label='Numerical average')nax.legend(p numpoints=1)nn""",['matplotlib'],['matplotlib']
40076147,"'pygrametl Dimension abstraction' 'Can someone with experience with pygrametl package in python help me understand below errornnSample code from pygrametl documentation :nnproductDimension = Dimension(n    name='product'n    key='productid'n    attributes='name' 'category' 'price'n    lookupatts='name')nnnCode that I have written : nnartist_dim=Dimension(n    name='Artist_dim'n    key='row_id'n    attributes='row_id''Artist_name''Artist_type''Country''ETL_BATCH_ID'n    lookupatts='Artist_name'n    ) nnnError:nn  Traceback (most recent call last):n      File ""artist_petl.py"" line 40 in <module>n        attributes='row_id''Artist_name''Artist_type''Country''ETL_BATCH_ID'n      File ""C:Anaconda3libsite-packagespygrametltables.py"" line 189 in __init__n        (self.quote(key) name))n      File ""C:Anaconda3libsite-packagespygrametl__init__.py"" line 663 in executen        self.__cursor.execute(stmt arguments)n    TypeError: expecting a dictionary sequence or keyword argsnn' nan","['python-2.7', 'python-3.x']","['dictionary', 'python-2.7']"
40076176,"'How to remove data from DataFrame permanently' 'After reading CSV data file with:nnimport pandas as pd  ndf = pd.read_csv('data.csv')nprint df.shapennnI get DataFrame 99 rows (indexes) long:nn(99 2)nnnTo cleanup DataFrame I go ahead and apply dropna() method which reduces it to 33 rows:nndf = df.dropna()nprint df.shapennnwhich prints:nn(33 2)nnnNow when I iterate the columns it prints out all 99 rows like they weren't dropped:nnfor index value in df'column1'.iteritems():n    print indexnnnwhich gives me this:nn0n1n2n.n.n.n97n98n99nnnIt appears the dropna() simply made the data ""hidden"". That hidden data returns back when I iterate DataFrame. How to assure the dropped data is removed from DataFrame instead just getting hidden?n' 'You're being confused by the fact that the row labels have been preserved so the last row label is still 99.nnExample:nnIn 2:ndf = pd.DataFrame({'a':01np.NaN np.NaN 4})ndfnnOut2:n    an0   0n1   1n2 NaNn3 NaNn4   4nnnAfter calling dropna the index row labels are preserved:nnIn 3:ndf = df.dropna()ndfnnOut3:n   an0  0n1  1n4  4nnnIf you want to reset so that they are contiguous then call reset_index(drop=True) to assign a new index:nnIn 4:ndf = df.reset_index(drop=True)ndfnnOut4:n   an0  0n1  1n2  4nn'",['pandas'],['pandas']
40076241,"'How to calculate counts and frequencies for pairs in list of lists?' 'Bases refers to ATG and Cnnsample = 'CGG''ATT''GCGC''TAAA'nn# Note on fragility of data: Each element can only be made up only 2 of the 4 bases.  n# 'CGG' ==> Only C and G'ATT' ==> Only A and T'GCGC'==> Only C and G'TAAA' ==> Only T and An# Elements like ""ATGG"" are not present in the data as the have more than 3 different types of basesnnnConsider the first pair : 'CGG''ATT'nnnCalculate frequency of each base in the pairs separately:nnCGG => (C = 1/3 G = 2/3)n ATT => (A = 1/3 T = 2/3)nCalculate frequency of occurrence of combination of bases in the pairs. Here the combinations are 'CA' and 'GT' (Notice order of the base matters. It is not 'CA''AC''GT' and 'TG'. Just only 'CA' and 'GT'). nnPairs => (CA = 1/3 GT = 2/3) nCalculate float(a) = (freq of Pairs) - ((freq of C in CGG) * (freq of A in ATT))nnEg in CA pairs float (a) = (freq of CA pairs) - ((freq of C in CGG) * (freq of A in ATT))nnOutput a = (1/3) - ((1/3) * (1/3)) = 0.222222nnnCalculating ""a"" for any one combination (either CA pair or GT pair)nnNOTE: If the pair is AAAC and CCCA the freq of C would it be 1/4 i.e. it is the frequency of the base over one of the pairsnnnCalculate bn float (b) = (float(a)^2)/ (freq of C in CGG) * (freq G in CGG) * (freq A in ATT) * (freq of T in ATT)nnOutput b = 1nnnnDo this for the entire listnn   Final Output a = 0.2222 - 0.125n                b = 1 0.3333nnnThis code has been adapted from this answer. Please note that there are subtle differences in the two questions and they are NOT the same in the approach to the problem.  nnHowever I am unable to get this code to run. I get the following error:n   for pair count in i:nTypeError: 'int' object is not iterablenn#Count individual bases.nnsample4 = 'CGG''ATT''GCGC''TAAA'nbase_counter = Counter()nfor i in enumerate(sample4):n    for pair count in i:n        base_counterpair0 += countn        base_counterpair1 += countn        print base_counternn# Get the total for each base.ntotal_count = sum(base_counter.values())nn# Convert counts to frequencies.nbase_freq = {}nfor base count in base_counter.items():n    base_freqbase = count / total_countn# Not sure how to write a code to count the number of pairs (Step 2)n# Let's say the counts have been stored in pair_countsnn# Examine a pair from the two unique pairs to calculate float_a.nfor i in enumerate(sample4):n    float(a) = (pair_countpair / sum(pair_count.values())) - (base_freqpair0 * base_freqpair1)nn# Step 7!nfor i in enumerate(sample4):n    float_b = float_a / float(base_freq00 * base_freq01 * base_freq10 * base_freq11)nn' ""You are not really using Counter any different than a plain dict. Try something like the following approach:nn>>> sample = 'CGG''ATT''GCGC''TAAA'n>>> from collections import Countern>>> base_counts = Counter(base) for base in sub for sub in samplen>>> base_countsnCounter({'G': 2 'C': 1}) Counter({'T': 2 'A': 1}) Counter({'G': 2 'C': 2}) Counter({'A': 3 'T': 1})nnnNow you can continue with a functional approach using nested comprehensions to transform your data*:nn>>> base_freqs = {k_v0:k_v1/len(basesi) for ik_v in enumerate(count.items())} for count in counts n...               for counts bases in zip(base_counts sample)n>>> n>>> base_freqsn{'G': 0.6666666666666666 'C': 0.3333333333333333} {'A': 0.3333333333333333 'T': 0.6666666666666666} {'G': 0.5 'C': 0.5} {'A': 0.75 'T': 0.25}n>>> nnn*Note some people do not like big nested comprehensions like that. I think it's fine as long as you are sticking to functional constructs and not mutating data structures inside your comprehensions. I actually find it very expressive. Others disagree vehemently. You can always unfold that code into nested for-loops.nnAnyway you can then work the same thing with the pairs. First:nn>>> pairs = list(zip(*bases)) for bases in samplen>>> pairsn('C' 'A') ('G' 'T') ('G' 'T') ('G' 'T') ('C' 'A') ('G' 'A') ('C' 'A')n>>> pair_counts = Counter(base_pair) for base_pair in pairsn>>> pair_countsnCounter({('G' 'T'): 2 ('C' 'A'): 1}) Counter({('C' 'A'): 2 ('G' 'T'): 1 ('G' 'A'): 1})n>>> nnnNow here it is easier to not use comprehensions so we don't have to calculate total more than once:nn>>> pair_freq = n>>> for count in pair_counts:n...   total = sum(count.values())n...   pair_freq.append({k:c/total for kc in count.items()})n... n>>> pair_freqn{('C' 'A'): 0.3333333333333333 ('G' 'T'): 0.6666666666666666} {('G' 'T'): 0.25 ('C' 'A'): 0.5 ('G' 'A'): 0.25}n>>> nn""","['list', 'dictionary']","['list', 'dictionary', 'python-3.x', 'python-2.7']"
40076254,"'DRF auth_token: ""non_field_errors"":  ""Unable to log in with provided credentials.""' 'Both JWT packages written for Django gave me issues with poor documentation so I try DRF-auth_token package. This is a good example I followed Django Rest Framework Token Authentication. You should in theory be able to go to nnlocalhost:8000/api-token-auth/nnurls.py:nnfrom django.conf.urls import url includenfrom django.contrib import adminnfrom django.contrib.auth.models import Usernfrom rest_framework.authtoken import viewsnnurlpatterns = n    url(r'^admin/' admin.site.urls)n    url(r'^api/' include('api.urls' namespace='api'))n    url(r'^orders/' include('orders.urls' namespace='orders'))n    url(r'^api-token-auth/' views.obtain_auth_token name='auth-token')nnnnnGetting a token for users is not working so I have rewritten it myself to make it work:nn@api_view('POST')ndef customer_login(request):n    """"""n    Try to login a customer (food orderer)n    """"""n    data = request.datann    try:n        username = data'username'n        password = data'password'n    except:n        return Response(status=status.HTTP_400_BAD_REQUEST)nn    try:n        user = User.objects.get(username=username password=password)n    except:n        return Response(status=status.HTTP_401_UNAUTHORIZED)nn    try:n        user_token = user.auth_token.keyn    except:n        user_token = Token.objects.create(user=user)nn    data = {'token': user_token}n    return Response(data=data status=status.HTTP_200_OK)nnnMy version works:nnhttp://localhost:8000/api/login/customer-login/n{""username"": ""thisguy@example.com"" ""password"": ""wombat""}n-->n{n  ""token"": ""292192b101153b7ced74dd52deb6b3df22ef2c74""n}nnnThe DRF auth_token does not work:nnhttp://localhost:8000/api-token-auth/n{""username"": ""thisguy@example.com"" ""password"": ""wombat""}n-->n{n  ""non_field_errors"": n    ""Unable to log in with provided credentials.""n  n}nnnsettings.pynnINSTALLED_APPS = n    'django.contrib.admin'n    'django.contrib.auth'n    'django.contrib.contenttypes'n    'django.contrib.sessions'n    'django.contrib.messages'n    'django.contrib.staticfiles'nn    # third party:n    'django_extensions'n    'rest_framework'n    'rest_framework.authtoken'nnnnREST_FRAMEWORK = {n    'DEFAULT_PERMISSION_CLASSES': (n        'rest_framework.permissions.IsAuthenticated'n    )n    'DEFAULT_AUTHENTICATION_CLASSES': (n        'rest_framework.authentication.TokenAuthentication'n    )n}nnnIt seems set up correctly. Every user in my DB has a token. Each user is is_authenticated and is_active in DB. Super users can get their token:nnlocalhost:8000/api-token-auth/n{""username"": ""mysuperuser"" ""password"": ""superuserpassword""}n-->n{n  ""token"": ""9297ff1f44dbc6caea67bea534f6f7590d2161b0""n}nnnfor some reason only super user can get a token:nnlocalhost:8000/api-token-auth/n{""username"": ""regularguy"" ""password"": ""password""}n-->n{n  ""non_field_errors"": n    ""Unable to log in with provided credentials.""n  n}nnnWhy can't my users log in and get their token? Thank youn' 'I went ahead and did this from the drf token auth docs and didn't run into any problems with superusers staffusers or normal users. Maybe take a look at my code and see if you can find some difference. https://github.com/awwester/so40076254drftokennnAlso try following the steps of the official docs instead of that SO answer and see if that fixes the problem - it's possible something changed.nnHere were the general steps I took:nnninstall django drfnput 'rest_framework' and 'rest_framework.authtoken' in INSTALLED_APPSnadd 'TokenAuthentication' in my rest_framework settingsnrun migratencreate tokens for users (I just did this in urls.py)ncreate the url for tokennPOST http://localhost:8000/token/ {""username"": ""..."" ""password"": ""...""}nnnIf you have the code public anywhere I'd be glad to take a further look and see what I find.n'",['django'],['django']
40076280,"'How is numpy pad implemented (for constant value)' ""I'm trying to implement the numpy pad function in theano for the constant mode. How is it implemented in numpy? Assume that pad values are just 0.nnGiven an array nna = np.array(12345678)n# pad values are just 0 as indicated by constant_values=0nnp.pad(a pad_width=(12)(34) mode='constant' constant_values=0)nnnwould returnnnarray(0 0 0 0 0 0 0 0 0 0 0n       0 0 0 1 2 3 4 0 0 0 0n       0 0 0 5 6 7 8 0 0 0 0n       0 0 0 0 0 0 0 0 0 0 0n       0 0 0 0 0 0 0 0 0 0 0)nnnNow if I know the number of dimensions of a beforehand I can just implement this by creating a new array of the new dimensions filled the pad value and fill in the corresponding elements in this array. But what if I don't know the dimensions of the input array? While I can still infer the dimensions of the output array from the input array I have no way of indexing it without knowing the number of dimensions in it. Or am I missing something?nnThat is if I know that the input dimension is say 3 then I could do:nnzeros_arraypad_width00:-pad_width01 pad_width10:-pad_width11 pad_width20:-pad_width21 = annnwhere zeros array is the new array created with the output dimensions.nnBut if I don't know the ndim before hand I cannot do this.n"" ""My instinct is to do:nndef ...(arg pad):n    out_shape = <arg.shape + padding>  # math on tuples/listsn    idx = slice(x1 x2) for ...   # again math on shape and paddingn    res = np.zeros(out_shape dtype=arg.dtype)n    residx = arg     # may need tuple(idx)n    return resnnnIn other words make the target array and copy the input with the appropriate  indexing tuple.  It will require some math and maybe iteration to construct the required shape and slicing but that should be straight forward if tedious.nnHowever it appears that np.pad iterates on the axes (if I've identified the correct alternative:nn   newmat = narray.copy()n   for axis ((pad_before pad_after) (before_val after_val)) n            in enumerate(zip(pad_width kwargs'constant_values')):n        newmat = _prepend_const(newmat pad_before before_val axis)n        newmat = _append_const(newmat pad_after after_val axis)nnnwhere _prepend_const is:nnnp.concatenate((np.zeros(padshape dtype=arr.dtype) arr) axis=axis)nnn(and append would be similar).  So it is adding each pre and post piece separately for each dimension.  Conceptually that is simple even if it might not be the fastest.nnIn 601: np.lib.arraypad._prepend_const(np.ones((35))300)nOut601: narray( 0.  0.  0.  0.  0.n        0.  0.  0.  0.  0.n        0.  0.  0.  0.  0.n        1.  1.  1.  1.  1.n        1.  1.  1.  1.  1.n        1.  1.  1.  1.  1.)nnIn 604: arg=np.ones((35)int)nIn 605: for i in range(2):n     ...:     arg=np.lib.arraypad._prepend_const(arg10i)n     ...:     arg=np.lib.arraypad._append_const(arg22i)n     ...:     nIn 606: argnOut606: narray(0 0 0 0 0 0 2 2n       0 1 1 1 1 1 2 2n       0 1 1 1 1 1 2 2n       0 1 1 1 1 1 2 2n       0 2 2 2 2 2 2 2n       0 2 2 2 2 2 2 2)nn""",['numpy'],['numpy']
40076368,"'matplotlib/pyplot not plotting data from specific .txt file' 'I have data saved via numpy's savetxt function and am extracting it to plot. When I plot it the script executes without errors but does not show the curves--only empty windows. This is strange because:nnnThe same script makes a fine plot when I import .txt data from another file (also saved using savetxt).nIf I create data points inside the script e.g. with arange it plots. nThe .txt data is getting loaded--I have printed it to the screen.nI checked my backend and it is TkAgg which the internet agrees it's supposed to be.  nnnMy code isnn # this script makes the plots of the eigenvalue distributions for the AAS 17-225 papernn# import python modulesnimport numpy as npnimport matplotlib as mplnimport matplotlib.pyplot as pltnfrom matplotlib.ticker import MaxNLocatornn# set plot options nmpl.rcParams'xtick.major.size' = 7nmpl.rcParams'xtick.major.width' = 3.0nmpl.rcParams'ytick.major.size' = 7nmpl.rcParams'ytick.major.width' = 3.0nmpl.rcParams'axes.linewidth' = 3.5nnplt.rc('text'usetex=True)nmpl.rcParams'text.latex.preamble'=r""usepackage{amsmath}""nplt.rc('font'family='serif')nplt.rc('axes'labelsize=24)nplt.rc('xtick'labelsize=24)nplt.rc('ytick'labelsize=24)nplt.rc('font'weight='bold')nplt.rc('axes'titlesize=20)nn# plot method argumentsnlw = 2 # linewidthnleft_adj = 0.055 # left adjustment nright_adj = 0.985 # left adjustment ntop_adj = 0.975 # left adjustment nbottom_adj = 0.075 # left adjustment nwspace = 0.205 # horizontal space between plotsnhspace = 0.2 # verticle space between plotsnn_suplot_rows = 2 # number of subplot rowsnn_suplot_columns = 3 # number of subplot columnsnn# load datandataDir ='/mnt/E0BA55A7BA557B4C/research/independent/recursivequats/paperCode/'ndf1 = dataDir+'lamda_0p1_0p1.txt'ndf2 = dataDir+'lamda_0.1_0.5.txt'ndf3 = dataDir+'lamda_0.1_1.0.txt'ndf4 = dataDir+'lamda_0.5_0.5.txt'ndf5 = dataDir+'lamda_0.5_1.0.txt'ndf6 = dataDir+'lamda_1.0_1.0.txt'nnprofile1 = np.loadtxt(df1)nprofile2 = np.loadtxt(df2)nprofile3 = np.loadtxt(df3)nprofile4 = np.loadtxt(df4)nprofile5 = np.loadtxt(df5)nprofile6 = np.loadtxt(df6)nnfig = plt.figure()nnax1 = fig.add_subplot(n_suplot_rowsn_suplot_columns1)np1 = ax1.plot(profile1:1profile1:0linewidth=lw)nnax2 = fig.add_subplot(n_suplot_rowsn_suplot_columns2)np1 = ax2.plot(profile2:1profile2:0linewidth=lw)nnax3 = fig.add_subplot(n_suplot_rowsn_suplot_columns3)np1 = ax3.plot(profile3:1profile3:0linewidth=lw)nnax4 = fig.add_subplot(n_suplot_rowsn_suplot_columns4)np1 = ax4.plot(profile4:1profile4:0linewidth=lw)nnax5 = fig.add_subplot(n_suplot_rowsn_suplot_columns5)np1 = ax5.plot(profile5:1profile5:0linewidth=lw)nnax6 = fig.add_subplot(n_suplot_rowsn_suplot_columns6)np1 = ax5.plot(profile6:1profile6:0linewidth=lw)nnnplt.subplots_adjust(left=left_adjright=right_adjtop=top_adjbottom=bottom_adjwspace=wspacehspace=hspace)nplt.show()nn' ""well a bit more digging and the problem has been identified. The script is plotting but the zoom on the plots is so poor that they are obscured by the thick lines on the border. So the problem was a user error. nnThis is why engineers shouldn't try to be artists... n""","['numpy', 'matplotlib']","['matplotlib', 'numpy']"
40076534,"'How to drop duplicate from DataFrame taking into account value of another column' ""When I drop John as duplicate specifying 'name' as the column name: nnimport pandas as pd   ndata = {'name':'Bill''Steve''John''John''John' 'age':2128223029}ndf = pd.DataFrame(data)ndf = df.drop_duplicates('name')nnnpandas drops all matching entities leaving the left-most:nn   age   namen0   21   Billn1   28  Steven2   22   JohnnnnInstead I would like to keep the row where John's age is the highest (in this example it is the age 30. How to achieve this?n"" ""Try this:nnIn 75: dfnOut75:n   age   namen0   21   Billn1   28  Steven2   22   Johnn3   30   Johnn4   29   JohnnnIn 76: df.sort_values('age').drop_duplicates('name' keep='last')nOut76:n   age   namen0   21   Billn1   28  Steven3   30   Johnnnnor this depending on your goals:nnIn 77: df.drop_duplicates('name' keep='last')nOut77:n   age   namen0   21   Billn1   28  Steven4   29   Johnnn""",['pandas'],['pandas']
40076616,"'iPython magic for Zipline cannot find data bundle' ""I have a Python 2.7 script that runs Zipline fine on the command prompt using --bundle=myBundle to load the custom data bundle myBundle which I have registered using extension.py.nnzipline run -f myAlgo.py --bundle=myBundle --start 2016-6-1 --end 2016-7-1 --data-frequency=minutennnProblem: However when I try to use the %zipline IPython magic to run the algorithm the bundle argument --bundle seems to have difficulty finding myBundle.nn%zipline --bundle=myBundle--start 2016-6-1 --end 2016-7-1 --data-frequency=minutennnRunning this will give the errornnUnknownBundle: No bundle registered with the name u'myBundle'nnnDo we have to register the bundle differently when using IPython notebook?n"" nan",['python-2.7'],['python-2.7']
40076700,"'Pycharm import matplotlib error: related to ft2font.so' 'I used Pycharm edu for mac (10.10.5) and I have python 2.7. Whenever I want to import matplotlib.pylab as plt. The error below comes out. Anyone knows how to fix it? It's really annoying...nnnnTraceback (most recent call last):n  File ""/Users/xiaolihe/Documents/ai_project1_phase2/main_test_integrated.py"" line 2 in <module>n    from a_star_lib import Worldn  File ""/Users/Documents/ai_project1_phase2/a_star_lib.py"" line 4 in <module>n    import matplotlib.pylab as pltn  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/pylab.py"" line 231 in <module>n    import matplotlib.financen  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/finance.py"" line 27 in <module>n    from matplotlib.collections import LineCollection PolyCollectionn  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/collections.py"" line 27 in <module>n    import matplotlib.backend_bases as backend_basesn  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/backend_bases.py"" line 62 in <module>n    import matplotlib.textpath as textpathn  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/textpath.py"" line 15 in <module>n    import matplotlib.font_manager as font_managern  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/font_manager.py"" line 58 in <module>n    from matplotlib import ft2fontnImportError: dlopen(/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/ft2font.so 2): Symbol not found: _FT_Get_PS_Font_Infon  Referenced from: /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/ft2font.son  Expected in: flat namespacen in /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/ft2font.sonnProcess finished with exit code 1nn' nan",['matplotlib'],"['matplotlib', 'python-2.7']"
40076806,"""Pandas merge not keeping 'on' column"" 'I'm trying to merge two dataframes in pandas on a common column name (orderid).  The resulting dataframe (the merged dataframe) is dropping the orderid from the 2nd data frame.  Per the documentation the 'on' column should be kept unless you explicitly tell it not to.  nnimport pandas as pd    ndf = pd.DataFrame(1'a' 2 'b' 3 'c' columns='orderid' 'ordervalue')ndf'orderid' = df'orderid'.astype(str)ndf2 = pd.DataFrame(1200 2 300 3 400 4500 columns='orderid' 'ordervalue')ndf2'orderid' = df2'orderid'.astype(str)npd.merge(df df2 on='orderid' how='outer' copy=True suffixes=('_left' '_right'))nnnWhich outputs this:nn|      |orderid | ordervalue_left | ordervalue_right |n|------|--------|-----------------|------------------|n| 0    | 1      | a               | 200              |n| 1    | 2      | b               | 300              |n| 2    | 3      | c               | 400              |n| 3    | 4      |                 | 500              |nnnWhat I am trying to create is this:nn|      | orderid_left | ordervalue_left | orderid_left | ordervalue_right |n|------|--------------|-----------------|--------------|------------------|n| 0    | 1            | a               | 1            | 200              |n| 1    | 2            | b               | 2            | 300              |n| 2    | 3            | c               | 3            | 400              |n| 3    | NaN          | NaN             | 4            | 500              |nnnHow should I write this?n' ""Rename the orderid columns so that df has a column named orderid_leftnand df2 has a column named orderid_right:nnimport pandas as pd    ndf = pd.DataFrame(1'a' 2 'b' 3 'c' columns='orderid' 'ordervalue')ndf'orderid' = df'orderid'.astype(str)ndf2 = pd.DataFrame(1200 2 300 3 400 4500 columns='orderid' 'ordervalue')ndf2'orderid' = df2'orderid'.astype(str)nndf = df.rename(columns={'orderid':'orderid_left'})ndf2 = df2.rename(columns={'orderid':'orderid_right'})nresult = pd.merge(df df2 left_on='orderid_left' right_on='orderid_right' n                  how='outer' suffixes=('_left' '_right'))nprint(result)nnnyieldsnn  orderid_left ordervalue_left orderid_right  ordervalue_rightn0            1               a             1               200n1            2               b             2               300n2            3               c             3               400n3          NaN             NaN             4               500nn""",['pandas'],['pandas']
40076861,"'How to merge two DataFrames into single matching the column values' ""Two DataFrames have matching values stored in their corresponding 'names' and 'flights' columns.nWhile the first DataFrame stores the distances the other stores the dates:nnimport pandas as pd   nndistances = {'names': 'A' 'B''C' 'distances':100 200 300}ndates = {'flights': 'C' 'B' 'A' 'dates':'1/1/16' '1/2/16' '1/3/16'}nndistancesDF = pd.DataFrame(distances)ndatesDF = pd.DataFrame(dates)nnndistancesDF:nn   distances    namesn0        100        An1        200        Bn2        300        CnnndatesDF:nn    dates  flightsn0  1/1/16        An1  1/2/16        Bn2  1/3/16        CnnnI would like to merge them into single Dataframe in a such a way that the matching entities are synced with the corresponding distances and dates. So the resulted DataFame would look like this:nnresultDF:nn   distances    names     dates n0        100        A    1/1/16 n1        200        B    1/2/16 n2        300        C    1/3/16nnnWhat would be the way of accomplishing it?n"" 'There is nothing that ties these dataframes together other than the positional index.  You can accomplish your desired example output with pd.concatnnpd.concat(distancesDF datesDF.dates axis=1)nnnnnnnTo address the edit and @kartik's commentnnif we create the dfs to match what's displayed.nndistances = {'names': 'A' 'B''C' 'distances':100 200 300}ndates = {'flights': 'A' 'B' 'C' 'dates':'1/1/16' '1/2/16' '1/3/16'}nndistancesDF = pd.DataFrame(distances)ndatesDF = pd.DataFrame(dates)nnnthen the following two options produce the same and probably desired result.nnmergenn distancesDF.merge(datesDF left_on='names' right_on='flights')'distances' 'names' 'dates'nnnjoinnndistancesDF.join(datesDF.set_index('flights') on='names')nnnboth producennn'",['pandas'],['pandas']
40076903,"'Python regex to replace a double newline delimited paragraph containing a string' ""Define a paragraph as a multi-line string delimited on both side with double new lines ('nn'). if there exist a paragraph which contains a certain string ('BAD') i want to replace that paragraph (i.e. any text containing BAD up to the closest preceding and following double newlines) with some other token ('GOOD'). this should be with a python 3 regex.nni have text such as:nndfsdfnnsdfdfnnnnblablablannblaBADnnblannnndsfsdfnnsdfdfnnnshould be:nndfsdfnnsdfdfnnnnGOODnnnndsfsdfnnsdfdfnn"" 'Here you are:nn/nn(?:^n|n(?!n))*BAD(?:^n|n(?!n))*/gnnnOK to break it down a little (because it's nasty looking):nnnnn matches two literal line breaks.n(?:^n|n(?!n))* is a non-capturing group that matches either a single non-line break character or a line break character that isn't followed by another. We repeat the entire group 0 or more times (in case BAD appears at the beginning of the paragraph).nBAD will match the literal text you want. Simple enough.nThen we use the same construction as above to match the rest of the paragraph.nnnThen you just replace it with nnGOOD and you're off to the races.nnDemo on Regex101n' ""Firstly you're mixing actual newlines and 'n' characters in your example I assume that you only meant either. Secondly let me challenge your assumption that you need regex for this:nninp = '''dfsdfnsdadfnnblablablanblaBADnblanndsfsdfnsdfdf'''nnreplaced = 'nn'.join('GOOD' if 'BAD' in k else k for k in inp.split('nn'))nnnThe result isnnprint(replaced)n'dfsdfnsdadfnnGOODnndsfsdfnsdfdf'nn""",['regex'],['regex']
40077188,"'Pandas - Data Frame - Reshaping Values in Data Frame' ""I am new to Pandas and have a data frame with a team's score in 2 separate columns. This is what I have.nnGame_ID Teams   Scorenn1    Team A  95n1    Team B  85n2    Team C  90n2    Team D  72nnnThis is where I would like to get to and then ideally to.nn1   Team A  95 Team B  94n2   Team C  90 Team B  72 nn"" 'You can try something as follows: Create a row_id within each group by the Game_ID and then unstack by the row_id which will transform your data to wide format:nnimport pandas as pdndf'row_id' = df.groupby('Game_ID').Game_ID.transform(lambda g: pd.Series(range(g.size)))ndf.set_index('row_id' 'Game_ID').unstack(level=0).sortlevel(level = 1 axis = 1)nnnnnUpdate:nnIf the row_id is preferred to be dropped you can drop the level from the columns:nndf1 = df.set_index('row_id' 'Game_ID').unstack(level=0).sortlevel(level = 1 axis = 1)   ndf1.columns = df1.columns.droplevel(level = 1)ndf1nnnn' 'Knowing that games always involve exactly 2 teams we can manipulate the underlying numpy array.nnpd.DataFrame(df.values: 1:.reshape(-1 4)n             pd.Index(df.values::2 0 name='Game_ID')n             'Team' 'Score' * 2)nnnn'",['pandas'],['pandas']
40077209,"'How to extract and divide values from dictionary with another in Python?' 'sample = 'CGG''ATT''GCGC''TAAA'nn#Frequencies of each base in the pairnd1 = {'G': 0.66 'C': 0.33} {'A': 0.33 'T': 0.66} {'G': 0.5 'C': 0.5} {'A': 0.75 'T': 0.25}nn#Frequencies of each pair occurring togethernnd2 = {('C' 'A'): 0.33 ('G' 'T'): 0.66} {('G' 'T'): 0.25 ('C' 'A'): 0.5 ('G' 'A'): 0.25}nnnThe Problem:nnConsider the first pair : 'CGG''ATT'nnHow to calculate a where a is :nnfloat(a) = (freq of pairs) - ((freq of C in CGG) * (freq of A in ATT))nneg. in CA pairs float (a) = (freq of CA pairs) - ((freq of C in CGG) * (freq of A in ATT))nnOutput a = (0.33) - ((0.33) * (0.33)) = 0.222222nnnCalculating ""a"" for any one combination (either CA pair or GT pair)nnFinal Output for sample : a = 0.2222 - 0.125nnnHow to calculate b where b is :nnfloat (b) = (float(a)^2)/ (freq of C in CGG) * (freq G in CGG) * (freq A in ATT) * (freq of T in ATT)nnOutput b = 1nnnDo this for the entire listnnFinal Output for sample : b = 1 0.3333nnnI do not know how to extract the required values from d1 and d2 and perform the mathematical operations. nnI tried to write the following code for value of annfloat a = {k: float(d1k0) - d2k0 * d2k1for k in d1.viewkeys() & d2.viewkeys()}nnnBut it does not work. Also I prefer a for loop instead of comprehensionsnnMy attempt to write (a pretty flawed) for-loop for the above:nnfloat_a = nfor pairi in enumerate(d2):n    for basej in enumerate(d1):n        float (a) = pairi0 - basej * basej+1n        float_a.append(a)nnfloat_b = n  for floata in enumerate(float_a):n    for basej in enumerate(d1):n        float (b) = (float(a) * float(a)) - (basej *    basej+1*basej+2*basej+3)n        float_b.append(b)nn' 'Usually when there is a tricky problem like this with multiple formulas and intermediate steps I like to modularize it by splitting the work into several functions. Here is the resulting commented code which handles the cases in the original question and in the comments:nnfrom collections import Counternndef get_base_freq(seq):n    """"""n    Returns the normalized frequency of each base in a given sequence as a dictionary.n    A dictionary comprehension converts the Counter object into a ""normalized"" dictionary.n    """"""n    seq_len = len(seq)n    base_counts = Counter(seq)n    base_freqs = {base: float(count)/seq_len for base count in base_counts.items()}n    return base_freqsnndef get_pair_freq(seq1 seq2):n    """"""n    Uses zip to merge two sequence strings together.n    Then performs same counting and normalization as in get_base_freq.n    """"""n    seq_len = len(seq1)n    pair_counts = Counter(zip(seq1 seq2))n    pair_freqs = {pair: float(count)/seq_len for pair count in pair_counts.items()}n    return pair_freqsnndef calc_a(d1 d2):n    """"""n    Arbitrarily takes the first pair in d2 and calculates the a-value from it.n    """"""n    first_pair pair_freq = d2.items()0n    base1 base2 = first_pairn    a = pair_freq - (d10base1*d11base2)n    return anndef calc_b(a d1):n    """"""n    For this calculation we need to use all of the values from d1 and multiply them together.n    This is done by merging the two sequence half-results together and multiplying in a for loop.n    """"""n    denom_ACGT = d10.values() + d11.values()n    denom = 1n    for val in denom_ACGT:n        denom *= valn    b = a*a/float(denom)n    return bnnif __name__ == ""__main__"":n    sample = 'CGG''ATT' 'GCGC''TAAA' 'ACAA''CAAC'n    b_result = n    for seq_pair in sample:n        d1 = get_base_freq(seq) for seq in seq_pairn        d2 = get_pair_freq(*seq_pair)n        a = calc_a(d1 d2)n        b = calc_b(a d1)n        b_result.append(b)n    print b_resultnnnLet me know if anything needs to be cleared up or if it fails for a case which I have not considered!n'","['list', 'dictionary']",['dictionary']
40077214,"'How do I distinguish two emails from one string in python using regex' 'I have a string (from a page source) that contains two emails:nn<span class=""inlinemeta"">From:                               D Hui &lt;dhui@tcmclinic.com&gt;nSent:                                 Friday June 18 2010 12:57 PMn</span>n<span class=""inlinemeta"">To:                                    'pcox@medcoc.org'nSubject:                               New med approved?nnnWhat I need is to pull out the four attributes: SentFrom SentTo SentOn Subject.nnWith the help on stackoverflow I am able to get SentOn I now am stuck on how to distinguish the two emails.nConsidering the actual raw text to be parsed could differ from one to one with minors like From may include a prefix (in this case it's D Hui) or may not (like the second email) and To could also be like that so I really need a bit flexible on the solution.nnThank you very much in advance I just started python a week ago so please pardon me if the question is too simple or too easy to find a solution online.nnAt the meantime I surely will try myself to see if I can figure it out.n' nan",['regex'],['python-2.7']
40077284,"'Trying to rewrite variables' '    print(""Please enter some integers to average. Enter 0 to indicate you are done."")nn#part (a) -- what are the initial values for these variables?n#incompletendone = 0nmySum = 0ncount =  0   nwhile not done:n    valid = False #don't yet have a valid inputn    while not valid: #this loop keeps attempting to get input until the user enters an integern        try:n            num = int(input())n            valid = True #now the input is valid and can use itn        except ValueError:n            print(""Input must be an integer."")  n    if num == 0:n        breakn        mySum = sum(num)n        count = len(num)n        #part (b) -- fill in the inside of this if statementn        #incompletennn    else: print num  #part (c) -- if num is not zero then... fill in the coden        #incompletennnavg = mySum / count #calculates averagenprint(""The average is"" avg) #prints averagennnExcuse the comments as this is an assignment from an instructor. As you can see line 28 of the code shows a divide by zero error for variable mySum. In the while loop I overwrote(or at least tried to) mySum but still got the division error. Am I going about this correctly or is there some syntax I'm not following? nnEDIT: New attempt:nn#part (a) -- what are the initial values for these variables?n#incompletendone = 0nmySum =  ncount =  len(mySum)  nnwhile not done:n    valid = False #don't yet have a valid inputn    while not valid: #this loop keeps attempting to get input until the user enters an integern        try:n            num = int(input())n            valid = True #now the input is valid and can use itn        except ValueError:n            print(""Input must be an integer."")  n    if num == 0:n        breakn        #part (b) -- fill in the inside of this if statementn        #incompletennn    else: mySum.append(num)n    count +=1#part (c) -- if num is not zero then... fill in the coden        #incompletennnavg = sum(mySum) / count #calculates averagennif len(mySum) == 0:n    print ""You haven't entered any number""nelse: print (""The average is"" avg) nn' 'Denominator cannot be zero. In this case count is zero.nnYou may need to use count += 1 instead of count = len(num).nnYou should check whether the denominator is zero before you do the division.nnSuggestion: study python 3 instead of python 2.7. Python 2 will be finally replaced by python 3.nn    mySum = 0n    count = 0n    while True:  # this loop keeps attempting to get input until the user enters        an integern        try:n            num = int(input(""input a num ""))n        except ValueError:n            print(""Input must be an integer."")n            continuen        if num == 0:n            breakn        else:n            mySum += numn            count += 1n            print(num)n    avg = mySum / count if count else 0n    print(""The average is"" avg)  # prints averagenn' 'The ""divide by zero"" is a consequence of other problems in your code (or incompleteness of it). The proximate cause can be understood from the message: you are dividing by 0 which means count is 0 at that point which means you haven't actually tracked the numbers you put in. This in turn is - because you don't do anything with the numbers you put in.nnnIn case num == 0 you immediately break the loop; the two statements below do not execute.nIn case of not num == 0 you just print the number; there is not storing of a number into an array that you can sum later there is no += summing in an interim variable and there is certainly no incrementing of count.nnnThere is two basic ways to do this hinted to by the above:nnList: Make an empty list outside the loop when 0 is entered just break otherwise add the new number to the list. After the loop check the length: if it's zero complain that no numbers have been entered otherwise divide the sum by the length. No count required.nnRunning total: Initialize total and count variables to 0 outside the loop; again just break on a 0 otherwise add one to the count and the number to the total. After the loop do the same just with total and count instead of with sum and len.n'",['python-2.7'],"['python-3.x', 'python-2.7']"
40077580,"'Remote command does not return python' ""I am rebooting a remote machine through Python as it is a reboot the current ssh session is killed. The request is not returned. I am not interested in the return though.nnos.command('sshpass -p password ssh user@host reboot')nnThe code is performing the reboot however the current session is killed and the script never returns.nnI can do an async and just ignore the thread any other easy options?n"" 'I'm surprised that the script doesn't return. The connection should be reset by the remote before it reboots. You can run the process asyc the one problem is that subprocesses not cleaned up up by their parents become zombies (still take up space in the process table). You can add a Timer to give the script time to do its dirty work and then clean it up in the background.nnNotice that I switched that command to a list of parameters and skipped setting shell=True. It just means that no intermediate shell process is executed.nnimport sysnimport subprocess as subpnimport threadingnimport timingnndef kill_process(proc):n    # kill process if aliven    if proc.poll() is None:n        proc.kill()n        time.sleep(.1)n        if proc.poll() is None:n            sys.stderr.write(""Proc won't dien"")n            returnn    # clean up dead processn    proc.wait()nnproc = subp.Popen('sshpass' '-p' password 'ssh' 'user@host' 'reboot')nthreading.Timer(5 kill_process args=(proc))nn# continue on your busy day...nn'",['python-2.7'],['python-2.7']
40077591,"""Output random number between 30-35 using Random.seed() 'for' and multiplication in Python"" 'I am new to programming. I had an assignment to write a code that will output a random number between 30 and 35. This code needs to use random.seed() a FOR statement and a multiplication. I understand the random.seed(x) generates an initial value that could be used in the proceeding section of the code. However I cant figure out how to proceed after obtaining the value of the random:nnimport randomnrandom.seed(70)nprint(random.random()) # This returns a value of 0.909769237923872nnnHow do i use this value to generate a random value between 30 and 35?nnNote: Without the specific directions above I have been able to write two codes that functions as desired so please I am not looking for alternative ways of writing the code.  n' 'I'm not exactly sure how the for loop is relevant here but you can use the formula that follows (based off Java's random number in range equation mentioned here) and in particular this answer which is as follows:nnminimum + int(random.random() * (maximum - minimum))nnnThe above will generate a number in the interval minimum maximum). This is because multiplying the random number in 0 1) by maximum - minimum will give you a range of values from maximum (inclusive) to maximum exclusive. Then you just add the minimum to that range to achieve the range of random values.nnWe can nerf it to fit your needs of 30 35 by setting minimum to 31 (inclusive) and 35 (exclusive):nn31 + int(random.random() * (35 - 31))nnnThe above will generate (30 35) or a number between 30 and 35 exclusive:nn>>> print(31 + int(random.random() * (35 - 31)))n34n>>> print(31 + int(random.random() * (35 - 31)))n32n>>> print(31 + int(random.random() * (35 - 31)))n32n...nnnThis would most optimally be applied into a function like so:nndef random_in_range(minimum maximum): #exclusive to exclusiven    return (minimum + 1) + int(random.random() * (maximum - (minimum + 1)))nnnAnd called like:nn>>> print(random_in_range(30 35))n33 nn' 'Here is another way to do it:nnimport randomn#initial random seed based on current system timen#https://docs.python.org/2/library/random.html#random.seednnrandom.seed(9) #We set this so random is repeatable in testingnrandom_range = 30 31 32 33 34 35nnwhile True:n     num = int(round(random.random()1)*100)n     if num in random_range:n        print numn        breaknnnThe seed is set to 9 so if you run this over and over again you will get the same random value...thus setting a seed.  Note that multiple iterations are run because it was mentioned to not use a choice like random.choice  n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40077852,"'Best Way to Use Back-to-Back if Statements That Rely on the Same Variable' 'I am working on a script that streams real time data and appends it to numpy arrays. If the array is a certain length I will use it as a trigger to perform another action. However I noticed sometimes they cancel one and other. To give an example:nnif len(closeBidArray) > 20:n    execution_logic()   nnif len(closeBidArray) > 1:  n    # spreadsheet_append n    data = ""%s"" % (closeBidArray-1)n    ayTools.spreadsheet_append(fileName data)  nncloseBidArray = np.append(closeBidArray bidPrice)nnnGiven the example above so long as closeBidArray is less than 20 it does not trigger the execution logic but does do spreadsheet_append and appends to the numpy array (as seen in the last line above). However if the length of closeBidArray is greater than 20 that when it refuses to perform spreadsheet_append nor will it append to numpy array despite the fact that both of those tasks are set to take place after. Any ideas on where I am going astray? Thanksn' nan",['python-3.x'],['numpy']
40077880,"'Bootstrap accordion with Django: How to only load the data for the open accordion section?' 'I'm trying to make a webpage that will display recipes in the format of a bootstrap accordion like so (see here).nThis is how I'm doing it as of now:nn<div class=""panel-group"" id=""accordion"">n    {% for recipe in recipes %}n    <div class=""panel panel-default"">n        <div class=""panel-heading"">n            <h4 class=""panel-title"">n                <a data-toggle=""collapse"" data-parent=""#accordion"" href=""#collapse{{ forloop.counter }}"">n                    {{ recipe }}n                </a>n            </h4>n        </div>n        <div id=""collapse{{ forloop.counter }}"" class=""panel-collapse collapse"">n            <div class=""panel-body"">n                <table class=""table table-hover"">n                    {% for ingredient in  foodtype|ingredients_in_recipe:recipe %}n                        <tr>n                            <td>n                                {{ ingredient.ingredient_name }}n                            </td>n                            <td>n                                {{ ingredient.ingredient_quantity }}n                            </td>n                        </tr>n                    {% endfor %}n                    <p>{{ recipe.details }}</p>n                </table>n            </div>n        </div>n    </div>n    {% endfor %}n</div>nnnI have made a custom template tag for this like so:nn@register.filterndef ingredients_in_recipe(foodtype recipe):n    return foodtype.ingredient_set.filter(recipe=recipe).order_by(""ingredient_name"")nnnThe problem is that I have 200+ recipes and loading all this data is way too slow. Ideally the template tag function ingredients_in_recipe should only be called when the user clicks on the recipe. However from my understanding this isn't possible because Django runs it all then sends the rendered HTML to the user.nnIs there anyway I could circumvent this issue whilst still keeping the accordion style like in the picture?nnThanks in advancenMaxnnEDIT: Here's my view as wellnndef detail(request foodtype_id):n     foodtype = get_object_or_404(foodtype id=foodtype_id)n     recipe = foodtype.recipe_set.values_list('recipe').order_by('recipe').distinct()n     context = {n         'foodtype': foodtypen         'recipe': recipen     }n     return render(request 'main/detail.html' context)nn' 'Always better to do that logic before it gets to the template. What if you set the ordering on ingredients so then you won't have to order them in the template? Does that work and improve the performance?nnclass Ingredient(models.Model):n  ...nn  class Meta:n    ordering = 'ingredient_name'nnn<div class=""panel-group"" id=""accordion"">n    {% for recipe in recipes %}n    <div class=""panel panel-default"">n        <div class=""panel-heading"">n            <h4 class=""panel-title"">n                <a data-toggle=""collapse"" data-parent=""#accordion"" href=""#collapse{{ forloop.counter }}"">n                    {{ recipe }}n                </a>n            </h4>n        </div>n        <div id=""collapse{{ forloop.counter }}"" class=""panel-collapse collapse"">n            <div class=""panel-body"">n                <table class=""table table-hover"">n                    {% for ingredient in recipe.ingredient_set.all %}n                        <tr>n                            <td>n                                {{ ingredient.ingredient_name }}n                            </td>n                            <td>n                                {{ ingredient.ingredient_quantity }}n                            </td>n                        </tr>n                    {% endfor %}n                    <p>{{ recipe.details }}</p>n                </table>n            </div>n        </div>n    </div>n    {% endfor %}n</div>nn'",['django'],['django']
40077881,"'Guessinggame (replace variable issue)' 'so doing this for my stage 1 computer science paper. following code is what i've written atm. Line 16 (while statement) is giving a syntax error. The book asks us tonn1) prompt the user to enter a guess and store the value in the ""guess"" variablen2) if guess is greater than goal print...n3) if guess is lower than goal... print...n4) if guess is same as goal print...  nnUnsure how to fix this. Any help will be greatly appreciated. Code as below.nn#Author: Anuj Salujan#Date: 17 October 2016nimport randomnngoal = random.randint(1100)nnguess = 0nnprint (""The object of this game is to"")nprint (""guess a number between 1 and 100"")nprint()nninputguess = int(input(""Please guess the number: "")nnwhile (guess != goal):n                 if inputguess > goaln                 print (""Too high try again."")n                 if inputguess < goaln                 print (""Too low try again."")n                 if inputguess == goal:n                 breaknif inputguess == goal:n                 print (""Well done!"")n                 print (""See you later."")nn' 'The code is only asking for a guess once before the while loop. You need to update the guess variable inside the while loop by asking for input again.n' 'Put this line : nninputguess = int(input(""Please guess the number: "") nnninside the while loop. The code is only asking the user input once user input must be in the loop.n' 'Have you read your stack trace in detail? It's very easy to just skim over them but stack traces can actually provide a lot of very useful information. For instance the message is probably complaining that it was expecting a closing parenthesis. The line:nninputguess = int(input(""Please guess the number: "")nnnshould actually benninputguess = int(input(""Please guess the number: ""))nnnThe stack trace says the error is on line 16 because that's where the interpreter realized something was wrong. More often than not the buggy code will be in the last line of code before the line it gives you.nnalso as other people stated you need to put the input statement within the while loop in order to update the variable.nnYou should also consider replacing tab characters with 4 spaces so it displays consistently no matter where you read it. Usually the text editor or IDE will have tab settings that you can change when you hit tab it will type 4 spaces. A quick Google search along the lines of ""{text editor} change tab settings"" will usually bring up results on how to change it where {text editor} is the name of the editor/IDE you're using.nnYou should also consider indenting the code within your if statements as it improves readabilityn' 'I think you are looking for this. hope this will work.    nnimport randomnngoal = random.randint(1100)nnguess = 0nnprint (""The object of this game is to"")nprint (""guess a number between 1 and 100"")nninputguess = int(input(""Please guess the number: ""))nnwhile True:n    if inputguess > goal:n        inputguess = int(input(""Too high try again: ""))nn    elif inputguess < goal:n        inputguess = int(input(""Too low try again: ""))nn    elif inputguess == goal:n        print (""Well done!"")n        print (""See you later."")n        breaknn' 'So I had someone help me irl and this works perfectly for anyone interested. Thanks everyone for help. :) Appreciate it.nngoal = random.randint(1100)nnguess = 0nnprint (""The object of this game is to"")nprint (""guess a number between 1 and 100"")nprint()nnnnwhile guess != goal:n                 guess = int(input(""Please guess the number: ""))n                 if guess > goal:n                     print (""Too high try again."")n                 if guess < goal:n                     print (""Too low try again."")n                 if guess == goal:n                             breaknnif guess == goal:n                 print (""Well done!"")n                 print (""See you later."")nn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40077966,'Cropping Python lists by value instead of by index' 'Good evening StackOverflow. nLately I've been wrestling with a Python program which I'll try to outline as briefly as possible. nnIn essence my program plots (and then fits a function to) graphs. Consider this graph.nThe graph plots just fine but I'd like it to do a little more than that: since the data is periodic over an interval OrbitalPeriod (1.76358757) I'd like it to start with our first x value and then iteratively plot all of the points  OrbitalPeriod away from it and then do the same exact thing over the next region of length OrbitalPeriod. nnI know that there is a way to slice lists in Python of the formnncroppedList = Lista:bnnnwhere a and b are the indices of the first and last elements you'd like to include in the new list respectively. However I have no idea what the indices are going to be for each of the values or how many values fall between each OrbitalPeriod-sized interval. nnWhat I want to do in pseudo-code looks something like this.nnn  croppedList = fullList on the domain a + (N * OrbitalPeriod) a + (N+1 * OrbitalPeriod) nnnwhere a is the x-value of the first meaningful data point.nnIf you have a workaround for this or a cropping method that would accept values instead of indices as arguments please let me know. Thanks!n' 'If you are working with numpy you can use it inside the bracketsnnm = xnM = x + OrbitalPeriodncroppedList = Listm <= ListncroppedList = croppedListcroppedList < Mnn',['list'],['list']
40077992,"'Global Variable Python' 'A=nndef main():n    global An    A=12345n    b()nndef b():n    if(len(A)>0):n        A=789n    else:n        if(A3==4):n            A.remove(2)nnmain()  nnnThis code gives error in line A.remove(2) giving reason:""UnboundLocalError: local variable 'A' referenced before assignment""nnbut A list is global and for sure it has been initialized in main() function.Please explain why this is giving error?nnAs A has been initialized again in b function will this cause error?n' ""You must declare a variable global in any function that assigns to it.nndef b():n    global An    if some_condition:n        A.append(6)n    else:n        A.remove(2)nnnWithout declaring A global within the scope of b() Python assumes that A belongs in the b() namespace. You can read it but cannot edit it (any changes made will not persist to the true A.nnYou're allowed to set A to something inside the function A = ... will work but only within the scope of the function.nnIf you try to mutate A inside of the function without defining A in your function's namespace then Python will tell you that you are trying to mutate a variable outside of your purview with UnboundLocalErrornnBy declaring A global the interpreter knows that you mean to edit the global variable.  nnI'm assuming that you meant for your code to look something like this (Otherwise it runs fine)nnA=nnif __name__ == '__main__':n    def main():n        global An        A=12345n        b()nn    def b():n        global An        if some_condition:n            A=789n        else:n            A.remove(2)n        print Ann    main()n    print Annprint Ann"" 'The reason you are getting this is because when you performed this assignment in your function: nnA = 7 8 9nnnThe interpreter will now see A as a locally bound variable. So what will happen now looking at this condition:nnif(len(A)>0):nnnWill actually throw your first UnboundLocalError exception because due to the fact as mentioned you never declared global A in your b function and you also created a locally bound variable A = 7 8 9 you are trying to use a local A before you ever declared it.nnYou actually face the same issue when you try to do this:nnA.remove(2)nnnTo solve this problem with respect to your code simply declare the global A back in your b() function.nndef b():n    global An    if(len(A)>0):n        A=789n    else:n        if(A3==4):n            A.remove(2)nnnHowever the better ideal and recommended way to do this is to not use global and just pass the arguments to your functionnnA = 1 2 3 4nnndef main(list_of_things):n    # do whatever operations you want to do heren    b(list_of_things)nndef b(list_of_things):n    # do things with list_of_thingsnnmain(A)nn'","['list', 'python-2.7', 'python-3.x']","['python-2.7', 'list']"
40078088,"'how can I get the value of Entry Widget when the related class is called after login class' 'I'm trying to make a login window. I found a good example code here in Stackoverflow and added it with a simple code using Entry widget. After log in successfully however I can't get correct values of textvariable of Entry Widget even though I try to get them with Entry's instance.get().nI've tried many ways I could do. But I can't find what's wrong. nI'm working with python 2.7. please help.nn    from Tkinter import *n    import tkMessageBox as tmnn    class LoginFrame:n          def __init__(self):n                root = Tk()nnn                self.label_1 = Label(root text=""Username"")n                self.label_2 = Label(root text=""Password"")nn                self.entry_1 = Entry(root)n                self.entry_2 = Entry(root show=""*"")nn                self.label_1.grid(row=0 sticky=E)n                self.label_2.grid(row=1 sticky=E)n                self.entry_1.grid(row=0 column=1)n                self.entry_2.grid(row=1 column=1)nn                self.checkbox = Checkbutton(root text=""Keep me logged in"")n                self.checkbox.grid(columnspan=2)nn                self.logbtn = Button(root text=""Login"" command = n                                            self._login_btn_clickked)n                self.logbtn.grid(columnspan=2)nn                root.mainloop()nn          def _login_btn_clickked(self):n                username = self.entry_1.get()n                password = self.entry_2.get()nn                #print(username password)nn          if username == ""1"" and password == ""1"":n              #tm.showinfo(""Login info"" ""Welcome John"")n              app = EntrySample()n              app.window.mainloop()nn          else:n              tm.showerror(""Login error"" ""Incorrect username"")nnn  class EntrySample:n          def __init__(self):n               self.window = Tk()n              self.window.title(""Test Entry"") nn              Label(self.window text = ""Kor"").grid(row = 1n                    column = 1 sticky = W)nn              self.kor = IntVar()n              self.enKor = Entry(self.window textvariable = self.korn                    justify = RIGHT).grid(row = 1 column = 2)nn              Label(self.window text = ""Eng"").grid(row = 2n                    column = 1 sticky = W)nnn              self.eng = IntVar()n              self.enEng = Entry(self.window textvariable = self.engn                    justify = RIGHT).grid(row = 2 column = 2)nn              Label(self.window text = ""Math"").grid(row = 3n                    column = 1 sticky = W)nn              self.math = IntVar()n              self.enMath = Entry(self.window textvariable = self.mathn                    justify = RIGHT).grid(row = 3 column = 2)nn              btComputePayment = Button(self.window text = ""Calculate""n                    command = self.compute).grid(n                            row = 4 column = 2 sticky = E)nnn          def compute(self):n              total = self.kor.get()+self.eng.get()+self.math.get()n              avg = total/3.0n              print totaln              print '%3.2f' %avgnnn  LoginFrame()nn' nan",['tkinter'],"['tkinter', 'python-2.7']"
40078107,"""python pandas dataframe - can't figure out how to lookup an index given a value from a df"" ""I have 2 dataframes of numerical data. Given a value from one of the columns in the second df I would like to look up the index for the value in the first df. More specifically I would like to create a third df which contains only index labels - using values from the second to look up its coordinates from the first.nnlistso = 21101221102511324112211092810830102261062511124110ndata = pd.DataFrame(listsoindex=list('abcdefghij') columns=list('AB'))nrollmax = pd.DataFrame(data.rolling(center=Falsewindow=5).max())nnnSo for the third df I hope to use the values from rollmax and figure out which row they showed up in data.  We can call this third df indexlookup.nnFor example rollmax.ix'j''A' = 30 so indexlookup.ix'j''A' = 'g'.nnThanks!n"" ""You can build a Series with the indexing the other way around:nnmapA = pd.Series(data.index index=data.A)nnnThen mapArollmax.ix'j''A' gives 'g'.n""",['pandas'],['pandas']
40078158,"'PyQt4 - QLineEdit.text() exported to a list position' 'I will try to lay this out as best I can. I am writing a GUI with PyQt4 using Python 3.4.3.nnThe code I am writing stores information in a list and then pulls information from said list in order to complete tasks based on comparative logic between set positions in the list. Though it does not seem to like sending the text of a lineEdit in to a list and returns the error found at the bottom. Thanks for any assistance given. I'm sure it's something simple that I am overlooking.nnThe following is my code:nnclass Ui_MainWindow(object):n    def setupUi(self MainWindow):n        self.lineedit = QtGui.QLineEdit()n        self.lineedit.setObjectName(_fromUtf8(""lineedit""))n        self.gridLayout_3.addWidget(self.lineedit 30 3 1 1)n        self.button = QtGui.QPushButton(self.tab_6)n        self.button.setObjectName(_fromUtf8(""button""))n        self.gridLayout_6.addWidget(button 0 3 1 1)n        self.button.clicked.connect(Ui_MainWindow.call)nn    list = 1 2 3nn    def call(self)n        Ui_MainWindow.list0 = self.lineedit.text()nnnThis is the error message I have been getting from the above:nnTraceback (most recent call last):nFile ""filename"" line 11 in callnUi_MainWindow.list0 = self.lineedit.text()nAttributeError: 'bool' object has no attribute 'lineedit'nnnMy question would be why does this code error out rather than sending the .text() of lineedit to my list? n' nan",['python-3.x'],"['python-3.x', 'python-2.7', 'list']"
40078164,"'How can I ensure a write has completed in PostgreSQL before releasing a lock?' 'I have a function on a Django model that calculates a value from a PostgreSQL 9.5 database and based on the result determines whether to add data in another row. The function must know the value before adding the row and future values of the calculation will be dependent on the new row.nnTo enforce these rules I'm trying to use advisory locks. A simplified version of what I'm trying to do is below:nnfrom django.db import connection models transactionnn...nndef create_usage(self num_credits):n    LOCK_SQL = '''SELECT pg_advisory_lock(1) FROM %s WHERE id = %s'''n    UNLOCK_SQL = '''SELECT pg_advisory_unlock(1) FROM %s WHERE id = %s'''nn    cursor = connection.cursor()n    try:n        # Create an advisory lock on the instance's rown        print('obtaining lock for object {}'.format(id(self))n        cursor.execute(LOCK_SQL self._meta.db_table self.id)n        print('obtained lock for object {}'.format(id(self))nn        # Perform some read and update when the lock is obtainedn        with transaction.atomic():n            # -- SELECT SUM(...) FROM table WHERE ...n            sum_credits = self.credits_used.aggregate(n                sum_credits=models.Sum('num_credits'))'sum_credits'n            print('existing credits: {}'.format(sum_credits))nn            if sum_credits < 100 - num_credits:n                print('inserting')n                # -- INSERT INTO table VALUE (...)n                self.credits_used.add(CreditUsage(num_credits=num_credits))n            else:n                print('not inserting')n    finally:n        # Release the lock when done or when an exception occursn        print('releasing lock for object {}'.format(id(self))n        cursor.execute(UNLOCK_SQL self._meta.db_table self.id)n        print('released lock for object {}'.format(id(self))nnn(this is loosely inspired by this Caktus Group post)nnI have this code running in several processes connected to the same database. In the console the order of the 'obtaining' and 'releasing' print statements are what I expect them to be (i.e. no lock is obtained before some other process releases it) but the data that I get from the database doesn't appear to update like I expect. For example when running a view (that calls obj.create_usage(5)) in quick succession from different threads I'll get:nnobtaining lock for object Anobtained lock for object Anexisting credits: 90ninsertingnreleasing lock for object Anobtaining lock for object Bnreleased lock for object Anobtained lock for object Bnexisting credits: 90ninsertingnobtaining lock for object Cnreleasing lock for object Bnreleased lock for object Bnobtained lock for object Cnexisting credits: 90ninsertingnreleasing lock for object Cnreleased lock for object Cnobtaining lock for object Dnobtained lock for object Dnexisting credits: 95nobtaining lock for object Eninsertingnreleasing lock for object Dnobtained lock for object Enreleased lock for object Dnexisting credits: 100nnot insertingnreleasing lock for object Enreleased lock for object EnnnNOTE: I used A B C D E instead of the objects' numeric IDs for readability.nnWhy wouldn't the writes register before the reads given the DB locks? I tried without the transaction.atomic at first but added it thinking that it would make a difference. It did not. Is there a way to enforce the insert to really complete before releasing the advisory lock?n' ""I assume it's because of Django's (or middleware's) transaction management  I'm not completely sure it's better to test it on your code but it looks for me like: when you try to acquire a lock Django might start a new transaction so when you're actually getting lock at cursor.execute(LOCK_SQL self._meta.db_table self.id) you are already isolated. nnWhile you waiting for lock another process (with acquired lock) does insert to the database and commits its transaction but the first process won't see this change when it actually acquires the lock because transaction has started before.nnYou could check your application settings for ATOMIC_REQUESTS or any middleware that could enable transactions per request.n""",['django'],['django']
40078181,"'Subtracting two cloumns in pandas with lists to create a cummalative column' ""dataframe conists of set x which is a universal set and subset columm contains of some subsets. I want to choose the subsets with the highest ratios until I covered the full set x. nuncovered = setx - subsetnThis is how my dataframe look like in pandas :nn   ratio                  set x        subset        uncoveredn2   2.00  1 3 6 8 9 0 7  8 3 6 1        0 9 7n0   1.50  1 3 6 8 9 0 7     1 3 6     0 8 9 7n1   1.00  1 3 6 8 9 0 7        9 0  8 1 3 6 7n3   0.75  1 3 6 8 9 0 7     1 3 7     0 8 6 9nnnI want to create another column with the subtraction of set x with cummalative of uncovered column until i get a empty list. nnI tried the below codennp'tt'=list(p'set x'-p'subset')nnnError Message :nnn  --------------------------------------------------------------------------- TypeError                                 Traceback (most recent calln  last)n  /Applications/anaconda/lib/python3.5/site-packages/pandas/core/ops.pyn  in na_op(x y)n      581             result = expressions.evaluate(op str_rep x yn  --> 582                                           raise_on_error=True **eval_kwargs)n      583         except TypeError:n  n  /Applications/anaconda/lib/python3.5/site-packages/pandas/computation/expressions.pyn  in evaluate(op op_str a b raise_on_error use_numexprn  **eval_kwargs)n      208         return _evaluate(op op_str a b raise_on_error=raise_on_errorn  --> 209                          **eval_kwargs)n      210     return _evaluate_standard(op op_str a b raise_on_error=raise_on_error)n  n  /Applications/anaconda/lib/python3.5/site-packages/pandas/computation/expressions.pyn  in _evaluate_numexpr(op op_str a b raise_on_error truedivn  reversed **eval_kwargs)n      119     if result is None:n  --> 120         result = _evaluate_standard(op op_str a b raise_on_error)n      121 n  n  /Applications/anaconda/lib/python3.5/site-packages/pandas/computation/expressions.pyn  in _evaluate_standard(op op_str a b raise_on_error **eval_kwargs)n       61         _store_test_result(False)n  ---> 62     return op(a b)n       63 n  n  TypeError: unsupported operand type(s) for -: 'list' and 'list'n  n  During handling of the above exception another exception occurred:n  n  TypeError                                 Traceback (most recent calln  last)  in ()n  ----> 1 p'tt'=list(p'set x'-p'subset')n  n  /Applications/anaconda/lib/python3.5/site-packages/pandas/core/ops.pyn  in wrapper(left right name na_op)n      639                     rvalues = algos.take_1d(rvalues ridx)n      640 n  --> 641             arr = na_op(lvalues rvalues)n      642 n      643             return left._constructor(wrap_results(arr) index=indexn  n  /Applications/anaconda/lib/python3.5/site-packages/pandas/core/ops.pyn  in na_op(x y)n      586                 result = np.empty(x.size dtype=dtype)n      587                 mask = notnull(x) & notnull(y)n  --> 588                 resultmask = op(xmask _values_from_object(ymask))n      589             elif isinstance(x np.ndarray):n      590                 result = np.empty(len(x) dtype=x.dtype)n  n  TypeError: unsupported operand type(s) for -: 'list' and 'list'nn"" ""This should work for you:nnimport pandas as pdnn#    ratio                  set x        subset        uncoveredn# 2   2.00  1 3 6 8 9 0 7  8 3 6 1        0 9 7n# 0   1.50  1 3 6 8 9 0 7     1 3 6     0 8 9 7n# 1   1.00  1 3 6 8 9 0 7        9 0  8 1 3 6 7n# 3   0.75  1 3 6 8 9 0 7     1 3 7     0 8 6 9nnp = pd.DataFrame(n    n        {'set x': 1 3 6 8 9 0 7 'subset': 1 3 6}n        {'set x': 1 3 6 8 9 0 7 'subset': 9 0}n        {'set x': 1 3 6 8 9 0 7 'subset': 8 3 6 1}n        {'set x': 1 3 6 8 9 0 7 'subset': 1 3 7}n    )nnndef set_operation(x):n    return list(set(x'set x') - set(x'subset'))nnp'tt' = p.apply(set_operation axis=1)nnnResult is:nn                   set x        subset               ttn0  1 3 6 8 9 0 7     1 3 6     0 8 9 7n1  1 3 6 8 9 0 7        9 0  8 1 3 6 7n2  1 3 6 8 9 0 7  8 3 6 1        0 9 7n3  1 3 6 8 9 0 7     1 3 7     0 8 9 6nn""",['pandas'],['pandas']
40078447,"'Pandas dataframe output formatting' 'I'm importing a trade list and trying to consolidate it into a position file with summed quantities and average prices.  I'm grouping based on (ticker type expiration and strike).  Two questions:nnnOutput has the index group (ticker type expiration and strike) in the first column.  How can I change this so that each index column outputs to its own column so the output csv is formatted the same way as the input data?nI currently force the stock trades to have values (""1"") because leaving the cells blank will cause an error but this adds bad data since ""1"" is not meaningful.  Is there a way to preserve """" without causing a problem?nnnDataframe:nn    GM      stock   1           1       32      100n    AAPL    call    201612      120     3.5     1000n    AAPL    call    201612      120     3.25    1000n    AAPL    call    201611      120     2.5     2000n    AAPL    put     201612      115     2.5     500n    AAPL    stock   1            1      117     100nnnCode:nn    import pandas as pdn    import numpy as npnn    df = pd.read_csv(input_file index_col='ticker' 'type' 'expiration' 'strike' names='ticker' 'type' 'expiration' 'strike' 'price' 'quantity')n    df_output = df.groupy(df.index).agg({'price':np.mean 'quantity':np.sum})n    df_output.to_csv(output_file sep='')nnncsv output comes out in this format:nn(ticker type expiration strike) price quantitynnndesired format:nnticker type expiration strike price quantitynn' 'For the first question you should use groupby(df.index_col) instead of groupby(df.index)nnFor the second I am not sure why you couldn't preserve """" is that numeric?nnI mock some data like below:nnimport pandas as pd                                                                                                 nimport numpy as np                                                                                                  nnd =                                                                                                                n    {'ticker':'A' 'type':'M' 'strike':'''price':32}                                                             n    {'ticker':'B' 'type':'F' 'strike':100'price':3.5}                                                           n    {'ticker':'C' 'type':'F' 'strike':'' 'price':2.5}                                                            nn                                                                                                                   ndf = pd.DataFrame(d)                                                                                                nprint df                                                                                                            nn#dgroup = df.groupby('ticker' 'type').agg({'price':np.mean})                                                     ndf.index_col = 'ticker' 'type' 'strike'                                                                         ndgroup = df.groupby(df.index_col).agg({'price':np.mean})   n#dgroup = df.groupby(df.index).agg({'price':np.mean})                                                 nprint dgroup                                                                                                        nprint type(dgroup)                                                                                                  ndgroup.to_csv('check.csv') nnnoutput in check.csv:nntickertypestrikeprice                                                                                            nAM32.0                                                                                                           nBF1003.5                                                                                                         nCF2.5  nn'",['pandas'],['pandas']
40078569,"'Print string without a certain word?' 'So if I have code like this:nna = ""a"" ""b"" ""c"" ""null"" nnprint annnThe number of ""null""s varies in the output quite a lot for some reason.nHow could I print a without the ""null""?n' 'A simple way to filter your list is using list comprehension:nnprint(x for x in a if x != ""null"")nn' 'Just iterate through your list to print out everything that does not equal to ""null""nna = ""a"" ""b"" ""c"" ""null"" nnfor data in a:n    if data != ""null"":n        print(data)nnnIf you were looking to filter out data you don't want in your data structure however then the easiest way to do this is to do this in a list comprehension that will remove unwanted ""null""nnres = data for data in a if data != ""null""nn' '@m1ksu  I just saw above you asking for a function : see belownna = ""a"" ""b"" ""c"" ""null""ndef remove_null(self):n    return x for x in self if x != ""null""nasd = remove_null(a)nprint asdnnnoutput nn'a' 'b' 'c'nn' 'I get the impression that you wish to convert the list to a string with a function and display each data element on a separate line without null being included.  So here's what I suggest:nn# remove null and convert list to string with function  n# and display results on separate linesnna = ""a"" ""b"" ""c"" ""null"" nndef str(A): n    a = data for data in A if data != ""null""n    aSTR = 'n'.join(a)n    return aSTRnnprint str(a)nnnRun code heren'",['python-2.7'],"['list', 'python-2.7']"
40078596,"'Grouping by almost similar strings' ""I have a dataset with city names and counts of crimes. The data is dirty such that a name of a city for example 'new york' is written as 'newyork' 'new york us' 'new york city' 'manhattan new york' etc. How can I group all these cities together and sum their crimes?nnI tried the 'difflib' package in python that matches strings and gives you a score. It doesn't work well. I also tried the geocode package in python. It has limits on number of times you can access the api and doesnt work well either. Any suggestions? n"" 'Maybe this might help:nnhttp://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/nnAnother way: if a string contains 'new' and 'york' then label it 'new york city'. nnAnother way: Create a dictionary of all the possible fuzzy words that occur and label each of them manually. And use that labelling to replace each of these fuzzy words with the label.n' 'Another approach is to go through each entry and strip the white space and see if they contain a base city name. For example 'newyork' 'new york us' 'new york city' 'manhattan new york' when stripped of white space would be 'newyork' 'newyorkus' 'newyorkcity' 'manhattannewyork' which all contain the word 'newyork'.nnThere are two approaches with this method you can go through and replace the all the 'new york' strings with ones that have no white space and are just 'newyork' or you can just check them on the fly.nnI wrote down an example below but since I don't know how your data is formatted I'm not sure how helpful it is.nncrime_count = 0nfor (key val) in dataset:n    if 'newyork' in key.replace("" "" """"):n        crime_count = crime_count + valnn'",['pandas'],['python-2.7']
40078607,"'Finding and extracting multiple substrings in a string?' 'After looking a few similar questions I have not been able to successfully implement a substring split on my data. For my specific case I have a bunch of strings and each string has a substring I need to extract. The strings are grouped together in a list and my data is NBA positions. I need to pull out the positions (either 'PG' 'SG' 'SF' 'PF' or 'C') from each string. Some strings will have more than one position. Here is the data.nntext = 'Chixa0SG SFxa0xa0DTD''Clexa0PF'nnnThe code should ideally look at the first string 'Chixa0SG SFxa0xa0DTD' and return 'SG''SF' the two positions. The code should look at the second string and return 'PF'.n' ""Leverage (zero width) lookarounds:nn(?<!w)PG|SG|SF|PF|C(?!w)nnnn(?<!w) is zero width negative lookbehind pattern making sure the desired match is not preceded by any alphanumericsnPG|SG|SF|PF|C matches any of the desired patternsn(?!w) is zero width negative lookahead pattern making sure the match is not followed by any alphanumericsnnnExample:nnIn 7: s = 'Chixa0SG SFxa0xa0DTD'nnIn 8: re.findall(r'(?<!w)PG|SG|SF|PF|C(?!w)' s)nOut8: 'SG' 'SF'nn"" ""heemayl's response is the most correct but you could probably get away with splitting on commas and keeping only the last two (or in the case of 'C' the last) characters in each substring.nns = 'Chixa0SG SFxa0xa0DTD'nfin = list(map(lambda x: x-2: if x != 'C' else x-1:s.split('')))nnnI can't test this at the moment as I'm on a chromebook but it should work.n""",['regex'],"['regex', 'python-2.7']"
40078748,"'Tkinter - Grid elements next to each other' 'I'm trying to make some UI in python with tkinter.nnThis is a sample of the code I'm using:nnroot = Tk()nroot.geometry(""1000x700x0x0"")nncanvas = Canvas(root width = 700 height = 700 bg ='white').grid(row = 0 column = 0)nbutton1 = Button(root text = ""w/e"" command = w/e).grid(row = 0 column = 1)nbutton2 = Button(root text = ""w/e"" command = w/e).grid(row = 1 column = 1)nnnThis is what i'm getting:nnand this is what I want:nnAny help on how can I do it?nnThanks!n' 'Since your GUI seems to have two logical groups of widgets I would organize it as such. Start by placing the canvas on the left and a frame on the right. You can use pack place grid or a paned window to manage them. For a left-to-right orientation pack is a good choice due to its simplicitynnNote that you don't have to do it this way but experience has taught me it makes layout problems much easier to solve.nnIn the following example I set expand to False for the button frame which means that the canvas will grow and shrink when the user resizes (because it has expand=True) but the buttons will only take up exactly as much space as they need. nncanvas = Canvas(root ...)nbuttonframe = Frame(root ...)nncanvas.pack(side=""left"" fill=""both"" expand=True)nbuttonframe.pack(side=""right"" fill=""both"" expand=False)nnnNext you can put all of the buttons in the right side without having to worry how their placement might affect objects on the left.nnThe important thing to remember when using grid is that you should designate at least one row and at least one column to be given any extra space. This can be a row and/or column that contains widgets or it can be an empty row and column on an edge.nnbutton1 = Button(buttonframe ...)nbutton2 = Button(buttonframe ...)nbutton3 = Button(buttonframe ...)n...nbutton1.grid(row=0 column=0)nbutton2.grid(row=0 column=1)nbutton3.grid(row=1 column=0)n...nbuttonframe.grid_rowconfigure(100 weight=1)nbuttonframe.grid_columnconfigure(2 weight=1)nnnnnnote: if you need to keep a reference to a widget you must create the widget and call grid (or pack or place) on two separate lines. This is because Button(...).grid(...) returns the value of the last function call and grid(...) returns Nonen'",['tkinter'],['tkinter']
40079155,"'matplotlib gives a ValueError: could not convert string to float:' ""I have a pandas DataFrame. The columns head and dtypes are as shown below:nnprint sorted_results.dtypesnprint sorted_results'coefficients'.head()nn0                objectncoefficients    float64ndtype: objectn     coefficientsn62       2.432853n70       2.187059n19       1.804636n68       1.507075n130      1.120488nnnI want to plot a barchart using matplot lib sonnplt.barh(range(len(sorted_results)) sorted_results'coefficients')nnngives the following:nnValueError                                Traceback (most recent call last)n<ipython-input-17-1d344a50d686> in <module>()n      1 n----> 2 plt.barh(range(len(sorted_results)) sorted_results'coefficients')nn/Users/sram/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc in barh(bottom width height left hold **kwargs)n   2665         ax.hold(hold)n   2666     try:n-> 2667         ret = ax.barh(bottom width height=height left=left **kwargs)n   2668     finally:n   2669         ax.hold(washold)nn/Users/sram/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc in barh(self bottom width height left **kwargs)n   2245 n   2246         patches = self.bar(left=left height=height width=widthn-> 2247                            bottom=bottom orientation='horizontal' **kwargs)n   2248         return patchesn   2249 nn/Users/sram/anaconda/lib/python2.7/site-packages/matplotlib/__init__.pyc in inner(ax *args **kwargs)n   1817                     warnings.warn(msg % (label_namer func.__name__)n   1818                                   RuntimeWarning stacklevel=2)n-> 1819             return func(ax *args **kwargs)n   1820         pre_doc = inner.__doc__n   1821         if pre_doc is None:nn/Users/sram/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc in bar(self left height width bottom **kwargs)n   2085                 edgecolor=en   2086                 linewidth=lwn-> 2087                 label='_nolegend_'n   2088                 )n   2089             r.update(kwargs)nn/Users/sram/anaconda/lib/python2.7/site-packages/matplotlib/patches.pyc in __init__(self xy width height angle **kwargs)n    640         self._x = float(xy0)n    641         self._y = float(xy1)n--> 642         self._width = float(width)n    643         self._height = float(height)n    644         self._angle = float(angle)nnValueError: could not convert string to float: coefficientsnnnCoefficients seems to have the right datatype. I'm stumped by why I am doing wrong heren"" nan","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40079178,"'Django - How to put a html folder into django templates' 'I have my website built using django framework. Now we know django is a MVC based framework. And now I have a html folder which contains html file generated by doxygen. There are many .html files inside the folder and link each file via ""<a>"" tag and have image(.png) inside the folder too. I know that django has to set urls to all html pages and put it into templates and also put the image into static file and collect it via ""manage.py collectstatics"". Is it any easier way to embed the whole html folder into my django project? n' nan",['django'],['django']
40079232,"""Regex for capital letters followed be a space folllowed by numbers 'ABC 123' or 'BLZ 420'"" ""So I have this script that identifies ABC-123nne = r'A-Z+-d+'nnnshouldn't this identify ABC 123nne = r'A-Z+/sd+'nnnOr am I missing something blindingly obvious. Thanks. This is in Python as well. n"" ""You have the wrong slash you need a backslash:nne = r'A-Z+sd+'nnn/s will match / followed by a s literally whereas s is a Regex token that indicates a whitespace.n""",['regex'],['regex']
40079379,'How is scipy.special.expi implemented?' 'I was using scipy.special.expn when I realized I could be using expi instead and it should be much faster to judge from the Cephes code that I expected it would be based on. But switching from expn to expi made almost no difference in runtime.nnThis made me suspect that expi is implemented by an equivalent call to expn which does not take advantage of the simpler conditions in force for expi. But looking through the source code for scipy I am baffled as to how expi is implemented. I can find the C source for expn but not expi.nnCan someone clarify how expi is implemented and/or where I can find the source for it?n' nan,['numpy'],['numpy']
40079400,"'How to add an unspecified amount of variables together?' 'I'm trying to add in python 3.5.2 but I have an unspecified amount of variables. I have to use very basic functions; I can't use list. I can't figure out how I'm supposed to add each new variable together without a list. When I run the code it adds the last entered price1 which is -1. I need to use the -1 to tell the program to total all the variables. nncount = 0nnwhile (True):nn     price1 = int( input(""Enter the price of item or enter -1 to get total: ""))nn     count += 1nn     if (price1 ==-1):n         subtotal = (price1 + ) #this is where I""m having troublen                                #at least I think this is the problemn         tax = (subtotal*0.05)n         total = (subtotal + tax)nn         print(""Subtotal: .  .  . . . "" subtotal)n         print(""Tax: . .  . . . . . . "" tax)n         print(""Total: . . . . . . . ."" total)nn         breaknn' 'Keep another variable around and sum than up also count isn't used for anything so no real reason to keep it around. nnFor example initialize a price name to 0:nnprice = 0nnnthen check if the value is -1 and if not simply increment (+=) the price variable with the value obtained for price1:nnif price1 == -1:n    subtotal = price n    tax =  subtotal*0.05n    total = subtotal + taxnn    print(""Subtotal: .  .  . . . "" subtotal)n    print(""Tax: . .  . . . . . . "" tax)n    print(""Total: . . . . . . . ."" total)nn    breaknelse:n    price += price1nn' 'You almost had it. Looking at your code what I would suggest you do is create a subtotal variable just outside of your loop and initialize it to 0. Furthermore you are not using count for anything so get rid of that.nnWhen you get your price input check it right after for the -1 condition. If you have a -1 value then proceed with your math otherwise your else will start running the subtotal with the subtotal += price.nnSo you should have something like:nnsubtotal = 0nwhile (True):nn     price = int( input(""Enter the price of item or enter -1 to get total: ""))nn     if price == -1:n         tax = subtotal*0.05n         total = subtotal + taxnn         print(""Subtotal: .  .  . . . "" subtotal)n         print(""Tax: . .  . . . . . . "" tax)n         print(""Total: . . . . . . . ."" total)nn         breakn     else:n         subtotal += pricenn'","['python-2.7', 'python-3.x']","['python-3.x', 'list', 'python-2.7']"
40079504,"'No JSON object could be decoded - Django request.body' 'I am making web service for posting comments from smart phone Below is my code nn@api_view('POST')ndef comment_post(requestnewsId=None):n    data = json.loads(request.body)n    responseData= dict({n       ""result"": list()n       })n    if(newsId):n        commentNews  = models.Comments.objects.create()n        commentNews.comment_description = data.get('comment_description').strip()n        commentNews.like_count = int(data.get('like_count'))n        commentNews.user_name = data.get('user_name').strip()n        commentNews.user_email_id = data.get('user_email_id').strip()n        commentNews.parent_comment = data.get('parent_comment').strip()n        commentNews.save()n        subscribed_user = models.SubscribedUsers.objects.create(username=data.get('user_name').strip()email=data.get('user_email_id').strip())n        news = models.News.objects.get(id=int(newsId))n        news.comments.add(commentNews)n        data ={n         'status':'success'n         }n    else:n        data ={n        'status':'failure'n        }n    responseData'result'.append(data)n    return Response(responseDatastatus=status.HTTP_200_OK) nnnWhenever i check it on local it works but on server side it gives me below errornnValueError at /service/comment_post/369nnNo JSON object could be decodednnRequest Method:     POSTnRequest URL:    http://dev.newskhabari.com/service/comment_post/369nDjango Version:     1.9.5nException Type:     ValueErrornException Value:    nnNo JSON object could be decodednnException Location:     /usr/local/lib/python2.7/json/decoder.py in raw_decode line 383nPython Executable:  /var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/bin/pythonnPython Version:     2.7.6nPython Path:    nn'/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/site-packages'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/site-packages/django'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/bin'n '/var/www/vhosts/newskhabari.com/newskhabari_dev'n '/usr/local/rvm/gems/ruby-2.2.2/gems/passenger-5.0.30/src/helper-scripts'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python27.zip'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/plat-linux2'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/lib-tk'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/lib-old'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/lib-dynload'n '/usr/local/lib/python2.7'n '/usr/local/lib/python2.7/plat-linux2'n '/usr/local/lib/python2.7/lib-tk'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/newskhabari-app-venv/lib/python2.7/site-packages'n '/var/www/vhosts/newskhabari.com/newskhabari_dev'n '/var/www/vhosts/newskhabari.com/newskhabari_dev/app'nnServer time:    Mon 17 Oct 2016 11:35:36 +0530nnnI am unable to figure out why it give nException Value: No JSON object could be decodedn' 'I guess You are using django-rest-framework. So You don't have to do json.loads() becasue django-rest-framework provides request.data for POST requests and request.query_params for GET requests already parsed in json format.nnSo I think this should work for you. nn@api_view('POST')ndef comment_post(requestnewsId=None):nresponseData= dict({n   ""result"": list()n   })nif(newsId):n    commentNews  = models.Comments.objects.create()n    commentNews.comment_description = request.data.get('comment_description').strip()n    commentNews.like_count = int(request.data.get('like_count'))n    commentNews.user_name = request.data.get('user_name').strip()n    commentNews.user_email_id = request.data.get('user_email_id').strip()n    commentNews.parent_comment = request.data.get('parent_comment').strip()n    commentNews.save()n    subscribed_user = models.SubscribedUsers.objects.create(username=request.data.get('user_name').strip()email=request.data.get('user_email_id').strip())n    news = models.News.objects.get(id=int(newsId))n    news.comments.add(commentNews)n    data ={n     'status':'success'n     }nelse:n    data ={n    'status':'failure'n    }nresponseData'result'.append(data)nreturn Response(responseDatastatus=status.HTTP_200_OK) nnnFor further info read the the docs heren'","['django', 'python-2.7']",['django']
40079728,"'Get models ordered by an attribute that belongs to its OneToOne model' ""Let's say there is one model named User and the other named Pet which has a OneToOne relationship with User the Pet model has an attribute age how to get the ten User that owns the top ten oldest dog?nnclass User(models.Model):n     name = models.CharField(max_length=50 null=False blank=False)nnclass Pet(models.Model):n     name = models.CharField(max_length=50 null=False blank=False)n     owner = models.OneToOneField(User on_delete=models.CASCADE)n     age = models.IntegerField(null=False)nnnnnIn User there is an attribute friends that has a ManyToMany relationship with User how to get the ten friends of User Tom that owns the top ten oldest dog?nnclass User(models.Model):n     name = models.CharField(max_length=50 null=False blank=False)n     friends = models.ManyToManyField(self ...)nnclass Pet(models.Model):n     name = models.CharField(max_length=50 null=False blank=False)n     owner = models.OneToOneField(User on_delete=models.CASCADE)n     age = models.IntegerField(null=False)nn"" ""Use the double-underscore syntax.nnUser.objects.order_by('-pet__age'):10nnnEditnnTo get the ten friends of Tom you can get the instance and filter:nnUser.objects.get(name='Tom').friends.order_by('-pet__age'):10nnnor if you already have Tom:nntom.friends.order_by('-pet__age'):10nn"" ""Try this :nFirst define unicode in model User like this:nBy thisUser model objects will always return name field of the user records.nn class User(models.Model):n    name = models.CharField(max_length=50 null=False blank=False)n    friends = models.ManyToManyField(self ...)nn    def __unicode__(self):n       return self.namennnThen use this query:nn   User.objects.filter(friends='Tom').order_by('-pet__age'):10nn"" ""Another solution (alternative to order_by) is using nlargest function of heapq module this might be better if you already have friends list (tom's friends in this case) with a large number of items (I mean from performance perspective).nnimport heapqnnheapq.nlargest(n    10n    User.objects.get(name='Tom').friends.all()n    key=lambda f: f.pet.agen)nnnNote: You have also nsmallest function that you can use to get the youngest pets.n""","['django', 'python-3.x']",['django']
40079773,"""subprocess pipe can't see EOF from a child in case of a few children run with subprocess"" 'I'm creating a master stand-alone module on Python which should run some children via subprocess module. Working with children is done in separate worker threads. Additionally I need to receive real-time output from a child so in a worker thread I also create reader helper thread which reads on a pipe from the child.nnAll is working correctly while I have only one worker thread and run only one child. When the child finishes the reader helper thread gets EOF and exits. But when I have two worker threads and run two children a pipe from early child doesn't see EOF until the second child is finished. Though they are completely unrelated.nnLet's take a look on simplest example for reproducing the problem.nThere is a simplest child:nnimport time sysnn# first arg is an ID. Second arg is how long to work in secondsnsys.stdout.write(""start slave %sn"" % sys.argv1)nsys.stdout.flush()nntime.sleep(int(sys.argv2))nnsys.stdout.write(""finish slave %sn"" % sys.argv1)nsys.stdout.flush()nnnAnd there is a master module:nnimport subprocess sys os threading timenng_logLock = threading.Lock()nndef log(msg):n    with g_logLock:n        t = time.time()n        print ""%s.%03d %-5s %s"" % n            (time.strftime('%H:%M:%S' time.localtime(t)) int((t - t // 1) * 1000) threading.currentThread().name msg)nndef thread1Proc():n    def reader(stdout):n        while True:n            line = stdout.readline()n            if not line:n                breakn            log('slave said: %s' % line.strip())n        log('finish slave reader thread')nn    log('thread 1 started')n    timeToWork = '1'n    util = subprocess.Popen((sys.executable 'slave.py' '1' timeToWork) stdout=subprocess.PIPE)n    readerT = threading.Thread(target=reader args=(util.stdout) name='t1-r')n    readerT.start()n    log('slave 1 returned %d' % util.wait())n    readerT.join()n    log('thread 1 finished')nndef thread2Proc():n    log('thread 2 started')n    timeToWork = '3'n    util = subprocess.Popen((sys.executable 'slave.py' '2' timeToWork))n    log('slave 2 returned %d' % util.wait())n    log('thread 2 finished')nn#---------------------------nlog('starting test')nnthreads = (threading.Thread(target=thread1Proc name='t1') threading.Thread(target=thread2Proc name='t2'))nfor t in threads:n    t.start()nfor t in threads:n    t.join()nnlog('finished test')nnnHere is what I see on the output (note - slave 1 outputs to the master via pipe while slave 2 outputs to a console because its output is not redirected):nn>master.pyn08:57:31.342 MainThread starting testn08:57:31.342 t1    thread 1 startedn08:57:31.342 t2    thread 2 startedn08:57:31.405 t1-r  slave said: start slave 1nstart slave 2n08:57:32.420 t1-r  slave said: finish slave 1n08:57:32.420 t1    slave 1 returned 0nfinish slave 2n08:57:34.415 t1-r  finish slave reader threadn08:57:34.415 t2    slave 2 returned 0n08:57:34.415 t1    thread 1 finishedn08:57:34.431 t2    thread 2 finishedn08:57:34.431 MainThread finished testnnnHere you can see that even if the slave 1 finishes at 32.420 its reader thread receives EOF and exits only when the slave 2 finishes also - at 34.415 (slave 1 works 1 second slave 2 - 3 seconds).nnWhy the reader thread doesn't see EOF just in time?nnUPD: forgot to say I use Python 2.7.12 x86 on Windows 7. Moved to it from v.2.7.9 but nothing changed. It's interesting to check the issue on Linux.n' nan",['python-2.7'],['python-2.7']
40079794,"'How to change the data types of a column in Pandas when read_csv()' ""I could not able to change the data types of specific column I tried using these below codes but neither works for me.nngetting ValueError: could not convert string to float: '?'nnThere were some issues in version supporting of Pandas as I got to know when I searched around.nndata.Global_intensity = data.Global_intensity.astype(pd.np.float)nndata.Global_intensity.apply(float)nndata'Global_intensity' = data'Global_intensity'.astype('float')nnnHere are the versions of modules I am working with.nnpython: 3.5.2.final.0npandas: 0.19.0nnumpy: 1.11.1nnn  part of the codennnimport pandas as pdnimport numpy as npnimport matplotlib.pylab as pltn%matplotlib inlinenfrom matplotlib.pylab import rcParamsnrcParams'figure.figsize' = 15 6nndata = pd.read_csv('Desktop/household_power_consumptions.csv')nprint (data.head())nprint ('n Data Types:')ndata'Global_intensity' = data'Global_intensity'.astype('float')nprint (data.dtypes)nnnWhat I need is to convert the data type of object into float of Global_intensity column to work with matplotlib.pylab library.nnThank you.n"" nan","['pandas', 'numpy']","['pandas', 'matplotlib']"
40079837,"'django 3.5 makemessages refers to previous virtual env' 'I am running django 1.10 with python 3.5 on windows 7 and I am trying to translate my test files.nnI have created the es language directory in the locale directory.nnIn the virtual environment at the command prompt I enter: python manage.py makemessages --locale=esnnI get the following error message:nn....n.manage.pyn.requirements.txt.pyn.requirementsbase.txt.pyn.requirementsdeployment.txt.pyn.requirementsdevelopment.txt.pyn.requirementsproduction.txt.pyn.runtime.txt.pynxgettext: Non-ASCII string at .envLibsitepackagescompressorfilterscssminrcssmin.py:70.n          Please specify the source encoding through --from-code.nnnI have seen this post and changed the ascii to utf-8 and even tried utf8. I get the same error message.nnWhen I open the file .envLibsitepackagescompressorfilterscssminrcssmin.py there is no code on line 70. Here is the relevant portion of the file:nnBoth python 2 (>= 2.4) and python 3 are supported.nn.. _YUI compressor: https://github.com/yui/yuicompressor/nn.. _the rule list by Isaac Schlueter: https://github.com/isaacs/cssmin/n""""""nif __doc__:n    # pylint: disable = W0622n    __doc__ = __doc__.encode('ascii').decode('unicode_escape')n__author__ = r""Andrxe9 Malo"".encode('ascii').decode('unicode_escape')n__docformat__ = ""restructuredtext en""n__license__ = ""Apache License Version 2.0""n__version__ = '1.0.6'n__all__ = 'cssmin'nnimport re as _rennnI have run out of ideas. Does anyone have any suggestions?n' ""Maybe there is a character even if you don't see it. Try pasteing in notepad++  the text (sometimes it helps to detect wrong chars) or try to delete/rewrite close newlines tabs or similar symbols just in case they came from a copy/paste from a file with different coding.n"" 'This error was due to an old virtual environment folder that was on my system. I have deleted this folder and a new error now displays. I have posted a different thread for the new error.n'",['django'],['django']
40079982,"'get_dummies() throws Memory Error' 'I am trying the create a matrix of data from 7 csv to find out common words among the files.nnimport pandas as pdnndf1 = pd.read_csv('A.csv' sep="";"" index_col=None header=None)ndf2 = pd.read_csv('B.csv' sep="";"" index_col=None header=None)ndf3 = pd.read_csv('C.csv' sep="";"" index_col=None header=None)ndf4 = pd.read_csv('D.csv' sep="";"" index_col=None header=None)ndf5 = pd.read_csv('E.csv' sep="";"" index_col=None header=None)ndf6 = pd.read_csv('F.csv' sep="";"" index_col=None header=None)ndf7 = pd.read_csv('G.csv' sep="";"" index_col=None header=None)nndf = pd.concat(df1df2df3df4df5df6df7 keys='A''B''C''D''E''F''G')ndf.reset_index(1 drop=True inplace=True)nnres = df.stack().reset_index(1 drop=True)nval = res.str.get_dummies().groupby(level=0).sum().Tnnval.to_csv('result.csv')nnnThis code works perfectly if I use 2-3 csv but when I use all 7 csv the words list goes above 60000 and the get_dummies() throws Memory Error my system gets hanged and I need to restart the system. Is there some way to resolve this issue. n' nan",['pandas'],['pandas']
40080019,"'deleting pandas dataframe column' 'I am trying to delete the column of a pandas dataframe and I get the following error: ValueError: labels ' 5' not contained in axis. However my print df.columns returnsInt64Index(0 1 2 3 4 5 6 dtype='int64'). See bellow the code as well:nndf = pd.read_csv(StringIO(data)skiprows=186sep="";""header=None)n#df.drop(' 5' inplace=True)nb= df.columns.tolist()nprint df.columnsnn' nan",['pandas'],['pandas']
40080156,"'Adding a seed to my program (Word Letter Scramble)' 'I am having trouble figuring out how to add a seed to my program. It is supposed to be able take a given seed value and return a scrambled sentence. The first and last letters in a words should stay the same as well as ending punctuation. Any punctuation within a word is allowed to be scrambled. nnimport randomnimport stringnnoriginal_text = input(""Enter your text: "").split(' ')nseed = int(input(""Enter a seed (0 for random): ""))nif seed is not 0:n    random.seed(seed)nnrandomized_list = nndef scramble_word(word):n    alpha = word0n    if word-1 == """" or ""."" or ""!"" or ""?"" or "":"" or "";"":n        omega = word-2 n        middle = word1:-2n    else:n        omega = word-1n        middle = word1:-1n    reorders_text = random.sample(middle len(middle))n    shuffled_text = """".join(reorders_text)n    new_words = alpha + shuffled_text + omegan    return new_wordsnfor item in original_text:n    if len(item) <= 3:n        randomized_list.append(item)n    else:n        randomized_list.append(scramble_word(item))nnew_words = "" "".join(randomized_list)nprint(new_words)nn' 'To add a seed to the program with 0 being a random seed you would need to call random.seed() to your program as so:nnseed = int(input(""Enter a seed (0 for random): ""))nif seed is not 0:  n    random.seed(seed)nnnPretty simple.nnSee the Python docs for more info: https://docs.python.org/3.5/library/random.htmlnnIn the future it is always worth turning to the documentation before posting here. For basic things like this the docs will probably answer your question.n'",['python-3.x'],"['python-3.x', 'python-2.7']"
40080248,'Change RGB color in matplotlib animation' 'I seems that it is not possible to change colors of a Matplotlib scatter plot through a RGB definition. Am I wrong?nnHere is a code (already given in stack overflow) which work with colors indexed in float:nnimport matplotlib.pyplot as pltnimport numpy as npnimport matplotlib.animation as animationnndef main():n    numframes = 100n    numpoints = 10nn    color_data = np.random.random((numframes numpoints))n    x y c = np.random.random((3 numpoints))nn    fig = plt.figure()n    scat = plt.scatter(x y c=c s=100)nn    ani = animation.FuncAnimation(fig update_plot frames=range(numframes)n                                  fargs=(color_data scat))n    plt.show()nndef update_plot(i data scat):n    scat.set_array(datai)n    return scatnnmain()nnnBut if color_data is defined through RGB colors I get an error: nnn  ValueError: Collections can only map rank 1 arraysnnnThe related code is the following (in this code I just change the color of one sample each time):nnimport matplotlib.pyplot as pltnimport numpy as npnimport matplotlib.animation as animationnndef main():n    numframes = 100n    numpoints = 10nn    rgb_color_data = np.random.random((numpoints 3))n    x y = np.random.random((2 numpoints))nn    fig = plt.figure()n    scat = plt.scatter(x y c=rgb_color_data s=100) #this work well at this levelnn    ani = animation.FuncAnimation(fig update_plot2 frames=range(numframes)n                                  fargs=(rgb_color_data scat))nn    plt.show()nndef update_plot2(idatascat):n    data i%10  = np.random.random((3))n    scat.set_array(data) # this fails n    return scatnnmain()nnnIs there a means to use set_array with RGB color array?n' 'Not sure what you are trying to achieve. But if you are trying to change the color why not use the set_color() function of Collection?nndef update_plot2(idatascat):n    data i%10  = np.random.random((3))n    scat.set_color(data) # <<<<<<<<<<<<<<<<<<<n    return scatnn',['matplotlib'],['matplotlib']
40080302,'How do i check via python/django if a task is running in celery if I only have the task name?' 'I was assigned recently to an existing django project and one of the tasks assigned to me was to check if there's a task currently running in celery.  It's my first time working with celery and I am a little lost as to how to do this. The version of celery being used is 3.1.18. Based on the existing setup of the project the only resource i have to do this is with the task name. So given the task name i need to find if that particular task is already executing. nnThe way i was testing the functions was i manually called the tasks in the shell with delay(). When i see that my worker has received the task i executed the commands i found in the links below to see if i could catch them but i haven't had luck doing this so far.nnHere's what i've found so far looking through stack overflownnHow to inspect and cancel Celery tasks by task namennI tried the following command from the link above via the python shellnn    task_list = celery.events.state.State().tasks_by_type(task.name)nnnand executed the following loop via the shellnn    for uuid _ in task_listn        print(uuid)nnnbut it was always empty. I checked the following settings and their values too. I couldn't find the stack overflow links for them but i found that i should set the following values as well to the settings below to start trackingnn    CELERY_RESULT_BACKEND = 'djcelery.backends.database:DatabaseBackend'n    CELERY_TRACK_STARTED = Truen    CELERY_SEND_TASK_SENT_EVENT = TruennI also found the following linknnRetrieve list of tasks in a queue in Celerynnand tried the inspect() function but i don't see any type of response when running it via the python shell. nnHope you could assist me in pointing me in the right direction to solve this.nnThanksn' nan,['django'],['django']
40080406,'Pending tasks submitted to concurrent.futures' 'I am using a concurrent.futures.ThreadPoolExecutor to download files from urls. nnDeclaration:nnmedia_download_manager = concurrent.futures.ThreadPoolExecutor(max_workers=4)nnnWhenever necessary downloads are triggered with the following statement:nnmedia_download_manager.map(download_media_job urls)nnnwhere download_media_job is a method that handles downloading along with some prior checks; urls is a list of unique urls of files to download. But since there are multiple threads to download files I do not want to submit duplicate urls while calling media_download_manager.map at separate places. nnHow do I get the list of pending tasks submitted to concurrent.futures.ThreadPoolExecutor without explicitly maintaining a separate list?n' nan,['python-2.7'],[]
40080593,"'For-loop with range is only taking the last element' ""I have a 2D array of strings from which I delete certain elements (those containing the '#' char). When I print lista from inside the loop it prints this: nn'call' '_imprimirArray'n'movl' '24' '%2' '%3'n'movl' '%1' '%2'n'call' '_buscarMayor'n'movl' '%1' '4' '%3'n'movl' '$LC1' '%2'n'call' '_printf'n'movl' '$LC2' '%2'n'call' '_system'n'movl' '$0' '%2'n'movl' '-4' '%2' '%3'nnnBut when I append each row to another 2D array only the last element is assigned:nn'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'n'movl' '-4' '%2' '%3'nnnHere's the loop:nndef quitarEtiquetas(labels programa):    n    lista = n    temp = nn    for i in range(0 len(programa)):n        del lista:n        for j in range(0 len(programai)):n            if(programaij.find('#') != -1):n                labels.append(programaij.replace('#' '') i)n            else:n                lista.append(programaij)n        print(lista)n        temp.append(lista)nn"" ""You're appending the same row many times to temp while just removing items from it on each iteration. Instead of del lista: just assign a new list to the variable: lista =  so that content in previously added rows doesn't get overwritten.nnEffectively you're doing following:nn>>> lista = n>>> temp = n>>> lista.append('foo')n>>> temp.append(lista)n>>> tempn'foo'n>>> del lista:n>>> tempnn>>> lista.append('bar')n>>> temp.append(lista)n>>> tempn'bar' 'bar'nn"" ""Adding to niemmi's answer what you need to do is:nn    for i in range(0 len(programa)):n        lista =  # creates a new empty list object alltogethern        ...nnninstead ofnn    for i in range(0 len(programa)):n        del lista:; # only clears the content the list object stays the samennnBTW no ; needed in python.n""","['list', 'python-3.x']","['list', 'python-2.7']"
40080675,'How to send a file to ASP.NET MVC action by python?' 'I want to send a file (image or video) to a MVC action or a web-service  what is the best way to do that ? n' nan,['python-3.x'],['python-2.7']
40080850,'Separate system of coordinates for x and y' 'I am using matplotlib for plotting in my project. I have a time series on my chart and I would like to add a text annotation. However I would like it to be floating like this: x dimension of the text would be bound to data (e.g. certain date on x-axis like 2015-05-04) and y dimension bound to Axes coordinates system (e.g. top of the Axes object). Could you please help me accomplish something like this?n' 'It seems like I found the solution: one should use blended transformation:nhttp://matplotlib.org/users/transforms_tutorial.html#blended-transformationsn',['matplotlib'],['matplotlib']
40081109,"'Pandas: convert unicode elem in column to list' 'I have dataframenncategory    dictionarynClassified  u'u043e' u'u0441' u'u043a' u'u043fu043e' u'u0443' u'avito' u'u043eu0431' u'u043du0438' u'u043eu0431u044au044fu0432u043bu0435u043du0438u044f' u'%8f-' u'u0434u043e' u'u0435u0449u0435' u'u043fu0440u0438' u'000' u'u0436u0435' u'u043au0430u043a' u'u0441u043e' u'u0438u043bu0438' u'u0442u043eu0432u0430u0440' u'u0442u0430u043a' u'u043eu0431u044au044fu0432u043bu0435u043du0438u0435' u'u043eu0431u044au044fu0432u043bu0435u043du0438u0439' u'u0443u0441u043bu0443u0433' u'u0441u0430u0439u0442' u'u043au0430u043a' u'u043bu0438' u'u043eu0431u044au0435u043au0442' u'avito.' u'###' u'u043e' u'u0444u043eu0442u043e' u'u0442u043eu043bu044cu043au043e' u'-avito-' u'u0434u043eu043bu0436u043du043e' u'u043du0438u043c'nSearch  u'u0441' u'u0443' u'u043a' u'u043fu043e' u'u043e' u'u043eu0431' u'u0432u0430u043c' u'u0432u0430u0448' u'u0437u0430u043fu0440u043eu0441u044b' u'u044fu043du0434u0435u043au0441' u'u0430u0432u0442u043eu043cu0430u0442u0438u0447u0435u0441u043au0438u0435' u'u0440u0430u0437' u'u0432u043eu0437u043cu043eu0436u043du043e' u'u0441u0438u043cu0432u043eu043bu044b' u'u044du0442u043eu043c' u'u0438u043bu0438' u'u0442u0430u043a' u'u0435u0441u043bu0438' u'u0431u0440u0430u0443u0437u0435u0440u0435' u'u0432u0430u0448u0435u0433u043e' u'u0432u0430u0448u0435u043c' u'u0432u0438u0440u0443u0441u043du043eu0439' u'u0432u043eu0441u043fu043eu043bu044cu0437u0443u0439u0442u0435u0441u044c' u'u043au043eu043cu043fu044cu044eu0442u0435u0440' u'u043cu043eu0436u0435u0442' u'u043du0430u043fu0440u0438u043cu0435u0440' u'u043du0430u0448u0435u0439' u'u043du0435u043eu0431u0445u043eu0434u0438u043cu043e' u'u043fu043eu0436u0430u043bu0443u0439u0441u0442u0430' u'u043fu043eu0438u0441u043au0443.' u'u0440u0435u043au043eu043cu0435u043du0434u0443u0435u043c' u'u0441u043bu0443u0447u0430u0435' u'u0447u0442u043eu0431u044b' u'an' u'.ru'nÐx90Ð³Ñx80ÐµÐ³Ð°Ñx82Ð¾Ñx80   u'u0441' u'u0443' u'u043a' u'u043fu043e' u'u043e' u'u043eu0431' u'u0432u0430u043c' u'u0432u0430u0448' u'u0437u0430u043fu0440u043eu0441u044b' u'u0430u0432u0442u043eu043cu0430u0442u0438u0447u0435u0441u043au0438u0435' u'u044fu043du0434u0435u043au0441' u'u0440u0430u0437' u'u0432u043eu0437u043cu043eu0436u043du043e' u'u0441u0438u043cu0432u043eu043bu044b' u'u044du0442u043eu043c' u'u0442u0430u043a' u'!(//yastatic.net/lego/_/la6qi18z8lwgnzdsar1qy1gwcwo.gif)' u'u0438u043bu0438' u'u0431u0440u0430u0443u0437u0435u0440u0435' u'u0432u0430u0448u0435u0433u043e' u'u0432u0430u0448u0435u043c' u'u0432u0438u0440u0443u0441u043du043eu0439' u'u0432u043eu0441u043fu043eu043bu044cu0437u0443u0439u0442u0435u0441u044c' u'u0435u0441u043bu0438' u'u043au043eu043cu043fu044cu044eu0442u0435u0440' u'u043cu043eu0436u0435u0442' u'u043du0430u043fu0440u0438u043cu0435u0440' u'u043du0430u0448u0435u0439' u'u043du0435u043eu0431u0445u043eu0434u0438u043cu043e' u'u043fu043eu0436u0430u043bu0443u0439u0441u0442u0430' u'u043fu043eu0438u0441u043au0443.' u'u0440u0435u043au043eu043cu0435u043du0434u0443u0435u043c' u'u0441u043bu0443u0447u0430u0435' u'u0447u0442u043eu0431u044b' u'u043du0438'nÐx90ÐºÑx81ÐµÑx81Ñx81Ñx83Ð°Ñx80Ñx8b  u'u0441' u'u043a' u'g3' u'lg' u'mypads.ru' u'u043e' u'u0447u0435u0445u043bu044b' u'u0442u0435u043bu0435u0444u043eu043d' u'dual' u'lte' u'u0442u0435u043bu0435u0444u043eu043du043eu0432' u'mac-set' u'u043fu043e' u'u0443' u'u043fu043bu0430u043du0448u0435u0442u043eu0432' u'-dual-' u'one' u'u0441u0430u043cu043eu0432u044bu0432u043eu0437' u'/g3' u'd855/d856/d858' u'|' u'mah' u'u0434u043bu044f' u'u0440.' u'sony' u'u043cu043eu0441u043au0432u0435' u'u0442u0435u043bu0435u0444u043eu043du0430' u'""u0441u0430u043cu043eu0432u044bu0432u043eu0437' u'""u043fu0443u043du043au0442' u'dopolnitelnoj-batarei-dlya-telefo-lg' u'u0441u0430u043cu043eu0432u044bu0432u043eu0437u0430' u'asus' u'circle' u'quick' u'u0431u0435u0441u043fu0440u043eu0432u043eu0434u043du0430u044f'nÐx98Ð½Ñx84Ð¾Ñx80Ð¼Ð°Ñx86Ð¸Ð¾Ð½Ð½Ñx8bÐ¹ Ñx80ÐµÑx81Ñx83Ñx80Ñx81   u'u043e' u'u0441' u'u043a' u'apple' u'u0443' u'u043fu043e' u'apple.com' u'|' u'app' u'store' u'iphone' u'(' u'mail.ru' u'u043c' u'ipad' u'u0432u043e' u'u0441u043e' u'u0433' u'image' u'id' u'u0434u043e' u'one' u'u0442u0435' u'u043eu0431' u'itunes' u'phone' u'le' u'ip' u'apple.' u'u043fu0440u0438' u'u0436u0435' u'se' u'os' u'###' u'!(http://store.storeimages.cdn-apple.com/4662/as-'nÐx9cÐ°Ð³Ð°Ð·Ð¸Ð½Ñx8b Ð¿Ñx80Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñx82ÐµÐ»ÐµÐ¹ u'u043e' u'u0441' u'u043a' u'(/' u'u0443' u'lenovo' u'u043fu043e' u'u0441u043e' u'u0437u0430u043au0430u0437' u'u043fu0440u0438' u'lenovo(/' u'u0430u043au0441u0435u0441u0441u0443u0430u0440u044b' u'u0432u0441u0435' u'u0438u043bu0438' u'(javascript:void(0)' u'u043fu043a' u'!(/local/templates/lenovo/images/close-buy-dialog.png)' u'u0434u043eu0441u0442u0430u0432u043au0430' u'###' u'u0438u043du0442u0435u0440u043du0435u0442-u043cu0430u0433u0430u0437u0438u043d' u'yoga' u'u0442u043eu0432u0430u0440' u'u0440u0443u0431.' u'u0440u0435u0433u0438u0441u0442u0440u0430u0446u0438u044f' u'u043fu0440u043eu0434u0443u043au0442u044b' u'u0444u043eu0440u0443u043cu0430' u'u043fu043eu043au0443u043fu043au0438' u'u043fu043eu0434u0434u0435u0440u0436u043au0430' u'u043eu0444u043eu0440u043cu0438u0442u044c' u'u0433u0430u0440u0430u043du0442u0438u044f' u'lenovo.' u'u0440u0430u043cu043au0430u0445' u'u043fu043eu0434u0434u0435u0440u0436u043au0438' u'u0432u043eu0439u0442u0438' u'u043cu0435u043du044f'nÐx9cÐ¾Ð½Ð¾Ð±Ñx80ÐµÐ½Ð´Ð¾Ð²Ñx8bÐµ Ñx81Ñx82Ñx80Ð°Ð½Ð¸Ñx86Ñx8b Ñx81 Ð¸Ð½Ñx84Ð¾Ñx80Ð¼Ð°Ñx86Ð¸ÐµÐ¹    u'u043e' u'u0441' u'u043a' u'apple' u'u0443' u'iphone' u'appleinsider.ru' u'mac' u'os' u'u043fu043e' u'ios' u'u0436u0435' u'macos' u'u043fu0440u0438' u'u0436' u'u043e' u'u043du0438' u'u043bu0438' u'macdigger' u'macosworld.ru' u'u0434u043e' u'(http://macosworld.ru' u'u0442u0430' u'macdigger.' u'macdigger.ru' u'(http://macosworld.ru/' u'(http://www.macdigger.ru' u'login.php?redirect_to=http%3a%2f%2fappleinsider.ru%2fios%2fbystro-' u'razryazhaetsya-iphone-vy-mozhete-emu-pomoch.html)' u'u043du043eu044fu0431u0440u044c' u'u2212' u'2015u0433(http://appleinsider.ru/ios/bystro-razryazhaetsya-iphone-vy-' u'u043eu0442u0432u0435u0442u0438u0442u044c(http://appleinsider.ru/wp-' u'u043fu0440u0438u043bu043eu0436u0435u043du0438u044f' u'u0432u043e'nÐx9eÐ½Ð»Ð°Ð¹Ð½-Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½  u'u043e' u'u0441' u'u043a' u'u0443' u'u043fu043e' u'u0433' u'se' u'u0434u043e' u'u0447' u'(' u'u0441u043e' u'u043du0438' u'u043eu0431' u'u0432u043e' u'u0442u0435' u'u0441u043cu0430u0440u0442u0444u043eu043d' u'smart' u'ip' u'u043fu0440u0438' u'u043bu0438' u'u043eu0441' u'pro' u'apple' u'phone' u'|' u'aliexpress' u'ebay' u'u0430u043au0441u0435u0441u0441u0443u0430u0440u044b' u'dns' u'u043b' u'u0436u0435' u'u0433u0431' u'3d' u'u043au0430u0440u0442' u'(//static.mvideo.ru/assets/img/stub.gif)'nÐx9eÑx84Ð¸Ñx86Ð¸Ð°Ð»Ñx8cÐ½Ñx8bÐµ Ð¸ Ð¼Ð¾Ð½Ð¾Ð±Ñx80ÐµÐ½Ð´Ð¾Ð²Ñx8bÐµ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ñx8b    u'u043e' u'u0441' u'u043a' u'microsoft' u'u0443' u'lumia' u'pro' u'sim' u'microsoftstore.ru' u'u0440.' u'u043du0438' u'u043fu043e' u'dual' u'u0432u043e' u'u043eu0441' u'office' u'3g' u'u043bu0438' u'de' u'nokia' u'hp' u'u0438u043bu0438' u'xbox' u'!microsoft' u'windows' u'06' u'u043fu0440u0438' u'lenovo' u'one' u'u0447u0435u0440u043du044bu0439' u'361254' u'u043du0443' u'microsoft' u'spectre' u'###'nÐxa0ÐµÐ¼Ð¾Ð½Ñx82  u'u043e' u'u0441' u'u043a' u'mcrf' u'u0443' u'|' u'mcrf.ru' u'u043fu043e' u'ati' u'sony' u'os' u'--' u'se' u'u0441u043e' u'u0432u043e' u'alva' u'android' u'htc' u'xperia' u'mi' u'(//www.mcrf.ru/forum/styles/mcrf/images/reputation/reputation_highpos.gif)' u'nics' u'u043bu0438' u'u0436u0435' u'box' u'!alva' u'###' u'u0442u0435u043b' u'u0434u043e' u'u043fu0440u0438' u'ns' u'!nics' u'param' u'wp' u'u0440u0443u0431.'nÐ¡Ð°Ð¹Ñx82Ñx8b Ð¿Ñx80Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñx82ÐµÐ»ÐµÐ¹    u'u043e' u'u0441' u'u043a' u'microsoft' u'u0443' u'store' u'|' u'u043fu043e' u'windows' u'you' u'one' u'search' u'samsung' u'(javascript:void(0))' u'lg' u'(' u'(https://www.microsoft.com' u'u0432u043e' u'xbox' u'office' u'###' u'support' u'htc' u'account' u'u0434u043e' u'javascript' u'&amp;' u'apps' u'+7' u're' u'games' u'mobile' u'phone' u'the' u'lg.com'nÐ¢ÐµÐ»ÐµÐºÐ¾Ð¼ u'u043e' u'u0441' u'u043a' u'tele2' u'tele2.' u'u043fu043e' u'u0434u043e' u'u0440u0435u0433u0438u043eu043d' u'u0443' u'u043du043eu043cu0435u0440u0430' u'u0437u0430u043au0430u0437u0430' u'u0440u0443u0431.' u'|' u'###' u'u0442u0430u0440u0438u0444' u'u0438u043du0442u0435u0440u043du0435u0442-u043cu0430u0433u0430u0437u0438u043d' u'!u0441u0430u0440u0430u0442u043eu0432' u'u0442u0432' u'u043fu0435u0440u0435u0439u0442u0438' u'u043du043eu043cu0435u0440u043eu0432' u'u0431u0438u043bu0430u0439u043d' u'u0438u043du0442u0435u0440u043du0435u0442' u'u0441u043cu0430u0440u0442u0444u043eu043du044b' u'u0433u0431' u'u043fu0435u0440u0435u043du043eu0441' u'u0437u0432u043eu043du043eu043a' u'u043eu0431u043bu0430u0441u0442u044c' u'u0440u0435u0433u0438u043eu043du0430' u'u0441u0430u0440u0430u0442u043eu0432u0441u043au0430u044f' u'u0442u0432u043eu0439' u'####' u'u0441u043cu0430u0440u0442u0444u043eu043d' u'u0438u043du0444u043eu0440u043cu0430u0446u0438u044f(/info)' u'u043fu043bu044eu0441' u'u043eu0431'nÐ¤Ð¾Ñx80Ñx83Ð¼Ñx8b Ð¸ Ð¾Ñx82Ð·Ñx8bÐ²Ñx8b u'u043e' u'u0441' u'u043a' u'u0443' u'u043fu043e' u'u0434u043e' u'u043eu0442u0437u044bu0432' u'u0432u043e' u'u043du0438' u'u0442u0435' u'u043eu0431' u'u0431' u'u0436u0435' u'""u0438u043du0444u043eu0440u043cu0430u0446u0438u044f' u'u043fu043eu043bu044cu0437u043eu0432u0430u0442u0435u043bu0435.""' u'de' u'u0435' u'u043c' u'u0444u043eu0442u043e' u'u043fu043eu043b' u'u0436' u'u043au043e' u'u0438u043c' u'u0432u0441u0435' u'u0441u043e' u'|' u'u043fu0440u0438' u'u0432u043eu043bu043eu0441' u'u0440' u'u0447u0438u0442u0430u0442u044c' u'_3' u'u0431u044b' u'u044du0442u043e' u'u043eu0442u0437u044bu0432u044b' u'u0442u0430u043a'nnnI need to convert column dictionary to lists. These are unicode.nI trynnlsts = df.dictionary.values.tolist()nfor lst in lsts:n    unicode(i) for i in lst.strip('').split('')nnnBut it doesn't help.n' ""Try this:nnrlst = nfor lst in lsts:n    ls0 = lst.strip(' ').split('')n    rlst.append(unicode(l.lstrip(' u'').rstrip(''')) for l in ls0)nnnrlst is your result as a list of lists of unicode strings.n""",['pandas'],"['dictionary', 'python-2.7']"
40081231,"'Testing List of Lists to remove unwanted lists based on a constraint' 'I have a list of lists. The lists are made up of people from certain areas if the lists have too many people from a certain area I would like to remove the list from the set of lists. The lists are lengths of 9nnlist=""Aarat""""California""n""Aaron""""California""n""Abba""""California""n""Abaddon""""California""n""Abner""""Nevada""n""Abram""""Nevada""n""Abraham""""Nevada""n""Absalom""""Nevada""n""Adullam""""Utah""n......n""Abital""""California""n""Abitub""""California""n""Absalom""""Nevada""n""Accad""""Nevada""n""Agar""""Utah""n""Agee""""Utah""n""Aijeleth-Shahar""""New Mexico""n""Ain""""New Mexico""n""Amram""""Washington""nCities=""California""""Nevada""""Utah""""New Mexico""""Idaho""""Washington""ndenk= nfor city in Cities:n    den=n    for i in list:n        a=i0n        b=i1n        c=i2n        d=i3n        e=i4n        f=i5n        g=i6n        h=i7n        k=i8n        if a==city:n            ab=1n        if b==city:n            ac=1n        if c==city:n            ad=1n        if d==city:n            ae=1n        if e==city:n            af=1n        if f==city:n            ag=1n        if g==city:n            ah=1n        if h==city:n            ai=1n        if k==city:n            aj=1n        if (ab+ac+ad+ae+af+ag+ah+ai+aj)>3:n            den.append(1)n        if (ab+ac+ad+ae+af+ag+ah+ai+aj)<4:n            den.append(0)n    denk.append(sum(den))nnfinalList=nfor i j in enumerate(denk):n    if j == 0:n        finalList.append(listi)nnnI attempt to count the amount of people from the city if the amount of people is greater than 3 I try to append a 1 if not 0. I only do this so i can sum up the amount of times the list goes over the quota. nnCities=""California""""Nevada""""Utah""""New Mexico""""Idaho""""Washington""nn""Aarat""""California""n""Aaron""""California""n""Abba""""California""n""Abaddon""""California""n""Abner""""Nevada""n""Abram""""Nevada""n""Abraham""""Nevada""n""Absalom""""Nevada""n""Adullam""""Utah""nnnIn testing this particular list the testing to see how many people are from California would make den=1 because there are more than 3 people from California. The next city Nevada would also make den=1 and so on....nden=110000ndenk=2nSo this list gets thrown outnn""Abital""""California""n""Abitub""""California""n""Absalom""""Nevada""n""Accad""""Nevada""n""Agar""""Utah""n""Agee""""Utah""n""Aijeleth-Shahar""""New Mexico""n""Ain""""New Mexico""n""Amram""""Washington""nnnDoing the same here yields den=0 for each city in Cities den=000000 denk=0 so the list will be accepted.nnThe finalList should not have any lists that have too many people from one place.n' 'Say you start with something like:nnlist=""Aarat""""California""n    ""Aaron""""California""n    ""Abba""""California""n    ""Abaddon""""California""n    ""Abner""""Nevada""n    ""Abram""""Nevada""n    ""Abraham""""Nevada""n    ""Absalom""""Nevada""n    ""Adullam""""Utah""""Abital""""California""n    ""Abitub""""California""n    ""Absalom""""Nevada""n    ""Accad""""Nevada""n    ""Agar""""Utah""n    ""Agee""""Utah""n    ""Aijeleth-Shahar""""New Mexico""n    ""Ain""""New Mexico""n    ""Amram""""Washington""nnnTo find the distribution within each second-level list you could use list comprehension and collections.Counter:nnimport collectionsnn>>> collections.Counter(e1 for e in l) for l in listnCounter({'California': 4 'Nevada': 4 'Utah': 1})n Counter({'California': 2n          'Nevada': 2n          'New Mexico': 2n          'Utah': 2n          'Washington': 1})nnnTo find the most common count within each second-level list you could usenn>>> collections.Counter(e1 for e in l).most_common(1)01 for l in listn4 2nnnSo to retain only second-level lists where the most common count is at most say 3 you could just usenn>>> l for l in list if collections.Counter(e1 for e in l).most_common(1)01 <= 3n'Abital' 'California'n  'Abitub' 'California'n  'Absalom' 'Nevada'n  'Accad' 'Nevada'n  'Agar' 'Utah'n  'Agee' 'Utah'n  'Aijeleth-Shahar' 'New Mexico'n  'Ain' 'New Mexico'n  'Amram' 'Washington'nn'",['list'],['list']
40081270,"'force Django to use new connection everytime' ""I'm using the default database setting for Django and conn_max_age is not set.   Hence it must be taking 0 as default.   nnI would like to force Django to use new connection for each request.   How do I force Django to use a new connection on every request?n"" nan",['django'],['django']
40081489,"'Matplotlib odd subplots' 'I have to plot a figure with 11 subpots as you can see below. But as it is an odd number i dont know how to deal the subplot (4312) to remove it... and place the 2 last plots on the centernMoreover i would like to increse the subplot size as the space is too important. The code is below.nnnnThe code is :nnplt.close()nnfig axes = plt.subplots(nrows=4 ncols=3)nnplt.tight_layout(pad=0.05 w_pad=0.001 h_pad=2.0)nax1 = plt.subplot(431) # creates first axisnax1.set_xticks()nax1.set_yticks()nax1.tick_params(labelsize=8) ni1 = ax1.imshow(IIImcmap='hot'extent=(0200002000)vmin=-0.2vmax=-0.1)ni11 = ax1.plot((0600)(10001000)'k-'linewidth=3)ncb1=plt.colorbar(i1ax=ax1ticks=-0.2-0.15-0.1fraction=0.046 pad=0.04format='%.3f')ncb1.ax.tick_params(labelsize=8)nax1.set_title(""$n = -3$"" y=1.05 fontsize=12)nnnax2 = plt.subplot(432) # creates second axisnax2.set_xticks()nax2.set_yticks()ni2=ax2.imshow(IImcmap='hot'extent=(0200002000)vmin=-0.1vmax=0.1)ni22 = ax2.plot((0600)(10001000)'k-'linewidth=3)nax2.set_title(""$n = -2$"" y=1.05 fontsize=12)nax2.set_xticklabels()nax2.set_yticklabels()ncb2=plt.colorbar(i2ax=ax2ticks=-0.10.00.1fraction=0.046 pad=0.04format='%.3f')ncb2.ax.tick_params(labelsize=8)nnax3 = plt.subplot(433) # creates first axisnax3.set_xticks()nax3.set_yticks()ni3 = ax3.imshow(Imcmap='hot'extent=(0200002000)vmin=-1vmax=-0.2)ni33 = ax3.plot((0600)(10001000)'k-'linewidth=3)nax3.set_title(""$n = -1$ "" y=1.05 fontsize=12)ncb3=plt.colorbar(i3ax=ax3ticks=-1-0.6-0.2fraction=0.046 pad=0.04format='%.3f')nax3.set_xticklabels()nax3.set_yticklabels()ncb3.ax.tick_params(labelsize=8)n#plt.gcf().tight_layout()nnnnnn#plt.tight_layout(pad=0.05 w_pad=0.001 h_pad=2.0)nax1 = plt.subplot(434) # creates first axisnax1.set_xticks()nax1.set_yticks()nax1.tick_params(labelsize=8) ni1 = ax1.imshow(ZV_0_modeIextent=(0200002000)cmap=plt.cm.hotorigin=""lower"" vmin=-1 vmax=1)ni11 = ax1.plot((0600)(10001000)'k-'linewidth=3)ncb1=plt.colorbar(i1ax=ax1ticks=-10 1fraction=0.046 pad=0.04format='%.2f')ncb1.ax.tick_params(labelsize=8)nax1.set_title(""$ n = 0$"" y=1.05 fontsize=12)nnnax2 = plt.subplot(435) # creates second axisnax2.set_xticks()nax2.set_yticks()ni2=ax2.imshow(Icmap='hot'extent=(0200002000) vmin=-1 vmax=1)ni22 = ax2.plot((0600)(10001000)'k-'linewidth=3)nax2.set_title(""$n = 1$"" y=1.05 fontsize=12)nax2.set_xticklabels()nax2.set_yticklabels()ncb2=plt.colorbar(i2ax=ax2fraction=0.046 pad=0.04ticks=-101format='%.2f')ncb2.ax.tick_params(labelsize=8)nnax3 = plt.subplot(436) # creates first axisnax3.set_xticks()nax3.set_yticks()ni3 = ax3.imshow(IIcmap='hot'extent=(0200002000)vmin=-1vmax=1)ni33 = ax3.plot((0600)(10001000)'k-'linewidth=3)nax3.set_title(""$n = 2$ "" y=1.05 fontsize=12)ncb3=plt.colorbar(i3ax=ax3fraction=0.046 pad=0.04ticks=-1.01.format='%.2f')nax3.set_xticklabels()nax3.set_yticklabels()ncb3.ax.tick_params(labelsize=8)nplt.gcf().tight_layout()nnnnnplt.tight_layout(pad=0.05 w_pad=0.001 h_pad=2.0)nax1 = plt.subplot(437) # creates first axisnax1.set_xticks()nax1.set_yticks()nax1.tick_params(labelsize=8) ni1 = ax1.imshow(IIIcmap=plt.cm.hotorigin=""lower""extent=(0200002000)vmin=-1 vmax=1)ni11 = ax1.plot((0600)(10001000)'k-'linewidth=3)ncb1=plt.colorbar(i1ax=ax1ticks=-10 1fraction=0.046 pad=0.04format='%.2f')ncb1.ax.tick_params(labelsize=8)nax1.set_title(""$ n = 3$"" y=1.05 fontsize=12)nnax2 = plt.subplot(438) # creates second axisnax2.set_xticks()nax2.set_yticks()ni2=ax2.imshow(IVcmap='hot'extent=(0200002000) vmin=-1 vmax=1)ni22 = ax2.plot((0600)(10001000)'k-'linewidth=3)nax2.set_title(""$n = 4$"" y=1.05 fontsize=12)nax2.set_xticklabels()nax2.set_yticklabels()ncb2=plt.colorbar(i2ax=ax2fraction=0.046 pad=0.04ticks=-101format='%.2f')ncb2.ax.tick_params(labelsize=8)nnax3 = plt.subplot(439) # creates first axisnax3.set_xticks()nax3.set_yticks()ni3 = ax3.imshow(Vcmap='hot'extent=(0200002000)vmin=-1vmax=1)ni33 = ax3.plot((0600)(10001000)'k-'linewidth=3)nax3.set_title(""$n = 5$ "" y=1.05 fontsize=12)ncb3=plt.colorbar(i3ax=ax3fraction=0.046 pad=0.04ticks=-1.01.format='%.2f')nax3.set_xticklabels()nax3.set_yticklabels()ncb3.ax.tick_params(labelsize=8)nplt.gcf().tight_layout()nnnnnplt.tight_layout(pad=0.05 w_pad=0.001 h_pad=2.0)nax1 = plt.subplot(4310) # creates first axisnax1.set_xticks()nax1.set_yticks()nax1.tick_params(labelsize=8) ni1 = ax1.imshow(VIcmap=plt.cm.hotorigin=""lower""extent=(0200002000)vmin=-1 vmax=1)ni11 = ax1.plot((0600)(10001000)'k-'linewidth=3)ncb1=plt.colorbar(i1ax=ax1ticks=-10 1fraction=0.046 pad=0.04format='%.2f')ncb1.ax.tick_params(labelsize=8)nax1.set_title(""$ n = 6$"" y=1.05 fontsize=12)nnax2 = plt.subplot(4311) # creates second axisnax2.set_xticks(0)nax2.set_yticks()ni2=ax2.imshow(VIIcmap='hot'extent=(0200002000) vmin=-1 vmax=1)ni22 = ax2.plot((0600)(10001000)'k-'linewidth=3)nax2.set_title(""$n = 7$"" y=1.05 fontsize=12)nax2.set_xticklabels()nax2.set_yticklabels()ncb2=plt.colorbar(i2ax=ax2fraction=0.046 pad=0.04ticks=-101format='%.2f')ncb2.ax.tick_params(labelsize=8)nnnplt.savefig('filtre.png' dpi=250bbox_inches='tight' pad_inches=0.1)nnplt.show()nn' 'One way of achieving what you require is to use matplotlibs subplot2grid feature. Using this you can set the total size of the grid (43 in your case) and choose to only plot data in certain subplots in this grid. Below is a simplified example:nnimport matplotlib.pyplot as pltnnx = 12ny = 34nnax1 = plt.subplot2grid((4 3) (0 0))nax2 = plt.subplot2grid((4 3) (0 1))nax3 = plt.subplot2grid((4 3) (0 2))nax4 = plt.subplot2grid((4 3) (1 0))nax5 = plt.subplot2grid((4 3) (1 1))nax6 = plt.subplot2grid((4 3) (1 2))nax7 = plt.subplot2grid((4 3) (2 0))nax8 = plt.subplot2grid((4 3) (2 1))nax9 = plt.subplot2grid((4 3) (2 2))nax10 = plt.subplot2grid((4 3) (3 0))nax11 = plt.subplot2grid((4 3) (3 1))nnplt.subplots_adjust(wspace = 0.3 hspace = 0.3) #make the figure look betternnax1.plot(xy)nax2.plot(xy)nax3.plot(xy)nax4.plot(xy)nax5.plot(xy)nax6.plot(xy)nax7.plot(xy)nax8.plot(xy)nax9.plot(xy)nax10.plot(xy)nax11.plot(xy)nnplt.show()nnnThis produces the figure:nnn'",['matplotlib'],['matplotlib']
40081709,"'Delete first n digits from a column' 'I have a pandas dataframe(roughly 7000 rows) that looks as follows:nnCol1    Col2n12345   1234n678910  6789 nnnI would like to delete the first 4 digits from col1 so as to end up with:nnCol1   Col2n5      1234n10     6789nnnOr just separate the first column in 2 columns.n' ""Separating first column into two new ones:nnIn 5: df'New1''New2' = (df'Col1'.astype(str)n                                         .str.extract(r'(d{4})(d+)' expand=True)n                                         .astype(int))nnIn 6: dfnOut6:n     Col1  Col2  New1 New2n0   12345  1234  1234    5n1  678910  6789  6789   10nnIn 9: df.dtypesnOut9:nCol1    int64nCol2    int64nNew1    int32nNew2    int32ndtype: objectnnnNOTE: this solution will work with Pandas version 0.18.0+n""",['pandas'],['pandas']
40081848,"""I can't iterate over line_styles (Matplotlib)"" 'Plot generates different colors for each lines but I also need to generate different line_styles for the graph. After searching for some information I found itertools module. Yet I can't generate plot with the error: There is no Line2D property ""shape_list"".nnimport itertoolsnfrom glob import globnimport numpy as npnimport matplotlib.pyplot as pltnimport matplotlib as mplnnshape_list = ""square"" ""triangle"" ""circle"" ""pentagon"" ""star"" ""octagon""nn# loop over all files in the current directory ending with .txtnfor fname in glob(""*.txt""):n    # read file skip header (1 line) and unpack into 3 variablesn    WL ABS T = np.genfromtxt(fname skip_header=1 unpack=True)n    g = itertools.cycle(shape_list)n    plt.plot(WL T label=fname0:3shape_list = g.__next__())nnplt.xlabel('Wavelength (nm)')nplt.xlim(2001000)nplt.ylim(0100)nplt.ylabel('Transmittance (%)')nmpl.rcParams.update({'font.size': 12})nplt.legend(loc=4prop={'size':10})nplt.grid(True)n#plt.legend(loc='lower center')nplt.savefig('Transmittance' dpi=600)nn' 'I think that g = itertools.cycle(shape_list) should go outside the loopnnAlso see here for valid markersnWhat you probably want isnnplt.plot(WL T label=fname0:3 marker = g.__next__())n' 'The markers you can use with plot are defined in the documentation nnto change the marker style use the marker= argument to the call to plot()nneg:nnplt.plot(WL T label=fname0:3 marker=g.__next__())nn'",['matplotlib'],['matplotlib']
40081888,"'xgboost plot importance figure size' ""How can I change the figure size of xgboost's plot importance function?nnTrying to pass a figsize=(1020) fails with the exception of unknown attribute.n"" nan",['matplotlib'],['matplotlib']
40082056,"'How to clean a string using python regular expression' 'I have the following string which have to cleannn#import rennaddr=""abcd&^fhj""nproblemchars = re.compile(r'=+/&<>;'""?%#$@. trn')nre.search(problemcharsaddr)nn' 'In that case use re.sub searching W (non-alphanum) and replacing by nothing.nnimport rennaddr=""abcd&^fhj""nprint(re.sub(""W""""""addr))nnn(""W+"" works too but not sure it would be more performant) n' 'you could use the filter function as well if you don't want to go with regexnnline = ""abcd&^fhj""nline = filter(str.isalpha line)nprint line # Change for python3 nnnOutput : nnabcdfhjnnnEdit: For python 3 you could change the print statement like thisnnprint(''.join(list(line)))nn'",['regex'],"['regex', 'python-3.x']"
40082114,"'How to faster compute the count frequency of words in a large words list with python and be a dictionary' ""There is a very long words list the length of list is about 360000. I want to get the each word frequency and to be a dictionary. nnFor example:nn{'I': 50 'good': 30.......}nnnSince the word list is large  I found it take a lot of time to compute it. Do you have faster method to accomplish this?nnMy code so far is the following:nn  dict_pronoun = dict((i lst_all_tweet_noun.count(i)) for i in n                        lst_all_tweet_noun)n  sorted(dict_pronoun)nn"" 'You are doing several things wrong here:nnnYou are building a huge list first then turn that list object into a dictionary. There is no need to use the .. list comprehension; just dropping the  and  would turn it into a much more memory-efficient generator expression.nYou are using dict() with a loop instead of a {keyexpr: valueexpr for ... in ...} dictionary comprehension; this would avoid a generator expression altogether and go straight to building a dictionary.nYou are using list.count() this does a full scan of the list for every element. You turned a linear scan to count N items into a O(N**2) quadratic problem. You could simply increment an integer in the dictionary each time you find the key already is present set the value to 0 otherwise but there are better options (see below).nThe sorted() call is busy-work; it returns a sorted list of keys that is then discarded again. Dictionaries are not sortable not and produce a dictionary again at any rate.nnnUse a collections.Counter() object here to do your counting; it uses a linear scan:nnfrom collections import Counternndict_pronoun = Counter(lst_all_tweet_noun)nnnA Counter has a Counter.most_common() method which will efficiently give you output sorted by counts which is what I suspect you wanted to achieve with the sorted() call.nnFor example to get the top K elements (where K is smaller than N the size of the dictionary) a heapq is used to get you those elements in O(NlogK) time (avoiding a full O(NlogN) sort).n'","['list', 'python-3.x', 'dictionary']","['dictionary', 'list', 'python-2.7']"
40082726,"'Complex pivoting in pandas' ""I have a dataframe like:nn In 4: dfnOut4: n        A        B   C   D      E     F   Gn0   apple   orange  10  20    cat   rat  10n1   apple   orange  10  20    cat   rat  20n2  grapes   banana  22  34    dog  frog  34n3  grapes   banana  22  34    dog  frog  40n4  grapes   banana  22  34    dog  frog  67n5    kiwi  avocado  90  89    ant   fox  76n6   apple   orange  10  20    cat   rat  10n7  cherry     date  56  91  tiger  lion  65nnnMy desired output is like:nnIn 3: dfnOut3: n        A        B   C   D      E     F  G_1  G_2  G_3n0   apple   orange  10  20    cat   rat   10   20    10n1  grapes   banana  22  34    dog  frog   34   40   67n2    kiwi  avocado  90  89    ant   fox   76    0    0n3  cherry     date  56  91  tiger  lion   65    0    0nnnI'm confused and tried a lot with pivot_table but could not figure how to add additional columns depending on values.nThanks for your reply.nEDITnI found a method using groupby but it works only if it is unique:nndf.groupby('A''B''C''D''E''F')'G'.unique()nOut26: nA       B        C   D   E      F   napple   orange   10  20  cat    rat         10 20ncherry  date     56  91  tiger  lion            65ngrapes  banana   22  34  dog    frog    34 40 67nkiwi    avocado  90  89  ant    fox             76nnnthen I will have to split the list into separate columns.nnSuppose if I have two duplicated rows then still I would like to add the value in G as separate column as shown in desired output.How can I include the duplicated values in separate columns.n"" ""Here's one waynnIn 237: dff = (df.groupby('A''B''C''D''E''F')'G'.unique()n   .....:          .apply(pd.Series 1).fillna(0))nnIn 238: dff.columns =  'G_%s' % (x+1) for x in dff.columnsnnIn 239: dffnOut239:n                                  G_1   G_2   G_3nA      B       C  D  E     Fnapple  orange  10 20 cat   rat   10.0  20.0   0.0ncherry date    56 91 tiger lion  65.0   0.0   0.0ngrapes banana  22 34 dog   frog  34.0  40.0  67.0nkiwi   avocado 90 89 ant   fox   76.0   0.0   0.0nn""","['pandas', 'numpy']",['pandas']
40082844,"'slicing series of panels' ""I have a simple dataframe:nn>>> df = pd.DataFrame(np.random.randint(05(20 2)) columns='col1''col2')n>>> df'ind1' = list('AAAAAABBBBCCCCCCCCCC')n>>> df.set_index('ind1' inplace=True)n>>> dfnn      col1  col2nind1            nA        0     4nA        1     2nA        1     0nA        4     1nA        1     3nA        0     0nB        0     4nB        2     0nB        3     1nB        0     3nC        1     3nC        2     1nC        4     0nC        4     0nC        4     1nC        3     0nC        4     4nC        0     2nC        0     2nC        1     2nnnI am trying to get the rolling correlation coefficient of its two columns:nn>>> df.groupby(level=0).rolling(3min_periods=1).corr()nnind1nA    <class 'pandas.core.panel.Panel'>nDimensions: ...nB    <class 'pandas.core.panel.Panel'>nDimensions: ...nC    <class 'pandas.core.panel.Panel'>nDimensions: ...ndtype: objectnnnThe problem is that the result is series of panels:nn>>> type(df.groupby(level=0).rolling(3min_periods=1).corr())nnpandas.core.series.SeriesnnnI am able to get desired coefficient for each row separately...nn>>> df.groupby(level=0).rolling(3min_periods=1).corr()'A'nn<class 'pandas.core.panel.Panel'>nDimensions: 10 (items) x 2 (major_axis) x 2 (minor_axis)nItems axis: C to CnMajor_axis axis: col1 to col2nMinor_axis axis: col1 to col2nn>>> df.groupby(level=0).rolling(3min_periods=1).corr().loc'A'.ix2nn          col1      col2ncol1  1.000000 -0.866025ncol2 -0.866025  1.000000nn>>> df.groupby(level=0).rolling(3min_periods=1).corr().loc'A'.ix2'col1''col2'nn-0.86602540378443849nnn...but I don't know how to slice the result (series of panels) in order to assign the results as a column to existing dataframe.  Something like:nndf'cor_coeff' = df.groupby(level=0).rolling(3min_periods=1).corr()'some slicing'nnnAny clues? Or a better way to get rolling correlation coefficients?n"" 'Your problem is that .corr() is being called without specifying the other argument.  Even though your dataframe only has two columns Pandas doesn't know which correlation you actually want so it calculates all possible correlations (col1 x col1 col1 x col2 col2 x col1 col2 x col2) and gives the results to you in a 2x2 datastructure.  If you want to get the results from one correlation you need to specify the correlation you want by setting the base column and the other column.  If you weren't using groupby you'd just do it this way:nndf'col1'.rolling(min_periods=1 window=3).corr(other=g'col2')nnnSince you're using groupby you need to nest it in an apply clause with a lambda function (or you could move it into a separate function if you preferred):nndf.groupby(level=0).apply(lambda g: g'col1'.rolling(min_periods=1 window=3).corr(other=g'col2'))nn'",['pandas'],['pandas']
40083007,"'Nesting a string inside a list n times ie list of a list of a list' 'def nest(x n):n    a = n    for i in range(n):n        a.append(x)n    return annprint nest(""hello"" 5)nnnThis gives an outputnn'hello' 'hello' 'hello' 'hello' 'hello'nnnThe desired output is nn""hello""nn' 'instead of appending you sould wrap x and call recursively the method till call number is lesser than nnndef nest(x n):n    if n <= 0:n        return xn    else:n        return nest(x n-1)nn' 'Every turn through the loop you are adding to the list. You want to be further nesting the list not adding more stuff onto it. You could do it something like this:nndef nest(x n):n    for _ in range(n):n        x = xn    return xnnnEach turn through the loop x has another list wrapped around it.n' 'Here is a pythonic recursion approach:nnIn 8: def nest(x n):n   ...:     return nest(x n-1) if n else x nnnDEMO:nnIn 9: nest(3 4)nOut9: 3nnIn 11: nest(""Stackoverflow"" 7)nOut11: 'Stackoverflow'nn'","['list', 'python-2.7']",['list']
40083108,"'Adding a table after a Python matplotlib basemap' ""I am creating a map using matplotlib basemap and I want to add a table underneath it (say 4 colums 4 rows) with text in the cells (the text and table is not linked in any way to the basemap). I have not been able to do so with subplots. This is saved as a 1 page pdf. Any suggestions?nnfrom mpl_toolkits.basemap import Basemapnimport matplotlibnmatplotlib.use('Agg')nimport matplotlib.pyplot as pltnnfig = plt.figure(figsize=(11.69*2 8.27*2) dpi=120)nfig.add_axes(0.10.10.80.8)nmap = Basemap(projection='merc' lat_0=57 lon_0=-135 resolution = 'l' area_thresh = 10000 llcrnrlon=-110 llcrnrlat=-50 urcrnrlon=150 urcrnrlat=60)n# A lot of map calls drawing the mapnplt.savefig('map.pdf' bbox_inches='tight')nn"" 'Create two subplots and add a table to the second axe object? See the documentation for Axes.table()nnhttp://matplotlib.org/api/axes_api.html?highlight=table#matplotlib.axes.Axes.tablennn  table(**kwargs) Add a table to the current axes.n  n  Call signature:n  n  table(cellText=None cellColours=Nonen        cellLoc='right' colWidths=Nonen        rowLabels=None rowColours=None rowLoc='left'n        colLabels=None colColours=None colLoc='center'n        loc='bottom' bbox=None): Returns a matplotlib.table.Table instance. n  n  For finer grained control over tables use the Table classn  and add it to the axes with add_table().nn'",['matplotlib'],['matplotlib']
40083118,"'Consecutive elements in a Sparse matrix row' 'I am working on a sparse matrix stored in COO format. What would be the fastest way to get the number of consecutive elements per each row.nnFor example consider the following matrix:nna = 0120100200001010nnnIts COO representation would be nn  (0 1)    1n  (0 2)    2n  (1 0)    1n  (1 3)    2n  (3 0)    1n  (3 2)    1nnnI need the result to be 1202. The first row contains two Non-zero elements that lies nearby. Hence its a group or set. In the second row we have two non-zero elementsbut they dont lie nearby and hence we can say that it forms two groups. The third row there are no non-zeroes and hence no groups. The fourth row has again two non-zeroes but separated by zeroes nad hence we consider as two groups. It would be like the number of clusters per row. Iterating through the rows are an option but only if there is no faster solution. Any help in this regard is appreciated. nnAnother simple example: consider the following row:nn12300020087600nnnThe above row should return 3 sine there are three groups of non-zeroes getting separated by zeroes.n' ""Convert it to a dense array and apply your logic row by row.nnnyou want the number of groups per rownzeros count when defining groupsnrow iteration is faster with arraysnnnIn coo format your matrix looks like:nnIn 623: M=sparse.coo_matrix(a)nIn 624: M.datanOut624: array(1 2 1 2 1 1)nIn 625: M.rownOut625: array(0 0 1 1 3 3 dtype=int32)nIn 626: M.colnOut626: array(1 2 0 3 0 2 dtype=int32)nnnThis format does not implement row indexing; csr and lil donnIn 627: M.tolil().datanOut627: array(1 2 1 2  1 1 dtype=object)nIn 628: M.tolil().rowsnOut628: array(1 2 0 3  0 2 dtype=object)nnnSo the sparse information for the 1st row is a list of nonzero data values 12 and list of their column numbers 12.  Compare that with the row of the dense array 0 1 2 0.  Which is easier to analyze?nnYour first task is to write a function that analyzes one row.  I haven't studied your logic enough to say whether the dense form is better than the sparse one or not.  It is easy to get the column information from the dense form with M.A0:.nonzero().nnIn your last example I can get the nonzero indices:nnIn 631: np.nonzero(12300020087600)nOut631: (array( 0  1  2  6  9 10 11 dtype=int32))nIn 632: idx=np.nonzero(12300020087600)0nIn 633: idxnOut633: array( 0  1  2  6  9 10 11 dtype=int32)nIn 634: np.diff(idx)nOut634: array(1 1 4 3 1 1 dtype=int32)nnnWe may be able to get the desired count from the number of diff values >1 though I'd have to look at more examples to define the details.nnExtension of the analysis to multiple rows depends on first thoroughly understanding the single row case.n""",['python-2.7'],['numpy']
40083181,"'Where is the image being uploaded?' ""I have created a custom User model in django:nnclass CustomUser(AbstractBaseUser PermissionsMixin):n    email = models.EmailField(_('email address') max_length=254 unique=True)n    first_name = models.CharField(_('first name') max_length=30)n    image = models.ImageField(_('profile image') upload_to='userimages/' default = 'user_default.jpeg')nnnNow I have created a serializer for django-rest-framework to register a new user:nnclass UserRegistrationSerializer(serializers.ModelSerializer):n    password = serializers.CharField(style={'input_type': 'password'}n                                     write_only=Truen                                     validators=settings.get('PASSWORD_VALIDATORS'))n    image = serializers.ImageField(max_length=None use_url=True)n    class Meta:n        model = Usern        fields = tuple(User.REQUIRED_FIELDS) + (n            User.USERNAME_FIELDn            User._meta.pk.namen            'image'n            'password'n        )nn    def create(self validated_data):n        if settings.get('SEND_ACTIVATION_EMAIL'):n            with transaction.atomic():n                user = User.objects.create_user(**validated_data)n                user.is_active = Falsen                user.save(update_fields='is_active')n        else:n            user = User.objects.create_user(**validated_data)n        return usernnnMy media settings are:nnimport osnnBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))nMEDIA_ROOT = os.path.join(BASE_DIR 'media')nMEDIA_URL = '/media/'nnnMy 'urls.py':nnurlpatterns = n    url(r'^admin/' admin.site.urls)n    url(r'^' include('app.urls'))n+ static(settings.MEDIA_URL document_root=settings.MEDIA_ROOT)nnnNow when I 'POST' on the /register/ endpoint the User gets created and I am able to see the image in the browser from the url in admin panel. But when I look into my project directory the image is just not there. I am not able to figure out the image location. I am pretty sure that the image gets uploaded in my computer as I tried uploading it from some other device on LAN and was able to access it (from the browser)after disconnecting from the other computer.nnPlease help.n"" ""You're correct that user uploaded files should be stored in MEDIA_ROOT.nnYou can check this location by firing up the Django shell and checking on setting:nn$ python manage.py shelln>>> from django.conf import settingsn>>> settings.MEDIA_ROOTn<< snip: the media root location >>nn"" ""If what you want is just to know your folder's location you can run the following command (In linux-based systems):nnsudo find / -name userimagesnn""",['django'],['django']
40083266,"'Replace comma with dot Pandas' ""Given the following array I want to replace commas with dots:nnarray('0140711' '0140711' '00999' '00999' '0001' '0001'n       '0140711' '0140711' '0140711' '0140711' '0140711'n       '0140711' 0L 0L 0L 0L '0140711' '0140711' '0140711'n       '0140711' '0140711' '01125688' '0140711' '01125688'n       '0140711' '01125688' '0140711' '01125688' '0140711'n       '0140711' '0140711' '0140711' '0140711' '0140711'n       '0140711' '0140711' '0140711' '0140711' '0140711'n       '0140711' '0140711' '0140711' '0140711' '0140711'n       '0140711' '0140711' '0140711' '0140711' dtype=object)nnnI've been trying different ways but I can`t figure out how to do this.nAlso I have as a DataFrame but can't apply the function:nndfn      1-8        1-7nH0   0140711   0140711nH1     00999     00999nH2      0001      0001nH3   0140711   0140711nH4   0140711   0140711nH5   0140711   0140711nH6          0          0nH7          0          0nH8   0140711   0140711nH9   0140711   0140711nH10  0140711  01125688nH11  0140711  01125688nH12  0140711  01125688nH13  0140711  01125688nH14  0140711   0140711nH15  0140711   0140711nH16  0140711   0140711nH17  0140711   0140711nH18  0140711   0140711nH19  0140711   0140711nH20  0140711   0140711nH21  0140711   0140711nH22  0140711   0140711nH23  0140711   0140711 nndf.applymap(lambda x: str(x.replace('''.')))nnnAny suggestion? Thanksn"" 'You need to assign the result of your operate back as the operation isn't inplace besides you can use apply or stack and unstack with vectorised str.replace to do this quicker:nnIn 5:ndf.apply(lambda x: x.str.replace('''.'))nnOut5:n          1-8        1-7nH0   0.140711   0.140711nH1     0.0999     0.0999nH2      0.001      0.001nH3   0.140711   0.140711nH4   0.140711   0.140711nH5   0.140711   0.140711nH6          0          0nH7          0          0nH8   0.140711   0.140711nH9   0.140711   0.140711nH10  0.140711  0.1125688nH11  0.140711  0.1125688nH12  0.140711  0.1125688nH13  0.140711  0.1125688nH14  0.140711   0.140711nH15  0.140711   0.140711nH16  0.140711   0.140711nH17  0.140711   0.140711nH18  0.140711   0.140711nH19  0.140711   0.140711nH20  0.140711   0.140711nH21  0.140711   0.140711nH22  0.140711   0.140711nH23  0.140711   0.140711nnIn 4:    ndf.stack().str.replace('''.').unstack()nnOut4:n          1-8        1-7nH0   0.140711   0.140711nH1     0.0999     0.0999nH2      0.001      0.001nH3   0.140711   0.140711nH4   0.140711   0.140711nH5   0.140711   0.140711nH6          0          0nH7          0          0nH8   0.140711   0.140711nH9   0.140711   0.140711nH10  0.140711  0.1125688nH11  0.140711  0.1125688nH12  0.140711  0.1125688nH13  0.140711  0.1125688nH14  0.140711   0.140711nH15  0.140711   0.140711nH16  0.140711   0.140711nH17  0.140711   0.140711nH18  0.140711   0.140711nH19  0.140711   0.140711nH20  0.140711   0.140711nH21  0.140711   0.140711nH22  0.140711   0.140711nH23  0.140711   0.140711nnnthe key thing here is to assign back the result:nndf = df.stack().str.replace('''.').unstack()n'",['pandas'],['pandas']
40083438,"'Accessing to a dict on a json in python' 'I am trying to assign a value of a dict copied in  JSON to a variable in my code. nThis is the dictionary copied on the .json:nn""Monetarios"": {""MIFID_NO_CURR_RISK"":""B1""}{""MIFID_CURR_RISK"":""B2""}n          ""Monetario Dinamico"": {""MIFID_NO_CURR_RISK"":""B1""}{""MIFID_CURR_RISK"":""B2""}n          ""Renta Fija Corto Plazo"": {""MIFID_NO_CURR_RISK"":""B1""}{""MIFID_CURR_RISK"":""B2""}n          ""Garantizados de RF"": {""MIFID_NO_CURR_RISK"":""B1""}{""MIFID_CURR_RISK"":""B2""}n          ""Renta Fija Largo Plazo"": {""MIFID_NO_CURR_RISK"":""B1""}{""MIFID_CURR_RISK"":""B2""}nnnAnd i am trying to show on screen for example the B1 of MIFID NO CURR RISK from ""Renta Fija Corto Plazo""nnI do this and works fine :nncarga_dict'Renta Fija Corto Plazo'nOut56: {u'MIFID_NO_CURR_RISK': u'B1'} {u'MIFID_CURR_RISK': u'B2'}nnnBut then I do this and i get an errornncarga_dict'Renta Fija Corto Plazo''MIFID_NO_CURR_RISK'nTraceback (most recent call last):nn  File ""<ipython-input-57-46b56ce8491a>"" line 1 in <module>n    carga_dict'Renta Fija Corto Plazo''MIFID_NO_CURR_RISK'nnTypeError: list indices must be integers not strnnnThank you alln' ""carga_dict'Renta Fija Corto Plazo'0'MIFID_NO_CURR_RISK'nnncarga_dict'Renta Fija Corto Plazo' is a list of dictionary. so you have to first select the list element and find the appropriate key.n""",['dictionary'],"['dictionary', 'list', 'python-2.7']"
40083648,"'I want to crawl data from 1 to 10 pages automatically from website.How can i do it?' 'import requestsnfrom bs4 import BeautifulSoupnMy_Url = ""http://questions.consumercomplaints.in/page/2""nData = requests.get(My_Url)nSoup = BeautifulSoup(Data.content)nhead_id = Soup.find_all({""div"":""href""})nlen(head_id)nfor i in head_id:n    print i.text nnnFrom above code i scrapped (reviews/complaints) from web page 2.nHow do i craw data automatically from Page 3 to 10 (http://questions.consumercomplaints.in/page/3) n' 'Why not surround your function in a ranged for loop?nnimport requestsnfrom bs4 import BeautifulSoupnfor i in range(311):n    My_Url = ""http://questions.consumercomplaints.in/page/"" + str(i)n    Data = requests.get(My_Url)n    Soup = BeautifulSoup(Data.content)n    head_id = Soup.find_all({""div"":""href""})n    len(head_id)n    for i in head_id:n        print i.text nnnHave look at how the range function works here.n'",['python-2.7'],"['python-3.x', 'python-2.7']"
40083816,"'trimming a pandas column with regex' 'I have a pandas column that look as follows:nn                                                 Sharesn0     (Code) at End of MonthReason for Alteration No...n1                                                   NaNn2                       (1301)109282837Exercise of CBn3                                    (1332)2772102770n4                                     (1333)526569100n5                                     (1352)837900000n6                                     (1376)117726260n7                                     (1377)484107500n8                                     (1379)333590400n9                                      (1380)41790000n10                                     (1381)56175000n11                                       (1382)7620000n12                                     (1383)12699000n13                (1384)8459000Jun. 28Public Offeringn14                                    (1400)100113000n15                                       (1401)7275000n16                              (1405)0Jun. 28Delistingn17                                    (1407)272352000n18                                      (1408)3239200n19                                    (1414)291025900n20                                    (1417)853818660n21                                    (1418)200105290n22                                    (1419)300558000n23                                    (1420)126200000n24                              (1429)35623000200500nnnand I know this might sound 'crazy' but I am looking to have 2 columns in which I would have: first column(the first 4 values within brackets and the second column the following values. Now the issue is that the some rows turn up wrongly For ex row 13 has Jun28. when 28 is a number so just stripping the text would not work also for ex row 24 has an additional value next to it 200500 that I do not need.nnBasically the second column would need to constitute only number as long as they are 3 decimals after the """"nResult df(hopefully):nnCol1    Col2n1301    109282837n1332    277210277n1333    52656910n.......nn' nan","['regex', 'pandas']",['pandas']
40083846,"'Alternative to deepcopy a lit of BitVectors in python' 'In my project I am using deepcopy() function to create a deep copy a list of BitVectors. Unfortunately its taking a lot of time. nna = <BitVector obj at 0x000...> <BitVector obj at 0x000...> <BitVector obj at 0x000...> ...nnnOn changing a I do not want b to reflect the changes. nnb = deepcopy(a)nnnBut the above equation is taking a lot of time. What alternative should I use for better performance?n' 'The BitVector implementation is pure python and copying could be optimised substantially. Further the provided implementation of BitVector.deep_copy is substantially slower than copy.deepcopy. Here is a an implementation of a deep copy that is ~10 times faster on my machine.nndef bitvector_copy(bitvector):n    new = BitVector.__new__(BitVector)n    new.__dict__ = {n        ""size"": bitvector.size # size is an int and immutablen        ""vector"": bitvector.vector: # vector is an array this is enough to get a deepcopyn        # the copy will be disassociated with any file it originated fromn        # this emulates how BitVector.deep_copy worksn        ""filename"": Nonen        ""FILEIN"": Nonen        ""FILEOUT"": Nonen    }n    return newnnnTo copy your list you would now do:nnnew_list = bitvector_copy(vec) for vec in old_listnnnFor most use cases that should be enough. However this isn't an exact deep copy though. Whilst all the new BitVectors are independent it causes problems if the list contains references to the same bit vector eg.nnold_list = BitVector(size=8) * 2nassert old_list0 is old_list1nnew_list = bitvector_copy(vec) for vec in old_listnassert new_list0 is new_list1 # AssertionError!nnnWith a few modifications you can modify the copy function to work with copy.deepcopy and have the function return a true deep copy. This does slow the copying down a little bit though.nndef bitvector_deepcopy(self memo):n    if id(self.vector) in memo:n        vector = memoid(self.vector)n    else:n        vector = memoid(self.vector) = self.vector:n    new = BitVector.__new__(BitVector)n    new.__dict__ = {n        ""size"": self.sizen        ""vector"": vectorn        ""filename"": Nonen        ""FILEIN"": Nonen        ""FILEOUT"": Nonen    }n    return newnBitVector.__deepcopy__ = bitvector_deepcopynn'",['python-3.x'],"['list', 'python-2.7']"
40084023,"'Remove duplicates from a list of list based on a subset of each list' 'I wrote a function to remove ""duplicates"" from a list of list.nnThe elements of my list are: nnip email phone number.nnnI would like to remove the sublists that got the same EMAIL and PHONE NUMBER I don't really care about the IP address.nnThe solution that I currently use is :nndef remove_duplicate_email_phone(data):n    for i in range(len(data)):n        for j in reversed(range(i+1len(data))):n            if datai1 == dataj1 and datai2 == dataj2 :n                data.pop(j)n    return datannnI would like to optimize this. It took more than 30 minutes to get the result.n' 'Your approach does a full scan for each and every element in the list making it take O(N**2) (quadratic) time. The list.pop(index) is also expensive as everything following index is moved up making your solution approach O(N**3) cubic time.nnUse a set and add (email phonenumber) tuples to it to check if you already have seen that pair; testing containment against a set takes O(1) constant time so you can clean out dupes in O(N) total time:nndef remove_duplicate_email_phone(data):n    seen = set()n    cleaned = n    for ip email phone in data:n        if (email phone) in seen:n            continuen        cleaned.append(ip email phone)n        seen.add((email phone))n    return cleanednnnThis produces a new list the old list is left untouched.n' 'Another solution might be to use groupby.nnfrom itertools import groupbynfrom operator import itemgetternndeduped = nndata.sort(key=itemgetter(12))nfor k v in groupby(data key=itemgetter(12):n    deduped.append(list(v)0)nnnor using a list comprehension:nndeduped = next(v) for k v in groupby(data key=itemgetter(12))nn' 'Another approach could be to use a Counternnfrom collections import Counternndata = (1 ""a@b.com"" 1234) (1 ""a@b.com"" 1234) (2 ""a@b.com"" 1234)ncounts = Counter(i:2 for i in data)nnprint i for i in data if countsi:2 == 1  # Get uniquenn'","['list', 'python-3.x']","['list', 'python-2.7']"
40084353,"'python: importing libpci raises SyntaxError' 'I just installed libpci on my machine:  nn$ pip2.7 install libpcinnnAnd tried to run this:  nn#!/usr/local/bin/python2.7nimport libpcinnprint('hello libpci')nnnbut this raises the following syntax error:nnTraceback (most recent call last):n  File ""./test.py"" line 2 in <module>n    import libpcin  File ""/usr/local/lib/python2.7/site-packages/libpci/__init__.py"" line 26 in <module>n    from libpci.wrapper import LibPCIn  File ""/usr/local/lib/python2.7/site-packages/libpci/wrapper.py"" line 26 in <module>n    from libpci._functions import pci_allocn  File ""/usr/local/lib/python2.7/site-packages/libpci/_functions.py"" line 39n    def pci_alloc() -> ctypes.POINTER(pci_access):n                    ^nSyntaxError: invalid syntaxnnnHow is it possible to have SyntaxError raised in libpci?nIs it because I am missing some dependencies? n' 'The libpci project requires Python 3.4 or newer. From the project tags:nnnCategoriesn...nProgramming Language :: Python :: 3nProgramming Language :: Python :: 3.4nnnnThe syntax error is thrown because the project uses annotations a Python 3 feature to configure the ctypes layer see the _ctypes_metadata() function.n'",['python-2.7'],"['python-3.x', 'python-2.7']"
40084424,"'pyexcel export error ""No content file name. Nothing is given""' 'I'm using django-pyexcel to export data from the website but when I go to the export URL I get the error:nnn  Exception Type: IOErrorn  n  Exception Value: No content file name. Nothing is givennnnThe code to export the data was copied from the example given in the documentation:nnreturn excel.make_response_from_a_table(Question 'xls' file_name=""sheet"")nn' ""The problem turned out to be the file format used xls in this case.nnI had only installed the xlsx (pyexcel-xlsx) processor so it did not know how to handle the xls file format.nnThe exception message could have been a bit better as I spent ages trying to figure out if there was a problem with the filename I'd supplied.n""",['django'],['django']
40084589,"'Setting low_memory to false while reading a mixed dtype 2.5GB csv file using Pandas is not working' ""Still Getting memory error. I tried setting engine='python' as well which is not working. Also it is taking up more than 32 GB of RAM. Is there an alternate solution?n"" nan",['pandas'],['pandas']
40084676,"'Change 1*140 dataframe to 7*20 dataframe in python pandas' 'How can I change the data-frame structure in python preferably using pandas?nnCurrently I have data as indexed and it is 1 column and 140 rows. The data is captured in a way such that every 8th value is in the similar category so basically I need to change the dimension of my pandas data-frame from 1*140 to 7*20. I also need to assign the column name.nnWhile trying to do same since my data is in list I get below errornnn  ValueError: Shape of passed values is (1 140) indices imply (7 140) nnnThe code used is as below:nndef convertDF(list_reviewDtls):ndf = pd.DataFrame(list_reviewDtls columns =""Review_URL""""Review""""Profile_URL""""Name""""Age""""Gender""""HomeTown"")ndf.to_csv('list.csv')nnnAny help will be appreciated.nThanksn' nan",['pandas'],['pandas']
40084822,"'Python RegEx in-text slash escape' ""I apologize for the incoherent title but it's hard to come up with one in this situation.nnI have a bunch of texts and (almost) always they start either like this:nnWord (Foo) - Main Textnnnor this:nnWord (Foo/Bar) - Main TextnnnI want to remove everything before the Main Text but it seems like the / character is messing up the regex I have.nnSo far I have this: re.search('^^)*/*)(.*)$' my_text)nnI've tested it on the regex101 site and it should work on both instances (either with or without the /) However when I plug it in my Python code it returns a NoneType when it encounters a /. What am I missing?n"" ""Do:nn^^-*-s*(.*)nnnNow only captured group is your desired portion.nnn^^-* matches substring upto first -n- matches a literal - s* matches zero or more whitespacenThe only captured group (.*) matches rest of the stringnnnExample:nnIn 10: s = 'Word (Foo/Bar) - Main Text'nnIn 11: re.search(r'^^-*-s*(.*)' s).group(1)nOut11: 'Main Text'nn""",['regex'],['regex']
40084931,'Taking subarrays from numpy array with given stride' 'Lets say I have a Python Numpy array array a.nnnumpy.array(1234567891011.)nnnI want to create a matrix of sub sequences from this array of length 5 with stride 3. The results matrix hence will look as follows:nnnumpy.array(12345456787891011)nnnOne possible way of implementing this would be using a for-loop.nnresult_matrix = np.zeros((3 5))nfor i in range(0 len(a) 3):n  result_matrixi = ai:i+5nnnIs there a cleaner way to implement this is Numpy?n' 'Approach #1 :  Using broadcasting -nnnrows = ((a.size-L)//S)+1nout = aS*np.arange(nrows):None + np.arange(L)nnnApproach #2 : Using more efficient NumPy strides -nnn = a.strides0nout = np.lib.stride_tricks.as_strided(a shape=(nrowsL) strides=(S*nn))nnnSample run -nnIn 183: anOut183: array( 1  2  3  4  5  6  7  8  9 10 11)nnIn 184: L = 5 # lengthnnIn 185: S = 3 # stridennIn 186: nrows = ((a.size-L)//S)+1nnIn 187: aS*np.arange(nrows):None + np.arange(L)nOut187: narray( 1  2  3  4  5n        4  5  6  7  8n        7  8  9 10 11)nnIn 188: n = a.strides0nnIn 189: np.lib.stride_tricks.as_strided(a shape=(nrowsL) strides=(S*nn))nOut189: narray( 1  2  3  4  5n        4  5  6  7  8n        7  8  9 10 11)nn',['numpy'],['numpy']
40085009,'Django Zinnia allow users to add entries' 'Ok so Django Zinnia ( http://docs.django-blog-zinnia.com/en/develop/) currently has the option to add entries but for superusers only and from the admin page. I am new to Django and I am looking for a way to allow normal users to add entries(draft status preset categories etc.). I have seen this question posted 2 times already here but no answer.. Can anybody help me with this please?  n' nan,['django'],['django']
40085062,"'Django Generic ForeignKey' ""i have three models named company admin and jobpost . Here Both company and admin can post the job. So i would like to implement generic foreignkey in post model .nnclass Admin(models.Model):n   id = models.AutoField(primary_key=True)nnclass Company(models.Model):n   id = models.UUIDField(primary_key=True default=uuid.uuid4 editable=False)nnclass JobPost(models.Model):n    content_type = models.ForeignKey()n    object_id = models.PositiveIntegerField()n    post_by = GenericForeignKey('content_type' 'object_id')nnnhere id of Admin is integer and id of Company is UUID.nIs it possible to implement a generic foreignkey in this case.n"" nan",['django'],['django']
40085140,"'Python AmazonAPI Error 503 Service Unavailable' 'Using AmazonApi for python gives me error 503. It is really strange as the same script has worked until three days ago. Since then it gives error 503. I did some research and found that amazon fires 503 when too many requests are submitted for a second. I do process an item every 5 seconds I do want to get price and name and I have even the lazy sleep(1) between them. nI saw someone suggested to use headers in order to make it work but it still doesn't.nnamazon_uk = AmazonAPI('credentials' region=""UK"")nheaders = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML like Gecko) Chrome/51.0.2704.106 Safari/537.36'}nnthen I do take the name and price by :nnNAME = amazon_uk.lookup(ItemId=url).titlensleep(1)nSALE_PRICE = amazon_uk.lookup(ItemId=url).price_and_currencynnnwhere url is taken from a file. nStrange thing is sometimes it goes up to the 30th item sometimes it crashes only at the 1st. nP.S. even if I put sleep everywhere it still fires the error.nDoes someone encountered it? nnThanksn' nan",['python-3.x'],['python-2.7']
40085300,"'How to smooth lines in a figure in python?' 'So with the code below I can plot a figure with 3 lines but they are  angular. Is it possible to smooth the lines? nnimport matplotlib.pyplot as pltnimport pandas as pdnn# Dataframe consist of 3 columnsndf'year' = '2005 2005 2005 2015 2015 2015 2030 2030 2030'ndf'name' = 'A' 'B' 'C' 'A' 'B' 'C' 'A' 'B' 'C'ndf'weight' = 80 65 88 65 60 70 60 55 65nfigax = plt.subplots()nn# plot figure to see how the weight develops through the yearsnfor name in 'A''B''C':n    ax.plot(dfdf.name==name.yeardfdf.name==name.weightlabel=name)nnax.set_xlabel(""year"")nax.set_ylabel(""weight"")nax.legend(loc='best')nn' 'You should apply interpolation on your data and it shouldn't be ""linear"". Here I applied the ""cubic"" interpolation using scipy's interp1d. Also note that for using cubic interpolation your data should have at least 4 points. So I added another year 2031 and another value too all weights (I got the new weight value by subtracting 1 from the last value of weights): nnHere's the code: nnimport matplotlib.pyplot as pltnimport pandas as pdnfrom scipy.interpolate import interp1dnimport numpy as npnn# df'year' = '2005 2005 2005 2015 2015 2015 2030 2030 2030'n# df'name' = 'A' 'B' 'C' 'A' 'B' 'C' 'A' 'B' 'C'n# df'weight' = 80 65 88 65 60 70 60 55 65nndf1 = pd.DataFrame()ndf1'Weight_A' = 80 65  60 59ndf1'Weight_B' = 65 60  55 54ndf1'Weight_C' = 88 70  65 64ndf1.index = 2005201520302031nnnax = df1.plot.line()nax.set_title('Before interpolation')nax.set_xlabel(""year"")nax.set_ylabel(""weight"")nnf1 = interp1d(df1.index df1'Weight_A'kind='cubic')nf2 = interp1d(df1.index df1'Weight_B'kind='cubic')nf3 = interp1d(df1.index df1'Weight_C'kind='cubic')nndf2 = pd.DataFrame()nnew_index = np.arange(20052031)ndf2'Weight_A' = f1(new_index)ndf2'Weight_B' = f2(new_index)ndf2'Weight_C' = f3(new_index)ndf2.index = new_indexnnax2 = df2.plot.line()nax2.set_title('After interpolation')nax2.set_xlabel(""year"")nax2.set_ylabel(""weight"")nnnplt.show()nnnAnd the results: nnnn'","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40085333,"'Size of list and string' 'I am trying to fetch the size of list in bytes and also size of string in bytes.nnIf we see the output below for the code size of list is shown as 52 bytes where as when I join the list and check the size output is 35 bytes. At last I tried to get size of string ""Iamtestingsize"" the output was again 35 bytes. So size of string after ""join"" and also size of string  ""Iamtestingsize"" is same.nnI have 2 questions here:nn1) why is the size of list showing a different output ? also please let me know if you have any idea on how to fetch the size of contents of list ?nn2) I thought 1 byte == 1 character and I was expecting size of strings msgstr and string will show as 14 bytes instead of 35. Please let me know if am missing anything here ?nn3) when I perform len() on list and strings for msgstr and string - 14 was returned whereas length of list returned 4 which is as I expected. nnimport sysnnlist = 'I' 'am' 'testing' 'size'nprint sys.getsizeof(list)nmsgstr = """".join(list)nprint ""size of msgstr is "" + str(sys.getsizeof(msgstr))nprint msgstrnstring = ""Iamtestingsize""nprint ""size of str is "" + str(sys.getsizeof(string))nprint len(list)nprint len(msgstr)nprint len(string)nnOutput:nn52nsize of msgstr is 35nIamtestingsizensize of str is 35n4n14n14nnnNote: I am using python 2.7n' 'nA list (any list) data structure requires additional maintenance overhead to keep elements inside it. This overhead is reflected in the difference of the results of getsizeof.nPython strings are a text sequence type - str and not C strings or anything alike. Same as Python lists there is associated metadata involved beyond the contents of the string alone:nnnnnPython 2.7.10 (default Jul 30 2016 18:31:42)nGCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34) on darwinnType ""help"" ""copyright"" ""credits"" or ""license"" for more information.n>>> import sysn>>> sys.getsizeof(b'asd')n40n>>> sys.getsizeof('asd')n40n>>> sys.getsizeof(u'asd')n56nnnnnnThe length of a string is intuitively defined as the number of characters in it.nn'",['python-2.7'],"['list', 'python-2.7']"
40085339,'Aggregating a dataframe to give the sum of values' 'I tried to group data based on multiple fields but the groupby is not coming in a perfect dataframennComgroup Cd Geo IMT Best Remit Name Q1  Q2  Q3  Q4  TotalnIT Product  AP  ANZ AVNET   0   0   0   823.09  823.09nIT Product  AG  ANZ TOSHIBA 0   0   5065.4  237060.72   242126.12nIT Product  EMEA    ANZ LENOVO  126664.47   0   0   113285.78   239950.25nIT Product  AP  ANZ LENOVO  196154.85   0   1122.15 10252.13    207529.13nnnI wrote the code as below and was the grouping has come in a totally different pattern. nnf = {'Q1':'sum'  'Q2':'sum'  'Q3':'sum'  'Q4':'sum' 'Total':'sum'} ntotal_spendfinal = total_spendfinal.groupby('Geo''IMT''Spend Type''Spend List').agg(f)nnnImage of how the dataframe looks like is attached. n' 'Need to do total_spendfinal.reset_index(inplace=True) n',['pandas'],['pandas']
40085367,"'Which scipy function should I use to interpolate from a rectangular grid to regularly spaced rectangular grid in 2D?' ""I pretty new to python and I'm looking for the most efficient pythonic way to interpolate from a grid to another one.nThe original grid is a structured grid (the terms regular or rectangular grid are also used) and the spacing is not uniform.nThe new grid is a regularly spaced grid. Both grids are 2D. For now it's ok using a simple interpolation method like linear interpolation pheraps in the future I could try something different like bicubic.nnI'm aware that there are methods to interpolate from an irregular grid to a regular one however given the regular structure of my original grid more efficient methods should be available.nnAfter searching in the scipy docs I have found 2 methods that seem to fit my case:  scipy.interpolate.RegularGridInterpolator and scipy.interpolate.RectBivariateSpline.nI don't understand the difference between the two functions which one should I use?nIs the difference purely in the interpolation methods? Also while the non-uniform spacing of the original grid is explicitly mentioned in RegularGridInterpolator RectBivariateSpline doc is silent about it.nnThanksnnAndrean"" ""RectBivariateSplinennImagine your grid as a canyon where the high values are peaks and the low values are valleys. The bivariate spline is going to try to fit a thin sheet over that canyon to interpolate. This will still work on irregularly space input as long as the x and y array you supply are also irregularly spaced and everything still lies on a rectangular grid.nnRegularGridInterpolatornnSame canyon but now we'll linearly interpolate the surrounding gridpoints to interpolate. We'll assume the input data is regularly space to save some computation. It sounds like this won't work for you. nnNow What?nnBoth of these map 2D-1D. It sounds like you have an input space with irregular but rectangularly space sample points and an output space with regularly spaced sample points. You might just try LinearNDInterpolator since you're in 2D it won't be that much more expensive.nnIf you're trying to interpolate a mapping between two 2D things you'll want to do two interpolations one that interpolates (x1 y1) -> x2 and one that interpolates (x1 y1) -> y2. nnVstacking the output of those will give you an array of points in your output space. nnI don't know of a more efficient method in scipy for taking advantage of the expected structure of the interpolation output given an irregular grid input.n""",['numpy'],['numpy']
40085390,"'Find pd.DataFrame cell that has the value of None' ""I have a pd.DataFrame that looks like this:nnindex  A        Bn0      apple    bearn0      axis     Nonen0      ant      Nonen0      avocado  Nonennnand my goal is to simple drop those row if they have None in the B column.nnI tried dfdf'B' != None but pandas returns me the exact same DataFrame without deleting the rows. And dfdf'B' == None gives only an empty DataFrame.nnIs this the correct way of trying to match the None value? I am not sure what is going on but test = None and then test == None works fine (returns True). Any thoughts are appreciated!n"" 'You could try this:nndf.dropna(subset=""B"")nn'",['pandas'],['pandas']
40085432,"'Python Kivy: Creat an editable List with 2 Colums' 'I am working on an Python Programm which sends Data to an Arduino. But at first he need to collect some data:WorktimeCylcusCyclus_temp and Cyclus_time. For the graphic interface i use Kivy. In the first screen he get the first 2 data but my problem is to creat an 2 collum list which ist editable: It should take the nummber from cyclus so that you can enter for each cyclus a time and a temperature.nnMy Current main.py:nnimport kivynkivy.require('1.7.0')nnfrom kivy.app import Appnfrom kivy.lang import Buildernfrom kivy.uix.boxlayout import BoxLayoutnfrom kivy.properties import ObjectPropertynfrom kivy.uix.textinput import TextInputnfrom kivy.uix.screenmanager import ScreenManager Screennncyclus = 0nworktime = 0nBuilder.load_file('layout.kv')nnclass start_screen(Screen):n    passnclass time_temp(Screen):n    passnnsm = ScreenManager()nnsm.add_widget(start_screen(name = 'Start Bildschirm'))nsm.add_widget(time_temp(name = 'time_temp'))nnnnclass Thermocycler(App):nn    def build(self):n        return smnn    def next(selfworktimecyclus):n        print(worktime)n        print(cyclus)n        sm.current = 'time_temp'n        self.load_kv(""layout.kv"")nnnnnnnif __name__ == '__main__':n    Thermocycler().run()nnnAnd the layout.kvnn#:import label kivy.uix.labeln#:import sla kivy.adapters.simplelistadaptern<start_screen>:n    BoxLayout:nn        Label:n            text: ""Anzahl der Zyklen""n            size: self.texture_sizen        Label:n            text: ""Gesamtdauer""n            size: self.texture_sizen        TextInput:n            id: cyclusn            text: 'Anzahl der Zyklen'nn        TextInput:n            id: worktimen            text: 'Gesamtdauer'   nn        Button:n            id: furthern            text: ""Weiter""n            on_release: app.next(worktime.textcyclus.text)nn<time_temp>:n    BoxLayout:n        ListView:n            adapter:n                sla.SimpleListAdapter(n                data=""Zyklus#{0}"".format(i) for i in range(6)n                cls=label.Label)nn        Button:n            id: furthern            text: ""Weiter""n            on_release: app.next(worktime.textcyclus.text)nnnI would be happy about any helpnnGrettings Tobiasn' nan",['python-3.x'],['python-2.7']
40085447,'Pandas: compare two dataframe and intersect that' 'I need to compare two dataframennID  year    month1  month2  month3  month4  month5  month6  month7ng01dotdufkbdugr3    2015    4                       ng01vyqllk8psrpke    2014        6   7   8   10      ng02c1uauj2n8ndal    2015    1   2   3   4   5   6   ng0372f0jg45130xh    2014    10  11  12              nnnamd nnID   year   month1  month2  month3  month4  month5ng02c1uauj2n8ndal    2015    5   6   7   8           ng01bhucu7pssewrl    2014    6   7   8   9   ng01lclje9q1xp4ro    2014    5               ng02gnfa3upxlg2tk    2015        9   10      nnnAnd I need to get nn    ID   year   month1  month2  month3  month4  month5ng02c1uauj2n8ndal    2015    7   8           ng01bhucu7pssewrl    2014    6   7   8   9   ng01lclje9q1xp4ro    2014    5               ng02gnfa3upxlg2tk    2015        9   10nnnI need to get dataframe that is out of intersection of this dataframes.nIs any way to do it?n' nan,['pandas'],['pandas']
40085536,"'Accessing dictionary keys&values via list of keys and values' 'This is going to be a very embarrassing first post from me - just coming back to coding in Python after learning basics ~6 months ago and not using it since then.nnI am coding a Blackjack game in object oriented approach and defined a Deck object as shown below:nnclass Deck(object):n    suits = ""spades"" ""clubs"" ""diamonds"" ""hearts""n    ranks = ""2"" ""3"" ""4"" ""5"" ""6"" ""7"" ""8"" ""9"" ""10"" ""Jack"" ""Queen"" ""King"" ""Ace""nndef __init__(self):n    self.spades = {""2"": 0 ""3"": 0 ""4"": 0 ""5"": 0 ""6"": 0 ""7"": 0 ""8"": 0 ""9"": 0 ""10"": 0 ""Jack"": 0 ""Queen"": 0 ""King"": 0 ""Ace"": 0}n    self.clubs = {""2"": 0 ""3"": 0 ""4"": 0 ""5"": 0 ""6"": 0 ""7"": 0 ""8"": 0 ""9"": 0 ""10"": 0 ""Jack"": 0 ""Queen"": 0 ""King"": 0 ""Ace"": 0}n    self.diamonds = {""2"": 0 ""3"": 0 ""4"": 0 ""5"": 0 ""6"": 0 ""7"": 0 ""8"": 0 ""9"": 0 ""10"": 0 ""Jack"": 0 ""Queen"": 0 ""King"": 0 ""Ace"": 0}n    self.hearts = {""2"": 0 ""3"": 0 ""4"": 0 ""5"": 0 ""6"": 0 ""7"": 0 ""8"": 0 ""9"": 0 ""10"": 0 ""Jack"": 0 ""Queen"": 0 ""King"": 0 ""Ace"": 0}nnnAfterwards I wanted to create a neat method which would initiate this deck by filling all 4 dictionaries holding count of ranks in each suit by writing something like below (that's the reason for class attributes I defined above:nndef initialize_deck(self):n    for suit in self.suits:n        for rank in self.ranks:n            self.suitrank = 1nnnThe problem is the code just does not do what I think it should be doing (as in e.g.: pulling first suit from self.suits list using it as a name of the dictionary iterating over all its keys and setting their associated values to 1). Instead I just get an error ""AttributeError: 'Deck' object has no attribute 'suit'"".nnWhat am I doing wrong in here? Is there a neat way of writing what I have in mind with 2 nested loops instead of writing it like below?nndef initialize_deck(self):n    for rank in self.ranks:n        self.spadesrank = 1n    for rank in self.ranks:n        self.clubsrank = 1n    for rank in self.ranks:n        self.diamondsrank = 1n    for rank in self.ranks:n        self.heartsrank = 1nnnThanks in advance for answers to what I know is probably a very basic problem.nnCheersn' 'You can use getattr function do get attribute from objectnndef initialize_deck(self):n    for suit in self.suits:n        suit_dict = getattr(self suit)n        for rank in self.ranks:n            suit_dictrank = 1nnnOr you can do it using setattrnndef initialize_deck(self):n    rank_map = {key: 1 for key in self.ranks}n    for suit in self.suits:n        setattr(self suit rank_map.copy())nn'",['dictionary'],"['dictionary', 'list']"
40085542,"'How to use Python main() function in GAE (Google App Engine)?' 'I'd like to use a main() function in my GAE code (note: the code below is just a minimal demonstration for a much larger program hence the need for a main()).nnIf I use the following code it performs as expected:nnimport webapp2nnclass GetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in GET')nnclass SetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in SET')nnapp = webapp2.WSGIApplication(n    ('/get'    GetHandler)n    ('/set'    SetHandler)n debug=True)nnnwhere my app.yaml is:nnruntime: python27napi_version: 1nthreadsafe: truennhandlers:n- url: /.*n  script: main.appnnnHowever I cannot figure out how to implement a main() function and still have app act as it does in the code at the top. Namely the following:nn# with main()nimport webapp2nnclass GetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in GET')nnclass SetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in SET')nndef main():n    app = webapp2.WSGIApplication(n        ('/get'    GetHandler)n        ('/set'    SetHandler)n     debug=True)nnif __name__ == '__main__':n    main()nnngives the following error for http://localhost:8080/get:nn$ dev_appserver.py .nINFO     2016-10-17 11:29:30962 devappserver2.py:769 Skipping SDK update check.nINFO     2016-10-17 11:29:31059 api_server.py:205 Starting API server at: http://localhost:45865nINFO     2016-10-17 11:29:31069 dispatcher.py:197 Starting module ""default"" running at: http://localhost:8080nINFO     2016-10-17 11:29:31073 admin_server.py:116 Starting admin server at: http://localhost:8000nERROR    2016-10-17 11:29:37461 wsgi.py:263 nTraceback (most recent call last):n  File ""/home/.../sdk/platform/google_appengine/google/appengine/runtime/wsgi.py"" line 240 in Handlen    handler = _config_handle.add_wsgi_middleware(self._LoadHandler())n  File ""/home/.../sdk/platform/google_appengine/google/appengine/runtime/wsgi.py"" line 302 in _LoadHandlern    raise errnImportError: <module 'main' from '/home/.../main.pyc'> has no attribute appnINFO     2016-10-17 11:29:37496 module.py:788 default: ""GET /get HTTP/1.1"" 500 -nnnEdit 1nnTrying:nn# with main()nimport webapp2nnapp = webapp2.RequestHandler()nnclass GetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in GET')nnclass SetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in SET')nndef main():n    global appn    app = webapp2.WSGIApplication(n        ('/get'    GetHandler)n        ('/set'    SetHandler)n     debug=True)n    return appnnif __name__ == '__main__':n    app = main()nnnResults in:nnINFO     2016-10-17 12:30:34751 module.py:402 default Detected file changes:n  /home/openstack/googleAppEngine/fastsimon/task2/task2_with_main/main.pynERROR    2016-10-17 12:30:42328 wsgi.py:279 nTraceback (most recent call last):n  File ""/home/openstack/googleAppEngine/google-cloud-sdk/platform/google_appengine/google/appengine/runtime/wsgi.py"" line 267 in Handlen    result = handler(dict(self._environ) self._StartResponse)nTypeError: 'RequestHandler' object is not callablenINFO     2016-10-17 12:30:42335 module.py:788 default: ""GET /get HTTP/1.1"" 500 -nn' 'GAE apps are not designed to be standalone apps a main() function doesn't make a lot of sense for them.nnBasically GAE apps are really just collections of handler code and rules/configurations designed to extend and customize the behaviour of the generic GAE infra/sandbox code so that it behaves your app. You can see that from your backtrace - other code is invoking your handler code (and the stack before reaching your code can be a lot deeper than that).nnIn your particular case the app variable must be a global in main.py to match the script: main.app config line in the app.yaml config file. This is what the traceback is about.nnAs for organizing the code for huge apps there are other ways of doing it:nnnsplitting the app in multiple modules/services each with their own app.yaml config file. For example: Can a default module in a Google App Engine app be a sibling of a non-default module in terms of folder structure?nsplitting a service/module into multiple ""scripts"" - primary entry points into the app.yaml file similar to your main.py file each with their own app config` - which really are just mappers between routes and handlers. For example: App Engine throws 404 Not Found for any path but rootnsplitting the handlers for one app mapper into multiple files using webapp2's lazy loaded handler technique. Examples:nnnApp Engine: Few big scripts or many small ones?nWhat determines start up time of dynamic instance and can it vary between weeks if code is same nnnnIn an extreme case a main.py file could contain just the app variable - that is really the only requirement.n' ""Seems that the solution was quite simple (it kept eluding me because it hid in plain sight): __name__ is main and not __main__!nnIn short the following code utilises a main() as expected:nn# with main()nimport webapp2nnclass GetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in GET')nnclass SetHandler(webapp2.RequestHandler):n    def get(self):n        self.response.headers'Content-Type' = 'text/plain'n        self.response.write('in SET')nndef main():n    global appn    app = webapp2.WSGIApplication(n        ('/get'    GetHandler)n        ('/set'    SetHandler)n     debug=True)nn# Note that it's 'main' and not '__main__'nif __name__ == 'main':n    main()nn""",['python-2.7'],['python-2.7']
40085589,"'python 2.7 unicode greek characters using matplotlib' 'I have this coode to plot a figure:nnplt.plot(xy color = ""blue"" label = u'u03C9')nnnï¿¼nThe unicode don't work in plot label but it works when I trynnprint(u'u03C9')nnnThank's in advance.n' 'Run plt.legend() to show the labels.nnYou can see a working version here: https://gist.github.com/davidbrai/742de3cb7def6da8f125e4572e691ee4n'",['matplotlib'],['matplotlib']
40085728,"'Using regex to match words and numbers with whitespaces' 'I am trying to create a regex pattern that would match the following:nnUpdated x word wordnnnx = being a number e.g. 2nnI have tried the following:nn(Updatedsdswsw)nnnFor example I would like: Updated 2 mins ago to match.nnBut it doesn't seem to work: http://regexr.com/3ef05n' 'You need to use quantifiers to show that the digit and word groups can consist of more than one character:nn(Updatedsd+sw+sw+)nnnThis works: http://regexr.com/3ef08n' 'Try this :nn(Updatedsd+sw+sw+)nnnThe + means ""one or more characters of this type"" which is probably what you need here.nnSee it here : http://regexr.com/3ef0bn'","['regex', 'python-2.7']",['regex']
40085735,"'Median of each columns in python' ""I am trying to find median of each column of my list in python. Here is my code snippet-nnX_train1=np.array(X_train1).astype(np.float)nmedian1= X_train1.median(axis=0)nnnBut I am getting the following error-nnAttributeError: 'numpy.ndarray' object has no attribute 'median'nnnHere is my X_train1 array-nn  100.           100.           100.         ...   100.           100.n    100.        n    91.56786232    96.62190102    98.08459941 ...   100.4891341n     99.60223361    93.26315789n    92.90859973    97.64075269   103.1123983  ...    96.08483893n     99.20446722    86.42105263n ... n  1193.656511      43.95921162   204.9478628  ...   260.0710993n    196.0911803     12.53894737n  1199.482215      44.61122178   207.833733   ...   266.2309527n    196.7031286     12.66526316n  1226.497073      44.64553811   209.5192855  ...   267.744815n    199.6481297     13.01894737nn"" 'You should use np.median.  e.g.:nnnp.median(X_train1axis=0)nn'",['numpy'],['numpy']
40085759,"'Importing dictionaries into python script?' 'So i am creating a very basic text based game however i want the answers the program gives to be relatively correct in response to different inputs. Instead of having to tell the program to write a specific thing for each different answer i want to be able to import a dictionary of types into the script and have keywords for the different groups of words (like negative and positive connotations). Is this possible? Everything i have read hasn't really answered my question or done what i wanted...nnmy mock up scripts below:nnDiction included:nna=raw_input(""Are you well?"")nif a=='yes':n    print(""Good to hear."")nelif a=='yep"":n     print(""Good to hear!"")  nn #I don't want to put it all in manually or use 'or'nelif a=='no':n    print(""That's not good!"")nelif a=='nope':n    print(""That's not good!"")nelse:n    print(""Oh."")nnnwith dictionary:nnmydiction.pynnNegConns=('no''nope''never''No''Nope') n#'no' etc. is what the user inputs NegConns is the keywordnPosConns=('yes''sure''okay''fine''good')nnntestmod.pynnimport mydictionnquestion=raw_input(""How are you?"")nif question== NegConns:n    print(""That's not good."")nelif question==PosConns:n    print(""Good to hear."")nelse:n    print(""oh."")nnnSo basically if the input is negative the program is sympathetic if the input is positive the program congratulates. I'm not sure if this is possible for exactly what i'm wanting or if i'm going about this the wrong way and i can't seem to find help so i'm putting it out there... Thanks in advance.n' 'This is almost correct except you want to tweak your import statement a bit:nnfrom mydiction import NegConns PosConnsnnnand change your equality tests to array-membership tests like so:nnif question in NegConns: ornif question in PosConns:nnnAlso you should check out https://docs.python.org/3/tutorial/controlflow.html#default-argument-values. The example code snippet looks almost exactly like the problem you're trying to solve.nnAdditionally consider using dictionaries or sets instead of lists/tuples. You should get the benefit of O(1) lookup while using the in operator on dictionaries/sets.n' ""I think that's OK but you could create a list with the Negative and Positive answers and check it during the if statement. See how it works:nn    negativeAnswers = 'No''Nope''I don't think so'n    positiveAnswers = 'Yeah' 'Yes' 'Of Course'nnquestion1 = raw_input('How are you?')nnif question.lowercase() in positiveAnswers;n    print('Nice to hear that!')nelif question.lowercase() in negativeAnswers:n    print('Oh')nelse:n    print('Sorry. I didn't understand you. :(')nnnI hope it helped you.n"" 'Let's say your directory structure is as:nn--my_project    # Your directory containing the filesn    -| mydiction.pyn    -| testmod.pynnnAdd a __init__.py in my_project directory to make it as python module. Now your project structure will be like:nn--my_project   n    -| __init__.pyn    -| mydiction.pyn    -| testmod.pynnnNow in order to import from mydiction.py to testmod.py you have to mention in your testmod.py as:nnfrom mydiction import NegConns PosConnsnn'",['python-2.7'],"['dictionary', 'python-2.7']"
40085783,"'Python : Data extraction from xml file' 'Given the following file of xml which stores the values of vehicles trip info. How can I generate a cumulative traveled distance over each time step as a .text file. There is no specific order in the xml it's all random.    nn<tripinfos>n        <tripinfo id=""1"" depart=""1.00"" arrival=""2"" duration=""1.00"" distance=""3""/>n        <tripinfo id=""5"" depart=""2.00"" arrival=""4"" duration=""2.00"" distance=""5""/>n        <tripinfo id=""10"" depart=""5.00"" arrival=""8"" duration=""3.00"" distance=""1""/>n        <tripinfo id=""3"" depart=""3.00"" arrival=""6"" duration=""3.00"" distance=""2""/>n        <tripinfo id=""8"" depart=""8.00"" arrival=""10"" duration=""2.00"" distance=""4""/>n</tripinfos>nnnoutput.textfilenn0 //Time step #0n0n3n3n8n8n10n10n11n11n15nn' 'I'm sure there's a better solution that uses an xml library but here's an easy onennimport numpy as npnna = open('file.xml')nlines = a.readlines()nnmy_arr = np.zeros((len(lines)-22))nfor i in range(len(lines1:-1)):n    contents=linesi+1.split('""')n    my_arri0=(eval(contents5))n    my_arri1=(eval(contents9))nn#Now sort according to arrival timesnmy_arr = (my_arrmy_arr:0.argsort())nprint(my_arr)nnfinal_output=ncum_dist=0nlast_index=0nnfor i in range(int(my_arr-10)+1):n    if(i == my_arrlast_index0):n        cum_dist+=my_arrlast_index1n        last_index+=1n    final_output.append(int(cum_dist))nnprint(final_output)nnp.savetxt('outputfile.txt'np.array(final_output) newline=''fmt='%s')na.close()nnnYour output is nn  2.   3.n   4.   5.n   6.   2.n   8.   1.n  10.   4.n0 0 3 3 8 8 10 10 11 11 15nn' 'I ended up using a dict to store each arrival time and since I know the max arrival time I can initalize the key with a range.nnimport xml.etree.ElementTree as ETnnfilepath = r'tripinfo.xml'ntree = ET.parse(filepath)nroot = tree.getroot()nmydict = {k: for k in range(7202)}nnfor trip in root.iter('tripinfo'):n    arrived = int(float(trip.get('arrival')))n    distance = float(trip.get('distance'))n    mydictarrived.append(distance)nnmysum = 0nnoutputfilepath = 'travelledDuration.txt'noutputfile = open(outputfilepath 'a')nfor i in range(7202):n    distanceList = mydictin    mysum += sum(distanceList)n    outputfile.write(str(mysum)+""n"")noutputfile.close()nn' 'Here I offer a partial solution to your problem.nn# import some packagesnfrom numpy import arraynimport xml.etree.ElementTree as etnn# init some listsnids=ndepart=narrival=nduration=ndistance=nn# prep the xml documentnxmltxt = """"""n    <root>n        <tripinfo id=""1"" depart=""1.00"" arrival=""2"" duration=""1.00"" distance=""3""/>n        <tripinfo id=""5"" depart=""2.00"" arrival=""4"" duration=""2.00"" distance=""5""/>n        <tripinfo id=""3"" depart=""3.00"" arrival=""6"" duration=""3.00"" distance=""2""/>n        <tripinfo id=""10"" depart=""5.00"" arrival=""8"" duration=""3.00"" distance=""1""/>n        <tripinfo id=""8"" depart=""8.00"" arrival=""10"" duration=""2.00"" distance=""4""/>n    </root>n""""""nn# parse the xml textnxmldoc = et.fromstring(xmltxt)nn# extract and output tripinfo attributesn# collect them into listsnfor item in xmldoc.iterfind('tripinfo'):n    att=item.attribn    ids.append(int(att'id'))n    depart.append(float(att'depart'))n    arrival.append(float(att'arrival'))n    duration.append(float(att'duration'))n    distance.append(float(att'distance'))nn# put lists into an np.arrayn# and transpose it    narr=array(ids depart arrival duration distance).Tnn# sort array by 'depart' column. (index=1)narr = arrarr:1.argsort()nnsumdist=0ndept=0nprint ""depart: %s; Sum_dist= %s"" % ( dept sumdist )nfor ea in arr:n    sumdist += ea4 # distancen    dept = ea1  # departn    # get 'arrival' 'duration' here so thatn    # you can use them to manipulate and get your exact solutionn    print ""depart: %s; Sum_dist= %s"" % ( dept sumdist )nnnThe output isnndepart: 0; Sum_dist= 0ndepart: 1.0; Sum_dist= 3.0ndepart: 2.0; Sum_dist= 8.0ndepart: 3.0; Sum_dist= 10.0ndepart: 5.0; Sum_dist= 11.0ndepart: 8.0; Sum_dist= 15.0nn'",['python-2.7'],['numpy']
40085792,'A secure serialization module like TrustedPickle with the capabilities of dill' 'Is there any Python 3 module for serialization which provides the trust relation and PKI signing capabilities of TrustedPickle and can serialize instances of objects like dill.n' nan,['python-3.x'],['python-3.x']
40085844,"""Python: How to 'refresh' random variables"" 'I have this code i want to know if there is anyway i can get rid of all these variables and instead only have one for each purpose. My code is a password generator with three different password strengths. Code will work without this but for design sake i want to make it smaller. I've tried making them functions but that didn't work.  I'm probably missing something obvious:nnimport timenimport randomnimport stringnnps = """"nname = """"nans1 = """"nlist_s = ""!""""Â£""""~""""%""""*""""(""""}""""#"""";""""@""""/"""":""""-""nlist_w = ""mouse""""human""""dog""""tree""""boom""""thief""""killer""""dealer""""feeler""""man""""woman""""death""nlist_w2 =""help""""yelp""""empire""""squire""""lier""""fryer""""kitchen""""bed""""matress"" ""criminal""""drug""nnrc1 = random.choice(string.ascii_lowercase)nrc2 = random.choice(string.ascii_lowercase)nrc3 = random.choice(string.ascii_lowercase)nrc4 = random.choice(string.ascii_lowercase)nrc5 = random.choice(string.ascii_uppercase)nrc6 = random.choice(string.ascii_uppercase)nrc7 = random.randrange(10)nrc8 = random.randrange(10)nrc9 = random.randrange(10)nrc10 = random.choice(list_s)nrc11 = random.choice(list_s)nrc12 = random.choice(list_w)nrc13 = random.choice(list_w2)nnwhile name == """":n    name = str(input(""Welcome to password64 before we begin enter your name:""))nwhile ans1 == """":n    ans1 = str(input(""Have you used password64 before "" + name + "" ?""))nnans1 = ans10.lower()nnif ans1 == ""n"":n    print (""Thank you for trying  password64 for the first time "" + name + "" !"")n    time.sleep(4)n    print (""I will ask you the strength of the password you want there will be three options: Strong Medium or Weak"")n    time.sleep(6)n    print (""A strong password is a mix of random numbers letters and symbols"")n    time.sleep(3)nprint (""A medium password will be a couple of words with random numbers and symbols"")n    time.sleep(3)n    print (""A weak password will be a couple of words with a number"")nelif ans1 == ""y"":n    print (""Thank you for reusing password64 "" + name + "" !"")n    time.sleep(2)n    print (""Let's get straight on with it then"")nnnwhile ps == """":n    ps = str(input(""Do you with to generate a strong medium or weak password?""))n    ps = ps0.lower()nnif ps == ""s"":n    a = rc1  rc2 rc3 rc4 rc5 rc6 rc7 rc8 rc9 rc10 rc11nelif ps == ""m"":n    a = rc12 rc13 rc7 rc8 rc10 rc11nelif ps == ""w"":n    a = rc12 rc13 rc7nelse:n    print (""You did not enter a valid password strength"")n    exit()nnrandom.shuffle(arandom.random)nnprint (""Your password is generating...."")nnfor i in range(0len(a)):n    time.sleep(1)n    print (ai end="""")nprint ("""")nprint (""Your password is ready to be used "" + name + "". Thank you for using    password64"")nn' 'why don't you put the randoms into a function?nnf.e.nn# -*- coding: cp1252 -*-nimport stringnimport randomnimport timennrandom_type = (""lower""""upper""""digit""""strange""""wordlist1""""wordlist2"")nnlist_s = ""!""""Â£""""~""""%""""*""""(""""}""""#"""";""""@""""/"""":""""-""nlist_w = ""mouse""""human""""dog""""tree""""boom""""thief""""killer""""dealer""""feeler""""man""""woman""""death""nlist_w2 =""help""""yelp""""empire""""squire""""lier""""fryer""""kitchen""""bed""""matress"" ""criminal""""drug""nndef random_part(which_type):n    if which_type == ""lower"":n        return random.choice(string.ascii_lowercase)n    elif which_type == ""upper"":n        return random.choice(string.ascii_uppercase)n    elif which_type == ""digit"":n        return str(random.randrange(10))n    elif which_type == ""digit"":n        return str(random.randrange(10))n    elif which_type == ""strange"":n        return random.choice(list_s)n    elif which_type == ""wordlist1"":n        return random.choice(list_w)n    else:n        return random.choice(list_w2)nndef generate_pw(password_strength):n    if password_strength == 'w':n        l = 'wordlist1''wordlist2''digit'n    elif password_strength == 'm':n        l = 'wordlist1''wordlist2''digit''digit''strange''strange'n    else:n        l = 'wordlist1''wordlist2''digit''digit''strange''strange''lower''upper'  #whatever you want tonn    result = n    for x in l:n        result.append(random_part(x))n    return resultnnprint generate_pw('s')nnnby the way: you could use only one word list if you would eliminate the Chosen value from list. So you could use more than 2 words in your Password. Same you could do with strange chars so every char could only appear once.nAnd jaou could shuffle the result.nBut it is your decisionn'",['list'],"['list', 'python-3.x', 'python-2.7']"
40085850,"'Matplotlib axis not displayed' ""The python code (python 2.7) running on windows 7 shown below results in the following inconsistent behaviour with respect to the display of axis which I do not understand:nn1 - a window is opened and a plot without an axis is displayed showing a pointn2 - on closing the window another window is opened and a plot is displayed showing the same point but this time with an axis. nnfrom osgeo import ogrnimport pylabnfrom ospybook.vectorplotter import VectorPlotternnvp = VectorPlotter(False)nnmyLoc = ogr.Geometry(ogr.wkbPoint)nnmyLoc.AddPoint(59.513)nvp.plot(myLoc'rs')npylab.show() ## the plot is displayed --without-- axes displayednnmyLoc.AddPoint(59.513)nvp.plot(myLoc'rs')npylab.show() ## the plot is displayed with axes displayednnnPlease note that in my environment if the vector plotter interactive mode is set to True pylab.show() opens  window but no plot is displayed.n"" 'try nnvp = VectorPlotter(interactive=False ticks=True)nn'",['matplotlib'],"['matplotlib', 'python-2.7']"
40086091,"'Error: Errno 71 Protocol error: pyvenv' ""I am using Centos7 with vagrant and virtualbox on windows10.nI am trying to create pyvenv virtual environment to develop python web apps with django. I have installed python 3.4. nnHowever when I type npyvenv-3.4 name_of_environmentnit gives back an error Error: Errno 71 Protocol error: 'lib' -> '/vagrant/django_apps/app1/name_of_environment/lib64'nnWhat is wrong?n"" 'pyvenv-3.4 --without-pip name_of_environmentnworkednnlooks like pip was not installed.nnthanks for the help.n'","['django', 'python-3.x']",['django']
40086386,"'Pandas to_sql() not working with Posgresql - value too long for type character varying' 'I'm using Pandas with SQLAlchemy to apply some ETL on one CSV filennAfter validating the fields and transforming some of them I try to export to my PostgreSQL database but I'm getting one error which does not make sense:nnsqlalchemy.exc.DataError: (psycopg2.DataError) value too long for type character varying(50)nnnI already changed the field to many values (it was initially setup as 15). I tried to get NaN values for that field and replacing with '' (there was only one field). For that I used:nn>>> df.locdf'foo'.isnull() 'foo' = ''nnnI tried changing the chunksize to 5000 and 1000. Initially it was not set.nn>>> df.to_sql(""mytable"" con index=False if_exists='append' chunksize=1000)nnnThe command above worked with sqlitennAfter having those problems I checked the column which was throwing the error again to see if there was any problem with its length. Apparently it did not but I ran the following code anyway:nn>>> df.foo.str.len().max() n11.0nnnI also tried the following:nn>>> df.fillna(value='' inplace=True)n>>> df'foo' = df'foo'.str.strip()nnnThen I also addednnfor f in Inventory._meta.get_fields():n    if f.get_internal_type() == 'CharField':n        dff.name = dff.name.str:f.max_lengthnnnBut it did not work eithernnI finally put the length of the column to 100 but this is not right. The field contains only 11 char per row. I ran out of ideas. This error is strange and I'd appreciate some help.n' ""Ok it's pretty embarrassing what happened. The code above was right since the beginning. The problem is that I'm merging some rows and concatenating in that column the merged values in a different function and I forgot. I thought the error was only in my validation function when it was never there.nnWhat did I do to find it out?nnI change the value of the column to a big value (100) so the code above would work then I ran the following SQL:nnSELECT length(foo) AS ln_foo FROM inventory WHERE length(foo) > 11nn""","['django', 'pandas']",['pandas']
40086415,"'Tryng to run 2 Python applications with different Python versions with mod_wsgi' ""I have in my Apache 2 applications: Django app and MoinMoin app. The first one is running now with Python3.4 and the second one (MoinMoin) with Python2.7nnWhen running dpkg:nnruben@babylon:/var/log/apache2$ dpkg -l | grep wsginrc  libapache2-mod-wsgi                   3.4-4ubuntu2.1.14.04.2                amd64        Python WSGI adapter module for Apachenii  libapache2-mod-wsgi-py3               3.4-4ubuntu2.1.14.04.2                amd64        Python 3 WSGI adapter module for Apachennnbut Apache can't run the 2 modules at the same time. Django (Python3) is working but MoinMoin (Python2.7) not. How can I fix that?nnThanks.n"" 'As you were told already in:nnnVirtual environment not recognized in WSGIPythonPathnnnyou cannot do that within a single Apache instance.nnThe simple answer as was described is to run a separate WSGI server such as mod_wsgi-express or you can use gunicorn our something else as well and set it up behind the main Apache instance it with Apache proxying to it.nnThere are a lot of details around doing this and as also suggested you are better off asking on the mod_wsgi mailing list if you want to do this with mod_wsgi.nnIf don't wish to use the mod_wsgi mailing list then you can find some information in:nnnhttp://blog.dscpl.com.au/2015/06/proxying-to-python-web-application.htmlnhttp://blog.dscpl.com.au/2015/07/redirection-problems-when-proxying-to.htmlnnnIt talks about proxying to backend WSGI application running in Docker but all the same principles apply as to setting up the proxy fronted and the issues that arise.n'",['django'],['django']
40086419,"'python calculations are being weird' 'Am having some problems with my code. I need to limit an input by multiples of 5 under a changing maximum.nnWith what I have now it should work but it isn't. What have i missed?nnwhile True:n        print(""Place your bet. Must be a multiple of 5"")n        posBets = range(5 (balance + 1) 5)n        bet = str(input())n        if bet == posBets:n            print(""You have bet $"" + str(bet))n            loop = 0n        elif bet != posBets:n                print(""Please bet an amount that is a multiple of 5 or an amount that is within your balance"")n                print(""Press enter to continue"")n                input()n                loop = 1n        if not(loop == 1):break #Exit loopnnnthere is also a problem with a loop. When im trying to get my new value it needs to subtract from the original value and send it back to the main function however it always adds it then doenst change the value that it sends to the mainnnwin = 1nlose = 2ntie = 3nr = win or lose or tienprint(""Battle shall now commence"")nprint(""Choose an attack"")nprint(""The attacks you can use are as follows"")nprint(""(1)Fury Punch"")nprint(""(2)Punishment kick"")nprint(""(3)Sword of justice"")nprint(""(4)Shuriken of Vengence"")nprint(""(5)Numchucks of Anger"")nprint(""(6)Knife of Freedom"")nattack = int(input())nwhile attack < 1 or attack > 6:n    print(""please input either: 1 2 3 4 5 or 6"")n    attack = int(input())nwinLose(attack win lose tie)nif r == win:n    newBalance = int(balance) + int(bet)nelif r == lose:n    newBalance = int(balance) - int(bet)nelse:n    if r == tie:n        balance = newBalance nprint(""Your Balance is $"" + str(newBalance))nreturn(bet newBalance)nnnhere is the full codenthank you for any helpnndef attack1(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""it is a tie there is no winner"")n    r = tienelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""You have lost"")n    r = losenelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""You have lost"")n    r = losenelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""You have won. Good job"")n    r = winnelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""You have lost"")n    r = losenreturn(r)nndef attack2(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""it is a tie there is no winner"")n    r = tienelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""You have lost"")n    r = losenelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""You have lost"")n    r = losenelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""You have won. Good job"")n    r = winnelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""You have lost"")n    r = losenreturn(r)nndef attack3(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""it is a tie there is no winner"")n    r = tienelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""You have lost"")n    r = losenelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""You have lost"")n    r = losenelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""You have won. Good job"")n    r = winnreturn(r)nndef attack4(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""You have lost"")n    r = losenelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""it is a tie there is no winner"")n    r = tienelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""You have lost"")n    r = losenelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""You have won. Good job"")n    r = winnreturn(r)nndef attack5(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""You have lost"")n    r = losenelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""You have lost"")n    r = losenelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""it is a tie there is no winner"")n    r = tienelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""You have lost"")n    r = losenreturn(r)nndef attack6(pcMove win tie lose):nif pcMove == 1:n    print(""Your opponent has choosen Fury Punch"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 2:n    print(""Your opponent has choosen Punishment Kick"")n    print(""You have won. Good job"")n    r = winnelif pcMove == 3:n    print(""Your opponent has choosen Sword of Justice"")n    print(""You have lost"")n    r = losenelif pcMove == 4:n    print(""Your opponent has choosen Shuriken of Vengeance"")n    print(""You have lost"")n    r = losenelif pcMove == 5:n    print(""Your opponent has choosen Numchucks of Anger"")n    print(""You have won. Good job"")n    r = winnelse:n    print(""Your opponent has choosen Knife of Freedom"")n    print(""it is a tie there is no winner"")n    r = tienreturn(r)nndef winLose(attack win tie lose):nimport randomnpcMove = random.randint(1 6);nwhile pcMove == 0:n    pcMove = random.randint(1 6);nif attack == 1:n    print(""You have choosen to use Fury Punch. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack1(pcMove win tie lose)n    r = win or lose or tienelif attack == 2:n    print(""You have choosen to use Punishment Kick. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack2(pcMove win tie lose)n    r = win or lose or tienelif attack == 3:n    print(""You have choosen to use Sword of Justice. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack3(pcMove win tie lose)n    r = win or lose or tienelif attack == 4:n    print(""You have choosen to use Shuriken of Vengence. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack4(pcMove win tie lose)n    r = win or lose or tienelif attack == 5:n    print(""You have choosen to use Numchucks of Anger. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack5(pcMove win tie lose)n    r = win or lose or tienelse: n    print(""You have choosen to use Knife of Freedom. Good Luck"")n    print(""Ready for battle. Press enter to start"")n    enter = input()n    attack6(pcMove win tie lose)n    r = win or lose or tienreturn(r)nndef instructions(name):nprint(""Welcome to Ultimate Ninja Combat!!!"" + name)nprint(""You will be playing against the computer and the winner gets bragging rights. Before each match you will have to place a bet which must be an amount which must be a multiple of 5. if you win you get that amount back from the computer. if you lose you lose the money. if your amount drops to zero you will be removed from the game"")nprint(""you will start with 100 dollars use it wisely"")nprint(""Each turn you will be asked to pick one of the following attacks"")nprint(""(1)Fury Punch"")nprint(""(2)Punishment kick"")nprint(""(3)Sword of justice"")nprint(""(4)Shuriken of Vengence"")nprint(""(5)Numchucks of Anger"")nprint(""(6)Knife of Freedom"")nprint(""choose wisely"")nprint(""  "")nprint(""  "")nprint(""  "")nndef gameplay(balance):nwhile True:n    print(""Place your bet. Must be a multiple of 5"")n    posBets = range(5 (balance + 1) 5)n    bet = str(input())n    if bet == posBets:n        print(""You have bet $"" + str(bet))n        loop = 0n    elif bet != posBets:n            print(""Please bet an amount that is a multiple of 5 or an amount that is within your balance"")n            print(""Press enter to continue"")n            input()n            loop = 1n    if not(loop == 1):break #Exit loopn    return(bet)nwin = 1nlose = 2ntie = 3nr = win or lose or tienprint(""Battle shall now commence"")nprint(""Choose an attack"")nprint(""The attacks you can use are as follows"")nprint(""(1)Fury Punch"")nprint(""(2)Punishment kick"")nprint(""(3)Sword of justice"")nprint(""(4)Shuriken of Vengence"")nprint(""(5)Numchucks of Anger"")nprint(""(6)Knife of Freedom"")nattack = int(input())nwhile attack < 1 or attack > 6:n    print(""please input either: 1 2 3 4 5 or 6"")n    attack = int(input())nwinLose(attack win lose tie)nif r == win:n    newBalance = int(balance) + int(bet)nelif r == lose:n    newBalance = int(balance) - int(bet)nelse:n    if r == tie:n        balance = newBalance nprint(""Your Balance is $"" + str(newBalance))nreturn(bet newBalance)nndef menu(name):n    balance = 100n    while True:n        newBalance = balancen        print(""Your current balance is $"" + str(balance))n        print(""Choose an option "" + name)n        print(""(I)nstructions"")n        print(""(P)lay game"")n        print(""(Q)uit game"")n        print(""Please Input IP or Q"")n        menuChoice = input()            n        if menuChoice == ""i"" or menuChoice == ""I"":n            instructions(name)n            loop = 1n        elif menuChoice == ""p"" or menuChoice == ""P"":n            gameplay(balance)nn            loop = 1n            print(""Press enter to contiue"")n            enter = input()n        elif menuChoice == ""q"" or menuChoice == ""Q"":n            loop = 0n        else:                   n            print(""I did not understand the response. Please Input I P or Q"")n            print(""Press enter to continue"")n            enter = input()n            loop = 1n        if not(loop == 1): break    #Exit loopn    return(menuChoice)nndef main():nprint(""Welcome to Ultimate Ninja Combat!!! What is your name?"")nname = input()nprint (""Welcome "" + name)nmenu(name)nnnmain() n' 'Your bet = str(input()) converts the number into a string which is why it can never equal the range. nnEven if it was an int a number cannot equal a range.nnWhat you want is nn    bet = int(input())n    if bet in posBets:nnnthe rest of the code seems full of errors to me: nnnfunctions need to be indented when definednsaying stuff like r = win or lose or tie after saying win=1 lose=2 tie=3 is basically asking r=1 or 2 or 3 which is always 1 because 1 evaluates as True and or stops as soon as it gets a True (just like and stops if it gets a False)nn'",['python-3.x'],['python-3.x']
40086641,"'Convert python list of string to bytearray' 'I would write a list on serial COM through pySerial.nnI create a list of string where each string is a parameter and then I pass the list to serial write function. There is an error because I cannot write list of string directly on serialnnThis is my code:nnimport datetimenimport timenimport sysnimport serialnndate = datetime.datetime.now()ndateStr = str(date.strftime('%d-%m-%Y'))nunixTime = int(time.time())ncrc = str(""1234"")nnnpacket = list()nnpacket.append('test')npacket.append(dateStr)npacket.append(unixTime)npacket.append('4')npacket.append('81')npacket.append('1')npacket.append('0')nnpacket.append('00.7')npacket.append('4')npacket.append('9')npacket.append('0')nnpacket.append('18.8')npacket.append('5')npacket.append('3')npacket.append('0')nnpacket.append('15.3')npacket.append('4')npacket.append('6')npacket.append('0')nnpacket.append('2')npacket.append('0')npacket.append('13')npacket.append('0')nnpacket.append('0')npacket.append('0')npacket.append('185.6')nn# add semicolon between list elementsnserialCOM.write(packet)nnnIs there a way to concatenate each list elements into a list or bytearray?nnFurthermore I need to add a semicolon between each list elements.nnThanks for the help!n' ""If you want an actual bytearray object pass the list into the bytearray constructor. nnserialCOM.write(bytearray(packet))nnnNote that unixTime is not converted to a string so you must convert that first.nnBut what you probably want (based on the comment about semicolons) is to just join the strings using the join method of a string like this:nn# Force all items in the list to be stringsnmsg = ';'.join(map(strpacket))nserialCOM.write(msg)nnnThe result of the join is then:nnIn50: ';'.join(map(strpacket))nOut50: 'test;17-10-2016;1476708605;4;81;1;0;00.7;4;9;0;18.8;5;3;0;15.3;4;6;0;2;0;13;0;0;0;185.6'nn""",['python-2.7'],"['list', 'python-2.7']"
40086963,'How to split the whole text when there can only be 2 arguments when doing python?' 'nnI tried to figure out the word frequency by writing this code but got stuck in the splitting partcan anyone tell me why there's an error and how to split the text into single words?n' nan,['python-2.7'],['python-2.7']
40087054,"'Is there a way to pin an exe in taskbar using python' ""I'm extracting an zip folder contains an EXE file using python. Once extracted I want to pin the EXE file to the task bar. Is there a way to do that using python?n"" 'Programs aren't supposed to do this in the first place; there is no supported way to do it even with an installer so Python isn't going to be any more supported. If you forcibly pin your program your program is a bad actor.n'",['python-3.x'],['python-2.7']
40087182,"'Drawing flags while generating random circle' 'For my program I am generating clear random circles. I need to colour certain parts of the window in order to recreate the Sweden flag. I thought about using while loops to describe certain areas (like if x < whatever) to colour it either blue or yellow? I'm a little lost on how to get started so any hints could be really helpful! Thank you! nn# using the SimpleGraphics librarynfrom SimpleGraphics import *nn# use the random library to generate random numbersnimport randomnn# size of the circlesndiameter = 15nnn##n# sets the name of the output windown# sets the size of the output windown#n# you can change thesen##nsetWindowTitle(""Flag of Poland"")nresize(800500)nnnnn##n# returns a vaid color based on the input coordinatesn#n# @param x is an x-coordinate n# @param y is a y-coordinate n# @return a colour based on the input xy values for the given flagn##ndef define_colour(xy):nn  return Nonennn# repeat until window is closedn# do NOT change anything in this while loopnwhile not closed():nn  # generate random x and y values n  x = random.randint(0 getWidth())n  y = random.randint(0getHeight())nn  # set colour for current circlen  setFill( define_colour(xy) )nn  # draw the current circlen  ellipse(x y diameter diameter)nn' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40087192,"'""LookupError: Couldn't find path to unrar library"" on Win10' 'I have installed unrar library by using pip install unrar which installed unrar-0.3.nAfter compiling my code using unrar library in pydev-eclipse I am getting the following error message:nnFile ""C:Python27libsite-packagesunrarunrarlib.py"" line 57 in <module>nraise LookupError(""Couldn't find path to unrar library."")nLookupError: Couldn't find path to unrar library.nnnI have looked over in C:Python27libsite-packagesunrarunrarlib.py and there its written:nnlib_path = os.environ.get('UNRAR_LIB_PATH' None)nn# find and load unrar librarynunrarlib = Nonenif platform.system() == 'Windows':n    from ctypes.wintypes import HANDLE as WIN_HANDLEn    HANDLE = WIN_HANDLEn    UNRARCALLBACK = ctypes.WINFUNCTYPE(ctypes.c_int ctypes.c_uintn                                       ctypes.c_long ctypes.c_longn                                       ctypes.c_long)n    lib_path = lib_path or find_library(""unrar.dll"")n    if lib_path:n        unrarlib = ctypes.WinDLL(lib_path)nelse:n    # assume unixnnnI cannot find the unrar.dll anywhere. Whereas the installation is done correctly. I don't know how to fix it. On my previous computer(win7 platform) it was working without any errors.n' 'You should download the UnRAR.dll Library from http://www.rarlab.com/rar/UnRARDLL.exe and extract it anywhere in your PATHnnEdit: You should set the UNRAR_LIB_PATH environment variable with the location of unrar.dllnnEdit2: As a last resort:nnnextract UnRARDLL.exe into C:Program Files (x86)UnrarDLLnif you're using Python2.7 64bit select UnRAR64.dll and UnRAR64.lib files from C:Program Files (x86)UnrarDLLx64 and rename them to unrar.dll and unrar.libncopy them in C:WindowsSystem32.nif you're using a 32bit version of python simply copy unrar.dll and unrar.lib from C:Program Files (x86)UnrarDLL to C:WindowsSystem32nn'",['python-2.7'],['python-2.7']
40087376,"'Python JSON List to Get Data and Retrieve Column Name' 'I am a newbie and can't find the answer so apologies in advance if this is a repeat question.nnI'm accessing a historical metal prices api that returns a dictionary of lists.  The first item in the list is the column names and the rest is data that falls under those column headers.nnI'm trying to write code that will return the Date and Cash Buyer values for all dates on record.nnHere's what I've written so far.  I've tried several dictionary and list methods and have not been able to get this to work.  I'm sure it's me.nnThe URL is purposefully restricted to 1 row (rows=1) for this posting and stripped of my API key.  However this URL will work for anyone but is rate limited without an API key:nnimport urllibnimport jsonnurl = ""https://www.quandl.com/api/v1/datasets/LME/PR_CU.json?rows=1""nresponse = urllib.urlopen(url)ndata = json.loads(response.read())nnnHere's a sample output as is:nn{n""code"": ""PR_CU""n""column_names"": n    ""Date""n    ""Cash Buyer""n    ""Cash Seller & Settlement""n    ""3-months Buyer""n    ""3-months Seller""n    ""15-months Buyer""n    ""15-months Seller""n    ""Dec 1 Buyer""n    ""Dec 1 Seller""n    ""Dec 2 Buyer""n    ""Dec 2 Seller""n    ""Dec 3 Buyer""n    ""Dec 3 Seller""nn""data"": n    n        ""2016-10-14""n        4672.0n        4672.5n        4691.0n        4692.0n        4730.0n        4740.0n        nulln        nulln        nulln        nulln        nulln        nulln    nn""description"": ""LME Official Prices in""display_url"": nulln""errors"": {}n""frequency"": ""daily""n""from_date"": ""2012-01-03""n""id"": 19701916n""name"": ""Copper Prices""n""premium"": falsen""private"": falsen""source_code"": ""LME""n""source_name"": ""London Metal Exchange""n""to_date"": ""2016-10-14""n""type"": nulln""updated_at"": ""2016-10-17T07:05:00.54n""urlize_name"": ""Copper-Prices""n}nnnThanks for your help in advancenMen' ""One way would be to get the position of 'Date' and 'Cache Buyer' columns and then iterate through the data part of the JSON. nnI will name the dictionary that you loaded from the JSON as dictionary in my example:nn# Get the columns and the data part of the response dictionaryncolumns = dictionary'column_names'ndata = dictionary'data'nn# This is done in case that the columns are not always in the same ordern# if they are you can just hardcode the values to 0 and 1nindex_of_date = columns.index('Date')nindex_of_cash_buyer = columns.index('Cash Buyer')nn# As data section is a list of lists we need ton# iterate through lists of data and collect the desired valuesnfor piece_of_data in data:n    date = piece_of_dataindex_of_daten    cash_buyer = piece_of_dataindex_of_cash_buyern    print date cash_buyernn""",['python-2.7'],"['dictionary', 'list']"
40087556,"'Python list integrateUpper/Lowercase check?' ""I currently use following code to select rows from a dataframe:nnlist = '3d block''3D Block''3D block''3d Block''cafe''Cafe'ndatadata'description'.str.contains('|'.join(list))nnnAs you can see I currently implement different queries for upper/lowercase as I realized that '3d print' didn't really match all the items in question.nnCan the code above be improved or shortened so that the list includes all possible variations of upper/lowercase characters both for one and two words?n"" ""You can simply convert them all to lower using the string.lower() functionnnMake your list contain only lower case characters. But you can do a safe check for that toonnmy_list='3d block' 'cafe'nn# As karthik suggested just to be safe convert your list to lowercasenfor i in range(len(my_list)):n    my_listi=ele.lower()nnmy_query='3D bLoCk'nif my_query.lower() in my_list:n    print('yes')nnnprints yesn"" 'You can do a case InSeNsitIvE selection  by passing the case parameter as False:nnlst = '3D Block' 'cafe'ndatadata'description'.str.contains('|'.join(lst) case=False)nnnAnd remember to not use list as a name as this will shadow the builtin list function and make it unusable later in your code.nnnnReference:nnpandas.Series.str.containsn'",['list'],"['list', 'python-2.7']"
40087573,"'Numpy array size is shrinking changing randomly. Index out of bounds error' 'I am making a large 3-column 10000 row array and filling it with random numbers. Then I am indexing through the rows and deleting rows that don't match my criteria. For some reason as I index through I get the following error: n        Traceback (most recent call last):n        File ""hw_2.py"" line 16 in <module>n        if math.sqrt(cubey0**(2) + cubey1**(2) + cubey2**(2)) > 1: n        IndexError: index 6786 is out of bounds for axis 0 with size 6786nnMy code is the following:nn    import numpy as npn    import mathnnn    #Create a large empty array that can be filled with random numbersn    cube=np.empty(100003);nn    #Fill the array with 1x3 (xyz) randos in a 1x1 cuben    for x in xrange(010000):n       cubex = np.random.uniform(-113) nn    #Consider each coordinate as a vector from the origin; reject all sets of xyz vectors whose magnitudes are greater than the radius of the sphere n    for y in xrange(010000):n        if math.sqrt(cubey0**(2) + cubey1**(2) + cubey2**(2)) > 1: n            cube = np.delete(cube (y) axis=0)nn    #Reject all sets of vectors whose xy components lay in a circle in the xy plane of radius 0.25n    for i in xrange(010000):n        if cubei0 > 0 and cubei0**(2) + cubei1**(2) <= 0.25:n            cube = np.delete(cube (i) axis=0)nn    #Report the average of all coordinates in each plane this will be the location of the center of mass   n    centermass = np.mean(cube axis=0)`nnnI don't understand why the size of the axis would be less than 10000 at this point all 10000 rows should be filled by the second command.n' ""So you're trying to select certain parts of the array it seems. There's typically no need to do np.delete you can use boolean masks instead: nnIn 34: np.random.seed(1234)nnIn 35: cube = np.random.uniform(-1 1 size=10000*3).reshape(10000 3)nnIn 36: mask = (cube**2).sum(axis=1) > 0.5nnIn 37: mask.shapenOut37: (10000)nnIn 38: cube~mask.shapenOut38: (1812 3)nnIn 39: np.mean(cube~mask axis=0)nOut39: array(  1.39564967e-07  -2.78051170e-03  -1.13108653e-03)nn""",['numpy'],['numpy']
40087800,"'How to convert nested list to object' 'When I receive JSON data like nn  n    {  n        ""id"":1n        ""name"":""New Island""n        ""residents"":  n            {  n                ""name"":""Paul""n                ""age"":""25""n            }n        n    }n    {  n        ""id"":2n        ""name"":""One Nation""n        ""residents"":  n            {  n                ""name"":""James""n                ""age"":""23""n            }n            {  n                ""name"":""Jessica""n                ""age"":""26""n            }n        n    }nnnndrf deserializer makes it to list which contain OrderedDictnnBut I want to make it to list of class object.nnHere are my django modelsnnclass Country(models.Model):n    name = models.CharField(max_length=20)nnclass Resident(models.Model):n    name = models.CharField(max_length=20)n    country = models.ForeignKey('Country' related_name='residents')nn' 'Override the serializer methods that control transformation from primitive to internal http://www.django-rest-framework.org/api-guide/serializers/#overriding-serialization-and-deserialization-behaviorn' 'From Python's JSON librarynnimport jsonnndata = '{""id"":1""name"":""New Island""""residents"":{""name"":""Paul""""age"":""25""}}{""id"":2""name"":""One Nation""""residents"":{""name"":""James""""age"":""23""}{""name"":""Jessica""""age"":""26""}}'nnx = json.loads(data)nnfor each_set in x:n    for every_person in each_set""residents"":n        print(every_person""name"") #getting resident's namen        print(every_person""age"")  #getting agen        print(each_set""name"") #getting the country namennnFrom there it's as easy as passing in the proper parameters to classes liken'",['django'],['django']
40088132,"'Tensorflow MNIST (Weight and bias variables)' 'I'm learning how to use Tensorflow with the MNIST tutorial but I'm blocking on a point of the tutorial.nnHere is the code provided : nnfrom tensorflow.examples.tutorials.mnist import input_datanimport tensorflow as tfnnmnist = input_data.read_data_sets(""MNIST_data/"" one_hot=True)nx = tf.placeholder(tf.float32 None 784)nW = tf.Variable(tf.zeros(784 10))nb = tf.Variable(tf.zeros(10))ny = tf.nn.softmax(tf.matmul(x W) + b)ny_ = tf.placeholder(tf.float32 None 10)nncross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y) reduction_indices=1))nntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)nsaver = tf.train.Saver()ninit = tf.initialize_all_variables()nsess = tf.Session()nsess.run(init)nfor i in range(1000):n  batch_xs batch_ys = mnist.train.next_batch(100)n  sess.run(train_step feed_dict={x: batch_xs y_: batch_ys})nnnBut I actually don't understand at all how the variables ""W"" (The weight) and ""b"" (The bias) are changed while the computing ?nOn each batch they are initialized at zero but after ?nI don't see at all where in the code they're going to change ?nnThanks you very much in advance!n' 'TensorFlow variables maintain their state from one run() call to the next. In your program they will be initialized to zero and then progressively updated in the training loop.nnThe code that changes the values of the variables is created implicitly by this line:nntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)nnnIn TensorFlow a tf.train.Optimizer is a class that creates operations for updating variables typically based on the gradient of some tensor (e.g. a loss) with respect to those variables. By default when youncall Optimizer.minimize() TensorFlow creates operations to update all variables on which the given tensor (in this case cross_entropy) depends.nnWhen you call sess.run(train_step) this runs a graph that includes those update operations and therefore instructs TensorFlow to update the values of the variables.n'",['python-3.x'],['python-2.7']
40088154,"'How to get current test case(s) status pass/failed in Robot Framework' 'I have used ${TEST STATUS} (Automatic variable) for getting the status giving error.n' 'There is a global variable called ${TEST_STATUS}. You can use it in teardown section.nnSee the corresponding part Automatic Variables in the documentation. nnhttp://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#id514n' 'you can use that variable only in teardown section. like below example. robot is maintaining two levels ""test levels"" and ""suit levels"". inside test level there is another two things called ""setup"" and ""teardown"". setup means before executing every testcase it will run. and teardown means after executing every testcase it will run. In below example before executing Default_values Overridden setup No_teardownetc. testcases Open_Application will run and after exiting the testcases Close Application will run. you can use that automatic variable in the tear down section only as described in docs and demonstated in the No_teardown testcase. In the No_teardown testcase it is checking whether it is true or not. you can change anything according to your need.nn*** Settings ***nTest Setup       Open Application    App AnTest Teardown    Close Applicationnn*** Test Cases ***nDefault valuesn    Documentation    Setup and teardown from setting tablen    Do SomethingnnOverridden setupn    Documentation    Own setup teardown from setting tablen    Setup    Open Application    App Bn    Do SomethingnnNo teardownn    Documentation    Default setup no teardown at alln    Do Somethingn    Teardown    Should Be True      '${TEST STATUS}' == 'True'nnNo teardown 2n    Documentation    Setup and teardown can be disabled also with special value NONEn    Do Somethingn    Teardown    NONEnnUsing variablesn    Documentation    Setup and teardown specified using variablesn    Setup    ${SETUP}n    Do Somethingn    Teardown    ${TEARDOWN}nnnThis example is modified version of this robot docs link:-nhttp://robotframework.org/robotframework/latest/RobotFrameworkUserGuide.html#test-setup-and-teardownnnHope this will remove your doubts.n'",['python-2.7'],"['django', 'python-2.7']"
40088157,"'python/matplotlib : imposed ticks with ticker partially missing' 'When plotting my figure with plt.axis('auto') 'natural' x-ticks are written with frequency 500nnnnWishing a frequency 200 I have used:nn    import matplotlib.ticker as tickernn    ticks_loc = ticker.MultipleLocator(base=200)nn    fig = plt.figure('Cutlines x-axis')n    ax = fig.add_subplot(111)n    ...n    plt.axis('equal')n    ax.xaxis.set_major_locator(ticks_loc)n    ax.yaxis.set_major_locator(ticks_loc)n    plt.grid()nnnwhich givesnnnnCuriously nnnall the ticks are not represented (ticks -1000 -800 -600 are missing) nplt.show() differs from savefig (in plt.show() 'only' ticks -1000 and -800 are missing not -600).nnnI have tried reducing the font size (with very tiny one) and/or by writing vertically -> no effect : always the same ticks are missing.nnIs there a way to have all the ticks visible (in horizontal mode) ?n' ""Why don't you simply use xticks instead of tickernnfig = plt.figure('Cutlines x-axis')nax = fig.add_subplot(111)n...nxlim = ax.get_xlim()nplt.xticks(np.arange(xlim0 xlim1+200 200))nn""",['matplotlib'],['matplotlib']
40088178,'Problems while extracting relations with nltk?' 'From this question's answer I am trying to understand how to extract relations from text. However when I try:nnimport nltknimport renfrom nltk.sem import extract_relsrtuplenn#billgatesbio from http://www.reuters.com/finance/stocks/officerProfile?symbol=MSFT.O&officerId=28066nwith open('/Users/user/Desktop/rel_extraction_sample.txt' 'r') as f:n    sample = f.read()nnsentences = nltk.sent_tokenize(sample)n#print(sentences)ntokenized_sentences = nltk.word_tokenize(sentence) for sentence in sentencesntagged_sentences = nltk.pos_tag(sentence) for sentence in tokenized_sentencesn#print(tagged_sentences)nn# here i changed reg ex and below i exchanged subj and obj classes' placesnOF = re.compile(r'.*bofb.*')n#OF = re.compile(r'bofb')n#IN = re.compile(r'.*binb(?!b.+ing)')nnfor i sent in enumerate(tagged_sentences):n    #print(sent)n    sent = nltk.ne_chunk(sent) # ne_chunk method expects one tagged sentencen    #print(sent)n    rels = extract_rels('PER' 'ORG' sent corpus='ace' pattern=OF window=7) # extract_rels method expects one chunked sentencen    for rel in rels:n        print('{0:<5}{1}'.format(i rtuple(rel)))nnnI am not getting any relation from the text. I tried to change the regex for: re.compile(r'bofb') and I still not getting any relation. Thus which is the correct way of using: nltk's extract_rels object?.n' nan,['python-3.x'],"['regex', 'python-2.7']"
40088441,"'groupby on NaN-only column gives IndexError' 'The following gives IndexError: index out of bounds:nnimport pandas as pdnfrom numpy import nannndf1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock': {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:14.05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: nan1: nan 2: nan 3: nan 4: nan 5: nan}})nndf1.groupby('Stock''EndTime').head(1)nnTraceback (most recent call last):nFile ""<stdin>"" line 1 in <module>nFile ""/users/.../egg_cache/p/pandas-0.16.2-py2.7-linux-x86_64.egg/pandas/core/groupby.py"" line 994 in headn   in_head = self._cumcount_array() < nnFile ""/users/.../egg_cache/p/pandas-0.16.2-py2.7-linux-x86_64.egg/pandas/core/groupby.py"" line 1034 in _cumcount_arrayn   arr = np.arange(self.grouper._max_groupsize dtype='int64')nFile ""pandas/src/properties.pyx"" line 34 in pandas.lib.cache_readonly.__get__ (pandas/lib.c:41917)nFile ""/users/.../egg_cache/p/pandas-0.16.2-py2.7-linux-x86_64.egg/pandas/core/groupby.py"" line 1343 in _max_groupsizen   if self.indices:nFile ""pandas/src/properties.pyx"" line 34 in pandas.lib.cache_readonly.__get__ (pandas/lib.c:41917)nFile ""/users/.../egg_cache/p/pandas-0.16.2-py2.7-linux-x86_64.egg/pandas/core/groupby.py"" line 1309 in indicesn    return _get_indices_dict(label_list keys)nFile ""/users/.../egg_cache/p/pandas-0.16.2-py2.7-linux-x86_64.egg/pandas/core/groupby.py"" line 3767 in _get_indices_dictn    return lib.indices_fast(sorter group_index keys sorted_labels)nFile ""pandas/lib.pyx"" line 1385 in pandas.lib.indices_fast (pandas/lib.c:23875)nFile ""pandas/src/util.pxd"" line 41 in util.get_value_at (pandas/lib.c:62901)nIndexError: index out of boundsnnnHowever if I exclude all NaN column it works fine as follows:nndf1.groupby('Stock''Date').head(1)n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn5  2016-10-11      NaN  10:08:36.657   XYZnnnAny idea if this is a bug in Pandas or am I missing something here. I am reading following: https://github.com/pandas-dev/pandas/issues/11016 nIf its a bug any suggestions for a workaround assuming getting rid of all Nan columns is not an option.nnSome more interesting observations:nndf1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock': {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:14.05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: nan1: nan 2: 1 3: nan 4: nan 5: nan}})nnprint df1n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn1  2016-10-11      NaN  08:00:00.243   ABCn2  2016-10-11        1  12:34:23.563   ABCn3  2016-10-11      NaN  08:14.05.908   ABCn4  2016-10-11      NaN  18:54:50.100   ABCn5  2016-10-11      NaN  10:08:36.657   XYZnndf1.groupby('Stock''EndTime').head(1)n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn2  2016-10-11        1  12:34:23.563   ABCnnnThe above output looks incorrect to me. Shouldn't it be:nn         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn2  2016-10-11        1  12:34:23.563   ABCn5  2016-10-11      NaN  10:08:36.657   XYZnnnNow for the following case:nndf1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock': {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:14.05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: nan1: nan 2: nan 3: nan 4: nan 5: 1}})nnprint df1n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn1  2016-10-11      NaN  08:00:00.243   ABCn2  2016-10-11      NaN  12:34:23.563   ABCn3  2016-10-11      NaN  08:14.05.908   ABCn4  2016-10-11      NaN  18:54:50.100   ABCn5  2016-10-11        1  10:08:36.657   XYZnndf1.groupby('Stock''EndTime').head(1)n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn5  2016-10-11        1  10:08:36.657   XYZnnnThis one is fine.n' ""@Rahul here is the output of your code when using Pandas 0.19.0:nnIn 5: df1nOut5:n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn1  2016-10-11      NaN  08:00:00.243   ABCn2  2016-10-11      NaN  12:34:23.563   ABCn3  2016-10-11      NaN  08:14.05.908   ABCn4  2016-10-11      NaN  18:54:50.100   ABCn5  2016-10-11      NaN  10:08:36.657   XYZnnIn 6: df1.groupby('Stock''EndTime').head(1)nOut6:n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCnnIn 7: df1.groupby('Stock''Date').head(1)nOut7:n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn5  2016-10-11      NaN  10:08:36.657   XYZnnIn 8: df1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock': {n   ...: 0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:14n   ...: .05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: nan1: nan 2: 1 3: nan 4: nan 5: nan}})n   ...:nnIn 9: df1.groupby('Stock''EndTime').head(1)nOut9:n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn2  2016-10-11      1.0  12:34:23.563   ABCnnIn 10: df1 = pd.DataFrame({'Date': {0: '2016-10-11' 1: '2016-10-11' 2: '2016-10-11' 3: '2016-10-11' 4: '2016-10-11'5: '2016-10-11'} 'Stock':n    ...: {0: 'ABC' 1: 'ABC' 2: 'ABC' 3: 'ABC' 4: 'ABC' 5: 'XYZ'} 'StartTime': {0: '08:00:00.241' 1: '08:00:00.243' 2: '12:34:23.563' 3: '08:n    ...: 14.05.908' 4: '18:54:50.100' 5: '10:08:36.657'} 'EndTime': {0: nan1: nan 2: nan 3: nan 4: nan 5: 1}})n    ...:nnIn 11: df1.groupby('Stock''EndTime').head(1)nOut11:n         Date  EndTime     StartTime Stockn0  2016-10-11      NaN  08:00:00.241   ABCn5  2016-10-11      1.0  10:08:36.657   XYZnn""",['pandas'],['pandas']
40088442,"'django app multiple hard drives Errno 18 Invalid cross-device link' ""I have a django app on a debian server and my current site_media directory on the current disk is full. So I want to upload files On a second disk. The path on server is /disk :nn        obj = form.save(commit=False)n        obj.user_id = self.request.user.pkn        obj.save()n        initial_path = obj.file.pathn        print(initial_path)n        new = settings.MEDIA_ROOT_NEW + obj.file.namen        print(new)n        os.rename(initial_pathnew)n        shutil.move(initial_path new)nnnand in my settings.py I have:nn        MEDIA_ROOT = os.path.join(PROJECT_PATH 'site_media/')n        MEDIA_ROOT_NEW = '/disk/site_media/'nnnstill I get error:ndjango Errno 18 Invalid cross-device linknnAny ideas???n"" 'os.rename() may fail across different file systems.nnn  The operation may fail on some Unix flavors if src and dst are on different filesystems.n  https://docs.python.org/3/library/os.html#os.renamennnshutil.move() should worknnn  If the destination is on the current filesystem then os.rename() is used. Otherwise src is copied (using shutil.copy2()) to dst and then removed.n  https://docs.python.org/3.4/library/shutil.html#shutil.movennnbut you've got a os.rename(initial_pathnew) just before your shutil.move(initial_path new). Remove the first os.rename() and it should work.n'",['django'],['django']
40088503,"'python django call chat.py in template $ajax ? giving error not found' 'hi i am new at python django.ni have template where i wana call a file through ajaxnn $.ajax({n    type: ""POST""n    url: ""chat.py""n    data: {foo: 'bar' bar: 'foo'}nnnand urls.pynnfrom django.conf.urls import include  urlnfrom . import viewsnfrom . import chatnnurlpatterns = n    url(r'^$' views.index name='index')nn  url(r'^$' chat.main name='main')nnnnand chat.pynnimport osnimport sysnnsys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))nsys.path.append(""../../tf_seq2seq_chatbot_parent"")nimport tensorflow as tfnnfrom tf_seq2seq_chatbot.lib.chat import chatnnndef main(_):n    #chat()n    print('kjgjkh')nnif __name__ == ""__main__"":n    tf.app.run()nnnand views.pynnfrom django.shortcuts import renderndef index(request):n    return render(request  ""base.html""  {})nnerror: poll/chat.py not foundnn' 'You haven't got a URL ""chat.py"". Your URLs are defined in the regexes in your urls.py; but you've only defined one which is just / although you've defined it twice which can't possibly work.nnMake those two URLs different and use the one you want in your Ajax call.n'",['django'],['django']
40088527,"'Sorting dict items by key beyond alphanumeric sorting' 'I have written this code:nnn=5ndizN={}nfor q in range(0n+1):n    h=n-qn    dizN'a'+str(q)+'p'+str(h)=0nnnthat creates such a dictionary:nndizNnnOut120: {'a0p5': 0 'a1p4': 0 'a2p3': 0 'a3p2': 0 'a4p1': 0 'a5p0': 0}nnnNote that ""n"" is the basic parameter for my code. As you can see the sum of integers present in dict keys string is always =n (=5 in this case where n=5).nnIt is important for me (for more difficult purposes in my program) that for every n anyone can choose the dict is ordered in this way: nn{'a0p(n)': 0 'a1p(n-1)': 0 ..... 'a(n-1)p1': 0 'a(n)p0': 0}nnnMy code is ok but only for n<10. n    If n is >=10 this is what happens: (n=12) dizN:nnOut121: n  {'a0p12': 0n   'a10p2': 0n   'a11p1': 0n   'a12p0': 0n   'a1p11': 0n   'a2p10': 0n   'a3p9': 0n   'a4p8': 0n   'a5p7': 0n   'a6p6': 0n   'a7p5': 0n   'a8p4': 0n   'a9p3': 0}nnnAs you can see the interpreter follows alphanumeric sorting;nnAnybody know if there is a way to obtain the same dict sorted this way:nn{'a0p12': 0n 'a1p11': 0n 'a2p10': 0n 'a3p9': 0n 'a4p8': 0n 'a5p7': 0n 'a6p6': 0n 'a7p5': 0n 'a8p4': 0n 'a9p3': 0n 'a10p2': 0n 'a11p1': 0n 'a12p0': 0}nnn?nnI know that dictionaries are basically non sortable but i hope somebody knows some trick to obtain my purpose anyway :)nnThanks a lot!n' 'dicts are unordered so to get the order you are going to have to sort the items and use an OrderedDict to maintain the sorted order. To get the order you want you can create tuples from the groups of integers so you sort as integers in lexicographical order:nnfrom itertools import groupbynfrom collections import OrderedDictnd = {'a0p12': 0 'a10p2': 0 'a11p1': 0 'a12p0': 0 'a1p11': 0 'a2p10': 0n     'a3p9': 0 'a4p8': 0 'a5p7': 0 'a6p6': 0 'a7p5': 0 'a8p4': 0 'a9p3': 0}nndef key_func(x):n    """"""'a0p12' -> (0 12)""""""n    return tuple(int("""".join(v)) for kv in groupby(x0 key=str.isdigit) if k)nod = OrderedDict(sorted(d.items() key=key_func))nnprint(od)nnnWhich would give you:nnOrderedDict(('a0p12' 0) ('a1p11' 0) ('a2p10' 0) ('a3p9' 0) n('a4p8' 0) ('a5p7' 0) ('a6p6' 0) ('a7p5' 0) ('a8p4' 0) n('a9p3' 0) ('a10p2' 0) ('a11p1' 0) ('a12p0' 0))nnnYou could also use a regex to find the groups of digits:nnfrom collections import OrderedDictnimport rennd = {'a0p12': 0 'a10p2': 0 'a11p1': 0 'a12p0': 0 'a1p11': 0 'a2p10': 0n     'a3p9': 0 'a4p8': 0 'a5p7': 0 'a6p6': 0 'a7p5': 0 'a8p4': 0 'a9p3': 0}nnnndef key_func(xpatt=re.compile(""d+"")):n    """"""'a0p12' -> (0 12)""""""n    return tuple(map(int patt.findall(x0)))nnod = OrderedDict(sorted(d.items() key=key_func))nnprint(od)nn'",['dictionary'],"['dictionary', 'python-2.7']"
40088576,"'Python - find highest dictionary key with value greater than zero' ""I have a dictionarynn{0: 12 1: 1 2: 13 3: 7 4: 0}nnnI want to find the highest dictionary key with a value greater than 0.nnIn this case the answer is 3.nnWhat's the best way to do this?n"" 'You can use max and dict.items() to do this:nnd = {0: 12 1: 1 2: 13 3: 7 4: 0}nnhighest = max(i for ij in d.items() if j > 0)nn' 'Use a genexpr to filter out the ""bad"" values and max to keep the highest that remains:nn# On Py2 use .iteritems() instead of .items()nmax(k for k v in mydict.items() if v > 0)nnnOr if you need to have a default if no keys qualify without an exception being raised:nn# Py3 max has default which makes this super-easy:nmax((k for k v in mydict.items() if v > 0) default=SOMEVALUEGOESHERE)nn# Py2 doesn't have default; workaround is to catch exception and use a default (EAFP):ntry:n    mymax = max(k for k v in mydict.iteritems() if v > 0)nexcept ValueError:n    mymax = SOMEVALUEGOESHEREnn# Or if you can't do that for some reason make a listcomp instead of genexprn# and check for at least one surviving key before calling max (LBYL)ngoodkeys = k for k v in mydict.iteritems() if v > 0nmymax = max(goodkeys) if goodkeys else SOMEVALUEGOESHEREnn'",['dictionary'],"['dictionary', 'python-2.7']"
40088585,"'Turn off error bars in Seaborn Bar Plot' ""I'm using GridSpec in matplotlib to create a page that has 9 subplots.  One of the subplots is a Seaborn bar plot created with the following code:nnimport seaborn as snsnsns.barplot(x=df'Time' y=df'Volume_Count' ax=ax7)nnnIs there a way to turn off the vertical error bars of the bar plot?  If not is it possible to reduce the horizontal width of the bars?nnThanks!n"" ""I'm not 100% sure since the seaborn website seems to be down but have you tried the ci argument? According to the documentation:nnn  ci : float or None optionaln      Size of confidence intervals to draw around estimated values. Ifn      None no bootstrapping will be performed and error bars willn      not be drawn.nnnsns.barplot(x=df'Time' y=df'Volume_Count' ax=ax7 ci=None)nn""",['matplotlib'],"['matplotlib', 'pandas']"
40088622,"'Linux : unable to install kivy in virtual environment' 'I am using python2.7 and created a virtual environment 'kivyenv'.nFirst i install Cython and then kivy in kivyenv.nnpip install Cythonnpip install kivynnnkivy failed to install giving some error :-nnIn file included from /tmp/pip-build-4T9oG4/kivy/kivy/graphics/opengl.c:274:0:n/tmp/pip-build-4T9oG4/kivy/kivy/graphics/gl_redirect.h:43:22: fatal error: GL/gl.h: No such file or directoryn #   include <GL/gl.h>n                      ^ncompilation terminated.n error: command 'x86_64-linux-gnu-gcc' failed with exit status 1nn----------------------------------------nCommand ""/root/kivyenv/bin/python2.7 -u -c ""import setuptools tokenize;__file__='/tmp/pip-build-4T9oG4/kivy/setup.py';nexec(compile(getattr(tokenize 'open' open)(__file__).read().replace('rn' 'n') __file__ 'exec'))"" ninstall --record /tmp/pip-3__DxE-record/install-record.txt --single-version-externally-managed --compile --install-headersn /root/kivyenv/include/site/python2.7/kivy"" failed with error code 1 in /tmp/pip-build-4T9oG4/kivy/nnnI am using Ubuntu 16.n' 'This is happening because you do not have dependency libraries installed on your system specifically the ones for OpenGL - most likely you do not have mesa packages installed.nnFollow the instructions for your specific distribution on how to install all of the needed dependencies at:  https://kivy.org/docs/installation/installation-linux.html#using-software-packagesn'",['python-2.7'],['python-2.7']
40088634,"'forcing a program to calculate an input' 'I was wondering if I could force the program to calculate an input before converting it to an integer.nfor example my code isnn    shift=int(raw_input(""input the shift you want ""))nnnIf I was to input 4**2 which should then in theory equal 16 however as the raw input is a string this cannot happen.nI would like to know if there was force the program to calculate the input meaning if I inputted a calculation then the program would work it out instead of just converting it to an integer and causing an error.n' 'If you don't mind being terribly unsafe you can use eval which accepts a single string argument as input and executes it as Python code:nnshift = eval(raw_input(""input the shift you want ""))nnnAnd here is an explanation of why you shouldn't do this in any kind of production code.nnA better option is to actually build a proper parser to behave like a calculator. There are plenty of resources for this floating around SO and elsewhere online.n'",['python-2.7'],"['python-2.7', 'python-3.x']"
40088691,"""Python help using 'numpy.masked_where' conditionally from another list"" ""I am writing an astronomy observation simulation. I have a data array which is 1 measurement per 24 hours:nndata = 01234nnnAnd I have a array which is the minutes of cloud/rain in a 24 hour period rounded to the nearest hour:nnweather = 0601201800nnnI want to use a masked array to hide the values in the data array based off the values in the weather array. Masking is important (instead of deleting) for plotting and data analysis further down the line.nnSo if I want to only show data points where there was < 120 mins of downtime I do:nndowntime = 120nndata_masked = np.ma.masked_where(weather < downtime data)nnnThis should result in:nndata_masked = 0 1 --- --- 4nnnBut my data_masked seems to be doing the opposite. If I plot both my data and weather on the same axis. I am masking the points where the weather downtime is below my threshold.nnI've tried inverting the operator which just seems to keep everything in. Any ideas or am I missing the point of numpy.ma?nnThanks!n"" 'Using numpy.ma returns a mask. That is it hides (masks) everything that fits the condition weather < downtime. If you want to show everything that fits the condition just invert the condition:nndata = np.array(01234)nweather = np.array(0601201800)ndowntime = 120ndata_masked = np.ma.masked_where(weather >= downtime data)ndata_maskednnnThen the output will be:nnmasked_array(data = 0 1 -- -- 4 n             mask = False False  True  True Falsen             fill_value = 999999)nnnTo access the data use data_masked.data.n' ""You'll want to usennnp.ma.MaskedArray(datamask)nnnNote that the mask specifies the data that is to be masked. Also for the following type of operationnnweather < downtimennnto work as you intend 'weather' needs to be an array rather than a list so:nnweather = np.array(0601201800)n...ndata_masked=np.ma.MaskedArray(data weather >= downtime)nnnNote that I used '>=' instead of '<' to get your required resultn""",['numpy'],['numpy']
40088710,"'Python Pandas - filtering df by the number of unique values within a group' ""Here is an example of data I'm working on. (as a pandas df)nn    index   inv Rev_stream  Bill_type   Net_revn       1    1   A           Original    -24.77n       2    1   B           Original    -24.77n       3    2   A           Original    -409.33n       4    2   B           Original    -409.33n       5    2   C           Original    -409.33n       6    2   D           Original    -409.33n       7    3   A           Original    -843.11n       8    3   A           Rebill       279.5n       9    3   B           Original    -843.11n      10    4   A           Rebill       279.5n      11    4   B           Original    -843.11n      12    5   B           Rebill       279.5nnnHow could I filter this df in a way to only get the lines where invoice/Rev_stream combo has both original and rebill kind of Net_rev. In the example above it would be only lines with index 7 and 8. nnIs there an easy way to do it without iterating over the whole dataframe and building dictionaries of invoice+RevStream : Bill_type?nnWhat I'm looking for is some kind ofnndf = dfdf'inv''Rev_stream''Bill_type'.unique().len() == 2nnnUnfortunately the code above doesn't work.nnThanks in advance.n"" 'You can group your data by inv and Rev_stream columns and then check for each group if both Original and Rebill are in the Bill_type values and filter based on the condition:nn(df.groupby('inv' 'Rev_stream')n   .filter(lambda g: 'Original' in g.Bill_type.values and 'Rebill' in g.Bill_type.values))nnnn'",['pandas'],['pandas']
40088732,"'How to create a loop to return to the start of a function python' 'I am unable to get my while loop to start back at the beginning not to sure what is wrong.nnFirst attemptnndef start() :nnif choice in weapon:n    print('You have taken the ') + choice + ('this is now in your backpack.n')  n    inventory.append(choice)nnelse:n    print(""Uh oh I don't know about that item"")nnstart()  nnnsecond attemptnnthe_choice = Falsenwhile not the_choice:nif choice in weapon:n    print('You have taken the ') + choice + ('this is now in your backpack.n')  n    inventory.append(choice)n    the_choice = Truen     # boom no loop needed nelse:n    print(""Uh oh I don't know about that item"")n    the_choice = False  nnnI just can't seem to figure it out. n' 'Your second attempt looks close but you need an esape if all items are done: but look at your spaces: the if is inside the while:nnchoice = next_choice() nfound = falsenwhile found & :n    if choice in weapon_stash:n        inventory.append(choice)n        found = Truen    else:n       choice = next_choice() # get from user?n       if choice == None:n           break; # break out on some condition otherwise infinite loopnn# found is now either true (a thing was found) or false (the user quit)nn' 'The reason I commented Visual Studio might not be the best python editor is that other editors would have warned you that you did not increase the indentation after your function definition start() in your first attempt nor did you indent after the start of your while loop in your second attempt. It always helps to include your error messages to help describe your problem but if I were to guess you are getting something to the tune of IndentationError messages. nnIndentation is one of the most important concepts of python coding and serves the same purpose as curly braces in java or c++. Wikipedia has a pretty straightforward description of how to do it.nnAs for editors I am a personal fan of spyder although there are many great ones out there: Pycharm pydev etc.. n' 'There are only indentation faults in the second attempt.nTry below code.nnthe_choice = Falsenwhile not the_choice:n    if choice in weapon:n        print('You have taken the ') + choice + ('this is now in your backpack.n')  n        inventory.append(choice)n        the_choice = Truen        # boom no loop needed n    else:n        print(""Uh oh I don't know about that item"")n        the_choice = FalsennnThis will stuck in a constant loop if the user keeps entering a value not in the list (weapon) so you can put a counter for every False and update like below.nncounter=0nthe_choice = Falsenwhile not the_choice:n    if choice in weapon:n        print('You have taken the ') + choice + ('this is now in your backpack.n')  n        inventory.append(choice)n        the_choice = Truen        # boom no loop needed n    else:n        print(""Uh oh I don't know about that item"")n        the_choice = Falsen        counter=counter+1nn    if counter >= 3:n        print('You have made 3 wrong attempts ')n        breaknn'",['python-2.7'],"['python-2.7', 'python-3.x']"
40088756,'Remove Outliers from Python fit' 'I have data from astronomical images where I need to fit the brightness of the objects of the images against some standard catalogue. Most of the objects on the images were recognized correctly by my script but sometimes there are some mismatches. I fit the 2 datasets using numpy.polyfit for a 2nd order polynomial. What I'm doing right now is fitting the data once and then excluding the mismatched objects that lie outside the curve. My code looks something like that:nnpoptG cov = np.polyfit(magInt magMa 2 cov=True)nerr = np.sqrt(np.diag(cov))nb = np.where((magMa < np.poly1d(poptG + 3 * err)(magInt)) &n             (magMa > np.poly1d(poptG - 3 * err)(magInt)))nmagInt = magIntbnmagMa = magMabnpoptG = np.polyfit(magInt magMa 2)nnnThis looks something like this for my data:nWhat I want is to have something like a 3 sigma neighborhood where objects get accepted and everything outside is neglected because it is almost certainly a mismatch. But for most of my curves the error gets so enormous that nothing would ever be excluded. The data isn't even spread so far that such a big error would be justified. nSo I guess that my method to calculate the 3 sigma neighborhood is simply wrong. I can see how moving the fit up and down 3 sigma is not really the correct approach but I couldn't think of anything better. I also looked at some other posts (numpy.polyfit: How to get 1-sigma uncertainty around the estimated curve? What's the error of numpy.polyfit?) but I couldn't really find a good solution for my case.n' nan,['numpy'],['numpy']
40088902,"""Custom 'static' template tag in Django"" 'everyone!nI need to make some specific changes for static tag. It's result of hours of my work but I got not what I needed. Following code works properly only if I remove ""django.contrib.staticfiles"" from INSTALLED_APPS. But it's not right way because I turn off whole functionality of this app.nPlease help me solve this issue. How can I specific a priority of ""staticfiles"".nnsettings.py:nnINSTALLED_APPS = (n    'django.contrib.admin'n    'django.contrib.auth'n    'django.contrib.contenttypes'n    'django.contrib.sessions'n    'django.contrib.messages'n    # 'django.contrib.staticfiles'        n)nnnmyapp/templatetags/staticfiles.py:nnimport renfrom django import templatenfrom django.contrib.staticfiles.templatetags.staticfiles import StaticFilesNodenfrom myapp.settings.local import STATIC_VERSIONnnnclass CustomStaticFilesNode(StaticFilesNode):nn    @classmethodn    def handle_token(cls parser token):n        path = versioning_js_and_css(n            token.split_contents()1n            get_actual_version()n        )n        node_obj = super().handle_token(parser token)n        node_obj.path = parser.compile_filter(path)n        return node_objnnndef get_actual_version():n    return STATIC_VERSIONnnndef versioning_js_and_css(path version tpl=""'{path}?v={version}'""):n    try:n        cleaned_path = re.search(""'(.*?)'"" path).group(1)n        if cleaned_path.endswith('.css') or cleaned_path.endswith('.js'):n            path = tpl.format(path=cleaned_path version=version)n    except AttributeError:n        passn    return pathnnndef do_static_custom(parser token):n    return CustomStaticFilesNode.handle_token(parser token)nnregister = template.Library()nregister.tag('static' do_static_custom)nnnThanks in advance!n' nan",['django'],['django']
40088930,"'Code that makes cyclic reference for x spaces in list' ""I have a tasko to make a program in which i get m n and k. I should create a list a with n*m element.nList b is supposed to have n*m element. It is created from list a with cyclic shift k to the right for m elements of lists. nI know it is poorly explained. Example is:nnn=3nm=4nA=1 2 3 4 5 6 7 8 9 10 11 12nk=1nB=4 1 2 3 8 5 6 7 12 9 10 11nnnWhat i have at the moment is:nnfrom random import randintnn = int(input())nm=int(input())nnA = nB=0nB=B*n*mnfor i in range(n*m):n    A = A + randint(1 30)nnprint('nLista A:n')nfor i in range(n*m):n    print(Ai end = ' ')nnprint()nnk=int(input())nnfor i in range(-1 m*n m):n    Bm-1-i=Ain    print(Bm-1-i)nnprint('nLista B:n')nfor i in range(n*m):n    print(Bi end = ' ')nnnThanksn"" 'Try this... nn# Start with an empty listnB = n# Take A in chunks of mnfor i in range( int(len(A)/m) ):n    # Take an m-sized chunk of An    chunk = Am*i:m*(i+1)n    # Shift it to the right by k (python style!)n    shift = chunk-k: + chunk:-kn    # Add it to Bn    B += shiftnprint (B)nn' ""Alternative:nnm=4nn=3nk=1nnA=list(range(11+m*n))nprint (A)nnt_1=A_:_+4 for _ in range(0len(A) 4)nprint (t_1)nnt_2=nfor sublist in t_1:n    t_2.append(sublist-k:+sublist:-k)nprint (t_2)nnB=nfor sublist in t_2:n    B.extend(sublist)nnprint (B)nnnIf you want greater speed then you could use a deque from the collections module to build t_2.nnHere's the result.nn1 2 3 4 5 6 7 8 9 10 11 12n1 2 3 4 5 6 7 8 9 10 11 12n4 1 2 3 8 5 6 7 12 9 10 11n4 1 2 3 8 5 6 7 12 9 10 11nn""",['list'],"['list', 'python-2.7', 'python-3.x']"
40089017,"'Django add common conditions in model' ""I have model nnclass QuerySetManager(models.Manager):n    def get_query_set(self):n        return self.model.QuerySet(self.model)nnclass Post(models.Model):n    objects = QuerySetManager()n    STATUS = (n         (1 'PENDING')n         (2 'ACTIVE')n    )n    title = models.CharField(max_length=512blank=Falsenull=True)n    status = models.IntegerField(default=1choices=STATUS)n    class QuerySet(models.query.QuerySet):n        def active(self):n            return self.filter(status=2)nnnWhen I try to access this waynnPost.objects.active().filter(other_condition='xxx').all()nnnit throws error 'QuerySetManager' object has no attribute 'active'nnCan anyone help me to achieve this?n"" 'I can't understand what you're doing here at all. The way to get a manager to return a queryset with the same methods is to use the as_manager classmethod.nnclass PostQuerySet(models.QuerySet):n    def active(self):n        return self.filter(status=2)nnclass Post(models.Model):n    objects = PostQuerySet.as_manager()nn'",['django'],['django']
40089042,"'Fill missing categorial values using pandas?' ""I'd like to fill missing categorial cells with new values per column. For example:nnc1  c2  c3na   nan  anb   q    nannc   d    nanna   p    znnnshould become something likennc1  c2  c3na   n1   anb   q    n2nc   d    n2na   p    znnnMy current problem is that I am using DictVectorizer for categorials column but it leaves NaNs as-is.n"" ""Fillna with some uniq string does what you want:nncategorial_data = pd.DataFrame({'sex': 'male' 'female' 'male' 'female'n                                'nationality': 'American' 'European' float('nan') 'European'})nprint(categorial_data)ncategorial_data=categorial_data.fillna('some_unique_string')nprint('after replacement')nprint(categorial_data)nencoder = DV(sparse = False)nencoded_data = encoder.fit_transform(categorial_data.T.to_dict().values())nprint(encoded_data)nnngives younn  nationality     sexn0    American    malen1    European  femalen2         NaN    malen3    European  femalenafter replacementn          nationality     sexn0            American    malen1            European  femalen2  some_unique_string    malen3            European  femalen 1.  0.  0.  0.  1.n  0.  1.  0.  1.  0.n  0.  0.  1.  0.  1.n  0.  1.  0.  1.  0.nn""",['pandas'],['pandas']
40089134,"'Difference between GET data as a function parameter and an item from requests.arg' ""I would like to know if there is any difference between:nn@app.route('/api/users/<int:id>' methods='GET')ndef get_user(id):n    pass  # handle user here with given idnnnandnn@app.route('/api/users')ndef get_user():n    id = request.args.get('id')n    # handle user here with given idnnnFurthermore is there a way to get multiple parameters in the former? Can they be optional parameters?n"" ""Yes it is. nnFirst method:nn@app.route('/api/users/<int:id>' methods='GET'ndef get_user(id):n    pass  # handle user here with given idnnnDefines a route and a method. This function is only triggered with this method over this path.nnSecond method:nn@app.route('/api/users')ndef get_user():n    id = request.args.get('id')n    # handle user here with given idnnnIt just defines a route. You can execute the function with all methods. nnThe route in the first method is: webexample.com/api/users/1 for user 1nnThe route in the second one is: webexample.com/api/users?id=1 for user 1n"" 'The main difference is that the URL triggering your function will be different. nnIf you use the flask function url_for(that i REALLY recommend) the URL structure returned by the function will be different because all the variables that you use and are not part of the endpoint will be treated like query parameters. nnSo in this case you can change your route without impacting your existing codebase. nnIn other words in your case you would have: nnUsing method variables: nnurl_for('get_user' id=1) => '/api/users/1'nnnWithout method variables:nnurl_for('get_user' id=1) => '/api/users?id=1'nnnWhich approach is better depends from the context you are working on. nIf you want to realize a REST based API you should define the identifiers argument as path arguments and the metadata as query arguments(you can read more about that here). n'",['python-3.x'],['python-2.7']
40089617,"'creating two separate lists read from a file in python' ""Can i please know how the data from a file can be split into two separate lists. For examplenfile contains data as 1234;567 nnmy code:nnfor num in open('filename''r'):n  list1 = num.strip(';').split()nnnHere  i want a new list before semi colon (i.e) 1234 and new list after semi colon (i.e) 567n"" 'Depending on the size of your file you could simply read the whole file into a string at once and then first split by semicolon then by comma:nnwith open('filename' 'r') as f:  #open filen    s = f.read()   #read entire contents into stringn    lists = s.split(';')  #split separate lists by semicolon delimitersn    for l in lists:  #for each listn        l = int(x) for x in l.split('')  #separate the string by commas and convert to integersnn' ""If you are certain that your file only contains 2 lists you can use a list comprehension:nnl1 l2 = sub.split('') for sub in data.split(';')n# l1 = '1' '2' '3' '4'n# l2 = '5' '6' '7'nnnMore generallynnlists = sub.split('') for sub in data.split(';')n# lists0 = '1' '2' '3' '4'n# lists1 = '5' '6' '7'nnnIf integers are needed you can use a second list comprehension:nnlists = int(item) for item in sub.split('') for sub in data.split(';')nn"" 'To get the final list you need to split on """" as well (and probably map() the result to int()):nnwith open(""filename"") as f: n     for line in f:n         list1 list2 = x.split("""") for x in line.rstrip().split("";"")nn'","['python-2.7', 'python-3.x']","['list', 'python-2.7']"
40089678,"'I trying to print sequence but getting KeyError? in python' 'I am getting only first input file correct output but I have A  B C D chain in my first file and getting right output in this case in second input file does't have c and d chain in this case our code is copying same data of first file data of C and D.? and also I am unable to increase this ids: chainIDs = 'A' 'B' 'C' 'D'nnI want to search A to Z chain ID If I replace with chainIDs = 'A' 'B' 'C' 'D' to chainIDs = 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H'.nnIf any chain id is not present in input file then code just ignore and continue for others.nnShowing error: nnf.write(dchainIDatomIDsi+j+ 'n')  nKeyError: 'E'nnnScript:nnimport osnnnd = {}natomIDs = 'C4B' 'O4B' 'C1B' 'C2B' 'C3B' 'C4B' 'O4B' 'C1B'nchainIDs = 'A' 'B' 'C' 'D' 'E' 'F'nwith open('filename.txt') as pdbline:n    for line in pdbline:n        filenames=line:8        n        with open(filenames) as pdbfile:n            for line in map(str.rstrip pdbfile):                n                if line:6 != ""HETATM"":n                    continuen                chainID = line21:22n                atomID = line13:16.strip()n                if chainID not in chainIDs:n                    continuen                if atomID not in atomIDs:n                    continuen                try:n                    dchainIDatomID = linen                except KeyError:n                    dchainID = {atomID: line}n        n = 4n        for chainID in chainIDs:n            for i in range(len(atomIDs)-n+1):n                for j in range(n):n                    f = open(filenames+'out.pdb' 'a')n                    f.write(dchainIDatomIDsi+j+ 'n')  n                    f.close()nnnFirst Input File:nnHETATM15207  C4B NAD A 501      47.266 101.038   7.214  1.00 11.48           C  nHETATM15208  O4B NAD A 501      46.466 100.713   8.371  1.00 11.48           O  nHETATM15209  C3B NAD A 501      47.659  99.689   6.567  1.00 11.48           C  nHETATM15211  C2B NAD A 501      46.447  98.835   6.988  1.00 11.48           C  nHETATM15213  C1B NAD A 501      46.221  99.300   8.426  1.00 11.48           C  nHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           C  nHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           O  nHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           C  nHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           C  nHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           C  nHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           C  nHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           O  nHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           C  nHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28           C  nHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           C  nHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           C  nHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           O  nHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           C  nHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99           C  nHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           C  nnnSecond Input File:nnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           C  nHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           O  nHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           C  nHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           C  nHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           C  nnnGetting Result for Second File:nnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           CnHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           OnHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           CnHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           CnHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           OnHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           CnHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           CnHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           CnHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           CnHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           CnHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           CnHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           CnHETATM15256  C2B NAD B 501      34.172 114.876  37.039  1.00 11.25           CnHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           CnHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           CnHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           OnHETATM15254  C3B NAD B 501      35.307 115.837  37.367  1.00 11.25           CnHETATM15252  C4B NAD B 501      36.455 115.053  36.671  1.00 11.25           CnHETATM15253  O4B NAD B 501      35.930 114.469  35.492  1.00 11.25           OnHETATM15258  C1B NAD B 501      34.524 114.613  35.551  1.00 11.25           CnHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           CnHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           OnHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           CnHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28           CnHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           OnHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           CnHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28           CnHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           CnHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           CnHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28           CnHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           CnHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           CnHETATM15301  C2B NAD C 501     100.220 130.922  17.375  1.00 12.28            CnHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           CnHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           CnHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           OnHETATM15299  C3B NAD C 501      99.346 129.675  17.343  1.00 12.28           CnHETATM15297  C4B NAD C 501      98.229 130.106  18.332  1.00 12.28           CnHETATM15298  O4B NAD C 501      98.083 131.545  18.199  1.00 12.28           OnHETATM15303  C1B NAD C 501      99.125 132.008  17.317  1.00 12.28           CnHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           CnHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           OnHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           CnHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99            CnHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           OnHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           CnHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99           CnHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           CnHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           CnHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99           CnHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           CnHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           CnHETATM15346  C2B NAD D 501      78.536 158.632  26.878  1.00 11.99           CnHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           CnHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           CnHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           OnHETATM15344  C3B NAD D 501      77.106 158.059  26.824  1.00 11.99           CnHETATM15342  C4B NAD D 501      77.335 156.939  25.788  1.00 11.99           CnHETATM15343  O4B NAD D 501      78.705 156.544  25.901  1.00 11.99           OnHETATM15348  C1B NAD D 501      79.351 157.345  26.900  1.00 11.99           CnnnExpected Output: I want to print all chain ID in present input file in following sequence (Only present chain id):nnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2475  C2B NAD A 352      91.477  22.027  50.635  1.00 48.07           CnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2473  C3B NAD A 352      90.818  23.341  50.501  1.00 49.46           CnHETATM 2471  C4B NAD A 352      91.432  24.158  51.658  1.00 51.58           CnHETATM 2472  O4B NAD A 352      92.697  23.519  52.005  1.00 47.28           OnHETATM 2477  C1B NAD A 352      92.868  22.416  51.075  1.00 49.66           Cnn' ""Just change the output loop to something like this:nnfor chainID in chainIDs:n    if chainID in d:n        for atom_id in dchainID:n            with open(filenames+'out.pdb' 'a') as f:n                f.write(dchainIDatom_id + 'n')                  nn""","['python-2.7', 'python-3.x']",['pandas']
40089787,"'Python: Where to put a one time initialization in a test case of unittest framework?' ""My test is simple. I want to send two requests to two different servers then compare whether the results match.nnI want to test the following things.nnnsend each request and see whether the return code is valid.ncompare different portion of the outputs in each test methodnnnI do not want to send the requests in setUp method because it will be send over and over for each new test. I would rather want to send the requests at the initialization. (maybe in the init method). But I found a lot of people were against that idea because they believe I should not override the init method for some reason. (I do not know exactly why) If that's the case where should I send the requests?nI am kind of against doing them in the class body (as shared variables).n"" 'A class method called before tests in an individual class run. setUpClass is called with the class as the only argument and must be decorated as a classmethod():nn@classmethodndef setUpClass(cls):n    ...nnnSee: https://docs.python.org/3/library/unittest.html#unittest.TestCase.setUpClassn'",['python-2.7'],"['python-2.7', 'python-3.x']"
40089822,"'optimization for processing big data in pyspark' ""Not a question->need a suggestionnnI am operating on 20gb+6gb=26Gb csv file with 1+3 (1-master 3-slave (each of 16 gb RAM).nnThis is how I am doing my opsnndf = spark.read.csv() #20gbndf1 = spark.read.csv() #6gbndf_merged= df.join(df1'name''left') ###merging ndf_merged.persists(StorageLevel.MEMORY_AND_DISK) ##if i do MEMORY_ONLY will I gain more performance?????nprint('No. of records found: 'df_merged.count())  ##just ensure persist by calling an actionndf_merged.registerTempTable('table_satya')nquery_list= query1query2query3  ###sql query string to be firedncity_list = city1 city2city3...total 8 citiesnfile_index=0 ###will create files based on increasing indexnfor query_str in query_list:n   result = spark.sql(query_str) #ex: select * from table_satya where date >= '2016-01-01'n   #result.persist()  ###willit increase performancen   for city in city_list:n        df_city = result.where(result.city_name==city)n        #store as csv file(pandas style single file)n        df_city.collect().toPandas().to_csv('file_'+str(file_index)+'.csv'index=False)n        file_index += 1nndf_merged.unpersist()  ###do I even need to do it or Spark can handle it internallynnnCurrently it is taking a huge time. nn#persist(On count())-34 mins.n#each result(on firing each sql query)-around (2*8=16min toPandas() Op)n#          #for each toPandas().to_csv() - around 2 min eachn#for 3 query 16*3= 48minn#total 34+48 = 82 min  ###Need optimization seriouslynnnSo can anybody suggest how can i optimize the above process for a better performance(Time and Memory both.)nnWhy I am worried is : I was doing the above on Python-Pandas platform (64Gb single machine with serialized pickle data) and I was able to do that in 8- 12mins. As my data-volume seems growing so need to adopt a technology like spark.nnThanks in Advance. :)n"" ""I think your best bet is cutting the source data down to size.  You mention that your source data has 90 cities but you are only interested in 8 of them.  Filter out the cities you don't want and keep the ones you do want in separate csv files:nnimport itertoolsnimport csvnncity_list = city1 city2city3...total 8 citiesnnwith open('f1.csv' 'rb') as f1 open('f2.csv' 'rb') as f2:n    r1 r2 = csv.reader(f1) csv.reader(f2)n    header = next(r1)n    next(r2) # discard headers in second filen    city_col = header.index('city_name')n    city_files = n    city_writers = {}n    try:n    for city in city_list:n            f = open(city+'.csv' 'wb')n            city_files.append(f)n            writer = csv.writer(f)n            writer.writerow(header)n            city_writerscity = writern        for row in itertools.chain(r1 r2):n            city_name = rowcity_coln            if city_name in city_writers:n                city_writerscity_name.writerow(row)n    finally:n        for f in city_files:n            f.close()nnnAfter this iterate over each city creating a DataFrame for the city then in a nested loop run your three queries.  Each DataFrame should have no problem fitting in memory and the queries should run quickly since they are running over a much smaller data set.n""",['python-2.7'],"['pandas', 'python-2.7', 'numpy']"
40089889,"'How to replace values in Â«groupbyÂ» (python) object?' ""Generally I need help in replacing one column in Â«groupbyÂ» object.nnI have a table with customer_id mcc_code tr_type (transaction type) and amount (of money):nncustomer_id    mcc_code   tr_type    amountn39026145       6011       7010       56147.89n39026145       5499       1010       -1392.47n39026145       5499       1010       -920.83n78029866       5411       1010       -8709.44n78029866       5541       1110       -21897.68n78029866       6011       2010       -8983.66nnnTable is longer. I have a lot of customers each make thousands of transaction trough different terminals (mcc_code).nnBasic solution is to use Â«groupbyÂ» attribute and then make sparce matrix for further Classifier usage:nnX = transactions.groupby('customer_id').apply(lambda x:  n                              x'mcc_code'.unstack().value_counts()).unstack().fillna(0)nnnBut I want to change this values from Â«groupbyÂ» by weighted arithmetic mean (valuei from value_counts * amounti / sum(amount))nnI tried to do next:nncode_counts = list(transactions.groupby('customer_id')'mcc_code'.value_counts(sort=False))nid_code_sums = list(transactions.groupby('customer_id' 'mcc_code')'amount'.sum())nsum_all = sum(id_code_sums)nweighted_mean = nfor i in range(len(id_code_sums)):n    weighted_mean.append(code_countsi*id_code_sumsi/sum_all)nnnNow I have needed list of values but they are some problems. First before making matrix I have that (using my data):nnX = transactions.groupby('customer_id').apply(lambda x:  n                              x'mcc_code'.unstack().value_counts()).unstack()nprint(X)n>>> customer_idn    39026145     5499    446n                 4814    138n                 6011    137n                 5331     82n                 5541     77n                 6012     13n                 5411     13n                 5200     10n                 5722      1n    52220754     6011    190n                 5411    149n                 6010     86n                 4829     76nnnFirst column is customer_id.nSecond column is mcc_code.nThird column is how often this customer uses that mcc terminal.nI need change third column with weighted_mean list.nBut first I can't understand how to do that.nSecond order of elements in my weighted_mean list differs from order in third column of grouped table.nAnd I don't know how to compare needed weighted means with right values from third column.nnAs a result I want the same sparce matrix but with new values from weighted_mean list.nAny suggestions?n"" nan","['python-3.x', 'pandas']","['python-2.7', 'pandas']"
40089988,"'Axes without labels and only one plot produced instead of many using matplotlib with LateX' 'I am testing a python code which produces some plots from a database results using  matplotlib with LateX. The problem is that I am getting only one plot and it is not labeled. Below the error and the lines of code that generates the error(I can post the whole method if needed).Any hint?nnif fileName is not None:n    if verbose:n        print(""Saving file"")n    from matplotlib.backends.backend_pdf import PdfPagesn    with PdfPages(fileName) as pdf:n        for fig in figures:n            for ax in fig.axes:n                __add_legend(ax outside=legend_outside)n            pdf.savefig(fig)nreturn figuresnnn__add_legend  is given by the followingnn   def __add_legend(ax handles=None labels=None alpha=0.5n             outside=None loc='best' *args **kwargs):n         if not handles:n             handles labels = ax.get_legend_handles_labels()n         if not handles:n             returnn         if outside is not None and len(handles) >= outside:n    # Shrink current axis by 20%n              box = ax.get_position()n              ax.set_position(box.x0 box.y0 box.width * 0.8 box.height)n              ax.legend(handles labels loc='center left' fancybox=Falsen              frameon=False shadow=Falsen              bbox_to_anchor=(1 0.5)).draggable(True)n         else:n              ax.legend(handles labels loc=loc fancybox=Truen              shadow=True).draggable(True)nnnThe error messagenn  Traceback (most recent call last):n  File ""../plot_prog.py"" line 5 in <module>n  run_program()n  File ""/home/hammouc/Documents/mimclib-last/mimclib/plot.py"" line 1364 in run_programnelse filteritr_convergent)nFile ""/home/hammouc/Documents/mimclib-last/mimclib/plot.py"" line 1285 in genPDFBookletnpdf.savefig(fig)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends /backend_pdf.py"" line 2473 in savefign figure.savefig(self format='pdf' **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/figure.py"" line 1563 in savefignself.canvas.print_figure(*args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backend_bases.py"" line 2232 in print_figuren**kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_pdf.py"" line 2536 in print_pdfnself.figure.draw(renderer)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/artist.py"" line 62 in draw_wrapperndraw(artist renderer *args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/figure.py"" line 1159 in drawnfunc(*args)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/artist.py"" line 62 in draw_wrapperndraw(artist renderer *args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_base.py"" line 2319 in drawna.draw(renderer)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/artist.py"" line 62 in draw_wrapperndraw(artist renderer *args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/axis.py"" line 1113 in drawntick.draw(renderer)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/artist.py"" line 62 in draw_wrapperndraw(artist renderer *args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/axis.py"" line 254 in drawnself.label1.draw(renderer)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/artist.py"" line 62 in draw_wrapperndraw(artist renderer *args **kwargs)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/text.py"" line 792 in drawnmtext=mtext)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_pdf.py"" line 1912 in draw_texnself._setup_textpos(curx cury angle oldx oldy)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_pdf.py"" line 1770 in _setup_textposnself.file.output(x - oldx y - oldy Op.textpos)nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_pdf.py"" line 589 in outputnself.write(fill(pdfRepr(x) for x in data))nFile ""/usr/local/lib/python2.7/dist-packages/matplotlib/backends/backend_pdf.py"" line 149 in pdfReprnraise ValueError(""Can only output finite numbers in PDF"")nValueError: Can only output finite numbers in PDFnnnI used pdb command in python just before pdf.savefigs() and I obtained this                          nn   > /home/hammouc/Documents/mimclib-last/mimclib   /plot.py(1287)genPDFBooklet()n   -> pdf.savefig(fig)n   (Pdb) n  Traceback (most recent call last):n  File ""../plot_prog.py"" line 5 in <module>n   run_program()n   File ""/home/hammouc/Documents/mimclib-last/mimclib/plot.py"" line 1367 in run_programn   else filteritr_convergent)n    File ""/home/hammouc/Documents/mimclib-last/mimclib/plot.py"" line 1287 in genPDFBookletn   pdf.savefig(fig)n   File ""/home/hammouc/Documents/mimclib-last/mimclib/plot.py"" line 1287 in genPDFBookletn  pdf.savefig(fig)n  File ""/usr/lib/python2.7/bdb.py"" line 48 in trace_dispatchn  return self.dispatch_line(frame)n  File ""/usr/lib/python2.7/bdb.py"" line 67 in dispatch_linen  if self.quitting: raise BdbQuit bdb.BdbQuitnn' nan","['python-2.7', 'matplotlib']",['matplotlib']
40090082,"'Matplotlib: Gridspec not displaying bar subplot' 'I have a 4x3 grid. I have 1 broken horizontal bar plot in the first row followed by 9 scatter plots. The height of the bar plot needs to be 2x height of the scatter plots. I am using gridspec to achieve this. However it doesn't plot the bar plot completely. See picture below:nnnnThe complete bar plot looks like thisnnnnI am not sure why is this happening. Any suggestions?nnHere's my code:nnimport numpy as npnfrom matplotlib import pyplot as pltnfrom matplotlib import gridspecnn#####Importing Data from csv file#####nndataset1 = np.genfromtxt('dataSet1.csv' dtype = float delimiter = '' skip_header = 1 names = 'a' 'b' 'c' 'x0')ndataset2 = np.genfromtxt('dataSet2.csv' dtype = float delimiter = '' skip_header = 1 names = 'a' 'b' 'c' 'x0')ndataset3 = np.genfromtxt('dataSet3.csv' dtype = float delimiter = '' skip_header = 1 names = 'a' 'b' 'c' 'x0')nncorr1 = np.corrcoef(dataset1'a'dataset1'x0')ncorr2 = np.corrcoef(dataset1'b'dataset1'x0')ncorr3 = np.corrcoef(dataset1'c'dataset1'x0')ncorr4 = np.corrcoef(dataset2'a'dataset2'x0')ncorr5 = np.corrcoef(dataset2'b'dataset2'x0')ncorr6 = np.corrcoef(dataset2'c'dataset2'x0')ncorr7 = np.corrcoef(dataset3'a'dataset3'x0')ncorr8 = np.corrcoef(dataset3'b'dataset3'x0')ncorr9 = np.corrcoef(dataset3'c'dataset3'x0')nnfig = plt.figure(figsize = (88))ngs = gridspec.GridSpec(4 3 height_ratios=2111) nndef tornado1():n    np.set_printoptions(precision=4)nn    variables = 'a1''b1''c1''a2''b2''c2''a3''b3''c3'n    base = 0  n    values = np.array(corr101corr201corr301n                       corr401corr501corr601n                       corr701corr801corr901)n    variables=zip(*sorted(zip(variables values)reverse = True key=lambda x: abs(x1)))0 n    values = sorted(valueskey=abs reverse=True)nn    # The y position for each variablen    ys = range(len(values))::-1  # top to bottom   nn    # Plot the bars one by onen    for y value in zip(ys values):n        high_width = base + valuenn        # Each bar is a ""broken"" horizontal bar chartn        ax1= plt.subplot(gs1).broken_barh(n            (base high_width)n            (y - 0.4 0.8)n            facecolors='red' 'red'  # Try different colors if you liken            edgecolors='black' 'black'n            linewidth=1n        )nn    # Draw a vertical line down the middlen    plt.axvline(base color='black')nn    # Position the x-axis on the top/bottom hide all the other spines (=axis lines)n    axes = plt.gca()  # (gca = get current axes)n    axes.spines'left'.set_visible(False)n    axes.spines'right'.set_visible(False)n    axes.spines'top'.set_visible(False)n    axes.xaxis.set_ticks_position('bottom')nn    # Make the y-axis display the variablesn    plt.yticks(ys variables)nn    plt.ylim(-2 len(variables))nn    plt.draw()n    returnnndef correlation1():nn    corr1 = np.corrcoef(dataset1'a'dataset1'x0')n    print corr101n    corr2 = np.corrcoef(dataset1'b'dataset1'x0')n    print corr201n    corr3 = np.corrcoef(dataset1'c'dataset1'x0')n    print corr301nn    ax2=plt.subplot(gs3)n    ax2.scatter(dataset1'a'dataset1'x0'marker = '.')n    ax2.set_xlabel('a1')n    ax2.set_ylabel('x01')n    ax3=plt.subplot(gs4)n    ax3.scatter(dataset1'b'dataset1'x0'marker = '.')n    ax3.set_xlabel('b1')n    #ax3.set_ylabel('x01')n    ax4=plt.subplot(gs5)n    ax4.scatter(dataset1'c'dataset1'x0'marker = '.')n    ax4.set_xlabel('c1')n    #ax4.set_ylabel('x01')n    ax5=fig.add_subplot(gs6)n    ax5.scatter(dataset2'a'dataset2'x0'marker = '.')n    ax5.set_xlabel('a2')n    ax5.set_ylabel('x02')n    ax6=fig.add_subplot(gs7)n    ax6.scatter(dataset2'b'dataset2'x0'marker = '.')n    ax6.set_xlabel('b2')n    #ax6.set_ylabel('x02')n    ax7=fig.add_subplot(gs8)n    ax7.scatter(dataset2'c'dataset2'x0'marker = '.')n    ax7.set_xlabel('c2')n    #ax7.set_ylabel('x02')n    ax8=plt.subplot(gs9)n    ax8.scatter(dataset3'a'dataset3'x0'marker = '.')n    ax8.set_xlabel('a3')n    ax8.set_ylabel('x03')n    ax9=plt.subplot(gs10)n    ax9.scatter(dataset3'b'dataset3'x0'marker = '.')n    ax9.set_xlabel('b3')n    #ax9.set_ylabel('x03')n    ax10=plt.subplot(gs11)n    ax10.scatter(dataset3'c'dataset3'x0'marker = '.')n    ax10.set_xlabel('c3')n    #ax10.set_ylabel('x03')nn    plt.show()n    returnnntornado1()ncorrelation1()nplt.tight_layout()nplt.show()nnnAny help would be highly appreciated :-)n' 'In the block of code:nn# Plot the bars one by onenfor y value in zip(ys values):n    high_width = base + valuenn    # Each bar is a ""broken"" horizontal bar chartn    ax1= plt.subplot(gs1).broken_barh(n        (base high_width)n        (y - 0.4 0.8)n        facecolors='red' 'red'  # Try different colors if you liken        edgecolors='black' 'black'n        linewidth=1n    )nnnYou're reinitializing gs1 on each loop so in the end your plot only contains the last bar. You should try something like this instead:nn# Plot the bars one by onenax1 = plt.subplot(gs1)nnfor y value in zip(ys values):n    high_width = base + valuenn    # Each bar is a ""broken"" horizontal bar chartn    ax1.broken_barh(n        (base high_width)n        (y - 0.4 0.8)n        facecolors='red' 'red'  # Try different colors if you liken        edgecolors='black' 'black'n        linewidth=1n    )nnnHope that helps.n'","['python-2.7', 'matplotlib']",['matplotlib']
40090090,'Django (1.10) override AdminSite' 'I've tried to override AdminSite class with my own custom class. I followed tutorial from django's  documentation: https://docs.djangoproject.com/en/1.10/ref/contrib/admin/#customizing-adminsite but it didn't work. To be specific I'd like to override original AdminSite with my own class and not just add another admin site into my project.nnI've created my custom class MyAdminSite which inherit from class nnfrom django.contrib.admin import AdminSitennnclass MyAdminSite(AdminSite):n    passnnnThen in my app urls.py I've add:nnfrom django.conf.urls import url includenimport django.contrib.admin as adminnfrom .admin_site import MyAdminSitennadmin.site = MyAdminSite()nadmin.autodiscover()nnnurlpatterns = n    url(r'^' admin.site.urls)nnnnIt seemed to work but admin models are register to AdminSite insted of MyAdminSite.nnI tried three ways of register models to my custom site:nn@admin.register(Model)nclass ModelAdmin(model.AdminModel):n...nnnThis way models are registered to original AdminSite.nnSecond way:nn@admin.site.register(Model):nclass ModelAdmin(model.AdminModel):n...nnnThat don't work and cause exception. The ModelAdmin class isn't passed to register method.nnLast way:nnclass ModelAdmin(model.AdminModel):n...nadmin.site.register(Model ModelAdmin)nnnThat works but on admin site I can see only my models not models from Django admin (Users and Groups).nnHow can I permanently override admin.site and register all models to MyAdminSite?n' nan,['django'],['django']
40090107,"'Args and dictionary in render_to_response' ""How to pass arguments and a dictionary in the query ?nnMy example does not worknnreturn render_to_response('bookmarks_add.html' {'categories': categories 'args':args})nnnSeparately worknnreturn render_to_response('bookmarks_add.html' args)nnnandnnreturn render_to_response('bookmarks_add.html' {'categories': categories})nn"" ""try this:nnargs.update({n   'categories': categoriesn})nreturn render_to_response('bookmarks_add.html' args)nn""",['django'],['django']
40090167,"'Django Python Script' 'I've been sifting through the documention but I don't feel like I'm getting a clear answer.  Is it possible to run something python-likennif company_name.startswith(('A')):nenter code herennnfrom within a Django site or app?  How would I go about it?nnCurrently the code I use is nn            {% for TblCompanies in object_list %}n              <tr class=""customer-table"">n                <td>{{ TblCompanies.company_id }}</td>n                <td>{{ TblCompanies.company_name }}</td>n                <td>{{ TblCompanies.contact_phone }}</td>n                <td>{{ TblCompanies.billing_address }}</td>n                <td>{{ TblCompanies.contact_e_mail }}</td>n              </tr>n            {% endfor %}nnnbut our customer database is too large and it's a burden to have to go through the list to find a customer.  I want to instead sort it alphabetically using urls like http://path/to/customer_list/An' 'Using slice filter you can get a substring; then compare the substring with the 'A':nn{% for TblCompanies in object_list %}n  {% if TblCompanies.company_name|slice:':1' == 'A' %}n  <tr class=""customer-table"">n    <td>{{ TblCompanies.company_id }}</td>n    <td>{{ TblCompanies.company_name }}</td>n    <td>{{ TblCompanies.contact_phone }}</td>n    <td>{{ TblCompanies.billing_address }}</td>n    <td>{{ TblCompanies.contact_e_mail }}</td>n  </tr>n  {% endif %}n{% endfor %}nnnAs @Matthias commented it would be better to pass filtered object_list in view. Assuming object_list is a queryset object:nnobject_list = object_list.filter(company_name__startswith='A')nnnnnSorintgnnSort the object_list before passing it to the template:nnpage = requests.REQUEST.get('page' 'A')  # or Get from view parametern                                          #    depending on url conf.nobject_list = (object_list.filter(company_name__startswith=page)n                          .order_by('company_name'))nnnUPDATEnnNOTE: Change app with actual app name.nnurls.py:nnurl(r'^/path/to/site/customers/(?P<page>A-Z)$' 'app.views.list_customers')nnnapp/views.py:nnfrom django.shortcuts import rendernndef list_compnaies(request page):n    object_list = (Customer.objects.filter(company_name__startswith=page)n                           .order_by('company_name'))n    return render(request 'customers/list.html' {n        'object_list': object_listn    })nnncustomers/list.htmlnn{# Link to A .. Z customer pages %}n{% for page in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' %}n<a href=""/path/to/site/customers/{{ page }}"">{{ page }}</a>n{# Use {% url ... %} once you learn the url tag if possible to reduce duplicated hard-coded url #}n{% endif %}nn{% for TblCompanies in object_list %}n<tr class=""customer-table"">n    <td>{{ TblCompanies.company_id }}</td>n    <td>{{ TblCompanies.company_name }}</td>n    <td>{{ TblCompanies.contact_phone }}</td>n    <td>{{ TblCompanies.billing_address }}</td>n    <td>{{ TblCompanies.contact_e_mail }}</td>n</tr>n{% endfor %}nn'",['django'],['django']
40090229,"'How to retrieve a data requested by user from django models?' 'I have a model and it has  user table as  ""foreign key"" in it . I need a query by which i can get user requested value . nnHere is  my models:nrnrnfrom django.db import modelsrn#from django.contrib.auth.models import Userrn rnfrom django.db import modelsrnfrom datetime import datetime    rn rnfrom django.conf import settingsrnrnclass schedulesdb(models.Model):rn    f_name = models.CharField(max_length=100)rn    dateAndTime = models.DateTimeField('%Y-%m-%d %H:%M:%S'null=True)rn    user = models.ForeignKey(settings.AUTH_USER_MODEL default=1)rnrn    def __unicode__(self):              #  on Python 2rn        return self.f_namern rnrnrnnnI was trying in this way I don't know what was wrong here :nnHere is my views.py:nnrnrndef dashboard(request):rncontainer=rnDIR = os.path.realpath(""/home/user/Desktop/Demo"")rnWAY = os.listdir(DIR)rnfor file in WAY:rn    if file.endswith('.mp4'):rn        file_name = filern        FDIR=os.path.join(DIR file)rn        container.append(FDIR)rn        rnreturn render(request 'dashboard.html' {'container': container})rnrndef new_scheduler(request):rnif request.method =='POST':rn    f_name = request.POST.get('file')rn    dateAndTime = request.POST.get('dateAndTime')rnScheduled_data = schedulesdb.objects.create(rn        f_name = filern        dateAndTime = dateAndTime  rn    )rnScheduled_data.save()rnreturn HttpResponse ('done')rnrnrndef new_job(request):rnuser = request.userrnprint user.usernamernprint user.idrn   rnschedule_entries = schedulesdb.objects.filter(user=request.user)rnprint schedule_entries.dateAndTimernrnrnreturn HttpResponse(schedule_entries)rnrnrnnnHere is my Traceback:nnrnrnPerforming system checks...rnrnSystem check identified no issues (0 silenced).rnOctober 17 2016 - 16:10:43rnDjango version 1.8 using settings 'pro1.settings'rnStarting development server at http://127.0.0.1:8000/rnQuit the server with CONTROL-C.rngokurn2rnrn17/Oct/2016 16:10:51""GET /job/ HTTP/1.1"" 200 0rnrnrnnnThanks in advance #peacen' 'In order to select all the records from schedulesdb model that relate to the current user do the following.nndef new_job(request):    n    schedule_entries = schedulesdb.objects.filter(user=request.user)n    return HttpResponse(schedule_entries)nnnP.S. It is always better to follow the Python convention so that other programmers can read your code faster. Start by reading the PEP-8 Style Guiden'",['django'],['django']
40090233,"'Django multiple forms on one view' 'I have a Django template that has data from a few different model types combining to make it. A dashboard if you will. And each of those has an edit form. nnIs it best to process all those forms in one view as they are posted back to the same place and differentiating between them by a unique field like below? nnOr if having lots of different dedicated avenues is the way forward? Thanks for any guidancennclass ProjectDetail(DetailView):nntemplate_name = 'project/view.html'nndef get_object(self):n    try:n        return Project.objects.filter(brief__slug=self.kwargs'slug').filter(team=get_user_team(self.request)).first()n        # add loop to allow multiple teams to work on the same brief (project)n    except Exception as e:n        project_error = '%s (%s)' % (e.message type(e))n        messages.error(self.request 'OH NO! %s' % project_error)n        return redirect('home')nndef get_context_data(self **kwargs):n    project = self.get_object()n    context = dict()n    context'project' = projectn    context'milestone_form' = MilestoneForm(initial={'project': project})n    context'view' = selfn    return contextnndef post(self request *args **kwargs):n    # get the context for the pagen    context = self.get_context_data()n    try:n        # switch for each of the form types on the team profile page (shown if member)n        if 'milestone_form_submit' in request.POST:n            project=self.get_object()n            # set date arbitrarily to half way to brief deadlinen            brief = Brief.objects.get(project=project)n            last_milestone = self.milestones().last()n            milestone_del_date = last_milestone.del_date + timedelta(days=7)nn            new_milestone = Milestone(n                                project=projectn                                title_text=request.POST.get('title_text')n                                del_date=milestone_del_daten                                )n            try:n                new_milestone.save()n                messages.success(self.request ""Excellent! New delivery popped on the bottom of the list"")n            except Exception as e:n                # pass the erroring form back in the context if notn                form = MilestoneForm(request.POST)n                context'milestone_form' = formn                messages.error(self.request ""OH NO! Deadline didn't save. Be a sport and check what you entered"")nn        elif 'milestone-edit-date-form-submit' in request.POST:n            # get object from dbn            milestone = Milestone.objects.get(pk=request.POST'id')n            # update del_date field sentn            milestone.del_date = request.POST'del_date'n            # save back to dbn            milestone.save()n            messages.success(self.request ""Updated that delivery right there!"")nn        elif ...nn    except Exception as e:n        messages.error(self.request ""OH NO! Deadline didn't save. Be a sport and check what you entered"")n    return render(request self.template_name context)nn' 'You can use mixins in order to solve your problem.nnExample from the gist https://gist.github.com/michelts/1029336nnclass MultipleFormsMixin(FormMixin):n    """"""n    A mixin that provides a way to show and handle several forms in an    request.n    """"""n    form_classes = {} # set the form classes as a mappingnn    def get_form_classes(self):n        return self.form_classesnn    def get_forms(self form_classes):n        return dict((key klass(**self.get_form_kwargs())) n            for key klass in form_classes.items())nn    def forms_valid(self forms):n        return super(MultipleFormsMixin self).form_valid(forms)nn    def forms_invalid(self forms):n        return self.render_to_response(self.get_context_data(forms=forms))nnnAs you can see when you inherit from this class you can handle multiple forms simultaneously. Look at the gist's code and adapt it to your problem.nnLook at this answern'",['django'],['django']
40090235,"'Joining string of a columns over several index while keeping other colums' 'Here is an example data set:nn>>> df1 = pandas.DataFrame({n    ""Name"": ""Alice"" ""Marie"" ""Smith"" ""Mallory"" ""Bob"" ""Doe""n    ""City"": ""Seattle"" None None ""Portland"" None Nonen    ""Age"": 24 None None 26 None Nonen    ""Group"": 1 1 1 2 2 2})nn>>> df1n    Age      City  Group     Namen0  24.0   Seattle      1    Alicen1   NaN      None      1    Marien2   NaN      None      1    Smithn3  26.0  Portland      2  Malloryn4   NaN      None      2      Bobn5   NaN      None      2      DoennnI would like to merge the Name column for all index of the same group while keeping the City and the Age wanting someting like:nn>>> df1_summarisedn    Age      City  Group     Namen0  24.0   Seattle      1    Alice Marie Smithn1  26.0  Portland      2    Mallory Bob DoennnI know those 2 columns (Age City) will be NaN/None after the first index of a given group from the structure of my starting data. nnI have tried the following:nn>>> print(df1.groupby('Group')'Name'.apply(' '.join))nGroupn1    Alice Marie Smithn2      Mallory Bob DoenName: Name dtype: objectnnnBut I would like to keep the Age and City columns...n' ""try this:nnIn 29: df1.groupby('Group').ffill().groupby('Group''Age''City').Name.apply(' '.join)nOut29:nGroup  Age   Cityn1      24.0  Seattle     Alice Marie Smithn2      26.0  Portland      Mallory Bob DoenName: Name dtype: objectnn"" 'using dropna and assign with groupbynndocs to assignnndf1.dropna(subset='Age' 'City') n   .assign(Name=df1.groupby('Group').Name.apply(' '.join).values)nnnnnnntimingnper requestnnnnnnupdatenuse groupby and aggnI thought of this and it feels far more satisfyingnndf1.groupby('Group').agg(dict(Age='first' City='first' Name=' '.join))nnnto get the exact outputnndf1.groupby('Group').agg(dict(Age='first' City='first' Name=' '.join)) n   .reset_index().reindex_axis(df1.columns 1)nn'",['pandas'],['pandas']
40090254,"'Grouping Tweets by Half-Hour Hour and Day in Pandas Dataframe' 'I'm working on a Sentiment Analysis project using Twitter Data and I've encountered a small problem regarding Dates.  The code itself runs fine but I don't know how to build custom time blocks for grouping my final data.  Right now it is defaulting to grouping them by the second which is not very useful.  I want to be able to group them in half-hour hour and day segments...nnFeel free to skip to the bottom of the code to see where the issue lies!nnHere is the code:nnimport tweepynAPI_KEY = ""XXXXX""nAPI_SECRET = XXXXXX""nauth = tweepy.AppAuthHandler(API_KEY API_SECRET)napi = tweepy.API(auth wait_on_rate_limit = True wait_on_rate_limit_notify = True)nimport sklearn as sknimport pandas as pdnimport got3n  #""Get Old Tweets"" to find older datanntweetCriteria = got3.manager.TweetCriteria() ntweetCriteria.setQuerySearch(""Kentucky Derby"")ntweetCriteria.setSince(""2016-05-07"") ntweetCriteria.setUntil(""2016-05-08"")ntweetCriteria.setMaxTweets(1000)nnTweetCriteria = got3.manager.TweetCriteria()nKYDerby_tweets = got3.manager.TweetManager.getTweets(tweetCriteria)nnfrom afinn import Afinnnafinn = Afinn()n    #getting afinn library to use for sentiment polarity analysisnnfor x in KYDerby_tweets:n    Text = x.textn    Retweets = x.retweetsn    Favorites = x.favoritesn    Date = x.daten    Id = x.idn    print(Text)nnAllText = nAllRetweets = nAllFavorites = nAllDates = nAllIDs = nfor x in KYDerby_tweets:n    Text = x.textn    Retweets = x.retweetsn    Favorites = x.favoritesn    Date = x.daten    AllText.append(Text)n    AllRetweets.append(Retweets)n    AllFavorites.append(Favorites)n    AllDates.append(Date)n    AllIDs.append(Id)nndata_set = x.id x.date x.text x.retweets x.favorites n        for x in KYDerby_tweetsndf = pd.DataFrame(data=data_set columns=""Id"" ""Date"" ""Text"" ""Favorites"" ""Retweets"")n    #I now have a DataFrame with my basic info in itnnpscore = nfor x in KYDerby_tweets:n    afinn.score(x.text)n    pscore.append(afinn.score(x.text))ndf'P Score' = pscoren    #I now have the pscores for each Tweet in the DataFramennnrc = pd.read_csv('C:usersandrew.smithdownloadsNRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt' sep=""t"" names=""word"" ""emotion"" ""association"" skiprows=45)n    #import NRC emotion lexiconnnnrc = nrcnrc""association""==1nnrc = nrcnrc""emotion"".isin(""positive"" ""negative"") == Falsen    #cleaned it up a bitnnfrom nltk import TweetTokenizerntt = TweetTokenizer()ntokenized = x.lower() for x in tokenizedn    #built my Tweet-specific NRC-ready tokenizernnemotions = list(set(nrc""emotion""))nindex2emotion = {}nemotion2index = {}nnfor i in range(len(emotions)):n    index2emotioni = emotionsin    emotion2indexemotionsi = i  ncv = 0 * len(emotions)n    #built indices showing locations of emotionsnnfor token in tokenized:n    sub = nrcnrc'word' == tokenn   token_emotions = sub'emotion'n   for e in token_emotions:n       position_index = emotion2indexen       cvposition_index+=1nnemotions = list(set(nrc'emotion'))nindex2emotion = {}nemotion2index = {}nfor i in range(len(emotions)):n    index2emotioni = emotionsin    emotion2indexemotionsi = inndef makeEmoVector(tweettext):n    cv = 0 * len(emotions)n    tokenized = tt.tokenize(tweettext)n    tokenized = x.lower() for x in tokenizedn    for token in tokenized:n        sub = nrcnrc'word' == tokenn        token_emotions = sub'emotion'n        for e in token_emotions:n            position_index = emotion2indexen            cvposition_index += 1n    return cvnntweettext = df.iloc14:'Text'nnemotion_vectors = nnfor text in df'Text':n    emotion_vector = makeEmoVector(text)n    emotion_vectors.append(emotion_vector)nnev = pd.DataFrame(emotion_vectors index=df.index columns=emotions)n    #Now I have a DataFrame with all of the emotion counts for each tweetnnDate_Group = df.groupby(""Date"")nDate_Groupemotions.agg(""sum"")n    #Finally we arrive at the problem!  When I run this I end up with tweets that are grouped *by the second.  What I want is to be able to group them: a) by the half-hour b) by the hour and c) by the daynn' nan",['pandas'],['pandas']
40090375,"'Convert a string into list of list' 'I have a string say:nns = ""abcdefghi""nnI need to create a list of lists of this such that the list formed will :-nnlist = 'a''b''c''d''e''f''g''h''i'nnNow the string can be anything but will always have length n * nnnSo if n = 4.nnThe len(s) = 16nnAnd the list will be:nn'1''2''3''4''5''6''7''8'...'13''14''15''16'nnnSo each list in the list of lists will have length 4.nnSo I want to write a function which takes string and n as input and gives na list of list as output where the length of each list within the list is n.nnHow can one do this ?nnUPDATE :nnHow can you convert the above list of list back to a string ?nnSo if l = list = 'a''b''c''d''e''f''g''h''i'nnHow to convert it to a string :-nns = ""abcdefghi""nnI found a solution for this in stackoverflow :-nns = """".join("""".join(map(strl)) for l in list)nnnThanks everyone !n' ""Here's a list comprehension that does the job:nnlist(si:i+n) for i in range(0 len(s) n)nnnIf n * n == len(s) is always true then just putnnn = int(len(s) ** 0.5) # Or use math.sqrtnnnFor the edit part here's another list comprehension:nn''.join(e for e in sub for sub in l)nn"" 'I'm a personal fan of numpy...nnimport numpy as npns = ""abcdefghi""nn = int(np.sqrt(len(s)))na = np.array(x for x in s dtype=str).reshape(nn)nn' 'from math import sqrtndef listify(s):n    n = sqrt(len(s))n    g = iter(s)n    return next(g) for i in range(n) for j in range(n)nnnI like using generators for problems like thisn'",['list'],"['list', 'python-2.7']"
40090383,"'How to get a graph to start a certain point? (matplotlib)' 'I was just wondering if anyone could tell me how to start a graph at a certain height on the y axis? nnLike if I wanted to start my curve at 50? I am plotting the trajectories of projectiles and I need to be able to plot it when they enter a starting height that isn't 0. Thanks in advance! I am very new to python and matplotlib.nnMy Code for firing at an angle:nndef angle_calculation():nnprint(""nTo calculate the components of a projectile fired at an angle"")nprint(""We need the angle(degrees) the initial velocity(ms-1) and"")nprint(""The gravity constant (9.81 on earth)n"")nangle_0 = float(input(""Please enter the angle you want it to be fired at: ""))nangle_0 = (angle_0)/180.0*np.pinspeed = float(input(""nPlease enter the initial velocity you want it to be fire atn In metres per second: ""))ng=9.81nplt.figure()ntime_max = ((2 * speed) * np.sin(angle_0)) / gntime = time_max*np.linspace(01100):Nonenx_values = ((speed * time) * np.cos(angle_0))ny_values = ((speed * time) * np.sin(angle_0)) - ((0.5 * g) * (time ** 2)) ndistance_x = (speed * np.cos(angle_0))*time_max nplt.plot(x_valuesy_values linewidth = 1.5)nplt.ylim(0200)nplt.xlim(0distance_x)nplt.show()   nprint("""")nprint (""The Range of this projectile will be ""(distance_x))nprint ("""")nfor x y in zip(y_values x_values):n    if x == 0 or y == 0:n        print(x y)nreturnnn' 'Is it what you're looking for? nnimport numpy as npnimport matplotlib.pyplot as pltnnprint(""nTo calculate the components of a projectile fired at an angle"")nprint(""We need the angle(degrees) the initial velocity(ms-1) and"")nprint(""The gravity constant (9.81 on earth)n"")nangle_0 = float(input(""Please enter the angle you want it to be fired at: ""))nangle_0 = (angle_0)/180.0*np.pinspeed = float(input(""nPlease enter the initial velocity you want it to be fire atn In metres per second: ""))nstart = float(input(""nPlease enter the starting pointn In metres: ""))ng=9.81nplt.figure()ntime_max = ((2 * speed) * np.sin(angle_0)) / gntime = time_max*np.linspace(01100):Nonenx_values = ((speed * time) * np.cos(angle_0))ny_values = ((speed * time) * np.sin(angle_0)) - ((0.5 * g) * (time ** 2))nx_values_trimmed = x_valuesx_values>startnstart_idx = np.where(x_values == x_values_trimmed0)0ny_values_trimmed = y_valuesint(start_idx):ndistance_x = (speed * np.cos(angle_0))*time_max nplt.plot(x_values_trimmedy_values_trimmed linewidth = 1.5)nplt.ylim(0200)nplt.xlim(startdistance_x)nplt.show()   nprint("""")nprint (""The Range of this projectile will be ""(distance_x))nprint ("""")nfor x y in zip(y_values x_values):n    if x == 0 or y == 0:n        print(x y)nnplt.show()nnnresult:nnTo calculate the components of a projectile fired at an anglenWe need the angle(degrees) the initial velocity(ms-1) andnThe gravity constant (9.81 on earth)nnPlease enter the angle you want it to be fired at: 50nnPlease enter the initial velocity you want it to be fire atn In metres per second: 30nnPlease enter the starting pointn In metres: 20nnnn'",['matplotlib'],['matplotlib']
40090445,"'paramiko.exec_command() not executing and returns ""Extra params found in CLI""' 'I am trying to ssh a server using Paramiko and execute a command. But the paramiko.exec_command() returns with an error.Why is this happening?nnThis is my Python script:nnimport paramikonnssh = paramiko.SSHClient()nssh.load_system_host_keys()nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())nssh.connect('10.126.141.132' username='usrm' password='passwd')nnstdin stdout stderr = ssh.exec_command(""show chassis"")nnprint(stdout.readlines())nnssh.close()nnnWhen executed it returns with this message:nnn  'Extra params found in CLI this is not supported exiting the CLI session:n'nnnI am using Python 3.5.2 :: Anaconda 4.1.1 (64-bit) with Paramiko on Windows.nnI have tried the commands manually and it is working.n' 'Based on your latest comment:nnn  I installed a Cygwin Terminal and SSH'd the server with the command...it came up with the Extra params error. Command I executed: ssh usrm@10.126.141.132 ""show chassis"" Output: No entry for terminal type ""dumb""; using dumb terminal settings. Extra params found in CLI this is not supported exiting the CLI session:nnnit sounds like the usrm account's login shell on the SSH server is not allowed to run commands in the non-interactive way. To solve the problem you have to use invoke_shell() like this:nnchan = ssh.invoke_shell()nchan.sendall('show chassisr')ns = chan.recv(4096)nprint snn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40090519,'Why the Pool class in multiprocessing lack the __exit__() method in Python 2?' 'It is not clear to me why the Python 2.7 implementation of Pool does not have the __exit__() method that is present in the Python 3 version of the same class. Is it safe to add the __exit__() method (together with __enter__() of course) (I just want to use with Pool(n) as p: ) or is there a special reason to avoid it? n' 'Doesn't seem like there's any reason to avoid it. Looking at it and testing it real quick didn't bring up any odd behavior. This was implemented in Issue 15064 it just seems it wasn't added in 2.7 (probably because only bug-fixes were considered).nnReturning self from __enter__ and calling terminate from __exit__ as implemented in Python 3.3 should be the way to go. Instead of altering the source though (if that was your intention) just create a custom subclass:nnfrom multiprocessing.pool import Pool as PoolClsnnclass CMPool(PoolCls):n    def __enter__(self):n        return selfn    def __exit__(self exc_type exc_val exc_tb):n        return self.terminate()nn',"['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40090522,"'Pandas: How to conditionally assign multiple columns?' ""I want to replace negative values with nan for only certain columns. The simplest way could be:nnfor col in 'a' 'b' 'c':n    df.locdfcol  < 0 col = np.nannnndf could have many columns and I only want to do this to specific columns. nnIs there a way to do this in one line? Seems like this should be easy but I have not been able to figure out.n"" 'use loc and wherenncols = 'a' 'b' 'c'ndf.loc: cols = dfcols.where(dfcols.whwere.ge(0) np.nan)nnndemonstrationnndf = pd.DataFrame(np.random.randn(10 5) columns=list('abcde'))ndfnnnnncols = list('abc')ndf.loc: cols = dfcols.where(dfcols.ge(0) np.nan)ndfnnnnnnnYou could speed it up with numpynndfcols = np.where(dfcols < 0 np.nan dfcols)nnnto do the same thing.nnnntiming nndef gen_df(n):n    return pd.DataFrame(np.random.randn(n 5) columns=list('abcde'))nnnsince assignment is an important part of this I create the df from scratch each loop.  I also added the timing for df creation.nnfor n = 10000nnnnfor n = 100000nnn' ""Here's a way:nndfdf.columns.isin('a' 'b' 'c') & (df < 0) = np.nannn"" ""You can use np.where to achieve this:nnIn 47:ndf = pd.DataFrame(np.random.randn(55) columns=list('abcde'))ndfnnOut47:n          a         b         c         d         en0  0.616829 -0.933365 -0.735308  0.665297 -1.333547n1  0.069158  2.266290 -0.068686 -0.787980 -0.082090n2  1.203311  1.661110 -1.227530 -1.625526  0.045932n3 -0.247134 -1.134400  0.355436  0.787232 -0.474243n4  0.131774  0.349103 -0.632660 -1.549563  1.196455nnIn 48:    ndf'a''b''c' = np.where(df'a''b''c' < 0 np.NaN df'a''b''c')ndfnnOut48:n          a         b         c         d         en0  0.616829       NaN       NaN  0.665297 -1.333547n1  0.069158  2.266290       NaN -0.787980 -0.082090n2  1.203311  1.661110       NaN -1.625526  0.045932n3       NaN       NaN  0.355436  0.787232 -0.474243n4  0.131774  0.349103       NaN -1.549563  1.196455nn"" ""If it has to be a one-liner:nndf'a' 'b' 'c' = df'a' 'b' 'c'.apply(lambda c: x>0 and x or np.nan for x in c)nn"" ""I don't think you'll get much simpler than this:nn>>> df = pd.DataFrame({'a': np.arange(-5 2) 'b': np.arange(-5 2) 'c': np.arange(-5 2) 'd': np.arange(-5 2) 'e': np.arange(-5 2)})n>>> dfn   a  b  c  d  en0 -5 -5 -5 -5 -5n1 -4 -4 -4 -4 -4n2 -3 -3 -3 -3 -3n3 -2 -2 -2 -2 -2n4 -1 -1 -1 -1 -1n5  0  0  0  0  0n6  1  1  1  1  1n>>> dfdfcols < 0 = np.nann>>> dfn     a    b    c  d  en0  NaN  NaN  NaN -5 -5n1  NaN  NaN  NaN -4 -4n2  NaN  NaN  NaN -3 -3n3  NaN  NaN  NaN -2 -2n4  NaN  NaN  NaN -1 -1n5  0.0  0.0  0.0  0  0n6  1.0  1.0  1.0  1  1nn"" ""Sure just pick your desired columns out of the mask:nn(df < 0)'a' 'b' 'c'nnnYou can use this mask in df(df < 0)'a' 'b' 'c' = np.nan.n""",['pandas'],['pandas']
40090600,"'Python type checking not working as expected' ""I'm sure I'm missing something obvious here but why does the following script actually work?nnimport enumnimport typingnnclass States(enum.Enum):n    a = 1n    b = 2nnstates = typing.NewType('states' States)nndef f(x: states) -> states:n    return xnnprint(n    f(States.b)n    f(3)n)nnnAs far I understand it it should fail on the call f(3) however it doesn't. Can someone shed some light on this behaviour?n"" 'No checking is performed by Python itself. This is specified in the ""Non- Goals"" section of PEP 484. When executed (i.e during run-time) Python completely ignores the annotations you provided and evaluates your statements as it usually does dynamically.nnIf you need type checking you should perform it yourself. This can currently be performed by static type checking tools like mypy.n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40090619,"'pandas: merge conditional on time range' ""I'd like to merge one data frame with another where the merge is conditional on the date/time falling in a particular range. nnFor example let's say I have the following two data frames.nnimport pandas as pdnimport datetimenn# Create main data frame.ndata = pd.DataFrame()ntime_seq1 = pd.DataFrame(pd.date_range('1/1/2016' periods=3 freq='H'))ntime_seq2 = pd.DataFrame(pd.date_range('1/2/2016' periods=3 freq='H'))ndata = data.append(time_seq1 ignore_index=True)ndata = data.append(time_seq1 ignore_index=True)ndata = data.append(time_seq1 ignore_index=True)ndata = data.append(time_seq2 ignore_index=True)ndata'myID' = '001''001''001''002''002''002''003''003''003''004''004''004'ndata.columns = 'Timestamp' 'myID'nn# Create second data frame.ndata2 = pd.DataFrame()ndata2'time' = pd.to_datetime('1/1/2016 12:06 AM') pd.to_datetime('1/1/2016 1:34 AM') pd.to_datetime('1/2/2016 12:25 AM')ndata2'myID' = '002' '003' '004'ndata2'specialID' = 'foo_0' 'foo_1' 'foo_2'nn# Show data frames.ndatan             Timestamp myIDn0  2016-01-01 00:00:00  001n1  2016-01-01 01:00:00  001n2  2016-01-01 02:00:00  001n3  2016-01-01 00:00:00  002n4  2016-01-01 01:00:00  002n5  2016-01-01 02:00:00  002n6  2016-01-01 00:00:00  003n7  2016-01-01 01:00:00  003n8  2016-01-01 02:00:00  003n9  2016-01-02 00:00:00  004n10 2016-01-02 01:00:00  004n11 2016-01-02 02:00:00  004nndata2n                 time myID specialIDn0 2016-01-01 00:06:00  002     foo_0n1 2016-01-01 01:34:00  003     foo_1n2 2016-01-02 00:25:00  004     foo_2nnnI would like to construct the following output. nn# Desired output.n             Timestamp myID special_IDn0  2016-01-01 00:00:00  001        NaNn1  2016-01-01 01:00:00  001        NaNn2  2016-01-01 02:00:00  001        NaNn3  2016-01-01 00:00:00  002        NaNn4  2016-01-01 01:00:00  002      foo_0n5  2016-01-01 02:00:00  002        NaNn6  2016-01-01 00:00:00  003        NaNn7  2016-01-01 01:00:00  003        NaNn8  2016-01-01 02:00:00  003      foo_1n9  2016-01-02 00:00:00  004        NaNn10 2016-01-02 01:00:00  004      foo_2n11 2016-01-02 02:00:00  004        NaNnnnIn particular I want to merge special_ID into data such that Timestamp is the first time occurring after the value of time. For example foo_0 would be in the row corresponding to 2016-01-01 01:00:00 with myID = 002 since that is the next time in data immediately following 2016-01-01 00:06:00 (the time of special_ID = foo_0) among the rows containing myID = 002. nnNote Timestamp is not the index of data and time is not the index of data2. Most other related posts seem to rely on using the datetime object as the index of the data frame.n"" ""Not very beautiful but i think it works.nndata'specialID' = Nonenfoolist = list(data2'myID')nfor i in data.index:n    if data.myIDi in foolist:n        if data.Timestampi> list(data2data2'myID' == data.myIDi.time)0:n            data'specialID'i = list(data2data2'myID' == data.myIDi.specialID)0n            foolist.remove(list(data2data2'myID' == data.myIDi.myID)0)nnIn 95: datanOut95:n             Timestamp myID specialIDn0  2016-01-01 00:00:00  001      Nonen1  2016-01-01 01:00:00  001      Nonen2  2016-01-01 02:00:00  001      Nonen3  2016-01-01 00:00:00  002      Nonen4  2016-01-01 01:00:00  002     foo_0n5  2016-01-01 02:00:00  002      Nonen6  2016-01-01 00:00:00  003      Nonen7  2016-01-01 01:00:00  003      Nonen8  2016-01-01 02:00:00  003     foo_1n9  2016-01-02 00:00:00  004      Nonen10 2016-01-02 01:00:00  004     foo_2n11 2016-01-02 02:00:00  004      Nonenn"" 'You can use merge_asof which is new in Pandas 0.19 to do most of the work.  Then combine loc and duplicated to remove secondary matches:nn# Data needs to be sorted for merge_asof.ndata = data.sort_values(by='Timestamp')nn# Perform the merge_asof.ndf = pd.merge_asof(data data2 left_on='Timestamp' right_on='time' by='myID').drop('time' axis=1)nn# Make the additional matches null.ndf.locdf'specialID'.duplicated() 'specialID' = np.nannn# Get the original ordering.ndf = df.set_index(data.index).sort_index()nnnThe resulting output:nn             Timestamp myID specialIDn0  2016-01-01 00:00:00  001       NaNn1  2016-01-01 01:00:00  001       NaNn2  2016-01-01 02:00:00  001       NaNn3  2016-01-01 00:00:00  002       NaNn4  2016-01-01 01:00:00  002     foo_0n5  2016-01-01 02:00:00  002       NaNn6  2016-01-01 00:00:00  003       NaNn7  2016-01-01 01:00:00  003       NaNn8  2016-01-01 02:00:00  003     foo_1n9  2016-01-02 00:00:00  004       NaNn10 2016-01-02 01:00:00  004     foo_2n11 2016-01-02 02:00:00  004       NaNnn'",['pandas'],['pandas']
40090659,"'Program to add together a series of number' 'n  I am writing a program that will add together a series ofn  numbers a user inputs until the user enters a rogue value of 0. Then  program will then display the total.nnnuser_input = Nonentotal_sum = 0nwhile user_input != 0:n    user_input = input(""Enter a number:"")n    total_sum = total_sum + user_input nn# Sample output:n# Enter a number: 5n# Enter a number: 50n# Enter a number: 10n# Enter a number: 0n# The total sum of the numbers are 65nprint(""The total sum of the numbers are {}"".format(total_sum))nnnThe error that keeps coming up is :nntotal_sum = total_sum + user_inputnTypeError: unsupported operand type(s) for +: 'int' and 'str'nn' 'you need to cast the input to an intnnuser_input = int(user_input )nn' 'input returns a string even if it's a string that contains a number (e.g. ""5""). You need to explicitly convert it to an int:nnuser_input = int(input(""Enter a number: ""))nn' 'You need to parse String value to Integer value.nnIn your case user_input is String Value.nnTo parse String value to Integer you need to use int(user_input) instead of user_input.nntotal_sum = total_sum + int(user_input)  //Like thisn' 'input(""Enter a number"") returns a string which means user_input is of type string.nSo you need to cast user_input to int in order to add. i.e. total_sum = total_sum + parseInt(user_input)n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40090710,"'Select specific fields from nested json data' 'I got nested json data from an API call which looks like this (I simplyfied it as far as I could):nn{""title"": ""10.2016 - Questionnaire"" n""title_ml"": n    {""French (France)"": ""10.2016 - Questionnaire"" n    ""English"": ""10.2016 - survey""}n""id"": ""123456789"" n""status"": ""Launched"" n""languages"": ""English"" ""French (France)"" n""pages"": n    {""id"": 2 n    ""description"": {""French (France)"": """"} n    ""properties"": n    ""title"": n        {""French (France)"": ""Octobre 2016"" n        ""English"": ""October 2016""} n    ""questions"": n        {""description"":  n        ""id"": 3n        ""title"": n            {""French (France)"": ""Sur une Ã©chelle ...?"" n            ""English"": ""On a scale ...?""} n        ""properties"": n            {""messages"": n                {""l_extreme_label"":  n                ""th_content"": } n            ""disabled"": false n            ""option_sort"": false} n        ""options"": n            {""title"": n                {""French (France)"": ""1"" n                ""English"": ""1""} n            ""properties"": n                {""explorer_color"": ""94C826"" n                ""disabled"": false} n            ""id"": 10001 n            ""value"": ""1""} n            {""title"": n                {""French (France)"": ""2"" n                ""English"": ""2""} n            ""properties"": n                {""explorer_color"": ""F5A417"" n                ""disabled"": false} n            ""id"": 10002 n            ""value"": ""2""}n            {""title"": n                {""French (France)"": ""3"" n                ""English"": ""3""} n            ""properties"": n                {""explorer_color"": ""94C826"" n                ""disabled"": false} n            ""id"": 10003 n            ""value"": ""3""}} nn        {""description"":  n        ""id"": 5n        ""title"": n            {""French (France)"": ""Avez-vous ...?"" n            ""English"": ""Do you ...?""} n        ""properties"": n            {""messages"": n                {""l_extreme_label"":  n                ""th_content"": } n            ""disabled"": false n            ""option_sort"": false}n        ""options"": n            {""title"": n                {""French (France)"": ""J'ai bien aimÃ©"" n                ""English"": ""I like it""} n            ""properties"": n                {""explorer_color"": ""94C826"" n                ""disabled"": false} n            ""id"": 10002 n            ""value"": ""1""} n            {""title"": n                {""French (France)"": ""Je n'ai pas aimÃ©"" n                ""English"": ""I don't like it""} n            ""properties"": n                {""explorer_color"": ""F5A417"" n                ""disabled"": false} n            ""id"": 10003 n            ""value"": ""0""}}n        n    }n}nnnLet me explain the content. It's from a survey (no reponses but meta data). You can see the title of the survey (""10.2016 - Questionnaire"") and the id (""123456789""). In ""pages.questions"" you'll find information about the question (e. g. question title in multiple languages and id). In ""pages.questions.options"" you'll find information about answer options (e. g. answer title in multiple languages and id). I would like to have a pandas Dataframe like this:nnnnMy problems are:nnnI don't need all information from the data. But I don't mind get all data and then delete the columns I don't need.nThe length within a nest differs. Like in this example there are 2 and 3 options available (sometimes there are none).nThe column names are the same. There are 3 ""id""s: one for survey one for ""pages.questions"" and one for ""pages.questions.options"" and actually one more for ""pages"" but I don't need it.nnnIt would be nice if some of you could help me! Thanks a lot!n(Btw: I use python 3.5)n' nan",['pandas'],"['pandas', 'python-3.x']"
40090724,"'Elasticsearch returning JSON with types not actual data' 'I'm using the python API for ElasticSearch to index a set of dictionaries. Executing the code below:nn    result = es.index(index=""index_name"" doc_type='test-type' id=i body=mydict)nnnwhen I access the index_name I get a JSON with the attribute/object types rather than the actual data:nn{""1"":{""aliases"":{}""mappings"":{""test-type"":{""properties"":n{""name1"":{""type"":""string""}n ""name2"":{""type"":""string""}n ""name3"":{""type"":""string""}n ""name4"":{""type"":""string""}n ""name5"":{""type"":""string""}n ""name6"":{""type"":""string""}n ""main_text"":{""type"":""string""}n ""name7"":{""type"":""string""}n ""name8"":{""type"":""string""}n ""publication_year"":{""type"":""string""}n ""publisher_id"":{""type"":""string""}n ""subjects"":{""type"":""string""}}}}nn ""settings"":{""index"": {""creation_date"":""1476708871632""""number_of_shards"":""5""""number_of_replicas"":""1""""uuid"":""OOUvfYDKTMinTbhKXBmfjA""""version"":{""created"":""2040199""}}}""warmers"":{}}}nnnHowever if I go in result'_source' the information is there. Also if I do es.search and query for a keyword in the main_text attribute I retrieve the document appropriately. Since the data of the demo document that comes with ES is able to show the actual data rather then just the type is this the right way of doing it? Am I missing something?n' nan",['dictionary'],"['python-2.7', 'dictionary']"
40090734,"'Implementing __eq__ using numpy isclose' ""I fear this might be closed as being a soft questionnbut perhaps there is an obvious idiomatic way.nnI have a class that contains a lot of information stored in floating point numbers. nI am thinking about implementing the __eq__ method using not exact but numerical equivalence similar to np.isclose. At the moment I have three options:nnn__eq__ means exact comparison. But there is a function similar to np.isclosen__eq__ means exact comparison. But there is a function similar to np.iscloseand __eq__ prints a warning everytime it is called and refers to using the function.n__eq__ means numerical comparison.nnnI can not think of any use case where someone would like to do exact floating point comparison with this class. Hence option three is my favourite. nBut I don't want to surprise the user.n"" 'One option would be to add a context manager to switch modes:nnfrom contextlib import contextmanagernclass MyObject(object):n    _use_loose_equality = Falsen    @contextmanagern    @classmethodn    def loose_equality(cls enabled=True):n        old_mode = cls._use_loose_equalityn        cls._use_loose_equality = enabledn        try:n            yieldn        finally:n            cls._use_loose_equality = old_modenn    def __eq__(self):n        if self._use_loose_equality:n            ...n        else:n            ...nnnWhich you would use as:nnx = MyObject(1.1)ny = MyObject(1.100001)nassert x != ynwith MyObject.loose_equality():n    assert x == ynnnOf course this is still as dangerous as 3 but at least you now have control of when to enable the dangerous behaviourn'","['python-3.x', 'numpy']",['numpy']
40090744,"'How to select by WEEK and count it in postgresql and Django' 'I'm trying to select by week and counting how many tickets were sold on that week.nni select the tickets using EVENT ID.nnWHERE EVENT ID 148nSAMPLE DATA: TICKETS TABLEn-------------------------------------------------nn    ""General"";0;""2016-09-02 17:50:45.644381+00""n    ""General"";0;""2016-09-03 21:05:54.830366+00""n    ""General"";0;""2016-09-02 18:21:33.976451+00""n    ""Early Bird"";500;""2016-09-09 19:15:33.721279+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Post Secondary Student"";1000;""2016-09-06 14:46:53.90927+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""General"";0;""2016-09-01 23:50:05.034436+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Post Secondary Student"";1000;""2016-09-06 14:46:53.90927+00""n    ""Post Secondary Student"";1000;""2016-09-06 14:46:53.90927+00""n    ""General"";0;""2016-09-03 18:39:15.571188+00""n    ""General"";0;""2016-09-07 20:14:35.959517+00""n    ""General"";0;""2016-09-03 21:33:04.349198+00""n    ""General"";0;""2016-09-07 18:21:22.220223+00""n    ""General"";0;""2016-09-01 23:34:55.773516+00""n    ""General"";0;""2016-09-01 23:42:15.498778+00""n    ""Early Bird"";500;""2016-09-09 19:15:33.721279+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""RSVP"";0;""2016-09-27 21:27:33.378934+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""General"";1000;""2016-09-09 19:15:33.72771+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""RSVP"";0;""2016-09-14 22:23:04.922607+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""Youth"";0;""2016-09-06 14:46:53.903704+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""General Admission"";0;""2016-09-23 15:35:54.972803+00""n    ""Free Admission"";0;""2016-10-03 19:12:12.965369+00""n    ""Free Admission"";0;""2016-10-06 19:00:25.926406+00""n    ""Free Admission"";0;""2016-10-06 19:00:25.926406+00""nnnAny suggestions how i would achieve that?nnI DID THIS TO FIND AND COUNT BY DAY:nnTicket.objects.filter(event_id=event_id event_ticket_id=ticket_type.id refunded=False).extra(where=('created')n                            select={'date_sold':'date(created)'}).values('date_sold').annotate(sold_count=Count('id'))nnnbut could not do by week.nnThank youn' ""Here is a solution that I used in a similar situation.nI used a Raw SQL query however.nnTicket.objects.raw('''SELECT COUNT(app_ticket.id) as id app_ticket.name EXTRACT(WEEK FROM app_ticket.created) as week EXTRACT(YEAR FROM app_ticket.created) as YEARn      FROM app_ticketn      WHERE app_ticket.event_id = %sn      GROUP BY app_ticket.name EXTRACT(WEEK FROM app_ticket.created) EXTRACT(YEAR FROM app_ticket.created) app_ticket.idn      ORDER BY EXTRACT(WEEK FROM app_ticket.created) EXTRACT(YEAR FROM app_ticket.created)''' 1)nnnHope it helps.n""",['django'],['django']
40090907,"'Throw a NotImplementedError in Python' 'when I try to run my code I face with this issue I have defined a real-time request for this scraping but still does not working. anyone knows how to deal with this issue in python?nHow sitemap is important in this case?nThanks in advance    nnimport loggingnimport renfrom urllib.parse import urljoin urlparsenfrom scrapy.contrib.spiders import CrawlSpider Rulenfrom scrapy import Requestnfrom scrapy.spiders import SitemapSpidernfrom scrapy.selector import Selectornfrom scrapy.linkextractors import LinkExtractornfrom scrapy.shell import inspect_responsenfrom sqlalchemy.orm import sessionmakernfrom content.spiders.templates.sitemap_template import ModSitemapSpidernfrom content.models import db_connect create_db_table Articlesnfrom content.items import ContentItemsnfrom content.item_functions import (process_itemn                                process_singular_itemn                                process_date_itemn                                process_array_itemn                                process_plural_textsn                                process_external_linksn                                process_article_text)nnHEADER_XPATH = '//h1@class=""article-title""//text()'nAUTHOR_XPATH = '//span@class=""cnnbyline""//text()'n            '//span@class=""byline""//text()'nPUBDATE_XPATH = '//span@class=""cnnDateStamp""//text()'nTAGS_XPATH = ''nCATEGORY_XPATH = ''nTEXT = '//div@id=""storytext""//text()'n    '//div@id=""storycontent""//p//text()'nINTERLINKS = '//span@class=""inStoryHeading""//a/@href'nDATE_FORMAT_STRING = '%Y-%m-%d'nnnclass CNNnewsSpider(ModSitemapSpider):nn    name = 'cnn'n    allowed_domains = ""cnn.com""n    sitemap_urls = ""http://edition.cnn.com/sitemaps/sitemap-news.xml""nnndef parse(self response):n    items = n    item = ContentItems()n    item'title' = process_singular_item(self response HEADER_XPATH single=True)n    item'resource' = urlparse(response.url).hostnamen    item'author' = process_array_item(self response AUTHOR_XPATH single=False)n    item'pubdate' = process_date_item(self response PUBDATE_XPATH DATE_FORMAT_STRING single=True)n    item'tags' = process_plural_texts(self response TAGS_XPATH single=False)n    item'category' = process_array_item(self response CATEGORY_XPATH single=False)n    item'article_text' = process_article_text(self response TEXT)n    item'external_links' = process_external_links(self response INTERLINKS single=False)n    item'link' = response.urln    items.append(item)n    return itemsnnnThis is my Text result:nnFile ""/home/nik/project/lib/python3.5/site-      packages/scrapy/spiders/__init__.py"" line 76 in parsenraise NotImplementedErrornNotImplementedErrorn2016-10-17 18:48:04 scrapy DEBUG: Redirecting (302) to <GET     http://edition.cnn.com/2016/10/15/opinions/the-black-panthers-heirs-after-50-     years-joseph/index.html> from <GET http://www.cnn.com/2016/10/15/opinions/the-     black-panthers-heirs-after-50-years-joseph/index.html>n2016-10-17 18:48:04 scrapy DEBUG: Redirecting (302) to <GET   http://edition.cnn.com/2016/10/15/africa/montreal-climate-change-hfc-  kigali/index.html> from <GET http://www.cnn.com/2016/10/15/africa/montreal-  climate-change-hfc-kigali/index.html>n2016-10-17 18:48:04 scrapy DEBUG: Redirecting (302) to <GET http://edition.cnn.com/2016/10/14/middleeast/battle-for-mosul-hawija-iraq/index.html> from <GET http://www.cnn.com/2016/10/14/middleeast/battle-for-mosul-hawija-iraq/index.html>n2016-10-17 18:48:04 scrapy ERROR: Spider error processing <GET    http://edition.cnn.com/2016/10/15/politics/donald-trump-hillary-clinton-drug-    test/index.html> (referer: http://edition.cnn.com/sitemaps/sitemap-news.xml)nTraceback (most recent call last):nFile ""/home/nik/project/lib/python3.5/site-   packages/twisted/internet/defer.py"" line 587 in _runCallbacksncurrent.result = callback(current.result *args **kw)nFile ""/home/nik/project/lib/python3.5/site-   packages/scrapy/spiders/__init__.py"" line 76 in parsenraise NotImplementedErrornn' 'The exception is being thrown because your class CNNnewsSpider does not override the method parse() from scrapy.BaseSpider.  Although you are defining a parse() method in the code you pasted it is not being included in CNNnewsSpider because of indentation: instead it is being defined as a standalone function.  You need to fix your indentation as follows:nnclass CNNnewsSpider(ModSitemapSpider):n    name = 'cnn'n    allowed_domains = ""cnn.com""n    sitemap_urls = ""http://edition.cnn.com/sitemaps/sitemap-news.xml""nn    def parse(self response):n        items = n        item = ContentItems()n        item'title' = process_singular_item(self response HEADER_XPATH single=True)n        item'resource' = urlparse(response.url).hostnamen        item'author' = process_array_item(self response AUTHOR_XPATH single=False)n        item'pubdate' = process_date_item(self response PUBDATE_XPATH DATE_FORMAT_STRING single=True)n        item'tags' = process_plural_texts(self response TAGS_XPATH single=False)n        item'category' = process_array_item(self response CATEGORY_XPATH single=False)n        item'article_text' = process_article_text(self response TEXT)n        item'external_links' = process_external_links(self response INTERLINKS single=False)n        item'link' = response.urln        items.append(item)n        return itemsnn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40090925,"'Gmail authentication error when sending email via django celery' 'TL;DR: I get a SMTPAuthenticationError from Gmail when trying to send emails using Celery/RabbitMQ tasks from my Django app despite the credentials passed in are correct. This does not happen when the emails are sent normally without Celery.nnHinnI am trying to send email to a user asynchronously using Celery/RabbitMQ in my Django application. I have the following code to send the email:nnfrom grad.celery import appnfrom django.core.mail import EmailMultiAlternativesnfrom django.template.loader import get_templatenfrom django.template import Contextnfrom grad import gradbasenfrom time import sleepnfrom grad import settingsnn@app.taskndef send_transaction_email(student_data student_email):n    html_email = get_template('grad/student_email.html')n    context = Context({n        'name': student_data'name'n        'university': student_data'university'n        'data': student_datan        'shorturl':  gradbase.encode_graduation_data(student_data)n    })n    msg = EmailMultiAlternatives('Subject Here'n                             'Message Here'n                             'myrealemailaddress@gmail.com'n                             student_email)n    msg.attach_alternative(html_email.render(context) ""text/html"")n    msg.send()nnnWhen I call the method normally:nntasks.send_transaction_email(entry stud_email)nnnThe emails are sent fine but if I delegate the call to a Celery task like so:nntasks.send_transaction_email.delay(entry stud_email)nnnI get the following trace:nnTraceback (most recent call last):nFile ""/Users/albydeca/Gradcoin/venv/lib/python2.7/site-        packages/celery/app/trace.py"" line 240 in trace_tasknR = retval = fun(*args **kwargs)nFile ""/Users/albydeca/Gradcoin/venv/lib/python2.7/site-packages/celery/app/trace.py"" line 438 in __protected_call__nreturn self.run(*args **kwargs)nFile ""/Users/albydeca/Gradcoin/grad/tasks.py"" line 27 in   send_transaction_emailnmsg.send()nFile ""/Users/albydeca/Gradcoin/venv/lib/python2.7/site-packages/django/core/mail/message.py"" line 303 in sendnreturn self.get_connection(fail_silently).send_messages(self)nFile ""/Users/albydeca/Gradcoin/venv/lib/python2.7/site-packages/django/core/mail/backends/smtp.py"" line 102 in send_messagesnnew_conn_created = self.open()nFile ""/Users/albydeca/Gradcoin/venv/lib/python2.7/site- packages/django/core/mail/backends/smtp.py"" line 69 in opennself.connection.login(self.username self.password)nFile   ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/smtplib.py"" line 622 in loginnraise SMTPAuthenticationError(code resp)nSMTPAuthenticationError: (535 '5.7.8 Username and Password not accepted. Learn    more atn5.7.8  https://support.google.com/mail/?p=BadCredentials q8sm53748398wjj.7 - gsmtp')nnnBasically Gmail does not recognise the credentials despite when I print them literally on the two lines before the one that causes the crash they are correct.nnCan someone help me?n' 'Try to make an app password here https://security.google.com/settings/security/apppasswords and use it as your password in the STMP settings. n'",['django'],['django']
40091067,"'How do I add several books to the bookstore in the admin form' 'In django imagine i have a model bookstore and a model book which has a foreign key to bookStore model . On the django adminI added like 10 books and on the bookstore I want to assign multiple books to this one bookstore. How do I do this ? Because even with foreignKey while editing the bookstore i can only choose one book...nnclass BookStore(models.Model):n    name = models.CharField(max_length=100)nnclass Book(models.Model):n    name = models.CharField(max_length=100)n    store = models.ForeignKey(BookStore null=True)nn' 'Your relationship is the wrong way around. If your bookstore has a fk to a book you are saying that ""each bookstore can only store one single book"". Instead you should have a fk from the book to the book store. This is saying ""a book belongs to a bookstore (and only one bookstore)""nnclass Book:n    bookstore = models.ForeignKey(""Bookstore"")nnclass Bookstore:n    ...nnnYou need to use an inline form if you want to add multiple books while editing your bookstore object: nnclass BookInline(admin.StackedInline):n    model = Booknnclass BookstoreAdmin(admin.ModelAdmin): n    model = Bookstoren    inlines = BookInlinenn'",['django'],['django']
40091243,"'Extract all characters between _ and .csv' 'I am trying to extract the date from a series of files of the form:nncosts_per_day_100516.csvnnI have gotten to the point of extracting the 6 but I don't understand why I can't extract more. What is wrong with the following:nntest_string = 'search_adwords_cost_by_state_100516.csv'nm = re.search(""_(^_)*.csv"" test_string)nm.group(1)nnnThis yields 6 rather than 100516. What am I doing wrong?n' 'm = re.search(""_(^_*).csv"" test_string)nnnThe repetition qualifier has to be inside the capturen' ""Data_Frame_Name.join(filter(lambda x: x.isdigit() Data_Frame_Name'Column_Name'))nnnThis will extract just digits. This may not be applicable for your case but would work well for extracting digits from multiple rows in a column.n""",['regex'],['python-2.7']
40091435,"'Remove only double letters sequences in word with best speed with python' 'Very popular task for finding/replacing double letters in a string. But exist solution where you can make remove double letters through few steps. For example we have string ""skalallapennndraaa"" and after replacing double letters we need to get in output ""skalpendra"". I tried solution with nnre.sub(r'(a-z)1+' r'1' ""skalallapennndraaa"")nnn but this don't remove all double letters in a string(result- ""skalalapendra""). If I use r'' as second parameter I got a closely related result ""skalaapendr"" but I still can't find right regular expression for replacement parameter. Any ideas?n' ""You can use this double replacement:nn>>> s = 'skalallapennndraaa'n>>> print re.sub(r'(a-z)1' '' re.sub(r'(a-z)(a-z)21' '' s))nskalpendrannn(a-z)(a-z)21 will remove alla type of cases and (a-z)1 will remove remaining double letters.nnnnUpdate: Based on comments below I realize a loop based approach is best. Here it is:nn>>> s = 'nballabnz'n>>> while re.search(r'(a-z)1' s):n...     s = re.sub(r'(a-z)1' '' s)n...n>>> print snznn""",['regex'],['regex']
40091472,"'How is base Exception getting initialized?' 'I'm confused by how the following exception in Python 3 gets initialized.nnclass MyException( Exception ):nn    def __init__(selfmsgfoo):n        self.foo = foonnraise MyException('this is msg'123)nnnIn Python 3 this outputs:nnTraceback (most recent call last):n  File ""exceptionTest.py"" line 7 in <module>n    raise MyException('this is msg'123)n__main__.MyException: ('this is msg' 123)nnnHow are the arguments getting initialized?  I'm surprised that the trackback shows the args since I'm not calling the super class initializer. nnIn Python 2 I get the following output which makes more sense to me since the args aren't included in the traceback.nnTraceback (most recent call last):n  File ""exceptionTest.py"" line 7 in <module>n    raise MyException('this is msg'123)n__main__.MyExceptionnn' 'The Python BaseException class is special in that it has a __new__ method that is put there specifically to handle this common case of errors.nnSo no BaseException.__init__ is not being called but BaseException.__new__ is. You can override __new__ and ignore the arguments passed in to suppress the setting of self.args:nn>>> class MyException(Exception):n...     def __new__(cls *args **kw):n...         return super().__new__(cls)  # ignoring argumentsn...     def __init__(selfmsgfoo):n...         self.foo = foon...n>>> MyException('this is msg' 123)  # no need to raise to see the resultnMyException()nnnThis addition is specific to Python 3 and is not present in Python 2. See issue #1692335 for the motivations and details.n'",['python-3.x'],"['python-3.x', 'python-2.7']"
40091490,"'Python HTML source code' 'I would like to write a script that picks a special point from the source code and returns it. (print it)nnimport urllib.request                           nnWebseite = ""http://myip.is/""                    nhtml_code = urllib.request.urlopen(Webseite)nnprint(html_code.read().decode('ISO-8859-1'))nnnThis is my current code.nI would like to print only the IP address that the website gives.nThe input of this I will print in python (title=""copy ip address"").n' 'You could use jsonip which returns a JSON object that you can easily parse using standard Python librarynnimport jsonnfrom urllib2 import urlopennnmy_ip = json.load(urlopen('http://jsonip.com'))'ip'nn' 'import requestsnfrom bs4 import BeautifulSoupnns = requests.Session()nr = s.get('http://myip.is/')nnsoup = BeautifulSoup(r.text ""html5lib"")nmyIP = mySoup.find('a' {'title': 'copy ip address'}).textnprint(myIP)nnnThis uses the requests library (which you should always use for HTTP requests) to pull the page feeds the content to BeautifulSoup a very nice HTML parser and asks BeautifulSoup to find a single <a> tag with the atrtibuet title set to 'copy ip address' and then save the text component of that tag as myIP. n' 'You can use a regular expression to find the IP addresses:nnimport urllib.requestnimport rennWebseite = ""http://myip.is/""nhtml_code = urllib.request.urlopen(Webseite)nncontent = html_code.read().decode('ISO-8859-1')nip_regex = r'(?:0-9{13}.){3}0-9{13}'nnips_found = re.findall(ip_regex content)nprint(ips_found0)nn'",['python-3.x'],"['regex', 'python-2.7']"
40091617,"'Test for consecutive numbers in list' 'I have a list that contains only integers and I want to check if all the numbers in the list are consecutive (the order of the numbers does not matter).nnIf there are repeated elements the function should return False.nnHere is my attempt to solve this:nndef isconsecutive(lst):n    """""" n    Returns True if all numbers in lst can be ordered consecutively and False otherwisen    """"""n    if len(set(lst)) == len(lst) and max(lst) - min(lst) == len(lst) - 1:n        return Truen    else:n        return FalsennnFor example:nnl = -2-3-1013254nnprint(isconsecutive(l))nnTruennnIs this the best way to do this?n' ""Here is another solution:nndef is_consecutive(l):n    setl = set(l)n    return len(l) == len(setl) and setl == set(range(min(l) max(l)+1))nnnHowever your solution is probably better as you don't store the whole range in memory.nnNote that you can always simplifynnif boolean_expression:n    return Truenelse:n    return Falsennnbynnreturn boolean_expressionnn"" 'A better approach in terms of how many times you look at the elements would be to incorporate finding the min max and short circuiting on any dupe all in one pass although would probably be beaten by the speed of the builtin functions depending on the inputs:nndef mn_mx(l):n    mn mx = float(""inf"") float(""-inf"")n    seen = set()n    for ele in l:n        # if we already saw the ele end the functionn        if ele in seen:n            return False Falsen        if ele < mn:n            mn = elen        if ele > mx:n            mx = elen        seen.add(ele)n    return mn mxnndef isconsecutive(lst):n    """"""n    Returns True if all numbers in lst can be ordered consecutively and False otherwisen    """"""n    mn mx = mn_mx(lst)n    # could check either if mn is False we found a dupen    if mn is False:n        return Falsen    # if we get here there are no dupesn    return mx - mn == len(lst) - 1nn'","['list', 'python-3.x']","['list', 'python-2.7']"
40091704,"'GET variables with Jade in Django templates' 'I use Jade (pyjade) with my Django project. For now I need to use static template tag with GET variable specified - something like following: link(rel=""shortcut icon"" href=""{% static 'images/favicon.ico?v=1' %}""). But I get /static/images/favicon.ico%3Fv%3D1 instead of /static/images/favicon.ico?v=1nWhy it happens and how can I fix this?nThanks in advance!n' 'You could try href=""{% static 'images/favicon.ico' %}""?v=1'n'",['django'],['django']
40091727,"'Can you write numpy slicing generically?' ""I want to do something likennxi : : = (rhsi : :-diagi * xi+1 : :)/diaginnnwhere x and rhs are 3D numpy arrays of size (TLS). diag is a 1D array of size T.nnThis will broadcast properly. nnBut now I'd like to write a similar function to work on 2D arrays or some other number of dimensions. How can I write this generically so that it will work on any array that has first dimension of size T. I don't want to duplicate code with just a different number of colons since there are a lot of these kinds of lines in the function. n"" 'xi = (rhsi - diagi * xi+1)/diaginnnThose colons are completely unnecessary.n'",['numpy'],['numpy']
40091753,"'CSV prints blank column between each data column' 'So the title explains my question - please see the image for clarification. nnnnI have tried the fixes from a couple of questions on here to no avail so here is my code: nndef csv_writer(file_a file_b):n    with open('Comparison.csv' 'wb') as csv_file:n        writer = csv.writer(csv_file delimiter='' escapechar=' ' lineterminator='n' quoting=csv.QUOTE_NONE)n        line = map(compare file_a.master_list file_b.master_list)n        for line in line:n            if line != None:n                writer.writerow(line)n            else:n                del linennnThe data for line on line 6 is a list in the following format:n'20' 'start' '1000' '1002'.nnI assume that my issue is to do with escapechar=' ' but having tried a variety of different options with no success I'm at a loss. n' ""I believe what is happening is that you are getting two  characters between each data item.nnFor example in '20' 'start' '1000' '1002' each element is joined with a  because of the delimiter='' option. This means that the  is being repeated and you'll end up with:nn20start10001002nnnNotice how there is an empty item between each of the items you want.nnYou can probably fix this by replacing delimiter='' with delimiter='' as you already have the  character and don't need another one.nnHope this helps!n""",['python-2.7'],"['python-2.7', 'list']"
40091796,"'Pandas: How to find the first valid column among a series of columns' 'I have a dataset of different sections of a race in a pandas dataframe from which I need to calculate certain features. It looks something like this:nnid         distance     timeto1000m    timeto800m    timeto600m   timeto400m   timeto200m    timetoFinishn1          1400m        10             21            30           39           50            60    n2          1200m        0              19            31           42           49            57   n3          1800m        0              0             0            38           49            62   n4          1000m        0              0             29           40           48            61nnnSo what I need to do is for each row find the first timetoXXm column that is non-zero and the correspoding distance XX. For instance for id=1 that would be 1000m for id=3 that would be 400m etc. nnI can do this with a series of if..elif..else conditions but was wondering if there is a better way of doing this kind of lookup in pandas/numpy?n' 'You can do it like this first filter the cols of interest and take a slice then call idxmin on the cols of interest to return the columns where the boolean condition is met:nnIn 11:ndf_slice = df.ix:df.columns.str.startswith('time')ndf_slicedf_slice!=0.idxmin(axis=1)nnOut11:n0    timeto1000mn1     timeto800mn2     timeto400mn3     timeto600mndtype: objectnnIn 15:ndf'first_valid' = df_slicedf_slice!=0.idxmin(axis=1)ndf'id''first_valid'nnOut15:n   id  first_validn0   1  timeto1000mn1   2   timeto800mn2   3   timeto400mn3   4   timeto600mnn' ""use idxmax(1)nndf.set_index('id' 'distance').ne(0).idxmax(1)nnid  distancen1   1400m       timeto1000mn2   1200m        timeto800mn3   1800m        timeto400mn4   1000m        timeto600mndtype: objectnn""","['pandas', 'numpy']",['pandas']
40091852,'Project euler 43 in Python' 'I came across another difficult Project Euler problem nLink to the problemnnMy first instinct was to try a simple brute force solution which took too much time to run.nnSo I thought of a nicer solution but I have no idea how to code it.nnI want to:nnnGenerate all the necessary triplets.nPut together all the combinations.nCalculate the sum.nnnI did the step 1 my result looks something like this:nnMultiples of 17: 0 1 7 0 3 4 0 5 1 0 6 8 0 8 5 1   0 2 1 3 6 1 5 3 1 7 0 1 8 7 2 0 4 2 3 8 2 8 9 3 0 6 3 4 0 3 5 7 3 7 4 3 9 1 4 0 8 4 2 5 4 5 9 4 7 6 4 9 3 5 1 0 5 2 7 5 6 1 5 7 8 6 1 2 6 2 9 6 8 0 6 9 7 7 1 4 7 3 1 7 4 8 7 6 5 7 8 2 8 1 6 8 5 0 8 6 7 9 0 1 9 1 8 9 3 5 9 5 2 9 8 6 etc...nnnNow here comes the tricky part for me. I tried putting them together with nested loops but that was really messy. If you have any advice please tell me :)n' nan,['list'],['python-2.7']
40091861,"'Overcaming impossibility of item assignment in tuple objects?' 'this question comes together with another one i posted few hours ago:nnnSorting dict items by key beyond alphanumeric sortingnnKeeping the need of having a tuple-like object ordered in that way http://stackoverflow.com/users/2141635/padraic-cunningham answered me very well nnnow i need to modify tuple items for example:nnod = sorted(dizN.items() key=key_func) #creates the sorted list of tuplesnnod31+=1 #is my attempt to increase by 1 the 2nd element of the 3rd tuple in the list of tuples; of course it is not possible.nnnKeep in mind which kind of object is ""od"":nnodnOut157: n('a0p12' 0)n ('a1p11' 0)n ('a2p10' 0)n ('a3p9' 0)n ('a4p8' 0)n ('a5p7' 0)n ('a6p6' 0)n ('a7p5' 0)n ('a8p4' 0)n ('a9p3' 0)n ('a10p2' 0)n ('a11p1' 0)n ('a12p0' 0)nnnI think a good solution for this problem would be to transform this list of tuples to a list of lists of 2 elements; nthis is the output i'm thinking to:nn'a0p12' 0n 'a1p11' 0n 'a2p10' 0n 'a3p9' 0n 'a4p8' 0n 'a5p7' 0n 'a6p6' 0n 'a7p5' 0n 'a8p4' 0n 'a9p3' 0n 'a10p2' 0n 'a11p1' 0n 'a12p0' 0nnnDoes anybody know how to do this?nThanks a lot to anyone will answer!n' nan",['list'],"['list', 'python-2.7', 'dictionary']"
40091864,'Find the row number using the first element of the row' 'I have a numpy matrix where I store some kind of key in the first element of the each row (or in another way all keys are in the first column).    nn1230112n121234n10254n901143nnnI want to get the row number searching by the key. I found that we can use numpy.where for this but not clear how to employ it to get the row number. I want something likenn>>numpy.func(myMatrix90)n3nnnAny help would be appreciated.n' 'Compare the first column with 90 within np.where. It will return an array of the indices of items which are equal with 90:nnIn 3: A = np.array(1230112n121234n10254n901143)nnnIn 6: np.where(A:0==90)0nOut6: array(3)nn' 'According to the online doc numpy.where if you give it only a boolean array will return lists of coordinates (one list per dimension) for the elements that are True.nSo we can get the information you want by grabbing the first column of your array  comparing it with the element you want to find and calling np.where on that boolean array. All that would look like that:nnrowcolumn=np.where(myMatrix;0==90) n#Note that column will just be 0 herenn',['numpy'],['numpy']
40091894,"'How to find a sentence containing a phrase in text using python re?' 'I have some text which is sentences some of which are questions. I'm trying to create a regular expression which will extract only the questions which contain a specific phrase namely 'NSF' :nnimport rens = ""This is a string. Is this a question? This isn't a question about NSF. Is this one about NSF? This one is a question about NSF but is it longer?""nnnIdeally the re.findall would return:nn'Is this one about NSF?''This one is a question about NSF but is it longer?'nnnbut my current best attempt is:nnre.findall('(.?.*?NSF.*?)+?'s)n"". Is this a question? This isn't a question about NSF. Is this one about NSF? This one is a question about NSF but is it longer?""nnnI know I need to do something with non-greedy-ness but I'm not sure where I'm messing up.n' 'DISCLAIMER: The answer is not aiming at a generic interrogative sentence splitting solution rather show how the strings supplied by OP can be matched with regular expressions. The best solution is to tokenize the text into sentences with nltk and parse sentences (see this thread).nnThe regex you might want to use for strings like the one you posted is based on matching all chars that are not final punctuation and then matching the subtring you want to appear inside the sentence and then matching those chars other than final punctuation again. To negated a single character use negated character classes.nns*(^!.?*?NSF^!.?*??)nnnSee the regex demo.nnDetails:nnns* - 0+ whitespacesn(^!.?*?NSF^.?*??)  - Group 1 capturingnnn^!.?*? - 0+ chars other than . ! and ? as few as possiblenNSF - the value you need to be present a sequence of chars NSFn^.?*? -  ibid.n? -  a literal ? (can be replaced with ?)nnn'",['regex'],['regex']
40091919,"'Deploying Django With AWS' ""So I am trying to deploy my django app(which mostly has REST Apis) but when I use Amazon CLI I end up having Fedora instance while I want to use Ubuntu instance. nnSo I tried to do this I made an ubuntu instance made a repository of my code installed git on ubuntu and cloned the code from git to ubuntu. Next thing I installed all the requirements.txt dependencies and everything is in virtualenv and working fine. nnBut here's the catch python manage.py runserver runs it on localhost(not really surprising). So the question is how to serve those apis(not on localhost)?n"" 'Don't use the runserver command on production. It's meant for local development only. nnOn production you need to setup an application server (uwsgi / gunicorn) and then use nginx as a reverse proxy. nnDigital Ocean articles are pretty good - https://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-14-04 nn(The same stuff apply for AWS as well)n' 'As mentioned in the other answer runserver command is only meant for local development. You can in fact make it listen on external interfaces by running it as python manage.py runserver 0.0.0.0:8000 but it is a bad idea. Configuring nginx+uwsgi to run a Django app is very easy. There are multiple tutorials and guides available for this. Here is the official uWSGI guidenhttp://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.htmln'",['django'],['django']
40091963,"'Pandas/Python adding row based on condition' ""I am looking to insert a row into a dataframe between two existing rows based on certain criteria.nnFor example my data frame:nn    import pandas as pdn    df = pd.DataFrame({'Col1':'A''B''D''E''Col2':'B' 'C' 'E' 'F' 'Col3':'1' '1' '1' '1'})nnnWhich looks like:nn    Col1    Col2    Col3n  0 A       B       1n  1 B       C       1n  2 D       E       1n  3 E       F       1nnnI want to be able to insert a new row between Index 1 and Index 2 given the condition:nnn = 0   nwhile n < len(df):n    (df.ixn'Col2' == df.ixn+1'Col1') == Falsen    Something Something insert rown    n+=1nnnMy desired output table would look like:nn    Col1    Col2    Col3n  0 A       B       1n  1 B       C       1n  2 C       D       1n  3 D       E       1n  4 E       F       1nnnI am struggling with conditional inserting of rows based on values in the previous and proceeding records.  I ultimately want to preform the above exercise on my real world example which would include multiple conditions and preserving the values of more than one column (in this example it was Col3 but in my real world it would be multiple columns)n"" ""UPDATE: memory saving method - first set a new index with a gap for a new row:nnIn 30: dfnOut30:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    D    E    1n3    E    F    1nnnif we want to insert a new row between indexes 1 and 2 we split the index at position 2:nnIn 31: idxs = np.split(df.index 2)nnnset a new index (with gap at position 2):nnIn 32: df.set_index(idxs0.union(idxs1 + 1) inplace=True)nnIn 33: dfnOut33:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n3    D    E    1n4    E    F    1nnninsert new row with index 2:nnIn 34: df.loc2 = 'X''X'2nnIn 35: dfnOut35:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n3    D    E    1n4    E    F    1n2    X    X    2nnnsort index:nnIn 38: df.sort_index(inplace=True)nnIn 39: dfnOut39:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    X    X    2n3    D    E    1n4    E    F    1nnnPS you also can insert DataFrame instead of single row using df.append(new_df):nnIn 42: dfnOut42:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    D    E    1n3    E    F    1nnIn 43: idxs = np.split(df.index 2)nnIn 45: new_df = pd.DataFrame('X' 'X' 10 'Y''Y'11 columns=df.columns)nnIn 49: new_df.index += idxs1.min()nnIn 51: new_dfnOut51:n  Col1 Col2  Col3n2    X    X    10n3    Y    Y    11nnIn 52: df = df.set_index(idxs0.union(idxs1+len(new_df)))nnIn 53: dfnOut53:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n4    D    E    1n5    E    F    1nnIn 54: df = df.append(new_df)nnIn 55: dfnOut55:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n4    D    E    1n5    E    F    1n2    X    X   10n3    Y    Y   11nnIn 56: df.sort_index(inplace=True)nnIn 57: dfnOut57:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    X    X   10n3    Y    Y   11n4    D    E    1n5    E    F    1nnnOLD answer:nnOne (among many) way to achieve that would be to split your DF and concatenate it together with needed DF in desired order:nnOriginal DF:nnIn 12: dfnOut12:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    D    E    1n3    E    F    1nnnlet's split it into two parts (0:1 2:end):nnIn 13: dfs = np.split(df 2)nnIn 14: dfsnOut14:n  Col1 Col2 Col3n 0    A    B    1n 1    B    C    1   Col1 Col2 Col3n 2    D    E    1n 3    E    F    1nnnnow we can concatenate it together with a new DF in desired order:nnIn 15: pd.concat(dfs0 pd.DataFrame('C''D' 1 columns=df.columns) dfs1 ignore_index=True)nOut15:n  Col1 Col2 Col3n0    A    B    1n1    B    C    1n2    C    D    1n3    D    E    1n4    E    F    1nn""",['pandas'],['pandas']
40091996,"'pandas transpose numeric column by group' ""code to make test datannimport pandas as pdnndftest = pd.DataFrame({'Amt': {0: 60 1: 35.0 2: 30.0 3: np.nan 4: 25}n                       'Year': {0: 2012.0 1: 2012.0 2: 2012.0 3: 2013.0 4: 2013.0}n                       'Name': {0: 'A' 1: 'A' 2: 'C' 3: 'A' 4: 'B'}})nnngivesnn    Amt     Name    Yearn0   60        A   2012.0n1   35.0      A   2012.0n2   30.0      C   2012.0n3   NaN       A   2013.0n4   25        B   2013.0nnncolumn Amt has max 2 values corresponding to group 'Name' 'Year'. I would like to pivot/transpose such that output is of the formnn       Name  Year   Amt1  Amt2n0         A  2012   35    60n2         C  2012   30    NaNn3         A  2013   NaN   NaNn4         B  2013   25    NaNnnnI have tried playing with pivot unstack pivot_table nnwhat I really want to do is to ensure there are two values of Amt per 'Name' 'Year' (NA's are OK) which I can achieve by stacking the desired outputn"" 'use groupby and applynnf = lambda x: x.sort_values(ascending=True).reset_index(drop=True)ndftest.groupby('Name' 'Year').Amt.apply(f).unstack()nnnn'",['pandas'],['pandas']
40092102,"'Python - Count the duplicate seq element in array' 'How to solve thisnnInput: 2nArray = 213222122nResult : 3 (Max of count of seq of 2)nnnI just simply used the for loop it works fine. But is there any other efficient way?nnfor i in array:n    if i == input:n        Cnt = Cnt + 1n        if Cnt > Result:n            Result = Cnt;n    else:n      Cnt = 0nn' 'You can use itertools.groupby for this:nnfrom itertools import groupbynmax(sum(1 for i in g) for k g in groupby(array) if k == input)nn' 'What I think your're describing can be solved with run length encoding.nnEssentially you take a sequence of numbers (most often used with characters or simply unsigned bytes) and condense it down into a list of tuples where one value represents the value and the other represents how many times in a row it occurs.nnarray = 213222122nruns = ncount = 0nncurrent = array0 #setup first iterationnfor i in array:n    if i == current: #continue sequencen        count += 1n    else:n        runs.append(count current) #start new sequencen        current = in        count = 1nruns.append(count current) #complete last iterationnnlongest_Sequence = max(runs)nn' ""You could seriously abuse side effects in a comprehension :-) :nnInput = 2nArray = 213222122nr = nResult = max((r.append(1)len(r))1 if x==Input else (r.clear()0)1 for x in Array)nnn.nnThat kind of rigamarole wouldn't be necessary if Python allowed assignments in expressions:nnr = 0nResult = max(++r if x==Input else r=0 for x in Array)   # What we want but NOT valid Python!nnnNote that a generator expression could be used instead of the list comprehension if you don't want to look at the intermediate result.  For the toy Array it doesn't matter but for an Array of hundreds of thousands of elements the generator saves memory.n""",['list'],"['python-2.7', 'list', 'python-3.x']"
40092147,"""Apache/Django Install: RuntimeError: Model class django.contrib.contenttypes.models.ContentType doesn't declare an explicit"" 'I am using Django 1.9 and python 2.7 on centos7nnI am getting the following error ONLY when trying to use Apache with Django.nnRuntimeError: Model class django.contrib.contenttypes.models.ContentType doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.nnnI do NOT get the error using the Django web-server my application works fine under the Django web-server but I have read not to use the Django web-server but Apache instead.nnI have run into multiple issues trying to get apache to work with django and have found solutions to all of the preceding issues but cannot resolve this one.nnHere are my installed apps with ""django.contrib.contenttypes"" in the list in this order:nn'django.contrib.admin'n'django.contrib.auth'n'django.contrib.contenttypes'n'django.contrib.sessions'n'django.contrib.messages'n'django.contrib.staticfiles'n'admin_alerts'n'admin_dq_metrics'n'admin_db_conn'n'admin_file_conn'n'admin_application'n'admin_process'n'admin_src_status_chk'n'admin_scheduler_template'n'export_to_db'n'export_to_file'n'migrate_to_prod'n'migrate_to_stg'n'migrate_to_dev'n'tableau_tde'n'ingest_file'n'ingest_db'n'scheduler'n'dq_entity_cross_ref'n'high_water_column_ref'n'process_control'n'difa_login'n'admin_create_user'n'update_export_ingest_data'n'admin_add_user'n'django.contrib.sites'nnnThanks...n' nan",['django'],['django']
40092150,"'Dropdown menu in Python Tkinter' 'I am new to Python Gui Tkinter. I was making an application in which one window has a drop down menu. The code is below but it is not executing. It just opens a window but no menu. What is the issue with the code? I have tried multiple times. Can anybody suggest how should I proceed? nnfrom Tkinter import *nroot = Tk()nnroot.title(""Data Entry Window"") nmenu = Menu(root) nroot.config(menu = menu)  nnsubMenu = Menu(menu) nmenu.add_cascade(label = ""Entry"" menu = subMenu)  nsubMenu.add_command(label = ""New Entry"") nsubMenu.add_separator() nsubMenu.add_command(label = ""Update Entry"") nsubMenu.add_separator() nsubMenu.add_command(label = ""Delete Entry"")  nneditMenu = Menu(menu) nmenu.add_cascade(label = ""Report"" menu = editMenu)  neditMenu.add_command(label = ""Day Report"") neditMenu.add_separator() neditMenu.add_command(label = ""Range Report"")nroot.mainloop()nn' nan",['tkinter'],['tkinter']
40092254,"'How to retain position values of original list after the elements of the list have been sorted into pairs (Python)?' 'sample = 'AAAA''CGCG''TTTT''AT$T''ACAC''ATGC''AATA'nPosition = 0    1     2     3      4     5     6nnnI have the above sample with positions associated with each element. I do several steps of filtering the code of which is given here.nnThe steps in the elimination are:nn#If each base is identical to itself eliminate those elements eg. AAAA TTTTn#If there are more than 2 types of bases (i.e.' conversions'== 1 ) then eliminate those elements eg. ATGCn#Make pairs of all remaining combinationsn#If a $ in the pair then the corresponding base from the other pair is eliminated eg. (CGCGAT$T) ==> (CGG ATT) and (ATT AAA)n#Remove all pairs where one of the elements has all identical bases eg. (ATTAAA)nnnIn the end I have an output with different combinations of the above as shown below.nnFinal Output 'CGG''ATT''CGCG''ACAC''CGCG''AATA''ATT''ACC'nnnI need to find a way such that I get the positions of these pairs with respect to the original sample as below. nnPosition = 13141634nn' ""You could convert the list to a list of tuples firstnnxs = 'AAAA' 'CGCG' 'TTTT' 'AT$T' 'ACAC' 'ATGC' 'AATA'nys = (i x) for ix in enumerate(xs)nnprint(ys)n=> (0 'AAAA') (1 'CGCG') (2 'TTTT') (3 'AT$T') (4 'ACAC') (5 'ATGC') (6 'AATA')nnnThen work with that as your input list insteadn""",['list'],"['list', 'python-2.7']"
40092294,"'Creating a matplotlib or seaborn histogram which uses percent rather than count?' 'Specifically I'm dealing with the Kaggle Titanic dataset. I've plotted a stacked histogram which shows ages that survived and died upon the titanic. Code below.nnfigure = plt.figure(figsize=(158))nplt.hist(datadata'Survived'==1'Age' datadata'Survived'==0'Age' stacked=True bins=30 label='Survived''Dead')nplt.xlabel('Age')nplt.ylabel('Number of passengers')nplt.legend()nnnI would like to alter the chart to show a single chart per bin of the percentage in that age group that survived. E.g. if a bin contained the ages between 10-20 years of age and 60% of people aboard the titanic in that age group survived then the height would line up 60% along the y-axis.nnEdit: I may have given a poor explanation to what I'm looking for. Rather than alter the y-axis values I'm looking to change the actual shape of the bars based on the percentage that survived.nnThe first bin on the graph shows roughly 65% survived in that age group. I would like this bin to line up against the y-axis at 65%. The following bins look to be 90% 50% 10% respectively and so on.nnnnThe graph would end up actually looking something like this:nnn' 'pd.Series.hist uses np.histogram underneath.nnLet's explore thatnnnp.random.seed(31415)ns = pd.Series(np.random.randn(100))nd = np.histogram(s normed=True)nprint('nthese are the normalized countsn')nprint(d0)nprint('nthese are the bin values or average of the bin edgesn')nprint(d1)nnthese are the normalized countsnn 0.11552497  0.18483996  0.06931498  0.32346993  0.39278491  0.36967992n  0.32346993  0.25415494  0.25415494  0.02310499nnthese are the bin edgesnn-2.25905503 -1.82624818 -1.39344133 -0.96063448 -0.52782764 -0.09502079n  0.33778606  0.77059291  1.20339976  1.6362066   2.06901345nnnWe can plot these while calculating the mean bin edgesnnpd.Series(d0 pd.Series(d1).rolling(2).mean().dropna().round(2).values).plot.bar()nnnnnACTUAL ANSWERnORnnWe could have simply passed normed=True to the pd.Series.hist method.  Which passes it along to np.histogramnns.hist(normed=True)nnnn' 'First of all it would be better if you create a function that splits your data in age groupsnn# This function splits our data frame in predifined age groupsndef cutDF(df):n    return pd.cut(n        df0 10 20 30 40 50 60 70 80 n        labels='0-10' '11-20' '21-30' '31-40' '41-50' '51-60' '61-70' '71-80')nnndata'AgeGroup' = data'Age'.apply(cutDF)nnnThen you can plot your graph as follows:nnsurvival_per_age_group = data.groupby('AgeGroup')'Survived'.mean()nn# Creating the plot that will show survival % per age group and gendernax = survival_per_age_group.plot(kind='bar' color='green')nax.set_title(""Survivors by Age Group"" fontsize=14 fontweight='bold')nax.set_xlabel(""Age Groups"")nax.set_ylabel(""Percentage"")nax.tick_params(axis='x' top='off')nax.tick_params(axis='y' right='off')nplt.xticks(rotation='horizontal')             nn# Importing the relevant fuction to format the y axis nfrom matplotlib.ticker import FuncFormatternnax.yaxis.set_major_formatter(FuncFormatter(lambda y _: '{:.0%}'.format(y)))nplt.show()nn'","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40092295,"'Im trying to write a program that reverses the order of values in an input file using a stack and saves the result to a file' 'def main():nfname = input(""Please input file name: "")n   # open input file nfin = open(fname ""r"")nn   # open output filenfout = open(""output.txt"" ""w"")nnfor line in fin:n    token = Stack()n    if token:n        token.pop()n        fout.write(items)n    fout.write(""n"")nfin.close()nfout.close()    nnnAssuming the input file contains a single value per line. nMy error message reads: pop from empty listnIm sure my problem is not getting the values from the input file and putting them in to a stack.n' 'Instead of if token: try using if !token.isEmpty():n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40092304,"'Python - Making text files' 'I seem to be having various problems with my code. Firstly I cannot split the text that the user inputs. nnE.g. if they type bob for their name ha8 9qy for their postcode and 17/03/10 for their date of birth the program will return ""bobha8 9qy17/03/10"". nnHow should I separate the input? Secondly i cannot find the text file I supposedly make. Lastly is there a way to return the information to the new display window created by Tkinter?nnimport tkinter as ktnname=input(""Enter your name"")npostcode=input(""Enter your postcode"")ndob=input(""Enter your date of birth"")nnwindow=kt.Tk()nwindow.title(""File"")nwindow.geometry(""300x150"")ndef submit():n    pythonfile = open(""User details""""w"")n    pythonfile.write((name))n    pythonfile.write((postcode))n    pythonfile.write((dob))n    pythonfile = open((""User details"")""r"")n    print (pythonfile.read())n    pythonfile.close()nBtn = kt.Button(window text=""Submit"" command=submit)nBtn.pack()nn' 'You have to add the .txt afther the filename. Also be sure that the file is in the same folder of the .py file. Pay attention to caps and spaces.nnpythonfile = open(""User details.txt""""w"")nnIf this does'nt work try adding os.chdir(os.path.dirname(os.path.abspath(sys.argv0))) afther the import for me it fixed the problem.nnFor the ""spacing problem"" try:nnpythonfile.write(name 'n' postcode 'n' dob)nnAlso when you create a alias for Tkinter use tk and when you open a file try naming it file_it or f_in so it's more readable for other people ...nWhen naming files don't use spaces it's just going to make everything harder try naming it like this: userDetails.txt or user_details.txtn'",['tkinter'],['tkinter']
40092309,"'Python Tkinter Canvas Many create_window() Items Not Scrolling with Scrollbar' 'Why doesn't the scrollbar initiate when create_window frame objects start to exceed the bottom self.container window?nnMy understanding is that widgets are scrollable if they are embedded on the canvas using create_window. For context I don't want to create a scrolling frame - put all your widget in a frame use create_window to add that frame to the canvas - because I intend to move these frame objects around on the canvas and leverage a lot of canvas capabilities. According to Effbot You cannot draw other canvas items on top of a widget. so if I had a scrolling frame I wouldn't be able to put widgets on top of that.nnSo how do I scroll the canvas that contains many create_window objects or what am I doing wrong below?nnimport tkinter as tknnclass Canvas_Scrollbar_CreateWindow(tk.Frame):nn  def __init__(self parent):n    tk.Frame.__init__(self parent)n    self.parent = parentn    self.parent.columnconfigure(0 weight=1)n    self.grid_columnconfigure(0 weight=1)nn    self.block_count = 0nn    self.button = tk.Button(self text='Add' command=self.addblock)n    self.button.grid(row=0 column=0 columnspan=2 sticky='new')nn    self.container = tk.Frame(self)n    self.container.grid(row=1 column=0 sticky='nsew')nn    self.canvas = tk.Canvas(self.container width=200 height=450)n    self.scrollbar = tk.Scrollbar(self.containern                                  orient='vertical'command=self.canvas.yview)n    self.canvas.config(yscrollcommand=self.scrollbar.set)n    self.canvas.grid(row=0 column=0 sticky='nsew')n    self.scrollbar.grid(row=0 column=1 sticky='nse')nn    self.container.bind('<Configure>' self.handle_scroll)nn  def addblock(self):n    self.block = tk.Frame(self.canvas bd=1 relief='solid')n    self.block.columnconfigure(0 weight=1)n    self.canvas.create_window((0 (self.block_count*25))n                              window=self.block anchor=""nw""n                              width=200 height=24)n    self.block_count += 1nn  def handle_scroll(self event):n    self.canvas.configure(scrollregion=self.canvas.bbox(""all""))nnroot = tk.Tk()napp = Canvas_Scrollbar_CreateWindow(root)napp.grid(row=0 column=0 sticky='ew')nroot.mainloop()nnnn' 'You must re-configure scrollregion when you add items to the canvas.n'",['tkinter'],['tkinter']
40092458,'How do I share a dictionary of locks in multiprocessing' 'I am using python multiprocessing and am trying to prevent simultaneous updates to a number of resources (for example files) each identified by a name. I do not know all names in advance.nTherefore I am trying to use nnclass A:n    resource_locks_lock = RLock()n    resource_locks = {}  # type: Dictstr RLocknn    def some_method(self name: str) -> Nonen        with A.resource_locks_lock:n            if name not in A.resource_locks.keys():n                A.resource_locksname = RLock()n            A.resource_locksname.acquire()n            ...n            A.resource_locksname.release()nnnHowever that does not prevent multiple instances of this class in separate processes (using python multiprocessing) from accessing the locked resource simultaneously. It seems each process gets its own version of the dictionary and the locks.nnWhat do I need to do to prevent simultaneous access across python multiprocessing boundaries?n' nan,['python-3.x'],"['python-2.7', 'dictionary', 'python-3.x']"
40092497,"'Maintaining Data Associations in a Dictionary with Multiple Lines per Key' ""I have a data set from a baseball team that I want to analyze in one of my first Python programming experiences (coming from C++). However the dataset has a more complex structure than my previous simple examples that I'd like to know the best (most pythonic) way to capture. The main difficulty is that the each player can have multiple seasons and I'd like all of those to be tied to the same key (the player's ID number) but to maintain their correlations with the seasons. An example player set in the database looks like:nnID       year AB  H 2B 3B HRnJimBob01 2009 100 27 3 1 1nJimBob01 2010 154 37 6 2 5nJimBob01 2011 123 36 8 0 3nnnI searched around SO and found that a dictionary is the way to go since I have a hashable key name system. And it looks like I might want a list for each element in the dictionary? However I'd like to be able to do something like:nnprint dict'JimBob01'2009nnnTo see only the stats from 2009 as well as something like:nnfor year in dict'JimBob01':n    total_ab += year'AB'`nnnand I think a list will not give me that flexibility. I apologize if this is an overly simplistic question I'm trying to adapt to the data structures available in Python.n"" ""Seems like you want a dictionary of dictionaries. Something like:nnplayerData = {n  'JimBob01': {n    '2009': ... // player data heren    '2010': ...n  }n}nnnYou can then look up the data for a particular year as you want by doing playerData'JimBob01''2009'nnDepending on the size of your dataset and how often you need to run analysis you might also want to look into a Sqlite database.n""",['dictionary'],"['dictionary', 'list']"
40092681,"""String being mutated to a dictionary but can't figure out where"" 'I'm trying to implement a scrabble type  game and the function playHand is returning an AttributeError: 'str' object has no attribute 'copy'. The error comes from updateHand Hand = Hand.copy() but I've tested updateHand individually and works just fine on its ow. I've tried looking it up but never really found anything. Apologies for the length! I can't help it. Thanks!nnVOWELS = 'aeiou'nCONSONANTS = 'bcdfghjklmnpqrstvwxyz'nHAND_SIZE = 7nnSCRABBLE_LETTER_VALUES = {n'a': 1 'b': 3 'c': 3 'd': 2 'e': 1 'f': 4 'g': 2 'h': 4 'i': 1 'j': 8 'k': 5 'l': 1 'm': 3 'n': 1 'o': 1 'p': 3 'q': 10 'r': 1 's': 1 't': 1 'u': 1 'v': 4 'w': 4 'x': 8 'y': 4 'z': 10n}nndef getWordScore(word n):n""""""nReturns the score for a word. Assumes the word is a valid word.nnThe score for a word is the sum of the points for letters in thenword multiplied by the length of the word PLUS 50 points if all nnletters are used on the first turn.nnLetters are scored as in Scrabble; A is worth 1 B is worth 3 C isnworth 3 D is worth 2 E is worth 1 and so on (see SCRABBLE_LETTER_VALUES)nnword: string (lowercase letters)nn: integer (HAND_SIZE; i.e. hand size required for additional points)nreturns: int >= 0n""""""nscore = 0nnfor letter in word:n    score += SCRABBLE_LETTER_VALUESletternnreturn score * len(word) + 50 * (len(word) == n)nndef displayHand(hand):n""""""nDisplays the letters currently in the hand.nnFor example:n>>> displayHand({'a':1 'x':2 'l':3 'e':1})nShould print out something like:n   a x x l l l enThe order of the letters is unimportant.nnhand: dictionary (string -> int)n""""""nfor letter in hand.keys():n    for j in range(handletter):n         print(letterend="" "")       # print all on the same linenprint()                             # print an empty linennndef updateHand(hand word):n""""""nAssumes that 'hand' has all the letters in word.nIn other words this assumes that however many timesna letter appears in 'word' 'hand' has at least asnmany of that letter in it. nnUpdates the hand: uses up the letters in the given wordnand returns the new hand without those letters in it.nnHas no side effects: does not modify hand.nnword: stringnhand: dictionary (string -> int)    nreturns: dictionary (string -> int)n""""""nnHand = hand.copy()nnfor letter in word:n    Handletter -= 1nnreturn Handnnnndef isValidWord(word hand wordList):n""""""nReturns True if word is in the wordList and is entirelyncomposed of letters in the hand. Otherwise returns False.nnDoes not mutate hand or wordList.nnword: stringnhand: dictionary (string -> int)nwordList: list of lowercase stringsn""""""nHand = hand.copy()nnif word not in wordList:n    return Falsennfor letter in word:n    if letter not in Hand:n        return(False)   n        breakn    else: n        Handletter -= 1  n        if Handletter < 0:n            return Falsenreturn True    nndef calculateHandlen(hand):n"""""" nReturns the length (number of letters) in the current hand.nnhand: dictionary (string int)nreturns: integern""""""nreturn sum(hand.values())nndef printCurrentHand(hand):nprint('Current Hand: ' end = ' ')ndisplayHand(hand)nndef printTotalScore(score):nprint('Total: ' + str(score) + ' points')nndef updateAndPrintScore(score word n):ncurrentScore = getWordScore(word n)nscore += currentScorenprint('"" ' + word + ' ""' + ' earned ' + str(currentScore) + ' points.' end             = ' ')nprint(printTotalScore(score))    nnreturn scorennndef playHand(hand wordList n):n""""""nAllows the user to play the given hand as follows:nn* The hand is displayed.n* The user may input a word or a single period (the string ""."") n  to indicate they're done playingn* Invalid words are rejected and a message is displayed askingn  the user to choose another word until they enter a valid word or "".""n* When a valid word is entered it uses up letters from the hand.n* After every valid word: the score for that word is displayedn  the remaining letters in the hand are displayed and the usern  is asked to input another word.n* The sum of the word scores is displayed when the hand finishes.n* The hand finishes when there are no more unused letters or the usern  inputs a "".""nn  hand: dictionary (string -> int)n  wordList: list of lowercase stringsn  n: integer (HAND_SIZE; i.e. hand size required for additional points)nn""""""nscore = 0# Keep track of the total scorenhand_copy = hand.copy()nnwhile calculateHandlen(hand_copy) > 0:n    printCurrentHand(hand_copy)n    word = input(""Enter word or a ""."" to indicate that you are finished: "")nn    if word == '.':n        print(""Goodbye!"" end = ' ')n        breaknn    if isValidWord(word hand_copy wordList):n        score += updateAndPrintScore(score word n)n        hand_copy = updateHand(word hand_copy)nn    else: n        print('Invalid word!')n        print()nnif calculateHandlen(hand_copy) == 0:n    print(""Run out of letters."" end = ' ')nnprintTotalScore(score)      nnplayHand({'h':1 'i':1 'c':1 'z':1 'm':2 'a':1}'him' 'cam' 7)nnnError codennrunfile('C:/Users/.spyder2-py3/ProjectsMIT/temp.py' wdir='C:/Users/.spyder2-py3/ProjectsMIT')nCurrent Hand:  c a h i m m z nnEnter word or a ""."" to indicate that you are finished: himn"" him "" earned 24 points. Total: 24 pointsnNonenTraceback (most recent call last):nn  File ""<ipython-input-2-2e4e8585ae85>"" line 1 in <module>n    runfile('C:/Users/.spyder2-py3/ProjectsMIT/temp.py' wdir='C:/Users/.spyder2-py3/ProjectsMIT')nn  File ""C:UsersAnaconda3libsite-packagesspyderlibwidgetsexternalshellsitecustomize.py"" line 714 in runfilen    execfile(filename namespace)nn  File ""C:UsersAnaconda3libsite-packagesspyderlibwidgetsexternalshellsitecustomize.py"" line 89 in execfilen    exec(compile(f.read() filename 'exec') namespace)nn    line 183 in <module>n    playHand({'h':1 'i':1 'c':1 'z':1 'm':2 'a':1}'him' 'cam' 7)nn    line 172 in playHandn    hand_copy = updateHand(word hand_copy)nn   line 72 in updateHandn    Hand = hand.copy()nnAttributeError: 'str' object has no attribute 'copy'nn' 'Your passed-in arguments to updateHand() are reversed from the expected arguments:nnline 161:nnhand_copy = updateHand(word hand_copy)nnnLine 49:nndef updateHand(hand word):nnnNotice that updateHand expects a hand to be the first arg but you pass a hand as the second arg.nnThe fix is simple. Replace line 161 with:nnhand_copy = updateHand(hand_copy word)nn'",['dictionary'],['dictionary']
40092686,"'Slicing a range of elements in each sublist?' ""I suspect there are more than one ways to do this in Python 2.7 but I'd like to be able to print the first three elements of each sublist in combos. Is there a way to do this without a loop? nncombos =  123.14 567.18 91011.12 123.15 nnnsuch that the output of a print statement would read:nn 123 567 91011 123 nnn***AFTER GETTING YOUR SUGGESTIONS:nI was struggling to see how this would work inside of my code structure but list comprehension can be done as part of an if statement like so which I failed to recognize:nnp0combos =  123.14 567.18 91011.12 123.15 np0 = 1 2 3nnif p0 not in combo:3 for combo in p0combos:n    print combo:3n    print 'p0 not found'nelse:n    print 'p0 found'n    print combo3:4nnnThe output:nnp0 foundn0.15nnnThanks all.n"" 'sublist:3 for sublist in combosnn' 'print temp_list:3 for temp_list in combosnn' 'n  I suspect there are more than one ways to do this in Python 2.7nnnYes and you can be quite creative with it. This is another alternativennfrom operator import itemgetternnmap(itemgetter(slice(3)) combos)nOut192: 1 2 3 5 6 7 9 10 11 1 2 3nn'",['list'],"['list', 'python-2.7']"
40092728,"'Use my phpBB db for a Django app (novice programmer)' ""I have a website with phpBB forums that I have used for a while. I want to expand the website and integrate all of my web apps. I was wondering how I can connect phpBB's MySQL database to Django apps so that I can have one central account system (ie. for registering logging in modifying accounts). nnI apologize if this comes off as vague. I would appreciate any help!n"" nan",['django'],['django']
40092747,"'Storing class information persistently?' 'everyone.  I am new to Python so forgive me if my code looks wild or  unbearable.nnAs a learning exercise I am attempting to create a text adventure game.  My trouble comes when I try to modify my Player object (a class).  This occurs when I try to ""move"" the location of my player from one location ""tile"" to another.  As you will see this may be achieved by reassigning the player.tile method of the Player class.nnThe game is run when the main game loop is called.  The main loop is as follows:nndef play():n    print(""Welcome to The Game!"")n    raw_input(""Press Enter to continue."")n    player = Player()n    player.tile = StartTile()n    room = player.tilen    while player.is_alive() and not player.victory:n        if player.is_alive() and not player.victory:n            print(room.intro_text())n            do_action(room player)n        elif not player.is_alive():n            print(""You have died an early death."")nnclass Player():n    def __init__(self):n        self.inventory = items.guns()n        self.tile = Nonen        self.x = 0n        self.y = 0n        self.hp = 100n        self.gold = 25n        self.desc = """"n        self.victory = Falsenndef use(thing):n    if thing.modify_player:n        thing.modify_player()n    else:n        return ""That doesn't seem to work.""nnclass door(Fixture):n    def __init__(self):n        self.name = ""a door""n        self.hotkey = ""door""n        self.take = Falsen        self.use = Truen        self.desc = ""Looks like the door is unlocked.""n        self.search = Falsen    def modify_player(self):n        player.tile = room_two()n        print(""You exit the room"")nnclass StartTile(MapTile):n    def __init__ (self):n        self.fixtures = door() desk()n        self.desc = ""This will be a fun little description.""n    def intro_text(self):n        return """"""n        You are sitting on your bed after having just woken up.n        """"""n        #first and second instances#nnclass room_two(MapTile):n    def __init__(self):n        self.first_visit = Falsen        self.fixtures = n    def intro_text(self):n        return """""" n        Outside your room there is a bathroom to your left a doorway in front of you and a long hallway to your right.n        """"""nnnMy trouble comes when the do_action command is called.  Here the player should be able to enter one of a number of commands (""use door"" ""look desk"").  In theory when ""use door"" is entered the player will move to the next tile room_two.  (See GitHub code.)  When I try to edit the Player class via use(door()) the player.tile does not change. However if I re-import the classes file via from classes import * the tile will show as changed. Anyone have any ideas about how to store information in a class persistently?  I would like to have class methods changed via other functions save and be accessible for the duration of the play() loop.nnI appreciate any and all help you may be able to afford me!  Getting stuck can be frustrating.  :DnnEDIT: Hopefully this code example is much clearer.nnThe other pertinent code (classes.py) is on my GitHub here.n' nan",['python-2.7'],"['python-2.7', 'python-3.x']"
40092890,"'How do I make the combobox update?' '# IMPORT MODULES -----------------------------------------------------------nfrom tkinter import *nfrom tkinter import Tk StringVar ttknn#---------------------------------------------------------------------------n# LISTSnnnHere are the lists which are used in the comboboxesnnBlankLines = ""------------""nCarBrandModel = ""------------""""Audi"" ""BMW"" ""Mercedes""nAudiModels = ""------------"" ""A4"" ""A8"" ""Q7"" ""R8""n#----------------------------------------------------------------------------------n#FUNCTIONSnndef ModelSelectionFunction():nn    CarBrandModelSelected = Var1.get()n    print(CarBrandModelSelected)nnnHere it gets the value from the combobox but my problem is that it does not update when I select something else from the comboboxnn    if CarBrandModelSelected == ""------------"":n        CarModelBox""value"" = BlankLinesn        CarModelBox.current(0)nn    elif CarBrandModelSelected == ""Audi"":n        CarModelBox""value"" = AudiModelsn        CarModelBox.current(0)nn# SET SCREEN ---------------------------------------------------------------nroot = Tk()nroot.geometry(""1350x750"")nroot.title(""Car Showroom System"")nroot.configure(bg=""white"")nn#--------------------------------------------------------------------------n# VARnVar1 = StringVar()nVar2 = StringVar()nnnHere the string variable are storednn#---------------------------------------------------------------------------nn# SELECTIONnSelectionFrame.grid_propagate(False)nnCarBrand = Label(SelectionFrame text=""Car :"")nCarBrand.grid(row=0 column=0)nCarBrandBox = ttk.Combobox(SelectionFrame textvariable=Var1 state=""readonly"")nCarBrandBox.bind(""<<ComboboxSelected>>"")nCarBrandBox""value"" = CarBrandModelnCarBrandBox.current(0)nCarBrandBox.grid(row=0 column=1)nnnnCarModel = Label(SelectionFrame text=""Model :"")nCarModel.grid(row=1 column=0)nCarModelBox = ttk.Combobox(SelectionFrame textvariable=Var2 state=""readonly"")nCarModelBox.grid(row=1 column=1)nModelSelectionFunction()nnnThis calls the function in order to decide what to put into the comboboxnn  root.mainloop()nn' 'You have to add function name to bindnnCarBrandBox.bind(""<<ComboboxSelected>>"" ModelSelectionFunction)nnnand tkinter executes it when you select in combobox.nnBecause tkinter sends extra argument to binded function so you need to receive it in your function. I add =None so you can still execute it without arguments. nndef ModelSelectionFunction(event=None)nnnnnBTW: this argument can give you selected valuennif event:n    print(event.widget.get())nn'","['python-3.x', 'tkinter']",['tkinter']
40092894,"'Adding a column which increment for every index which meets a criteria on another column' ""I am trying to generate a column from a DataFrame to base my grouping on. I know that every NaN column under a non NaN one belong to the same group. So I wrote this loop (cf below) but I was wondering if there was a more pandas/pythonic way to write it with apply or a comprehension list.nnimport pandasnn>>> DF = pandas.DataFrame(134 None None None 129374 None None 12 Nonen                      columns='Val')n>>> a = 0n>>> for i in DF'Val':n        if i > 1:n            a.append(a-1 + 1)n        else:n            a.append(a-1)n>>> a.pop(0)  # remove 1st 0 which does not correspond to any rowsn>>> DF'Group' = an>>> DFn        Val  Groupn0     134.0      1n1       NaN      1n2       NaN      1n3       NaN      1n4  129374.0      2n5       NaN      2n6       NaN      2n7      12.0      3n8       NaN      3nn"" 'Use pd.notnull to identify non-NaN values. Then use cumsum to create the Group column:nnimport pandas as pdnndf = pd.DataFrame(134 None None None 129374 None None 12 Nonen                  columns='Val')ndf'Group' = pd.notnull(df'Val').cumsum()nprint(df)nnnyieldsnn        Val  Groupn0     134.0      1n1       NaN      1n2       NaN      1n3       NaN      1n4  129374.0      2n5       NaN      2n6       NaN      2n7      12.0      3n8       NaN      3nn'",['pandas'],['pandas']
40092913,'AH00112: Warning - Centos 6 / Apache 2.4 / Django 1.9 / mod_wsgi 3.5 / python 2.7' 'I have a dedicated server with GoDaddy.  I seem to have successfully set up everything properly but I can't seem to figure out why I'm getting this issue:nnWhen I restart apache:nnroot@sXXX-XXX-XXX-XXX /# /scripts/restartsrv httpdnnnI get this:nnAH00112: Warning: DocumentRoot /usr/local/apache/var/www/<my_django_project> does not existnAH00112: Warning: DocumentRoot /usr/local/apache/var/www/<my_django_project> does not existnAH00112: Warning: DocumentRoot /usr/local/apache/var/www/<my_django_project> does not existnnnI never specified a path of /usr/local/apache/var/www/<my_django_project> ???nnIt seems to just append my var/www/<my_django_project> to /usr/local/apache ... not sure whynnMy httpd.conf file:nn... a bunch of pre configured goDaddy stuff I'm guessing here ...nnnLoadModule wsgi_module /usr/local/apache/extramodules/mod_wsgi.sonAddHandler wsgi-script .wsginn<VirtualHost XXX.XXX.XXX.X:80>nnServerName XXX.XXX.XXX.XXXnErrorLog /var/log/httpd/error.logn# DocumentRoot /public_html/nServerAdmin admin-noreply@mysite.comnnAlias /favicon.ico /var/www/<my_django_project>/static/favicon.iconnAlias /static /var/www/<my_django_project>/staticn<Directory /var/www/<my_django_project>/static>n        Require all grantedn</Directory>nnAlias /media /var/www/<my_django_project>/median<Directory /var/www/<my_django_project>/media>n        Require all grantedn</Directory>nnWSGIDaemonProcess <my_django_project> python-path= /var/www/<my_django_project>:/var/www/<my_django_project>/<my_django_project>:/var/www/<my_django_project>/<my_django_project_site>:/usr/local/lib/python2.7/site-packagesnWSGIProcessGroup <my_django_project>nWSGIScriptAlias / /var/www/<my_django_project>/<my_django_project>/wsgi.pynn<Directory /var/www/<my_django_project>/<my_django_project>>n    <Files wsgi.py>n        Require all grantedn    </Files>n</Directory>nn</VirtualHost>nn... more stuff already in the conf file ...nnnWhen I go to XXX-XXX-XXX-XXX:80 in my internet browser it told me it can't find .htaccess file.  But now it's just redirecting me to http://XXX.XXX.XXX.XXX/cgi-sys/defaultwebpage.cginnAny help would be much appreciatednnEDIT:nnIt was pointed out that AH00112: Warning: DocumentRoot /usr/local/apache/var/www/<my_django_project> does not exist was due to not adding / in front of path.nnMy browser now gives me:nnForbiddennnYou don't have permission to access / on this server.nServer unable to read htaccess file denying access to be safennAdditionally a 403 Forbidden error was encountered while trying to use an ErrorDocument to handle the request.nn' 'This would indicate you have set DocumentRoot directive somewhere in your Apache configuration files to a path that does not have a leading slash. When that occurs Apache will append the path to the end of the ServerRoot directory which in your case is /usr/local/apache. Make sure that all your file system paths you set up are absolute path names with  leading slash.n',"['django', 'python-2.7']",['django']
40092929,'Using Python 3.5 multiprocessing.pool.startmap with multiple arguments and chunksize is always 1' 'I've searched Python 3 Docs  example paralized code and threads regarding setting the chunksize argument but I am still at a loss. nnI have multiple large arrays that are passed as arguments to a function that I need to parallelize. After I zip the function arguments to make it an iteratable the starmap function seems to pass the arguments with the chunksize = 1 even when I pass a different chunksize argument to starmap. Ideally I need to chop up my arrays into X chunks and send them to X CPUs. What am I doing wrong?nnI used the following example code nnimport multiprocessingnimport numpy as npnndef square(x y):n    if type(x) == int or type(y) == int:n        print(x y 'Passed one pair of values')n    return np.multiply(xy)nna = range(100)nb = range(100)nuse_num_cpu = multiprocessing.cpu_count()-1npl = multiprocessing.Pool(processes = use_num_cpu)nargs = zip(a b)nM = pl.starmap(func = square iterable = args chunksize = 10)nnnThe output looks like this:nn0 0 Passed one pair of valuesn10 10 Passed one pair of valuesn1 1 Passed one pair of valuesn11 11 Passed one pair of valuesn20 20 Passed one pair of valuesn2 2 Passed one pair of valuesn12 12 Passed one pair of valuesn13 13 Passed one pair of valuesn3 3 Passed one pair of valuesn14 14 Passed one pair of valuesn15 15 Passed one pair of valuesn4 4 Passed one pair of valuesn16 16 Passed one pair of valuesn5 5 Passed one pair of valuesn...n90 90 Passed one pair of valuesn77 77 Passed one pair of valuesn78 78 Passed one pair of valuesn91 91 Passed one pair of valuesn79 79 Passed one pair of valuesn92 92 Passed one pair of valuesn93 93 Passed one pair of valuesn94 94 Passed one pair of valuesn95 95 Passed one pair of valuesn96 96 Passed one pair of valuesn97 97 Passed one pair of valuesn98 98 Passed one pair of valuesn99 99 Passed one pair of valuesnn' nan,['python-3.x'],"['python-3.x', 'numpy']"
40093086,"'Cannot run Django development server' 'I'm new to Django and have gone through the recommended installation (set up for GeoDjango) and am now going through the general django tutorial to get an idea of how it works.nnIN the tutorial https://docs.djangoproject.com/en/1.10/intro/tutorial01/ it tells you to try and run the django development server withnnpython manage.py runserver nnnbut when I do I get an error nnSystem check identified no issues (0 silenced).nUnhandled exception in thread started by <function check_errors.<locals>.wrapper at 0x04E20300>nTraceback (most recent call last):n  File ""C:Python35libsite-packagesdjangodbbackendsbasebase.py"" line 199 in ensure_connectionn    self.connect()n  File ""C:Python35libsite-packagesdjangodbbackendsbasebase.py"" line 171 in connectn    self.connection = self.get_new_connection(conn_params)n  File ""C:Python35libsite-packagesdjangodbbackendspostgresqlbase.py"" line 176 in get_new_connectionn    connection = Database.connect(**conn_params)n  File ""C:Python35libsite-packagespsycopg2__init__.py"" line 164 in connectn    conn = _connect(dsn connection_factory=connection_factory async=async)npsycopg2.OperationalError: fe_sendauth: no password suppliednnnIf anyone could shed any light on why this might be happening that would be extremely helpful.n' nan",['django'],['django']
40093331,"'How to access variable from html/python to JavaScript?' 'We have a project setup implemented in Django and we're trying to create a search function. Currently we pass our database of users from view.py to our .html file (view.py code below)nndef search(request):nntemplate_name = ""search/search_it.html""nusers = models.Profile.objects.all()nncontext = {'users': users}nreturn render(request template_name context)nnnInside of our html code is where we are having issues. We are able to read our passed in users as below.nn{% if users %}n   <ul>n   {% for user in users %}nn   <!--n   <script>n      var username = user.slug --> Does not recognize user objectn      document.getElementById(""a1"").value = username;n   </script>n   -->nn      <a id=""test"" value=""/users/{{user.slug}}""></a>n   {% endfor %}n   </ul>n{% endif %}nnnOur issue is that we would like to compare the search input against each passed in user's name. Our html file uses a onclick button into javascript. We have decided to try to tackle this various ways including:nnnUse the javascript value outside of the <script></script> - Did not work for obvious scope reasonsnTry to load the names into strings and then grab each name inside of the javascript - Messy and not proficientnnnand (what we would like to do)nnnLoad each user into a javascript array that can be used by our search function inside of our array.nnnWe have spent a lot of time searching for similar questions with no avail. Where we are having the most trouble comprehending is how to grab the user data fromnn{% for user in users %}nnnand pass that into javascript to add to an array. Any help would be wonderful.n' nan",['django'],['django']
40093352,"'OpenPyxl Module Needed For DataFrames?' ""I'm trying to write a series to an excel file with the with the code below:nnappIdSeries.to_frame(name='excelFile').to_excel(excelFile sheet_name='sheetName')nnnBut I get the following error: nnImportError: No module named openpyxlnnnI installed the pandas module with the bash command below:nnsudo yum install python-pandasnnnDo I also need to install the openpyxl module write Data Frames to excel files? Obviously I need it to write series to excel files. n"" nan",['pandas'],['pandas']
40093369,"'Reading through a bunch of .gz files error: Error -3 while decompressing: invalid code lengths set' 'I am trying to parse a bunch of .gz json files (the files are text files) by using the same function using multiprocessing in Python 2.7.10. However almost at the very end of parsing each line in these files it produces this error:nnerror: Error -3 while decompressing: invalid code lengths setnnand stops the execution.nnThis is my code:nnimport gzipnimport jsonnfrom multiprocessing import Pool cpu_countnndef build_list(file_name):nn    count = 0nn    try:n        json_file = gzip.open(file_name ""r"")n    except Exception as e:n        print en    else:nn        # Data parsingn        for line in json_file:n            try:n                row = json.loads(line)n            except Exception as e:n                print en            else:                n                count += 1nnif __name__ == ""__main__"":nn    files = ""h1.json.gz"" ""h2.json.gz"" ""h3.json.gz"" ""h4.json.gz"" ""h5.json.gz""nn    pool = Pool(processes=cpu_count()-1)n    pool.map(build_list files)nnnIt is important to clarify that the program starts running well and that the files are assigned at each processor when I check with top. I also check the integrity of the files with gunzip -t and they seems to be well formed. Also I did not see any exception raised before the error. Do you have any ideas on how can I fix it? Thanks in advance. n' 'Read in binary mode:nngzip.open(file_name ""rb"")nnnReading in text mode may mangle the data (as it is not text) on some platforms and will cause odd errors such as this.n' 'I ended up using a try block that checks the integrity of every line in the pointer when reading. So the final code looks like this:nndef build_list(file_name):nn    count = 0nn    try:n        json_file = gzip.open(file_name ""r"")n    except Exception as e:n        print en    else:nn        try:n            # Data parsingn            for line in json_file:n                try:n                    row = json.loads(line)n                except Exception as e:n                    print en                else:                n                    count += 1n        except Exception as e:n            print ennnThank you for all your comments. n'",['python-2.7'],['python-2.7']
40093463,"'Python Script locked for debug in VS 2015' 'I'm doing the nucleai courses. Exercises are based on python scripts and I'm using Visual Studio 2015. At some point we have to use the library nltk. I was trying to debug some code I'm calling (I have the source) and something really weird happens: breakpoints work but I can't use F10 to jump line to line. It just skips all the script. I can debug without any problem any of my scripts but not those within the library.nSo my question is: is there any option to ""unlock"" the script so I can debug line by line? nI'm new with python and I can't find anything similar on google. I'm posting the code in case something is relevant. nThe function I want to debug is 'Respond'nnfrom __future__ import print_functionnnimport renimport randomnfrom nltk import compatnnreflections = {n""i am""       : ""you are""n""i was""      : ""you were""n""i""          : ""you""n""i'm""        : ""you are""n""i'd""        : ""you would""n""i've""       : ""you have""n""i'll""       : ""you will""n""my""         : ""your""n""you are""    : ""I am""n""you were""   : ""I was""n""you've""     : ""I have""n""you'll""     : ""I will""n""your""       : ""my""n""yours""      : ""mine""n""you""        : ""me""n""me""         : ""you""n}nnclass Chat(object):ndef __init__(self pairs reflections={}):n    self._pairs = (re.compile(x re.IGNORECASE)y) for (xy) in pairsn    self._reflections = reflectionsn    self._regex = self._compile_reflections()nnndef _compile_reflections(self):n    sorted_refl = sorted(self._reflections.keys() key=lenn            reverse=True)n    return  re.compile(r""b({0})b"".format(""|"".join(map(re.escapen        sorted_refl))) re.IGNORECASE)nndef _substitute(self str):n   return self._regex.sub(lambda mo:n            self._reflectionsmo.stringmo.start():mo.end()n                str.lower())nndef _wildcards(self response match):n    pos = response.find('%')n    while pos >= 0:n        num = int(responsepos+1:pos+2)n        response = response:pos + n            self._substitute(match.group(num)) + n            responsepos+2:n        pos = response.find('%')n    return responsenndef respond(self str):n    # check each patternn    for (pattern response) in self._pairs:n        match = pattern.match(str)nn        # did the pattern match?n        if match:n            resp = random.choice(response)    # pick a random responsen            resp = self._wildcards(resp match) # process wildcardsnn            # fix munged punctuation at the endn            if resp-2: == '?.': resp = resp:-2 + '.'n            if resp-2: == '??': resp = resp:-2 + '?'n            return respnn# Hold a conversation with a chatbotndef converse(self quit=""quit""):n    input = """"n    while input != quit:n        input = quitn        try: input = compat.raw_input("">"")n        except EOFError:n            print(input)n        if input:n            while input-1 in ""!."": input = input:-1n            print(self.respond(input))nnnAny help will be very much appreciated. nThanks.nnEDIT: nI solved my problem but I haven't found a solution for the question. I'm using PyCharm (as suggested in the first comment) and it works like a charm. I can debug everything without any problem now. No file modification at all. I'm inclined to think that this is a bug in Python tools for Visual Studio. n' 'Other members also got the similar issue my suggestion is that you can use the PyCharm instead of PTVS as a workaround. Of course you could also start a discussion(Q AND A) from this site for PTVS tool:nnhttps://visualstudiogallery.msdn.microsoft.com/9ea113de-a009-46cd-99f5-65ef0595f937n'",['python-3.x'],"['regex', 'python-2.7']"
40093475,"'Only show value of n*n matrix if value from another n*n has a certain value (Python)' ""So I'm currently trying to calculate the Pearson's R and p-value for some data I have. This is done by this code:nnimport numpy as npnfrom scipy.stats import pearsonr betainfrom pandas import DataFramenimport seaborn as snsnimport matplotlib.pyplot as pltnndef corrcoef(matrix): #function that calculates the Pearson's R and p-valuen    r = np.corrcoef(matrix)n    rf = rnp.triu_indices(r.shape0 1)n    df = matrix.shape1 - 2n    ts = rf * rf * (df / (1 - rf * rf))n    pf = betai(0.5 * df 0.5 df / (df + ts))n    p = np.zeros(shape=r.shape)n    pnp.triu_indices(p.shape0 1) = pfn    pnp.tril_indices(p.shape0 -1) = pfn    pnp.diag_indices(p.shape0) = np.ones(p.shape0)n    return r pnndata = np.loadtxt('corr-data.txt') #data matrix loadednnsig_lvl = 0.05 #significance levelnnr_mat p_mat = corrcoef(data) #use function on data and put the answers in two different matricesnndf_rmat = DataFrame(r_mat columns=Index index=Index) #make data readable for the seaborn packagendf_pmat = DataFrame(p_mat columns=Index index=Index)nnr_matabs(r_mat) <= .90 = np.nan #if the R-value matrix elements are under 0.90 don't show them - make them NaN. np_matabs(p_mat) >= sig_lvl = np.nan #this is probably the issue.nnmask_pmat = np.zeros_like(p_mat)nmask_pmatnp.tril_indices_from(mask_pmat) = True #only showing the upper triangle of the values since it's symmetrical in the diagonalnnsns.plt.subplot(122)nax_pmat = sns.heatmap(np.around(df_pmat decimals=2) annot=True mask = mask_pmat) #subplot sequence for the p-value matrix onlynnsns.plt.show()nnnIt might not be the most optimal code but as of now it works as intended. Using the seaborn package I get a heat/colormap of the different values if they are high enough (>= 0.95) or have the right significance level and only the upper triangle. However what I would actually like to do is to only show the p-value for those R-values that are represented in the first plot. Values that are smaller than 0.95 is just replaced by NaN and is no color in the heat map. So only values in the p-value matrix should be represented if values in the R-value matrix is represented.nnCan this be done or...?nnAnd please let me know if something is unclear. Then I will try to further explain.nnThanks in advancen"" ""I think what you're saying is this:nnp_matr_mat < 0.95 = np.nannnnThis works because p and r are the same shape.  It would go into your code instead of:nnif r_matabs(r_mat) <= .90 == np.nan:n    p_mat = np.nannnnNote if you compare NaN to a value the result is always false.n""","['numpy', 'matplotlib']","['pandas', 'matplotlib', 'numpy']"
40093627,'Align image columns by max value' 'I have an image where I would like to offset each column so that the maximum value of each column is vertically centered in the image. Here's some toy data:nnunaligned = np.array(0012321000n                      0001232100n                      0123432100n                      0012321000n                      0001232100).TnnnnnOnce aligned it should look likennaligned = np.array(0001232100n                    0001232100n                    0012343210n                    0001232100n                    0001232100).TnnnnnI could go column by column find the index of the maximum value then rewrite the column to a new array with the maximum value at the midpoint. But is there a concise (and faster) way to do this especially if I have images with thousands of columns? Perhaps even some image processing routine with the column max values used as control points?nnThanks!n' 'Here's an approach using broadcasting -nnmn = unaligned.shapencol_shifts = m//2 - unaligned.argmax(0)nrow_idx = np.mod(np.arange(m):None-col_shiftsm)naligned_out = unalignedrow_idxnp.arange(n)nnnIf you are trying to fill the shifted in positions with zeros and the ends of the columns are zeros we can alternatively get row_idx with clipping like so -nnrow_idx = (np.arange(m):None-col_shifts).clip(min=0max=m-1)nn',['numpy'],['numpy']
40093641,"'Python matplotlib: How can I draw an errorbar graph without lines and points?' ""I am currently using the following code to plot errorbar graphs.nnplt.errorbar(log_I_mean_ log_V2_mean_ xerr yerr '.')nnnHowever the end result shows a circular point in the centre of each errorbar intersection point. How can I plot just the errorbars without the central point as is required in scientific work?n"" 'use 'none' instead of '.':nnimport matplotlib.pyplot as pltnnx = np.arange(0.1 4 0.5)ny = np.exp(-x)nnyerr = 0.1 + 0.2*np.sqrt(x)nxerr = 0.1 + yerrnnplt.figure()nplt.errorbar(x y 0.2 0.4'none')nplt.title(""Simplest errorbars 0.2 in x 0.4 in y"")nnnresult: nnnnP.S. this is slightly modified version of part of the example of pylab heren'",['matplotlib'],['matplotlib']
40093774,"'Merge 2 data streams into 1 after using pandas' 'I have two separate curl calls which generate two separate csv files. Both files have a common field(name_id). I am trying to merge these files and print them on console. nnnFrom first csv I want to add all columns in table(name_id phone_num zip). There will be two more columns(cases_week1 cases_week2) which are not part of first csv but they are in second csv. nFrom second csv I want to add all values of (cases_week1 and cases_week2) where there is match between both files using common column(name_id)If there is no match simply move over to next record. nnnP.S: First csv will always have more rows than second csv.nncd_curl csvn----------------nname_id phone_num zipnabc123 9989898 12345ndef456 3874982 45678nghi789 7728261 91011nncc_curl csvn-----------------nname_id cases_week1 cases_week2nabc123 3 3ndef456 5 2nzzz111 7 11nnTable structuren---------------nCREATE TABLE `data`.`call` (n  `name_id` VARCHAR(50) NOT NULLn  `phone_num` VARCHAR(45) NOT NULLn  `zip` VARCHAR(45) NOT NULLn  `cases_week1` VARCHAR(45) NOT NULLn  `cases_week2` VARCHAR(45) NOT NULLn  PRIMARY KEY (`name_id`)n)nENGINE = InnoDB;nnCoden----n#!/usr/bin/python3nnimport pandas as pdnncd_curl = ""url-1-hidden-due-to-security""    ncc_curl = ""url-2-hidden-due-to-security""nncd= pd.read_csv(cd_curl)ncc= pd.read_csv(cc_curl)nnfor row in cd.to_dict(orient=""records""):n    print(row'name_id' row'phone_num' row'zip')nnnDesired outputn--------------nabc123 9989898 12345 3 3ndef456 3874982 45678 5 2nghi789 7728261 91011nnnHow can I print the values of cases_week1 and cases_2 where the name_id matches? n' nan","['python-3.x', 'pandas']",['pandas']
40093776,"'CSV >> Tensorflow >> regression (via neural network) model' 'Read the original post at the bottom... I'm going to clarify and narrow the scope with updates up top.nnEdits (10/17 4pm): Let me add that this is a common task but seems to not be answered by any forums I've read thus I've asked this. I could give you my broken code but I don't want to waste your time with code that is not functionally correct. Sorry I've asked it this way. I just don't understand the APIs and the documentation doesn't tell me the data types.nnHere is the latest code I have that reads the CSV into two ndarrays:nn#!/usr/bin/env pythonnimport tensorflow as tfnimport csvnimport numpy as npnfrom numpy import genfromtxtnn# Build Example Data is CSV format but use Iris datanfrom sklearn import datasetsnfrom sklearn.cross_validation import train_test_splitnimport sklearnndef buildDataFromIris():n    iris = datasets.load_iris()n    data = np.loadtxt(open(""t100.csv.out""""rb"")delimiter=""""skiprows=0)n    labels = np.copy(data)n    labels = labels:924n    print ""labels: "" type (labels) labels.shape labels.ndimn    data = np.delete(data 924 axis=1)n    print ""data: "" type (data) data.shape data.ndimnnnAnd here is base code that I want to use. The example this came from wasn't complete either. The APIs in the links below are vague. If I can at least figure out the data types input into DNNRegressor and the others in the docs I might be able to write some custom code.nnestimator = DNNRegressor(n    feature_columns=education_emb occupation_embn    hidden_units=1024 512 256)nn# Or estimator using the ProximalAdagradOptimizer optimizer withn# regularization.nestimator = DNNRegressor(n    feature_columns=education_emb occupation_embn    hidden_units=1024 512 256n    optimizer=tf.train.ProximalAdagradOptimizer(n      learning_rate=0.1n      l1_regularization_strength=0.001n    ))nn# Input buildersndef input_fn_train: # returns x Yn  passnestimator.fit(input_fn=input_fn_train)nndef input_fn_eval: # returns x Yn  passnestimator.evaluate(input_fn=input_fn_eval)nestimator.predict(x=x)nnnAnd then the big question is how to get these to work together.nnOriginal post:nnFirst please understand that I'm not new to programming.  However I'm very new to Python TensorFlow and numpy. Endless Googling has left me better educated on Python and numpy but still clueless on solving my task.nnI want to read a CSV of integer/floating point values and predict a value using a neural network. Once I have a basic (anything) topology working I can work on getting accuracy. I plan to later compare performance and accuracy with RandomForest and GBT but let's not worry about those steps. nnI have found several examples that read the Iris dataset and do classification but I don't understand how to make them work for regression.nnHere is one line of the input:   nnn  168040101101010100110010101010101010101011001100101010101010110010101010101010101010101010101100101010110010101010101010101010101010101100101010101011001000110010000010100000101000001000100001001000100010001000010000001000000100100000000110000001000001000000000010010000000100000000001000000000000000010000000000000001000001000000010000000000000010000000000000000000000100000010000000000000000000100000000000000000000000000000000000000000000100000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000010000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000010000000000000000100000000000000000000000010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.4902650.6208050.549770.8692990.4222680.3512230.335720.683080.404550.477790.3076280.3019210.3186460.3659936135.81nnnThat should be 925 values. The last column is the output. The first is the RowID. Most are binary values because I've already done one-hot encoding. The test files do not have the output/last column. The full training file has around 10M rows. Performance matters.nnHere are a few pages I've been looking at.nnnBase code that reads CSV and works (classifier):nhttps://www.tensorflow.org/versions/r0.9/tutorials/tflearn/index.htmlnRegressor:nhttps://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.learn.html#DNNRegressornMNIST:nhttps://www.tensorflow.org/versions/r0.11/tutorials/mnist/tf/index.htmlnCSV reading:nhttps://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#csv-filesnColumn embedding:nhttps://www.tensorflow.org/versions/r0.11/tutorials/wide_and_deep/index.htmlnList of APIs (DNNRegressor TensorFlowDNNRegressor LinearRegressornTensorFlowLinearRegressor TensorFlowRNNRegressornTensorFlowRegressor):nhttps://www.tensorflow.org/versions/r0.9/api_docs/python/contrib.learn.htmlnnnI'm most interested in this example as a baseline. It's from the last link. nnclass tf.contrib.learn.DNNRegressornnA regressor for TensorFlow DNN models.nnExample:nneducation = sparse_column_with_hash_bucket(column_name=""education""n                                           hash_bucket_size=1000)noccupation = sparse_column_with_hash_bucket(column_name=""occupation""n                                            hash_bucket_size=1000)nneducation_emb = embedding_column(sparse_id_column=education dimension=16n                                 combiner=""sum"")noccupation_emb = embedding_column(sparse_id_column=occupation dimension=16n                                 combiner=""sum"")nnestimator = DNNRegressor(n    feature_columns=education_emb occupation_embn    hidden_units=1024 512 256)nn# Or estimator using the ProximalAdagradOptimizer optimizer withn# regularization.nestimator = DNNRegressor(n    feature_columns=education_emb occupation_embn    hidden_units=1024 512 256n    optimizer=tf.train.ProximalAdagradOptimizer(n      learning_rate=0.1n      l1_regularization_strength=0.001n    ))nn# Input buildersndef input_fn_train: # returns x Yn  passnestimator.fit(input_fn=input_fn_train)nndef input_fn_eval: # returns x Yn  passnestimator.evaluate(input_fn=input_fn_eval)nestimator.predict(x=x)nn' nan",['numpy'],"['numpy', 'python-2.7']"
40093792,"'Python Image RGB list to 2D Array python 2' ""I successfully converted my image to RGB values using:nnfrom PIL import Imagenim = Image.open(imageDir 'r')nnpix_val_rgb = list(im.getdata())nnnOf course this only give me an 1D array. Is there any built in function that converts 1D arrays to 2D or would this be a type of task that I will have to program on my own?nnThank you in advance!n"" nan",['list'],"['python-2.7', 'list']"
40093814,"'Virtualenv and Pip hanging forever' 'I am running a django project with a virtualenv that was working completely fine up until this afternoon. I went to run source my-env/bin/activate and it seemed to activate (it gave me the usual command prompt) but when I tried python manage.py runserver it said it could not locate django. I ran a python script and tried to import django and sure enough it said there was no module named django. So I removed this virtualenv and created a new one and did a pip install -r requirements.txt. It was then I noticed that pip was hanging forever and upon type ^C it would give a long traceback which I provided below. Once this happened I tried once again to delete the virtualenv and start over only now when I typed virtualenv new-env it would hang on ""Installing setuptools pip wheel..."" and also gave a long traceback upon entering ^C. I have looked all over the online forums and tried everything to fix this and nothing seems to be working.  If anyone has any ideas on how to fix this I would really appreciate it. nnInstalling setuptools pip wheel...^CTraceback (most recent call last):n  File ""/usr/local/bin/virtualenv"" line 11 in <module>ndone.n    sys.exit(main())n  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 669 in mainnTraceback (most recent call last):n  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 2327 in <module>n    raise SystemExit(popen.wait())n  File ""/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"" line 1384 in waitn    main()n  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 711 in mainn    symlink=options.symlink)n  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 944 in create_environmentn    download=downloadn  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 900 in install_wheeln    call_subprocess(cmd show_stdout=False extra_env=env stdin=SCRIPT)n  File ""/usr/local/lib/python2.7/site-packages/virtualenv.py"" line 767 in call_subprocessn    line = stdout.readline()nKeyboardInterruptn    pid sts = _eintr_retry_call(os.waitpid self.pid 0)n  File ""/usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"" line 476 in _eintr_retry_calln    return func(*args)nKeyboardInterruptnn' nan","['django', 'python-3.x']",['django']
40093895,"'Python Error: Not all arguments converted during string formatting' 'def process_cars(text_file):n    total_cmpg = 0n    for line in text_file:n        if((line % 2) == 0):n            city_mpg = (line52:54)n            print(city_mpg)n            city_mpg = int(city_mpg)n            total_cmpg += city_mpgn    print (""Total miles per gallon in the city:"" total_cmpg)nnnThe error comes in the if((line % 2) == 0): I have searched on the other questions with the same error but none of them could solve the problem. The error is: Not all arguments converted during string formatting. I want to mod the position of the line. For example if it is the third line then 2 % 2.n' 'def process_cars(text_file):n    total_cmpg = 0n    for file_line_number line in enumerate(text_file):n        if((file_line_number % 2) == 0):n            city_mpg = (line52:54)n            print(city_mpg)n            city_mpg = int(city_mpg)n            total_cmpg += city_mpgn    print (""Total miles per gallon in the city:"" total_cmpg)nnnBased on your comments you want to only do the if statement every x amount of lines. Try what we have above since we are using enumerate() which keeps a count of what ever is next in the object. In our case it keeps the count of the line number while still giving us what the line is. nnfile_line_number is the file number line currently and line is the content of the line.n'",['python-3.x'],"['python-2.7', 'python-3.x']"
40093971,"'Pandas DataFrame insert / fill missing rows from previous dates' 'I have a DataFrame consisting of dates other columns and a numerical value where some value combinations in ""other columns"" could be missing and I want to populate them from previous dates.nnExample. Say the DataFrame is like below. You can see on 2016-01-01 we have data for (LN A) (LN B) (NY A) and (NY B) on columns (location band).nnn        date  location  band  valuen0 2016-01-01        LN     A   10.0n1 2016-01-01        LN     B    5.0n2 2016-01-01        NY     A    9.0n3 2016-01-01        NY     B    6.0n4 2016-01-02        LN     A   11.0n5 2016-01-02        NY     B    7.0n6 2016-01-03        NY     A   10.0nnnThen you notice on 2016-01-02 we only have (LN A) and (NY B) but (LN B) and (NY A) are missing. Again on 2016-01-03 only (NY A) is available; all other three combinations are missing.nnWhat I want to do is to populate the missing combinations of each date from its predecessor. Say for 2016-01-02 I would like to add two more rows ""rolled over"" from 2016-01-01: (LN B 5.0) and (NY A 9.0) for columns (location band value). Same for 2016-01-03. So as to make the whole thing like below:nnn        date  location  band  valuen 0 2016-01-01        LN     A   10.0n 1 2016-01-01        LN     B    5.0n 2 2016-01-01        NY     A    9.0n 3 2016-01-01        NY     B    6.0n 4 2016-01-02        LN     A   11.0n 5 2016-01-02        NY     B    7.0n 6 2016-01-03        NY     A   10.0n 7 2016-01-02        LN     B    5.0n 8 2016-01-02        NY     A    9.0n 9 2016-01-03        LN     A   11.0n10 2016-01-03        LN     B    5.0n11 2016-01-03        NY     B    7.0nnnNote rows 7-11 are populated from rows 1 2 4 7 and 5 respectively. The order is not really important as I can always sort afterwards if all the data I need is present.nnAnyone to help? Thanks a lot!n' ""You can use a unstack/stack method to get all missing values followed by a forward fill:nn# Use unstack/stack to add missing locations.ndf = df.set_index('date' 'location' 'band') n       .unstack(level='location' 'band') n       .stack(level='location' 'band' dropna=False)nn# Forward fill NaN values within 'location' 'band' groups.ndf = df.groupby(level='location' 'band').ffill().reset_index()nnnOr you can directly build a MultiIndex containing all combinations:nn# Build the full MultiIndex set the partial MultiIndex and reindex.nlevels = 'date' 'location' 'band'nfull_idx = pd.MultiIndex.from_product(dfcol.unique() for col in levels names=levels)ndf = df.set_index(levels).reindex(full_idx)nn# Forward fill NaN values within 'location' 'band' groups.ndf = df.groupby(level='location' 'band').ffill().reset_index()nnnThe resulting output for either method:nn         date location band  valuen0  2016-01-01       LN    A   10.0n1  2016-01-01       LN    B    5.0n2  2016-01-01       NY    A    9.0n3  2016-01-01       NY    B    6.0n4  2016-01-02       LN    A   11.0n5  2016-01-02       LN    B    5.0n6  2016-01-02       NY    A    9.0n7  2016-01-02       NY    B    7.0n8  2016-01-03       LN    A   11.0n9  2016-01-03       LN    B    5.0n10 2016-01-03       NY    A   10.0n11 2016-01-03       NY    B    7.0nn"" ""My solution in summary using the product operation to get all the combinations in a multi index then some stacking and ffill().nndf =pd.DataFrame({'date': {0: '2016-01-01' 1: '2016-01-01' 2: '2016-01-01' 3: '2016-01-01' 4: '2016-01-02' 5: '2016-01-02' 6: '2016-01-03'} 'band': {0: 'A' 1: 'B' 2: 'A' 3: 'B' 4: 'A' 5: 'B' 6: 'A'} 'location': {0: 'LN' 1: 'LN' 2: 'NY' 3: 'NY' 4: 'LN' 5: 'NY' 6: 'NY'} 'value': {0: 10 1: 5 2: 9 3: 6 4: 11 5: 7 6: 10}})nunique_dates = df'date'.unique()ndf.set_index('date''location''band'inplace=True)nidx = pd.MultiIndex.from_product(unique_dates'LN''NY''A''B')ndf  = df.reindex(idx)ndf = df.unstack(level=21)nnnwhich produces:nn             value                      n                 A      B       A      Bn                LN     LN      NY     NYn2016-01-01 10.0000 5.0000  9.0000 6.0000n2016-01-02 11.0000    nan     nan 7.0000n2016-01-03     nan    nan 10.0000    nannnnand finally:nndf = df.ffill()ndf = df.stack().stack()nprint dfnnn                  valuen2016-01-01 LN A 10.0000n              B  5.0000n           NY A  9.0000n              B  6.0000n2016-01-02 LN A 11.0000n              B  5.0000n           NY A  9.0000n              B  7.0000n2016-01-03 LN A 11.0000n              B  5.0000n           NY A 10.0000n              B  7.0000nn""",['pandas'],['pandas']
40094120,"'Python: Errno 2 No such file or directory - weird issue' 'I'm learning with a tutorial Create your own shell in Python and I have some weird issue. I wrote following code:nnimport sysnimport shlexnimport osnnSHELL_STATUS_RUN = 1nSHELL_STATUS_STOP = 0nndef shell_loop():n    status = SHELL_STATUS_RUNnn    while status == SHELL_STATUS_RUN:n        sys.stdout.write('> ') #display a command promptn        sys.stdout.flush()n        cmd = sys.stdin.readline()  #read command inputn        cmd_tokens = tokenize(cmd) #tokenize the command inputn        status = execute(cmd_tokens) #execute the command and retrieve new statusnndef main():n    shell_loop()nndef tokenize(string):n    return shlex.split(string)nndef execute(cmd_tokens): #execute commandn    os.execvp(cmd_tokens0 cmd_tokens) #return status indicating to wait for the next command in shell_loopn    return SHELL_STATUS_RUNnnnif __name__ == ""__main__"":n    main()nnnAnd now when I'm typing a ""mkdir folder"" command it returns error: Errno 2 No such file or directory. BUT if I write previously ""help"" command which works correctly (displays me all available commands) command mkdir works correctly and it creating a folder. Please guide me what's wrong with my code?nI'm writing in Notepad++ on Windows 8.1 64xn' 'Copy-paste from comments in my link (thanks for Ari Gold)nnHi tyh it seems like you tried it on Windows. (I forgot to note that it works on Linux and Mac or Unix-like emulator like Cygwin only)nnFor the first problem it seems like it cannot find mkdir command on your system environment. You might find the directory that the mkdir binary resides in and use execvpe() to explicitly specify environment insteadnnFor the second problem the os module on Windows has no fork() function. nHowever I suggest you to use Cygwin on Windows to emulate Unix like environment and two problems above should be gone.nnIn Windows 10 there is Linux-Bash which might work but I never try.n'",['python-3.x'],['python-2.7']
40094156,"'URL query parameters are not processed in django rest' 'Here is my views.py:nnclass my4appCompanyData(generics.ListAPIView):n    serializer_class = my4appSerializernn    def get_queryset(selfrequest):n        """"""Optionally restricts the returned data to ofa companyn        by filtering against a `id` query parameter in the URL. """"""n        queryset = companies_csrhub.objects.all()n        #url_id = self.request.query_params.get('id' None)n        url_id = request.GET.get('id' None)n        if id is not None:n            queryset = queryset.filter(id=url_id)n        elif id is ALL:n            queryset = companies_csrhub.objects.all()n        else:n            queryset = ""Error data not found""n        return querysetnnnAnd my urls.py:nnrouter.register(r'api/my4app/company/$' views.my4appCompanyData.as_view()base_name=""company"")nnnURL used for checking: mywebsite/api/my4app/company/?id=100227nnPlanning to add multiple filters with default values but not working. Please help.n' 'class my4appCompanyData(generics.ListAPIView):n    serializer_class = my4appSerializernn    def get_queryset(selfrequest):n        """"""Optionally restricts the returned data to ofa companyn        by filtering against a `id` query parameter in the URL. """"""n        queryset = companies_csrhub.objects.all()n        url_id = request.query_params.get('id' None)n        if id is not None:n            queryset = queryset.filter(id=url_id)n        elif id is ALL:n            queryset = companies_csrhub.objects.all()n        else:n            queryset = n        return querysetnnnDelete the return id since id is not a queryset therefore it'd give an error. Also in the else part of if statement you return string but you can't do that also since string is not a queryset.n' 'According the official docs (http://www.django-rest-framework.org/api-guide/filtering/#filtering-against-query-parameters)nnI think your code is not working because you are using:nnurl_id = request.query_params.get('id' None)nnnInstead of:nnurl_id = self.request.query_params.get('id' None)nnnIn the documentation you can find that get_queryset function just receives self param you must remove request param.n'",['django'],['django']
40094260,"'Displaying unique name with total of column value in a group with additional variables in python' ""I'm learning Python and thought working on a project might be the best way to learn it. I have about 200000 rows of data in which the data shows list of medication for the patient. Here's a sample of the data. nnPTID PTNAME     MME   DRNAME       DRUGNAME                    SPLY STR QTY  FACTORn1   PATIENT A  2700    DR A   OXYCODONE HCL 15 MG             30  15  120 1.5n1   PATIENT A  2700    DR B   OXYCODONE HCL 15 MG             30  15  120 1.5n2   PATIENT B  4050    DR C   MORPHINE SULFATE ER 15 MG       30  15  270 1n2   PATIENT B  4050    DR C   MORPHINE SULFATE ER 15 MG       30  15  270 1n2   PATIENT B   840    DR A   OXYCODONE-ACETAMINOPHE 10MG-32  14  10  56  1.5n2   PATIENT B  1350    DR C   OXYCODONE-ACETAMINOPHE 5 MG-32  15  5   180 1.5n3   PATIENT C  1350    DR C   OXYCODONE-ACETAMINOPHE 5 MG-32  15  5   180 1.5n3   PATIENT C  1800    DR D   OXYCODONE-ACETAMINOPHE 10MG-32  30  10  120 1.5nnnI've been thinking about this a lot and have tried many ways but none of the code produce any results or makes any sense. Honestly I don't even know where to begin. A little help would be highly appreciated. nnSo what I want to do is consolidate the data for each patients and calculate the Total MME for each patient. The DRUGNAME should show the one that has higher MME. In other words the dataframe should only have one row for each patient.  nnOne thing I did try is nngroupby_ptname = semp.groupby('PTNAME').apply(lambda x: x.MME.sum())nnnwhich shows unique patient names with total MME  but I'm not sure how to add other variables in this new dataframe. n"" 'Have another look at the documentation for the pandas groupby methods. nnHere's something that could work for you:nn#first get the total MME for each patient and drug combinationntotal_mme=semp.groupby('PTNAME''DRUGNAME')'MME'.sum()n#this will be a series object with index corresponding to PTNAME and DRUGNAME and values corresponding to the total MMEn#now get the indices corresponding to the drug with the max MME totalnmax_drug_indices=total_mme.groupby(level='PTNAME').idxmax()n#index the total MME with these indicesnout=total_mmemax_drug_indicesnn' ""IIUC you can do it this way:nnIn 62: df.sort_values('MME').groupby('PTNAME').agg({'MME':'sum' 'DRUGNAME':'last'})nOut62:n                                  DRUGNAME    MMEnPTNAMEnPATIENT A             OXYCODONE HCL 15 MG   5400nPATIENT B       MORPHINE SULFATE ER 15 MG  10290nPATIENT C  OXYCODONE-ACETAMINOPHE 10MG-32   3150nnnor with .reset_index():nnIn 64: df.sort_values('MME').groupby('PTNAME').agg({'MME':'sum' 'DRUGNAME':'last'}).reset_index()nOut64:n       PTNAME                        DRUGNAME    MMEn0  PATIENT A             OXYCODONE HCL 15 MG   5400n1  PATIENT B       MORPHINE SULFATE ER 15 MG  10290n2  PATIENT C  OXYCODONE-ACETAMINOPHE 10MG-32   3150nnnUPDATE: more fun with agg() functionnnIn 84: agg_funcs = {n    ...:     'MME':{'MME_max':'last'n    ...:            'MME_total':'sum'}n    ...:     'DRUGNAME':{'DRUGNAME_max_MME':'last'}n    ...: }n    ...:n    ...: rslt = (df.sort_values('MME')n    ...:          .groupby('PTNAME')n    ...:          .agg(agg_funcs)n    ...:          .reset_index()n    ...: )n    ...: rslt.columns = tup1 if tup1 else tup0 for tup in rslt.columnsn    ...:nnIn 85: rsltnOut85:n       PTNAME  MME_total  MME_max                DRUGNAME_max_MMEn0  PATIENT A       5400     2700             OXYCODONE HCL 15 MGn1  PATIENT B      10290     4050       MORPHINE SULFATE ER 15 MGn2  PATIENT C       3150     1800  OXYCODONE-ACETAMINOPHE 10MG-32nn""",['pandas'],['pandas']
40094461,"'Paramiko capturing command output' 'I have an issue that has been giving me a headache for a few days. I am using the Paramiko module with Python 2.7.10 and I'd like to issue multiple commands to a Brocade router but only return output from one of the given commands like so:nn#!/usr/bin/env pythonnimport paramiko timennrouter = 'r1.test.example.com'npassword = 'password'nusername = 'testuser'nnssh = paramiko.SSHClient()nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())nssh.connect(router username=username password=password)nprint('Successfully connected to %s' % router)nnremote_conn = ssh.invoke_shell()noutput = remote_conn.recv(1000)nn# Disable paging on Brocade.nremote_conn.send('terminal length 0n')n# Check interface status.nremote_conn.send('show interfaces ethernet 0/1n') # I only want output from this command.ntime.sleep(2)noutput = remote_conn.recv(5000)nprint(output)nnnIf I were to print the full output it would contain everything issued to the router but I only want to see output from the show interfaces ethernet 0/1n command.nnCan anyone help with this issue?nnOne final thing I would like to ask. I want to filter through the output variable and check for occurrences of strings like ""up"" or ""down"" but I can't seem to get it to work because everything in the output appears to be on new lines?nnFor example:nnIf I iterate over the output variable in a for loop I get all of the characters in the variable like so:nnfor line in output:n    print(line)nnnI get an output like this:nntnnennrnnmnninnnnnannlnnlnnennnnngnntnnhnn0nnAny way around this?nnAgainnnThanks in advance for any help.nnBest regardsnnAaron C.n' 'For your second question: Though I am not specialist of paramiko I see that function recv according to the doc returns a string. If you apply a for loop on a string you will get characters (and not lines as one might perhaps expect). The newline is caused by your use of the print function as explained on this page at paragraph 6.3.nnI haven't studied what paramiko suggests to do. But why don't you treat the full string as a single entity? For example you could check the presence of ""up"" as:nnif ""up"" in output:nnnOr if that suits your needs better you could split the string into lines and then do whatever test you want to do:nnfor line in output.split('n'): nn' ""If you can the exec_command() call provides a simpler mechanism to invoke a command. I have seen Cisco switches abruptly drop connections that try exec_command() so that may not be usable with Brocade devices.nnIf you must go the invoke_shell() route be sure to clear all pending output after connecting and after send('terminal length 0n') checking recv_ready() before calling recv() to avoid blocking on reading data that might not ever arrive. Since you are controlling an interactive shell sleep() calls might be needed to allow the server adequate time to process and send data or it might be necessary to poll the output string to confirm that your last command completed by recognizing the shell prompt string.n"" ""After reading all of the comment I have made the following changes:nn#!/usr/bin/env pythonnimport paramiko timennrouter = 'r2.test.example.com'npassword = 'password'nusername = 'testuser'nnssh = paramiko.SSHClient()nssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())nssh.connect(router username=username password=password)nprint('Successfully connected to %s' % router)nnremote_conn = ssh.invoke_shell()noutput = remote_conn.recv(1000)nn# Disable paging on Brocade.nremote_conn.send('terminal length 0n')ntime.sleep(2)n# Clearing output.nif remote_conn.recv_ready():n    output = remote_conn.recv(1000)nn# Check interface status.nremote_conn.send('show interfaces ethernet 4/1n') # I only want output from this command.ntime.sleep(2)n# Getting output I want.nif remote_conn.recv_ready():n    output = remote_conn.recv(5000)nprint(output)nn# Test: Check if interface is up.nfor line in output.split('n'):n    if 'line protocol is up' in line:n        print(line)nnnEverything works great now.nnThank you for all the help.nnBest regardsnnAaron C.n""",['python-2.7'],['python-2.7']
40094470,'Why does adding parenthesis around a yield call in a generator allow it to compile/run?' 'I have a method:nn@gen.coroutinendef my_func(x):n    return 2 * xnnnbasically a tornado coroutine.nnI am making a list such as:nnmy_funcs = nfor x in range(0 10):n    f = yield my_func(x)n    my_funcs.append(x)nnnIn trying to make this a list comprehension such as:nnmy_funcs = yield my_func(i) for i in range(010)nnnI realized this was invalid syntax. It turns out you can do this using () around the yield:nnmy_funcs = (yield my_func(i)) for i in range(010)nnnnDoes this behavior (the syntax for wrapping a yield foo() call in () such as (yield foo() ) in order to allow this above code to execute) have a specific type of name?nnnIs it some form of operator precedence with yield?nnIs this behavior with yield documented somewhere?nnnPython 2.7.11 on OSX. This code does need to work in both Python2/3 which is why the above list comprehension is not a good idea (see here for why the above list comp works in Python 2.7 but is broken in Python 3).n' 'yield expressions must be parenthesized in any context except as an entire statement or as the right-hand side of an assignment:nn# If your code doesn't look like this you need parentheses:nyield xny = yield xnnnThis is stated in the PEP that introduced yield expressions (as opposed to yield statements) and it's implied by the contexts in which yield_expr appears in the grammar although no one is expecting you to read the grammar:nnn  A yield-expression must always be parenthesized except when itn      occurs at the top-level expression on the right-hand side of ann      assignment.nn',['python-2.7'],"['list', 'python-2.7']"
40094588,"'How to get a list of matchable characters from a regex class' ""Given a regex character class/set how can i get a list of all matchable characters (in python 3). E.g.:nndA-Cnnnshould givenn'0''1''2''3''4''5''6''7''8''9''A''B''C'nn"" ""import rennx = '123456789ABCDE'npattern = r'dA-C'nprint(re.findall(patternx))    n#prints '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C'nnnIs this what you are looking for? nnIf you don't have x and just want to match ascii characters you can use :nnimport renimport stringnnx = string.ascii_uppercase + string.digitsnpattern = r'dA-C'nprint(re.findall(patternx))    nnnIf you want to take inputs for the pattern you can simply just do:nn pattern = input() #with either one from abovenn"" 'I think what you are looking for is string.printable which returns all the printable characters in Python. For example:nn>>> import stringn>>> string.printablen'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!""#$%&'()*+-./:;<=>?@^_`{|}~ tnrx0bx0c'nnnNow to check content satisfied by your regex you may do:nn>>> import ren>>> x = string.printablen>>> pattern = r'dA-C'n>>> print(re.findall(pattern x))n'0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'A' 'B' 'C'nnnstring.printable is a combination of digits letters punctuation and whitespace. Also check String Constants for complete list of constants available with string module.nnnnIn case you need the list of all unicode characters you may do:nnimport sysnunicode_list = chr(i) for i in range(sys.maxunicode)nnnNote: It will be a huge list and console might get stuck for a while to give the result as value of sys.maxunicode is:nn>>> sys.maxunicoden1114111nnnIn case you are dealing with some specific unicode formats refer Unicode Character Ranges for limiting the ranges you are interested in.n' 'You probably hoped to just extract them from the regexp itself but it's not that easy: Consider specifications like S which doesn't match a contiguous range of characters negated specifications like ^abcd and of course goodies like (?!aeiou)w (which matches any single letter except the five vowels given). So it's far simpler to just try out each candidate character against your regexp.nnBut checking all Unicode codepoints is not very practical both because of the large number of tests and because the result could be a very large list: A character class regexp might contain specifications like wnwhich can match an enormous number of characters from all over the Unicode table. Or it could contain a negated specification like ^abcdnwhich matches even more.  So let's assume that you can restrict your interest to a particularnsubset of thenUnicode range. After consulting a table of Unicode rangesnyou might decide for the sake of example that you are interested in the ranges 0000-024Fn(Basic and Extended Latin) and 0590-074F (Hebrew and Arabic).nnYou can then churn through each of these unicode codepointsnchecking which ones are matched by your regexp:nnimport rennmyregexp = r""dA-C""ninterest =  (0x0000 0x024F)n             (0x0590 0x06FF) nnnpattern = re.compile(myregexp)nmatched =     nfor low high in interest:n    matched.extend(chr(p) for p in range(low high+1) if pattern.match(chr(p)))nn>>> print("""".join(matched))n0123456789ABCÙxa0Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹nn'","['regex', 'python-3.x']","['regex', 'list']"
40094642,"'How to add a plot into a pop up window' 'So I have a window with a plot and when i click on a fixed point in the plot it opens a pop up window with the exact coordinates of that specific point. Now i want to make that in that pop up window there is also shown a small plot with that point. I have no idea how to do this since every point you click has to have a different plot. nthis is the script:nnfrom PyQt4.uic import loadUiTypenfrom PyQt4 import QtCore QtGuinnfrom matplotlib.figure import Figurenfrom matplotlib.backends.backend_qt4agg import (n    FigureCanvasQTAgg as FigureCanvasn    NavigationToolbar2QT as NavigationToolbar)nimport matplotlib.pyplot as pltnimport sysnnUi_MainWindow QMainWindow = loadUiType('window.ui')nnclass Main(QMainWindow Ui_MainWindow):n    def __init__(self parent=None):n        super(Main self).__init__()n        self.setupUi(self)n        self.fig_dict = {}nn        self.mplfigs.itemClicked.connect(self.changefig)nn        fig = Figure()n        self.addmpl(fig)nn    def changefig(selfitem):n        text = item.text()n        self.rmmpl()n        self.addmpl(self.fig_dictstr(text))nn    def addfig(self name fig):n        self.fig_dictname = fign        self.mplfigs.addItem(name)nn    def addmpl(self fig):n        self.canvas = FigureCanvas(fig)n        self.mplvl.addWidget(self.canvas)n        self.canvas.draw()nn        self.toolbar = NavigationToolbar(self.canvas self.mplwindow coordinates=True)n        self.mplvl.addWidget(self.toolbar)nn        self.canvas.mpl_connect('pick_event' self.on_pick)nn    def rmmpl(self):n        self.mplvl.removeWidget(self.canvas)n        self.canvas.close()n        self.mplvl.removeWidget(self.toolbar)n        self.toolbar.close()nn    def on_pick(self event):n        print('On Pick!')n        thisline = event.artistn        xdata = thisline.get_xdata()n        ydata = thisline.get_ydata()n        ind = event.indn        print(ind)n        msg = str(xdata) + ' ' + str(ydata)n        points = tuple(zip(xdataind ydataind))n        myString = ""got data %s %s"" % (str(xdataind)str(ydataind))n        print('onpick points:' points)nn        QtGui.QMessageBox.information(self ""Click!"" '' + myString)nnnif __name__ == '__main__':n    import sysn    from PyQt4 import QtGuinnn# If you want to display concrete POINTS:n    x_series_1 = 4123 45n    y_series_1 = 439275463nn    x_series_2 = 4246810n    y_series_2 = 448121618nn# If you want to display a FUNCTION:n    x_series_3 = 1510152025n    y_series_3 = x**2 for x in x_series_3nn    x_series_4 = 123456n    y_series_4 = x**3 for x in x_series_4nn    fig1 = Figure()n    fig1=plt.figure()n    ax1f1 = fig1.add_subplot(111)n    ax1f1.plot(x_series_1 y_series_1 marker='s' linestyle='-' color='k'picker = 5)n    ax1f1.plot(x_series_2 y_series_2 marker='s' linestyle='-' color='k'picker = 5)n    ax1f1.plot(x_series_3 y_series_3 marker='s' linestyle='-' color='k'picker = 5)n    ax1f1.plot(x_series_4 y_series_4 marker='s' linestyle='-' color='k'picker = 5)n    #ax1f1.plot(x_series_1 y_series_1)nn    # If you want to display concrete POINTS:n    ax1f1.plot(x_series_1 y_series_1 label=""Graph 1"")n    ax1f1.plot(x_series_2 y_series_2 label=""Graph 2"")nn    # If you want to dispay a FUNCTION:n    ax1f1.plot(x_series_3 y_series_3 label=""Graph 3"")n    ax1f1.plot(x_series_4 y_series_4 label=""Graph 4"")nn    #create legendn    ax1f1.legend(loc=""upper left"")n    app = QtGui.QApplication(sys.argv)n    main = Main()n    main.addfig('One plot' fig1)n    print main.fig_dictn    main.show()n    sys.exit(app.exec_())nnnthank you in advance folks!n' nan",['matplotlib'],['matplotlib']
40094735,"'Concating CSV files but Filtering Duplicates by 2 Columns' ""I have a csv I want to update based on certain criteria. Example: nncsv: nName     UniqueID    StatusnApple    1121        FullnOrange   1122        EatennApple    1123        RottennnnNew values (also in a csv):nncsv1:nApple    1121        Eatennorange   1122        EatennPear     1233        Wiggly nnnthe updated csv would look like this:nnName     UniqueID    StatusnApple    1121        FullnOrange   1122        EatennApple    1123        RottennPear     1233        WigglynApple    1121        EatennnnSo basically skip the entries that have the same UniqueID and Status. If it's a new UniqueID or an existing UniqueID and a different Status I want it included as a separate row. So from the above example orange   1122  Eaten was excluded. nnI tried converting the csv to a DataFrame and using the drop_duplicates. nndata = pd.concat(pd.DataFrame.from_csv(csv csv1).drop_duplicates(subset='Status' 'UniqueID')nnBut it predictably dropped all the duplicates. Which resulted in:nn    Name     UniqueID    Statusn    Apple    1121        Fulln    Orange   1122        Eatenn    Apple    1123        Rottenn    Pear     1233        Wigglyn   # Apple    1121        Eaten  <-- this result was excludednn"" ""ncat csv csv1 | awk '{if (!status$2 || status$2!=$3) {print $0; status$2=$3} }'nnnexplanationnnprint these files in sequence and iterete line by linenncat csv csv1 | awk '{ nnKeep second column (unique id) in an array key and the third one column as the value. Then check if the array element doesn't exists (it means this is first occurence of that row) OR value is not equal to the third one (it means that value has changed)nnif (!status$2 || status$2!=$3) {nnthen simply print the row and set the array valuennprint $0;nstatus$2=$3nnif endsnn}nnawk endsn}'n"" 'setup nnimport pandas as pdnfrom StringIO import StringIOnncsv = """"""Name     UniqueID    StatusnApple    1121        FullnOrange   1122        EatennApple    1123        Rotten""""""nncsv1 = """"""Name     UniqueID    StatusnApple    1121        EatennOrange   1122        EatennPear     1233        Wiggly """"""nnnoption 1nset_index + combine_first + reducenndef fruit_status1(f):n    return pd.read_csv(StringIO(f) delim_whitespace=Truen                       index_col='UniqueID' 'Status')nndef update1(d1 d2):n    return d2.combine_first(d1)nnreduce(update1 fruit_status1(f) for f in csv csv1)nnnnnoption 2npd.concat + drop_duplicatesnndef fruit_status2(f):n    return pd.read_csv(StringIO(f) delim_whitespace=True)nnpd.concat(fruit_status2(f) for f in csv csv1) n    .drop_duplicates(subset='UniqueID' 'Status')nnnn'",['pandas'],['pandas']
40094762,"'Matplotlib Add Space Betwen Lines and left and right axes' ""Given the following line graph:nnimport matplotlib.pyplot as pltnfrom matplotlib.ticker import FuncFormatter MaxNLocatornfig = plt.figure()nax = fig.add_subplot(111)nxs = range(26)nys = range(26)nlabels = list('abcdefghijklmnopqrstuvwxyz')nnndef format_fn(tick_val tick_pos):n    if int(tick_val) in xs:n        return labelsint(tick_val)n    else:n        return ''nax.xaxis.set_major_formatter(FuncFormatter(format_fn))nax.xaxis.set_major_locator(MaxNLocator(integer=True))nax.plot(xs ys)nplt.show()nnnHow can I add space between the left end of the line and the left y-axis and the same for the right side? For example there should be space between the 0 on the bottom of the y-axis and the 'a' on the left side of the x-axis.nnThanks in advance!n"" 'I guess the easiest would be to add a ax.margins(margin) call where margin is a float between 0 and 1 that multiplied by the plot dimensions (width and height) gives the margin size it will be added.nnNot sure how it fares with non trivial layouts (subplots tight layout) but seems to work pretty well with your example.n'",['matplotlib'],['matplotlib']
40094823,"'Django Rest Framework invalid username/password' 'Trying to do a simple 'GET' wih admin credentials returnsnnn  ""detail"": ""Invalid username/password.""nnnI have a custom user model where I deleted the username instead I use facebook_id :nnUSERNAME_FIELD = 'facebook_id'nnnnnI tried changing the DEFAULT_PERMISSION_CLASSES:nn('rest_framework.permissions.IsAuthenticated') -- doesn't work!n('rest_framework.permissions.IsAdminUser') -- doesn't work!nnnThe only one that works is:nn('rest_framework.permissions.AllowAny')nnnBut I do not want that since I'm building an API for a Mobile AppnnI also declared a CustomUserAdmin model and CustomUserCreationForm  apparently this was not the problemnnnnHelp me understand what needs to be done to fix this annoying problem I'm guessing it might have something to do with Permissions/Authentication or the fact that I CustomUserModel..nnAlso let me know if there is a better way for a mobile app client to authenticate to the apin' ""You have the default and then you have per view.  You can set the default to IsAuthenticated and then you override your view's particular permission_classes. e.g.nnclass ObtainJSONWebLogin(APIView):n    permission_classes = ()nnnor nnclass Foo(viewsets.ModelViewSet):n    permission_classes = ()nn""",['django'],"['django', 'python-2.7']"
40094839,"""Exception Value: object of type 'PolymorphicModelBase' has no len()"" 'I am converting existing models/admin over to django-polymorphic.  I think I have the models and migrations done successfully (at least it's working in the shell) but I can't get the admin to work.  I'm finding the documentation a little fuzzy but I think I've followed it correctly.nnclass LibraryItemAdmin(PolymorphicParentModelAdmin):n    base_model = LibraryItemn    child_models = (Whitepaper)nnnclass LibraryItemChildAdmin(PolymorphicChildModelAdmin):n    base_model = LibraryItemnnnclass WhitepaperAdmin(LibraryItemChildAdmin):n    form = LibraryFormn    base_model = WhitepapernnnI don't understand the issue:nnTraceback:nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/handlers/base.py"" in get_responsen  108.                 response = middleware_method(request)nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/middleware/common.py"" in process_requestn  74.             if (not urlresolvers.is_valid_path(request.path_info urlconf) andnFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/urlresolvers.py"" in is_valid_pathn  646.         resolve(path urlconf)nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/urlresolvers.py"" in resolven  521.     return get_resolver(urlconf).resolve(path)nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/urlresolvers.py"" in resolven  365.             for pattern in self.url_patterns:nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/urlresolvers.py"" in url_patternsn  401.         patterns = getattr(self.urlconf_module ""urlpatterns"" self.urlconf_module)nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/core/urlresolvers.py"" in urlconf_modulen  395.             self._urlconf_module = import_module(self.urlconf_name)nFile ""/usr/lib/python2.7/importlib/__init__.py"" in import_modulen  37.     __import__(name)nFile ""/srv/www/urls.py"" in <module>n  349.     url(r'^admin/' include(admin.site.urls) name='admin')nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/contrib/admin/sites.py"" in urlsn  291.         return self.get_urls() 'admin' self.namenFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/contrib/admin/sites.py"" in get_urlsn  275.                 url(r'^%s/%s/' % (model._meta.app_label model._meta.model_name) include(model_admin.urls))nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/django/contrib/admin/options.py"" in urlsn  631.         return self.get_urls()nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/polymorphic/admin/parentadmin.py"" in get_urlsn  283.         self._lazy_setup()nFile ""/root/.virtualenvs/divesite/local/lib/python2.7/site-packages/polymorphic/admin/parentadmin.py"" in _lazy_setupn  92.         self._compat_mode = len(child_models) and isinstance(child_models0 (list tuple))nnException Type: TypeError at /admin/librarynException Value: object of type 'PolymorphicModelBase' has no len()nn' 'Documentation is out of date.  Bad docs.  Bad.nnchild_models should be an iterable of (Model ModelAdmin) tuples.nnhttps://github.com/django-polymorphic/django-polymorphic/issues/227n'",['django'],['django']
40094938,"'Numpy: how I can determine if all elements of numpy array are equal to a number' 'I need to know if all the elements of an array of numpy are equal to a numbernnIt would be like:nnnumbers = np.zeros(5) # array00000nprint numbers.allEqual(0) # return True because all elements are 0nnnI can make an algorithm but there is some method implemented in numpy library?n' ""You can break that down into np.all() which takes a boolean array and checks it's all True and an equality comparison:nnnp.all(numbers == 0)n# or equivalentlyn(numbers == 0).all()nn""",['numpy'],['numpy']
40095125,'calculate consecutive stepwise differences from multiple numpy arrays' 'does anyone know how to calculate consecutive stepwise differences fromnmultiple numpy arrays. More precise I would like to sum up differencen1 2 and 3 and then sum up difference 2 3 and 4 and so on. Finally thenhighest difference sum should be stored in diff_sum. Below you find my test ndata and my code. I hope you understand what I would like to do otherwise please contact me and I try to explain my problem in a better way.nn#import modulesnimport numpy as npn#define the test datan#initialise numpy test arraysnsh_20121001 = np.array(0.0) #day 1nnsh_20121002 = np.array(0.2) #day 2nnsh_20121003 = np.array(0.4) #day 3nnsh_20121004 = np.array(0.6) #day 4nnsh_20121005 = np.array(0.2) #day 5nnsh_20121006 = np.array(0.0) #day 6nnsh_20121007 = np.array(0.0) #day 7n#initialise a listnfilelist =        n#append the numpy array into a filelistnfilelist0.append(sh_20121001)nfilelist1.append(sh_20121002)nfilelist2.append(sh_20121003)nfilelist3.append(sh_20121004)nfilelist4.append(sh_20121005)nfilelist5.append(sh_20121006)nfilelist6.append(sh_20121007)nn#intitialse an array to store the value from the day beforenvalue_day_before = np.zeros(1) n#initialise an arrays for diff 1ndiff1 = np.zeros(1)n#initialise an array for diff 2ndiff2 = np.zeros(1)n#initilise an array fore diff 3ndiff3 = np.zeros(1)n#initialise an array to store consecutive sum of three differencesndiff_sum = np.zeros(1)n#define counterncounter = 0n#start while loopnfor i in range(7):n    #read values from filelistn    value = filelisti0n    if counter == 0:n        #calc difference 1n        diff10 = value0 - value_day_before0n    if counter == 1:n        #calc difference 2n        diff20 = value0 - value_day_before0n    if counter == 2:n        #calc difference 3n        diff30 = value0 - value_day_before0n    #sum the first three differencesn    diff_sum = diff1 + diff2 + diff3n    #store the current valuen    value_day_before = valuen    #raise countern    counter += 1n#END CODEn#my result should be the maximum sum of all consecutive calculated differences sums and thus n#my result should be:n#diff_sumn#array( 0.6)nn' nan,['numpy'],['numpy']
40095136,"'Time Indexing issue' 'I have the following code  nnimport datetimen#import numpy as npnimport jacks_toolbox.getHistoricalData as dtnnn# ------------------------------------------------------------------------------n# Confign# ------------------------------------------------------------------------------nrolling_time = 15nnum_days = 20nnStart = ""2016-09-27 00:00:00""nEnd = ""2016-10-14 23:00:00""nnsettleTimeStr = ""2016-10-14 14:00:00""nn# ------------------------------------------------------------------------------n# Start executionn# ------------------------------------------------------------------------------n# Get a window of data from MySQL and plot itnstartTime  = datetime.datetime.strptime(Start ""%Y-%m-%d %H:%M:%S"")nendTime    = datetime.datetime.strptime(End ""%Y-%m-%d %H:%M:%S"")nsettleTime = datetime.datetime.strptime(settleTimeStr ""%Y-%m-%d %H:%M:%S"")nnprint ""Start time: "" + startTime.strftime(""%Y-%m-%d %H:%M:%S"")nprint ""End time: "" + endTime.strftime(""%Y-%m-%d %H:%M:%S"")nprint ""Settle time: "" + settleTime.strftime(""%Y-%m-%d %H:%M:%S"")nndata = dt.getHistoricalDataByTime(startTime endTime 5)nsettles = dt.getHistoricalDataByTime(startTime settleTime 5)nnprint settles::1425nnnI am trying to index it so that it prints the thetime every 24 hours from my starting time but currently it is printing the following:nnStart time: 2016-09-27 00:00:00nEnd time: 2016-10-14 23:00:00nSettle time: 2016-10-14 14:00:00nInst                     7_year        UBZ6n2016-09-27 00:00:00   99.735491  183.839583n2016-09-28 00:00:00   99.906250  185.593750n2016-09-29 00:00:00   99.714375  184.936422n2016-09-30 00:00:00  100.012908  186.308594n2016-10-03 00:00:00   99.596467  184.013021n2016-10-04 00:00:00   99.450893  183.697917n2016-10-05 00:01:00   99.109375  181.457386n2016-10-06 00:01:00   98.953804  180.645833n2016-10-07 00:01:00   98.761837  180.049107n2016-10-10 00:01:00         NaN  179.682292n2016-10-11 00:31:00   98.584375  178.619318n2016-10-12 00:31:00   98.501563  178.125000n2016-10-13 00:31:00   98.799342  179.251042n2016-10-14 00:31:00   98.687500  178.328125nnnFor some reason this is adding one minute then 30 minutes to the times I am trying to index it on and I am not sure why this is. Initially I started with 1440 since that is 24*60 but noticed that it was off by 15 minutes for the first group of times so I then switched to 1425 and this is what I got. Any help/advice would be appreciated. n' nan",['python-2.7'],['python-2.7']
40095306,"'Python regular expression search text file count substring' 'I am attempting to use a regular expression statement in python to search a text file and count the number of times a user defined word appears. When I run my code though instead of getting a sum of the number of times that unique word appears in the file I am getting a count for the number lines within that file contain that word.nnExample: the word 'apple' exists 56 times in the text file. Appearing in 20 of the total 63 lines of text. When I run my code the console prints '20' for the count of 'apple' instead of the correct '56'. nnI thought by using the re.findall() method it would fix this but it has not.nnimport renn#If user selects Regular Expressions as their search methodnelif user_search_method == ""2"":n    print ""n>>> You selected the Regular Expressions search method""n    f = open(filename 'r')n    words = sum(1 for w in f if re.findall(user_search_value w re.M|re.I))n    f.close()n    print(""Your search value of '%s' appears %s times in this file"" % (user_search_value words))nn' ""You're just adding 1 if it matches I guess you don't want the search to go over lines so you can do this:nnwords = sum(len(re.findall(user_search_value w re.M|re.I)) for w in f)nn""",['regex'],['regex']
40095325,"'Covariance matrix from np.polyfit() has negative diagonal?' 'Problem: the cov=True option of np.polyfit() produces a diagonal with non-sensical negative values.nnUPDATE: after playing with this some more I am really starting to suspect a bug in numpy? Is that possible? Deleting any pair of 13 values from the dataset will fix the problem.nnI am using np.polyfit() to calculate the slope and intercept coefficients of a dataset. A plot of the values produces a very linear (but not perfectly) linear graph. I am attempting to get the standard deviation on these coefficients with np.sqrt(np.diag(cov)); however this throws an error because the diagonal contains negative values. nnIt should be mathematically impossible to produce a covariate matrix with a negative diagonal--what is numpy doing wrong?nnHere is a snippet that reproduces the problem:nnimport numpy as npnnx = 1476728821.797 1476728821.904 1476728821.911 1476728821.920 1476728822.031 1476728822.039n     1476728822.047 1476728822.153 1476728822.162 1476728822.171 1476728822.280 1476728822.289n     1476728822.297 1476728822.407 1476728822.416 1476728822.423 1476728822.530 1476728822.539n     1476728822.547 1476728822.657 1476728822.666 1476728822.674 1476728822.759 1476728822.788n     1476728822.797 1476728822.805 1476728822.915 1476728822.923 1476728822.931 1476728823.038n     1476728823.047 1476728823.054 1476728823.165 1476728823.175 1476728823.182 1476728823.292n     1476728823.300 1476728823.308 1476728823.415 1476728823.424 1476728823.432 1476728823.551n     1476728823.559 1476728823.567 1476728823.678 1476728823.689 1476728823.697 1476728823.808n     1476728823.828 1476728823.837 1476728823.947 1476728823.956 1476728823.964 1476728824.074n     1476728824.083 1476728824.091 1476728824.201 1476728824.209 1476728824.217 1476728824.324n     1476728824.333 1476728824.341 1476728824.451 1476728824.460 1476728824.468 1476728824.579n     1476728824.590 1476728824.598 1476728824.721 1476728824.730 1476728824.788nny = 6309927 6310105 6310116 6310125 6310299 6310317 6310326 6310501 6310513 6310523 6310688n     6310703 6310712 6310875 6310891 6310900 6311058 6311069 6311079 6311243 6311261 6311272n     6311414 6311463 6311479 6311490 6311665 6311683 6311692 6311857 6311867 6311877 6312037n     6312054 6312065 6312230 6312248 6312257 6312430 6312442 6312455 6312646 6312665 6312675n     6312860 6312879 6312894 6313071 6313103 6313117 6313287 6313304 6313315 6313489 6313505n     6313518 6313675 6313692 6313701 6313875 6313888 6313898 6314076 6314093 6314104 6314285n     6314306 6314321 6314526 6314541 6314638nnz cov = np.polyfit(np.asarray(x) np.asarray(y) 1 cov=True)nnstd = np.sqrt(np.diag(cov))nnprint znprint covnprint stdnn' ""It looks like it's related to your x values: they have a total range of about 3 with an offset of about 1.5 billion.nnIn your codennnp.asarray(x)nnnconverts the x values in a ndarray of float64. While this is fine to correctly represent the x values themselves it might not be enough to carry on the required computations to get the covariance matrix.nnnp.asarray(x dtype=np.float128)nnnwould solve the problem but polyfit can't work with float128 :(nnTypeError: array type float128 is unsupported in linalgnnnAs a workaround you can subtract the offset from x and then using polyfit. This produces a covariance matrix with positive diagonal:nnx1 = x - np.mean(x)nz1 cov1 = np.polyfit(np.asarray(x1) np.asarray(y) 1 cov=True)nstd1 = np.sqrt(np.diag(cov1))nnprint z1    # prints: array(  1.56607841e+03   6.31224162e+06)nprint cov1  # prints: array(  4.56066546e+00  -2.90980285e-07n            #                 -2.90980285e-07   3.36480951e+00)nprint std1  # prints: array( 2.13557146  1.83434171)nnnYou'll have to rescale the results accordingly.n""","['python-2.7', 'numpy']",['numpy']
40095362,"'graphene django relay: Relay transform error' 'Being very new to GraphQL I have a graphene django implementation of a server with two models following rather closely the graphene docs' example.nnIn graphiql I can do this and get a result back.nnnnFollowing another relay tutorial I'm intending to render the result of this query on screen.nnMy attempt looks like this:nnclass Note extends Component {n  render() {n    return(n      <div> {this.props.store.title} </div>n    )n  }n}nnNote = Relay.createContainer(Note {n  fragments: {n    store: () => Relay.QL`n      fragment on Query {n        note(id: ""Tm90ZU5vZGU6MQ=="") {n          idn          titlen        }n      }n    `n  }n});nnclass NoteRoute extends Relay.Route {n  static routeName = 'NoteRoute';n  static queries = {n    store: Component => {nn      return Relay.QL`n      query {n        ${Component.getFragment('store')}n      }n    `}n  };n}nnnMy browser's console shows the following error:nnUncaught Error: Relay transform error ``There are 0 fields supplied to the query named `Index` but queries must have exactly one field.`` in file `/Users/.../src/index.js`. Try updating your GraphQL schema if an argument/field/type was recently added.nnnI've been trying to figure it out on my own with limited success.nnCan someone point me in the right direction?n' ""Thanks @stubailo for pointing me in the right direction. I made some adjustments and now have a minimum example running like this:nnNoteList = Relay.createContainer(NoteList {n  fragments: {n    store: () => Relay.QL`n      fragment N on NoteNodeConnection {n        edges {n          node{n            idn            titlen            noten          }n        }n      }n    `n  }n});nnclass NoteRoute extends Relay.Route {n  static routeName = 'NoteRoute';n  static queries = {n    store: Component => {nn      return Relay.QL`n      query {n        notes {n          ${Component.getFragment('store')}n        }n      }n    `}n  };n}nn""",['django'],['django']
40095460,"'How to add custom search_field Django admin' ""I want to create a new search field box with my on filters and add to the django admin:nnadmin.pynn  from django.contrib import adminnfrom .models import Aluno Datanfrom .relatorio import salvarRelatorionnnnclass AdminAluno(admin.ModelAdmin):n    list_editable = 'is_active'n    list_display = 'first_name' 'matricula' 'is_active''cpf' 'cargo' 'date_joined''image_tag' ##mostra esses camposn    search_fields = 'first_name' 'matricula' ## campos q pesquisen    exclude = 'password'nnclass AdminData(admin.ModelAdmin):n    list_display = 'aluno__first_name''data_entrada' 'hora_entrada' 'hora_saida' 'descricao' ##mostra esses camposn    search_fields = 'aluno__first_name' 'matricula' 'data_entrada' ## campos q pesquisen    actions = salvarRelatorionnnadmin.site.register(Aluno AdminAluno)nadmin.site.register(Data AdminData)nnnI want to create a extra search field to filter with data_entrada__gte and data_entrada__lte.n"" nan",['django'],['django']
40095632,"'Replacing values in a column for a subset of rows' ""I have a dataframe having multiple columns. I would like to replace the value in a column called Discriminant. Now this value needs to only be replaced for a few rows whenever a condition is met in another column called ids. I tried various methods; The most common method seems to be using the .loc method but for some reason it doesn't work for me. nnHere are the variations that I am unsuccessfully trying:nnencodedid - variable used for condition checkingnnindices - variable used for subsetting the dataframe (starts from zero)nnVariation 1:nndfdf.ids == encodedid.locdf.ids==encodedid 'Discriminant'.valuesindices = 'Y'nnnVariation 2:nndfdf'ids' == encodedid.ilocindices:.set_value('questionid''Discriminant' 'Y')nnnVariation 3:nndf.locdf.ids==encodedid 'Discriminant'indices = 'Y'nnnVariation 3 particularly has been disappointing in that most posts on SO tend to say it should work but it gives me the following error:nnValueError:  0  1  2  3  5  6  7  8 10 11 12 13 14 16 17 18 19 20 21 22 23 not contained in the indexnnnAny pointers will be highly appreciated.n"" ""you are slicing too much. try something like this:nnindexer = dfdf.ids == encodedid.indexndf.locindexer 'Discriminant' = 'Y'nnn.loc needs an index list and a column list. you can set the value of that slice easily using = 'what you need'nnlooking at your problem you might want to set that for 2 columns at the same time such has:nnindexer = dfdf.ids == encodedid.indexncolumn_list = 'Discriminant' 'questionid'nndf.locindexer column_list = 'Y'nn"" ""Maybe something like this. I don't have a dataframe to test it but...  nndf'Discriminant' = np.where(df'ids' == 'some_condition' 'replace' df'Discriminant')nn""",['pandas'],['pandas']
40095686,"'Multi-dimensional outer-product in python' 'I was doing MNIST dataset and trying to get a outer product of my two vectors w_i(ith class) and a_k(kth sample).nnThe w_i for i = 0...9 has 784 coordinates.nnThe a_k for k = 1...n also has 784 coordinates.nnI created two arrays w_ij and a_ij which contain all ten classes and k samples. The shape of w_ij is (10 784) and a_ij is (n 784).nnI was trying to get a result something like:nnw_0 dot a_1 w_0 dot a_2 ...  w_0 dot a_n # (first row)nw_1 dot a_1 w_1 dot a_2 ... w_1 dot a_n # (second row)n...nw_9 dot a_1 ... w_9 dot a_n # (nth row)nnnSo the shape of array should be like (10 n). I tried to use scipy.outer(w_ij a_k) or scipy.multiply.outer(w_ij a_k). However it led me to a result whose shape is (7840 784*n). Could someone direct me to the right path?n' ""It looks like you want the following:nnres = np.einsum('piqi->pq' w a)nnnWhich is shorthand for the following in index notation:nnrespq = wpi*aqinnnIn this notation the convention is to sum over all indices which do not appear in the outputnnnnHowever note that ijjk->ik is just the standard matrix product and ij->ji is just the matrix transpose. So we can simplify this as followsnnnp.einsum('piqi->pq' w a)   # as beforennp.einsum('piiq->pq' w a.T) # transpose and swapping indices cancel outnnp.einsum('ijjk->ik' w a.T) # index names don't matternw @ a.T                        # wait a sec this is just matrix multiplication (python 3.5+)nn""",['numpy'],['numpy']
40095712,"'When to apply(pd.to_numeric) and when to astype(np.float64) in python?' 'I have a pandas DataFrame object named xiv which has a column of int64 Volume measurements.  nnIn: xiv'Volume'.head(5)nOut: nn0    252000n1    484000n2     62000n3    168000n4    232000nName: Volume dtype: int64nnnI have read other posts (like this and this) that suggest the following solutions.  But when I use either approach it doesn't appear to change the dtype of the underlying data:nnIn: xiv'Volume' = pd.to_numeric(xiv'Volume')nnIn: xiv'Volume'.dtypesnOut: ndtype('int64')nnnOr...nnIn: xiv'Volume' = pd.to_numeric(xiv'Volume')nOut: ###omitted for brevity###nnIn: xiv'Volume'.dtypesnOut: ndtype('int64')nnIn: xiv'Volume' = xiv'Volume'.apply(pd.to_numeric)nnIn: xiv'Volume'.dtypesnOut: ndtype('int64')nnnI've also tried making a separate pandas Series and using the methods listed above on that Series and reassigning to the x'Volume' obect which is a pandas.core.series.Series object.nnI have however found a solution to this problem using the numpy package's float64 type - this works but I don't know why it's different.nnIn: xiv'Volume' = xiv'Volume'.astype(np.float64)nnIn: xiv'Volume'.dtypesnOut: ndtype('float64') nnnCan someone explain how to accomplish with the pandas library what the numpy library seems to do easily with its float64 class; that is convert the column in the xiv DataFrame to a float64 in place.n' 'If you already have numeric dtypes (int8|16|32|64float64boolean) you can convert it to another ""numeric"" dtype using Pandas .astype() method.nnDemo:nnIn 90: df = pd.DataFrame(np.random.randint(10**510**7(53))columns=list('abc') dtype=np.int64)nnIn 91: dfnOut91:n         a        b        cn0  9059440  9590567  2076918n1  5861102  4566089  1947323n2  6636568   162770  2487991n3  6794572  5236903  5628779n4   470121  4044395  4546794nnIn 92: df.dtypesnOut92:na    int64nb    int64nc    int64ndtype: objectnnIn 93: df'a' = df'a'.astype(float)nnIn 94: df.dtypesnOut94:na    float64nb      int64nc      int64ndtype: objectnnnIt won't work for object (string) dtypes that can't be converted to numbers:nnIn 95: df.ix1 'b' = 'XXXXXX'nnIn 96: dfnOut96:n           a        b        cn0  9059440.0  9590567  2076918n1  5861102.0   XXXXXX  1947323n2  6636568.0   162770  2487991n3  6794572.0  5236903  5628779n4   470121.0  4044395  4546794nnIn 97: df.dtypesnOut97:na    float64nb     objectnc      int64ndtype: objectnnIn 98: df'b'.astype(float)n...nskippedn...nValueError: could not convert string to float: 'XXXXXX'nnnSo here we want to use pd.to_numeric() method:nnIn 99: df.b = pd.to_numeric(df'b' errors='coerse')nnIn 100: dfnOut100:n           a          b        cn0  9059440.0  9590567.0  2076918n1  5861102.0        NaN  1947323n2  6636568.0   162770.0  2487991n3  6794572.0  5236903.0  5628779n4   470121.0  4044395.0  4546794nnIn 101: df.dtypesnOut101:na    float64nb    float64nc      int64ndtype: objectnn'","['pandas', 'numpy']",['pandas']
40095906,"'Pandas concat : Incorrect total length after dataframes are concatenated' 'I am trying to concatenate 2 dataframes. nn'data' df looks like below (length = 6260):nntailnn                           bs     forecastn2016-09-25 17:15:00  2.371138     NaNn2016-09-25 17:20:00  2.611324     NaNn2016-09-25 17:25:00  2.503655     NaNn2016-09-25 17:30:00  2.439995     NaNn2016-09-25 17:35:00  3.140531     NaNnnn'future' df looks like below (length = 289):nnheadnn                      bs     forecastn2016-09-25 23:55:00  NaN      NaNn2016-09-26 00:00:00  NaN      NaNn2016-09-26 00:05:00  NaN      NaNn2016-09-26 00:10:00  NaN      NaNn2016-09-26 00:15:00  NaN      NaNnntailnn                      bs     forecast n2016-09-26 23:35:00  NaN     NaN n2016-09-26 23:40:00  NaN     NaNn2016-09-26 23:45:00  NaN     NaNn2016-09-26 23:50:00  NaN     NaNn2016-09-26 23:55:00  NaN     NaNnnnThen I concatenated  both dfs like so:nndata = pd.concat(data future)nnnThe results came out as I wanted:nn                           bs     forecastn2016-09-25 17:35:00  3.140531     NaNn2016-09-25 23:55:00  NaN          NaNn2016-09-26 00:00:00  NaN          NaNn2016-09-26 00:05:00  NaN          NaNn2016-09-26 00:10:00  NaN          NaNn2016-09-26 00:15:00  NaN          NaNnnnHowever when I checked the length of ""data"" it is 6518 instead of 6549 (6260+289).nnIs it suppose to work like this? or did I do something wrong?nnWhat happened to the rest of the 31 rows ? (6549 - 6518)n' nan",['pandas'],['pandas']
40096005,"'Generating random numbers as the value of dictionary in python' ""Could you please tell me how can I generate a dictionary with 100 rows that have random number between 0 and 1 in each row as the value? For example in data frame I can have:nn   df'Rand' = random.sample(random.random() 100)nnnBut I don't know how to do that for a dictionary.n"" 'Firstly it should be list and not dict. Check: In Python when to use a Dictionary List or Set?nnIn order to get the list of values you may use list comprehension as: nn>>> import randomn>>> row_count = 10n>>> my_list = random.random() for i in range(row_count)n# Value of 'my_list':n# 0.9158936600374181 0.8998648755500501 0.07002867165493243 0.6694284854833131 0.4903966580363698 0.9462143737260301 0.8014661448602305 0.47964245438139297 0.42326131297319725 0.77540761767324nnnIn order to fetch 5th item (i.e. 4th index):nn>>> my_list4n0.4903966580363698nn' 'I think what you want is something like:nn{k: random.random() for k in range(100)}nn'",['dictionary'],"['dictionary', 'list']"
40096059,"'pandas subset using sliced boolean index' ""code to make test data:nnimport pandas as pdnimport numpy as npnntestdf = {'date': range(10)n      'event': 'A' 'A' np.nan 'B' 'B' 'A' 'B' np.nan 'A' 'B'n      'id': 1 * 7 + 2 * 3}ntestdf = pd.DataFrame(testdf)nnprint(testdf)nnngives nn    date event  idn0     0     A   1n1     1     A   1n2     2   NaN   1n3     3     B   1n4     4     B   1n5     5     A   1n6     6     B   1n7     7   NaN   2n8     8     A   2n9     9     B   2nnnsubset testdfnndf_sub = testdf.loctestdf.event == 'A':nprint(df_sub)n    date event  idn0     0     A   1n1     1     A   1n5     5     A   1n8     8     A   2nnn(Note: not re-indexed)nncreate conditional boolean indexnnbool_sliced_idx1 = df_sub.date < 4nbool_sliced_idx2 = (df_sub.date > 4) & (df_sub.date < 6)nnnI want to insert conditional values using this new index in original df likenndftest 'new_column' = np.nanndftest.locbool_sliced_idx1 'new_column' = 'new_conditional_value'nnnwhich obviously (now) gives error:nnpandas.core.indexing.IndexingError: Unalignable boolean Series key providednnnbool_sliced_idx1 looks likenn>>> print(bool_sliced_idx1)n0     Truen1     Truen5    Falsen8    FalsenName: date dtype: boolnnnI tried testdf.ix(bool_sliced_idx1==True).index: but that doesn't work becausenn>>> (bool_sliced_idx1==True).indexnInt64Index(0 1 5 8 dtype='int64')nn"" 'This workednnidx = np.where(bool_sliced_idx1==True)0n## or n# np.ravel(np.where(bool_sliced_idx1==True))nnidx_original = df_sub.indexidxntestdf.ilocidx_original:nn' ""IIUC you can just combine all of your conditions at once instead of trying to chain them.  For example df_sub.date < 4 is really just (testdf.event == 'A') & (testdf.date < 4).  So you could do something like:nn# Create the conditions.ncond1 = (testdf.event == 'A') & (testdf.date < 4)ncond2 = (testdf.event == 'A') & (testdf.date.between(4 6 inclusive=False))nn# Make the assignments.ntestdf.loccond1 'new_col' = 'foo'ntestdf.loccond2 'new_col' = 'bar'nnnWhich would give you:nn   date event  id new_coln0     0     A   1     foon1     1     A   1     foon2     2   NaN   1     NaNn3     3     B   1     NaNn4     4     B   1     NaNn5     5     A   1     barn6     6     B   1     NaNn7     7   NaN   2     NaNn8     8     A   2     NaNn9     9     B   2     NaNnn""",['pandas'],['pandas']
40096173,"'The positions of all vowels in the string' 'I am trying to write programs that reads a line of input as a string and print the positions of all vowels in the string.nnline = str(input(""Enter a line of text: ""))nnvowels = ('a' 'e' 'i' 'o' 'u')nposition = """"nfor i in line :n    if i.lower() in vowels :n       position += (""%d "" i)nprint(""Positions of Vowels "" + position)nnnExpected: Positions of Vowels 1345nnGives me: Positions of VowelsnnWhat can I do?n' ""If you want a list of indexes the following should work using enumerate:nn>>> text = 'hello world vowel'n>>> vowels = 'aeiou'n>>> i for i c in enumerate(text.lower()) if c in vowelsn1 4 7 13 15nnnFor your comma formatting:nn>>> ' '.join(str(i) for i c in enumerate(text.lower()) if c in vowels)n'1 4 7 13 15'nn""",['python-3.x'],"['python-2.7', 'list', 'python-3.x']"
40096197,"'Filter django admin according to polymorphic' ""Trying to get django-polymorphic to work in the admin.  I have a number of ChildModels inheriting from BaseModel but clicking on any of them in the Django admin all lead to a listing of all BaseModel objects which is useless to me.  I've tried both redefining the queryset and including the list_filter as the documentation (outdated I've learned) suggests but neither seems to have any effect.nnclass BaseModelChildAdmin(PolymorphicChildModelAdmin):nn    base_model = BaseModeln    show_in_index = Falsen    form = BaseModelFormnnnclass ChildModelAdmin(BaseModelChildAdmin):n    exclude = ('asset_url' 'asset_file')n    base_model = ChildModeln    show_in_index = Truenn    def queryset(self request):n        qs = ChildModel.objects.all()n        return qsnnclass BaseModelAdmin(PolymorphicParentModelAdmin):n    base_model = BaseModeln    child_models = (ChildModel ChildModelAdmin)nn    list_filter = (PolymorphicChildModelFilter)nn"" nan",['django'],['django']
40096278,"'Creating histograms in pandas with columns with equidistant base not proportional to the range' 'I am creating an histogram in pandas simply using:nntrain_data.hist(""MY_VARIABLE"" bins=05 1050100500100050001000050000100000)nnn(train_data is a pandas df).nnThe problem is that since the range 50000100000 is so large I can barely see the small ranges 05 or 510 etc. I would like the histogram to have equidistant bars on the x-axis not proportional to the range. Is this possible?n' 'You can do it this way:nnbins = 0 5 1050100500100050001000050000100000ndf.groupby(pd.cut(df.a bins=bins labels=bins1:)).size().plot.bar(rot=0)nnnDemo:nndf = pd.DataFrame(np.random.randint(010**5(10**42))columns=list('ab'))nbins = 0 5 1050100500100050001000050000100000ndf.groupby(pd.cut(df.a bins=bins labels=bins1:)).size().plot.bar(rot=0)nnnnnfiltering results:nnthreshold = 100n(df.groupby(pd.cut(df.an                   bins=bins n                   labels=bins1:))n   .size()n   .to_frame('count')n   .query('count > @threshold')n)nnOut84:n        countnan5000      396n10000     492n50000    4044n100000   4961nnnplotting filtered:nn(df.groupby(pd.cut(df.an                   bins=bins n                   labels=bins1:))n   .size()n   .to_frame('count')n   .query('count > @threshold')n   .plot.bar(rot=0 width=1.0)n)nnnn'",['pandas'],['pandas']
40096323,"'Lambda function does not return correct value' 'Im trying to make a variant of the Gillespie algorithm and to determine the reaction propensities Im trying to automatically generate the propensity vector using lambda expressions. However when creating SSA.P all goes wrong. The last loop in the block of code PROPLOOP returns two propensities where the one generated using P_alternative is the correct one. The question is: how do I get the same values for SSA.P as for SSA.P_alternative?nnimport numpy as npnfrom numpy.random import uniformnclass Markov:n  def __init__(selfz0t0tfratesstoich):n    self.S=stoichnn    self.z0=z0n    self.rates=ratesnn    self.P=self.propensities()n    self.P_alternative=n      lambda zrate:(0.5*rate0*z0*(z0-1))n      lambda zrate:rate1*np.prod(z0)n      lambda zrate:rate2*np.prod(z1)n      lambda zrate:rate3*np.prod(z1)n      lambda zrate:rate4*np.prod(znp.array(01))n      lambda zrate:rate5nn    self.t0=t0n    self.tf=tfnnn  def propensities(self):n    prop=n    for ireac in enumerate(self.S.T):n      if all(z>=0 for z in reac):n        prop.append(lambda zrate:ratei)nn      if any(z==-1 for z in reac):n        j=np.where(reac==-1)0n        prop.append(lambda zrate:ratei*np.prod(zj))nn      if any(z==-2 for z in reac):n        j=np.where(reac==-2)00n        prop.append(lambda zrate:(0.5*ratei*zj*(zj-1))0)nn    return propnnnstoich=np.array(n        -2 -1  2  0 -1  0n         1  0 -1 -1 -1  1n         0  0  0  1  1  0)nnrates=np.array(1.00.02200.00.00040.90.9)nnz0=np.array(5407300)nnSSA=Markov(z0=z0t0=0tf=100rates=ratesstoich=stoich)nn#PROPLOOP; the values should be equal for both SSA.P and SSA.P_alternative where SSA.P_alternative is the correct onenfor i in xrange(len(SSA.P)):n  print ""Inexplicably wrong""SSA.Pi(z0rates)n  print ""Correct answer""SSA.P_alternativei(z0rates) ""n""nnnoutput is:nnInexplicably wrong 130977.0nCorrect answer 145530.0 nnInexplicably wrong 354780.0nCorrect answer 10.8 nnInexplicably wrong 354780.0nCorrect answer 146000.0 nnInexplicably wrong 354780.0nCorrect answer 0.292 nnCorrect answer 354780.0nCorrect answer 354780.0 nnInexplicably wrong 0.9nCorrect answer 0.9 nn' ""The issue is that you're creating your lambda functions in a loop and they refer to the variables i and j that may change as the loop goes on.nnThe lambda doesn't copy the values of i or j when it is created it just keeps a reference to the namespace that they are defined in. When it uses the variables when it is called later it looks them up in that namespace. Since your lambdas get called after the loop (and indeed the whole function) has ended they all see the final values the variables were given which is not what you intended. This explains why the two versions of your code give the same output on the last iteration. The final value of i and j is the expected one for the last lambda function.nnYou can work around this issue by making the lambda keep a copy of the current value of i and j when it is defined. The easiest way to do this is with a default argument:nnfor ireac in enumerate(self.S.T):n  if all(z>=0 for z in reac):n    prop.append(lambda z rate i=i: ratei) # add i=i here and further downnn  if any(z==-1 for z in reac):n    j=np.where(reac==-1)0n    prop.append(lambda z rate i=i j=j: ratei*np.prod(zj))nn  if any(z==-2 for z in reac):n    j=np.where(reac==-2)00n    prop.append(lambda z rate i=i j=j: (0.5*ratei*zj*(zj-1))0)nnnThe i=i (and j=j where necessary) in the lambda definitions makes the variables arguments of the lambda function with a default value that is the current value of i (and j) in the outer namespace. Since you only pass two arguments when you call the lambda function the saved default values will be used.n""",['numpy'],['numpy']
40096516,"'Django general and app templates' 'I want to customize my Django project I will have a dashboard app and a home site app (you can enter from this home site to the dashboard with a URL).nI want to save a template for the HTML and css so both apps can use them.nnI followed this tutorial on django official site but I think I missed a setup because. This is the error: Not Found: /css/style.css. nnAt this point my django project is structured this way I think that I will add another app (module) to serve the home page:nnmysite/n    manage.pyn    mysite/n        __init__.pyn        settings.pyn        urls.pyn        wsgi.pyn    dashboard/n        __init__.pyn        admin.pyn        migrations/n            __init__.pyn            0001_initial.pyn        models.pyn        static/n        templates/n            polls/n                index.htmln        tests.pyn        urls.pyn        views.pyn    templates/n        css/n            style.cssnnnAnd my settings.py is like this:nnTEMPLATES = n    {n        'BACKEND': 'django.template.backends.django.DjangoTemplates'n        'DIRS': os.path.join(BASE_DIR 'mysite/templates/') os.path.join(BASE_DIR 'templates')n        'APP_DIRS': Truen        'OPTIONS': {n            'context_processors': n                'django.template.context_processors.debug'n                'django.template.context_processors.request'n                'django.contrib.auth.context_processors.auth'n                'django.contrib.messages.context_processors.messages'n            n        }n    }nnn' 'I found a way to do this. The problem isn't with the templates settings the problem is with the staticfiles_dir.nnSTATICFILES_DIRS = n    os.path.join(BASE_DIR ""static"")n    'var/css/style.css'nnnnIt is important to remark that the templates should have <link rel=""stylesheet"" href={% static 'css/style.css' %}>nnI also loaded HTML files that are general templates for various apps.n'",['django'],['django']
40096612,"'How do I open a text file in Python?' 'Currently I am trying to open a text file called ""temperature.txt"" i have saved on my desktop using file handler however for some reason i cannot get it to work. Could anyone tell me what im doing wrong.nn#!/Python34/pythonnfrom math import *nnfh = open('temperature.txt')nnnum_list = nnfor num in  fh:n    num_list.append(int(num))nnfh.close()nn' ""You simply need to use .readlines() on fhnnlike this:nn#!/Python34/pythonnfrom math import *nnfh = open('temperature.txt')nnnum_list = nnread_lines = fh.readlines()nfor line in read_lines:n    num_list.append(int(line))nnfh.close()nn"" ""The pythonic way to do this is nn#!/Python34/pythonnfrom math import *nnnum_list = nnwith open('temperature.text' 'r') as fh:n    for line in fh:n        num_list.append(int(line))nnnYou don't need to use close here because the 'with' statement handles that automatically.nnIf you are comfortable with List comprehensions - this is another method : nn#!/Python34/pythonnfrom math import *nnwith open('temperature.text' 'r') as fh:n    num_list = int(line) for line in fhnnnIn both cases 'temperature.text' must be in your current directory and I have left the math module import although neither piece of code needs itn""",['python-3.x'],"['list', 'python-2.7']"
40096730,"'nose not running all tests' ""So for this function I have a json file with list of files  which are testsnndef wantFunction(self function):n    test = '.'.join(function.__module__ function.__name__)n    if test in self.ctrl.keys():n            for in evidence.values():n                if os.environ'ENNVAR' in controls:n                    return Truen    return FalsennnThis takes the input from a json file (contains the list of tests) but once it detects a test which returns True the wantFunction does not go through the other tests present in the json file (list). Could someone tell why it is happening?n"" nan",['python-2.7'],"['python-2.7', 'list']"
40096826,"'Ranking python dictionary by percentile' ""If i have a dictionary that records the count frequency of random objects:nndict = {'oranges': 4  'apple': 3  'banana': 3  'pear' :1 'strawberry' : 1....}nnnAnd I want only the keys that are in the top 25th percentile by frequency how would i do that ? Especially if it's a very long tail list and a lot of records will have the same count. n"" 'Use a collections.Counter object and exploit its most_common method to return the keys with the highest frequency up to the required percentile.nnFor the 25th percentile divide the length of the dictionary by 4 and pass that value to most_common:nn>>> from collections import Countern>>> dct = {'oranges': 4  'apple': 3  'banana': 3  'pear' :1 'strawberry' : 1}n>>> c = Counter(dct)n>>> tup0 for tup in c.most_common(len(dct)//4)n'oranges'nnnNote that potential elements in that percentile with equal frequencies will be selected arbitrarily.n'","['numpy', 'dictionary']","['dictionary', 'list']"
40097024,"'What is the most efficient way to compare every value of 2 numpy matrices?' 'I'd like to more efficiently take every value of 2 matrices(a and b) of the same size and return a third boolean(or 1/ 0 matrix to make things clean) into matrixc containing the results of the conditions.nnExample:nnCondition: For a == 0 and b == 3nna = 1 0n    0 1 nnb = 3 5n    3 9 nnnWould return:nnc = 0 0n    1 0nnn01 is the only place where a == 0 and b == 3 so it is the only place True in c nnThis is the code I have so far:nnimport numpy as npnna = np.matrix(""1 0; 0 1"")nprint(a'n')nb = np.matrix(""3 5; 3 9"")nprint(b'n')nnc = nfor x in range(0np.shape(a)1):n    row = n    for y in range(0np.shape(a)1):n        row.append(int(axy == 0 and bxy == 3)) # the int() is there just to keep things tighty for the 3 prints n    c.append(row)nc = np.matrix(c)nprint(c)nnnresults:nn1 0n 0 1 nn3 5n 3 9 nn0 0n 1 0nnnI could also use:nna=a==0nb=b==3nc=a&bnnnBut that would require making a copy of a and b and with big matrices would that still be efficient ?nnWhy can't I just use a == 0 & b == 3 ?nnI need to do a comparison like this for several matrices that are 1000+ size so you could see where iterating thought them would be quite slow.nnThank you very much for any help I'm sure the answer is something simple and right in front of me but I'm just dumb.n' 'You can use (pretty) much the expression that you wanted:nn>>> (a == 0) & (b == 3)nmatrix(False Falsen         True False dtype=bool)nnnBeware you need the parenthesis to make the precendence work out as you'd like -- Normally & will bind tighter than ==.  If you don't like the extra parenthesis you can use the more verbose (though arguably more semantically correct) np.logical_and function.nnAlso note that while no copies are being made there are temporary arrays being created.  Specifically the result of a == 0 and b == 3 are both going to be allocated and freed in this statement.  Generally that's not such a big deal and numpy's vectorized operations remain fast.  However if that isn't fast enough for you you can use a library like numexpr to remove the temporary arrays:nn>>> numexpr.evaluate('(a == 0) & (b == 3)')narray(False Falsen        True False dtype=bool)nnnAnd of course if you need 1 and 0 you can use result.astype(int) on the output array to make arrays of ints rather than booleans.n'","['python-3.x', 'numpy']",['numpy']
40097086,"'Plotting asymmetric error bars Matplotlib' 'So I have three sets of data:nnmin_data = np.array( 0.317 0.312 0.305 0.296 0.281 0.264 0.255 n0.237 0.222 0.203 0.186 0.17 0.155 0.113 0.08)nnavg_data = np.array( 0.3325 0.3235 0.3135 0.30216667 0.2905 0.27433333 n0.26116667 0.24416667 0.22833333 0.20966667 0.19366667 0.177 n0.16316667 0.14016667 0.097)nnmax_data = np.array( 0.346 0.331 0.32 0.31 0.299 0.282 0.266 0.25 n0.234 0.218 0.204 0.187 0.175 0.162 0.115)nnnI need to plot this data with error bars. nnI have attempted:nnx = np.linspace(0 100 15)nerr = min_data max_datanplt.errorbar(x avg_data 'bo' yerr=err)nnTypeError: errorbar() got multiple values for argument 'yerr'nnnThe final graph should look like this:nnplt.plot(x::-1 avg_data 'ro')nplt.plot(x::-1 min_data 'bo')nplt.plot(x::-1 max_data 'bo')nnnnnWhere the blue points represent where the error bars should be located.nnAll the documentation I have been able to find only allows asymmetric errors that is equal in + and - y directions.nnThank youn' ""Your code is failing because it thinks that 'bo' is the yerr argument since the third argument in plt.errorbar is yerr.  If you want to pass the format specifier then you should use the fmt keyword.  nnplt.errorbar(x avg_data fmt='bo' yerr=err)nn""","['numpy', 'matplotlib']",['matplotlib']
40097088,"'BS4 get XML tag variables' 'I am playing around with web scraping using bs4 and trying to get the title and color tag from this line of xml <graph gid=""1"" color=""#000000"" balloon_color=""#000000"" title=""Approve"">nnThe output result would be a dict something along the lines of {'title':'approve' 'color':'#000000'}nnThe page where the xml is herennI've already written this function which is by no means efficient but would like the titles of my dataframe to be the result of the title rather than a manually inputted value. So rather than GID1 it would read Approve or Obama or whatever the result of title is. nndef rcp_poll_data(xml):n    soup=bs(xml""xml"")n    dates = soup.find('series')n    datesval = dates.findChildren(string=True)n    del datesval-7:n    obama = soup.find('graph' { ""gid"" : ""1"" })n    obamaval = obama.findChildren(string=True)n    romney = soup.find('graph' { ""gid"" : ""2"" })n    romneyval = romney.findChildren(string=True)n    result = pd.DataFrame({'date':pd.to_datetime(datesval) 'GID1':obamaval 'GID2':romneyval})n    return resultnnnI'm using bs4 and struggling to find the right terminology that would get me there. Are these tags i'm trying to isolate or elements or attributes?nnThis isn't a professional thing i'm just nurdling around for fun. So any help to get me slightly closer would be great. (i'm using python 3)n' 'You just need to pull the attributes once you find the graph node:nnimport requestsnfrom bs4 import BeautifulSoupnnsoup = BeautifulSoup(requests.get(""http://charts.realclearpolitics.com/charts/1044.xml"").content""xml"")ng = soup.find(""graph"" gid=""1"")ndata = {""title"":g""title"" ""color"": g""color""}nnnWhich will give you:nn{'color': '#000000' 'title': 'Approve'}nn'",['python-3.x'],"['pandas', 'python-2.7']"
40097194,"""Python loop through Dataframe 'Series' object has no attribute"" 'Using pandas version 0.19.0 I have a dataframe with compiled regular expressions inside.  I want to loop over the dataframe and see if any of the regular expressions match a value.  I can do it with two for loops but I can't figure out how to do it so that it'll return a same sized dataframe.nnimport pandas as pdnimport renninp = {'c1':re.compile('a') 'c2':re.compile('b')} {'c1':re.compile('c')'c2':re.compile('d')} {'c1':re.compile('e')'c2':re.compile('f')}ndf = pd.DataFrame(inp)nfor iv in df.items():n  for a in v:n    if (a.match('a')):n      print(""matched"")n    else:n      print(""failed"")nnnThis fails:nna.match('a') for a in v for iv in df.items()nnnn  AttributeError: 'Series' object has no attribute 'match'nnnWhat I want:nna.match('a') for a in v for iv in df.items()n              c1                                         c2n0   <_sre.SRE_Match object; span=(0 1) match='a'>     Nonen1   None                                                Nonen2   None                                                Nonenn' 'It looks like you need to use the applymap method. See the docs here for more info. nndf.applymap(lambda x: x.match('a'))nnnOutput:nnn'",['pandas'],"['pandas', 'regex']"
40097213,"'How do I median bin a 2D image in python?' 'I have a 2D numarray of size WIDTHxHEIGHT. I would like to bin the array by finding the median of each bin so that the resultant array is WIDTH/binsize x HEIGHT/binsize. Assume that both WIDTH and HEIGHT are divisible by binsize. nnI have found solutions where the binned array values are the sum or average of the individual elements in each bin: nHow to bin a 2D array in numpy?nnHowever if I want to do a median combine of elements in each bin I haven't been able to figure out a solution. Your help would be much appreciated!n' 'Is this what you are looking for? nnimport numpy as npna = np.arange(24).reshape(46)nndef median_binner(abin_xbin_y):n    mn = np.shape(a)n    return np.array(np.median(col) for row in a.reshape(bin_xbin_ym//bin_xn//bin_y) for col in row).reshape(bin_xbin_y)nnnnprint ""Original Matrix:""nprint anprint ""n""nbin_tester1 = median_binner(a23)nprint ""2x3 median bin :""nprint bin_tester1nprint ""n""nbin_tester2 = median_binner(a22)nprint ""2x2 median bin :""nprint bin_tester2nnnresult: nnOriginal Matrix:n 0  1  2  3  4  5n  6  7  8  9 10 11n 12 13 14 15 16 17n 18 19 20 21 22 23nnn2x3 median bin :n  1.5   5.5   9.5n  13.5  17.5  21.5nnn2x2 median bin :n  2.5   8.5n  14.5  20.5nn'",['numpy'],['numpy']
40097249,"'Prevent numpy from vectorizing multiplication' 'I created a set of little helper classes for working with degrees and radians. I have included some numpy ufuncs (radians degrees sin cos...) so that I can have deg objects inside of numpy arrays and perform numpy trig operations (e.g. np.cos(np.array(5*deg 10*deg 15*deg))) on the numpy arrays. nnHowever I have discovered that when ""multiplying"" an ndarray by the deg class on the RHS the numpy object's __mul__ method gets invoked on the array rather than UnitMeta.__rmul__ leading to raising a TypeError inside of NumberMixin.__new__ as desired. It works correctly (raises an error) when deg is the LHS e.g. deg * np.array(1). nnOnly a portion of the classes is shown below for brevity. nn'deg.py'nfrom numbers import Numbernimport numpy as npnnclass UnitMeta(type):n    def __mul__(cls other):n        return cls(other)n    def __rmul__(cls other):n        '''So can write things like ""1 * deg""'''n        return cls(other)nnclass NumberMixin():n    def __new__(cls v):n        if not isinstance(v Number):n            raise TypeError('A valid numeric type value is required. {} is not numeric.'.format(type(v)))n        return super().__new__()n    def __mul__(self other):n        return self._v * othern    def __rmul__(self other):n        return self.__mul__(other)n    def radians(self): # NOTE: overridden in deg below n        return np.radians(self._v)n    def degrees(self): # NOTE: overridden in deg below n        return np.degrees(self._v)n    def sin(self):n        return np.sin(self._v)n    def cos(self):n        return np.cos(self._v)n    def tan(self):n        return np.tan(self._v)nnclass deg(NumberMixin metaclass = UnitMeta):n    def __init__(self d = 0.0):n        if isinstance(d deg):n            self._v = d._vn            self._deg = d._degn        else:n            self._v = np.radians(d)n            self._deg = dn    def __mul__(self other):n        if isinstance(type(other)UnitMeta):n            return NotImplementedn        else:n            return super().__mul__(other)n    def __str__(self):n        return str(self._deg) + 'Â°'n    def __repr__(self):n        return str('deg({})'.format(self._deg))n    def __format__(self spec):n        return self._deg.__format__(spec) + 'Â°'n    def degrees(self):n        return selfn    def radians(self):n        return self._vnnnif __name__ == '__main__':n    try:n        print('FAILURE: ' deg * np.array(1)  ' exception not caught')n    except TypeError:n        print('SUCCESS: deg * np.array(1) exception caught.')n    try:n        print('FAILURE: ' np.array(1) * deg ' exception not caught')n    except TypeError:n        print('SUCCESS: np.array(1) * deg exception caught.')        nnnEverything else works well. nnI want to prevent numpy from doing this so that I can write things more like ""normal math"" e.g.:nn5 * degnnn...but have an exception come up and not get swallowed when something like this accidentally occurs: nna = np.array(5)na * deg <- TypeErrornnnAny suggestions? I haven't worked with numpy much as of yet so apologies if there is an obvious solution. n' nan",['numpy'],['numpy']
40097366,"'Python 3.5 dictionary comparison' ""I am trying to compare all elements of one dictionary to make sure they are in a second with the correct number. I am new at Python so I know there is something simple I am probably missing and I have been working on this one problem for hours so my code is likely very ugly and wrong. Here is an example of what I have so far.nntry:       n    for key in dict_one:n        if dict_two.get(key 0) == dict_onekey:n           del dict_onekeyn           if dict_onekey < 0 :                n              return Falsen        else:n             return Truenexcept KeyError:n   passnnnI have tried all(dict_two.get(key0)) as well and it didn't work.  The final output should check that you can spell a word from dict_two using the words in dict_one True if you can False if you can't so if dict_two word requires three Es then dict_one should have 3 Es or return false. Or two Ns if you were spelling bunny ex dict_one = {b: 1 u: 1 n:1 y:1 x: 3} and dict_two ={b: 1 u: 1. n: 2 y:1} False because you need 2 Ns in the word and dict_one only has one. nnI can get dict_two to populate correctly when I enter a word and dict_one properly pulls random numbers and amounts of those numbers. And I can get them to compare properly for letters included in each I just can't get it to produce right answer of True or False for the number of letters needed. I feel I am close to an answer but then just make it worse when I try new things and dig my hole deeper. nnThank you! n"" ""So you want to check to see that every letter in dict2 has at mapping in dict1 least as large as that letters mapping in dict2?  That's accomplished fairly easily.nndef can_spell(dict1 dict2):n    try:n        return all(dict1k >= v for k v in dict2.items())n    except KeyError:n        return FalsennnThis gets every (key value) pair in dict2 and then compares v with the mapping of that key in dict1.  all returns True iff every expression in that generator comprehension is true.n""","['python-3.x', 'dictionary']","['dictionary', 'list']"
40097372,"'Python sorting a nested list with conditional comparison' 'I am trying to sort a nested list A. len(A) = n and len(Ai) = d for all i. I would like to sort using the first element of Ai. But if Ai0 == Aj0 then I want to sort using the next element i.e. Ai1. If Ai1 == Aj1 then use the next element Ai2 and so on. nnHere is an example with n = 4 and d = 2. Because 36 and 37 have the same first element they are compared based on the second element.nnA = 37 45 3 6 51nA_sorted = 36 37 45 51nnnIn Python 2.7 I used custom comparison function. nA.sort(cmp=comp_func). But I am trying to do this in Python 3 which does not have the cmp argument option. So I need to use key argument instead. How do I implement this custom sorting in Python 3?n' ""This is the default Python sorting behavior.  Have you tried doing this and it hasn't worked?n""",['python-3.x'],"['list', 'python-2.7']"
40097674,"'""check_array ValueError: Found array with 0 sample(s)""' 'I need to setup retrieval-2016-deepvision.nnI have successfully run the following:nnndatabase (oxford)ndatabase (paris)ndata/models/fetch_models.shnread_data.pynnnBut when I run features.py I have the following error:nnTraceback (most recent call last):n  File ""features.py"" line 119 in <module>n    learn_transform(paramsfeats)n  File ""features.py"" line 23 in learn_transformn    feats = normalize(feats)n  File ""/usr/lib/python2.7/dist-packages/sklearn/preprocessing/data.py"" line 1280 in normalizen    estimator='the normalize function' dtype=FLOAT_DTYPES)n  File ""/usr/lib/python2.7/dist-packages/sklearn/utils/validation.py"" line 407 in check_arrayn    context))nValueError: Found array with 0 sample(s) (shape=(0 512)) while a minimum of 1 is required by the normalize function.nn' nan",['django'],"['numpy', 'pandas', 'python-2.7']"
40097693,"'TensorFlow estimator.predict: Saving when as_iterable=True' 'I have modified the Wide and Deep tutorial (running python 2.7) to use a regressor instead of a classifier and to output the predictions of my test data. I currently do this (import numpy as np):nnpredicts = m.predict(input_fn=lambda: input_fn(df_test))nnp.savetxt(""predict.csv"" predicts delimiter="""")nnnWith the latest r0.11 version I am getting a warning about upcoming deprecation in which the return value will be an iterable. To accommodate this I attempted the following:nnpredicts = m.predict(input_fn=lambda: input_fn(df_test) as_iterable=True)nnp.savetxt(""predict.csv"" list(predicts) delimiter="""")nnnThis did not have the desired effect. The CPUs hit about 80% and stayed that way seemingly indefinitely. I finally had to kill it after a half hour with no data written. What was it trying to do?nnAny suggestions as to how I can get these predictions out to a text file when returned with as_iterable=True?n' nan",['numpy'],"['numpy', 'python-2.7']"
40097706,"'Pandas Grouping - Creating a Generic Aggregation Function' 'I need to do a lot of aggregation on data and I was hoping to write a function that would allow me to passnn1) The string to use for groupingn2) The fields that would constitute the numerator/denominator/ and formulannAs I will be doing a lot of cuts on the data using different groupings and different numerators and denominators it would be easier for me to create a generic group by and pass it what I neednnSo lets take the following example:nnimport pandas as pdndf=pd.read_csv(""https://raw.githubusercontent.com/wesm/pydata-book/master/ch08/tips.csv"" sep='')n(df.groupby('sex' 'smoker')'total_bill''tip'.sum().apply(lambda r: r.tip/r.total_bill axis = 1))nnnNow I would want to create a function that would allow me to pass a group by value and a numerator denominator fieldnnSo for examplenngroupbyvalue='sex' 'smoker'nfieldstoaggregate='tip''total_bill'nnnAnd plug them into something likenn(df.groupby(groupbyvalue)fieldstoaggregate.sum().apply(lambda r: r.tip/r.total_bill axis = 1))nnnThat works fine but when I tried to replace the formula with something like:  nndfformula=""r.tip/r.total_bill""nnnAnd then placed it in the formula as follows nn(df.groupby(groupbyvalue)fieldstoaggregate.sum().apply(lambda r: dfformula axis = 1)*10000)nnnMy output looks as follows:nnsex     smokernFemale  No        r.tip/r.total_billr.tip/r.total_billr.tip/r.to...n        Yes       r.tip/r.total_billr.tip/r.total_billr.tip/r.to...nMale    No        r.tip/r.total_billr.tip/r.total_billr.tip/r.to...n       Yes       r.tip/r.total_billr.tip/r.total_billr.tip/r.to...ndtype: objectnnnIs there any way to create the calculation dynamically then use it in the formula rather than having it interpreted as a string?nnThanksn' 'You can achieve this using eval() functionnnimport pandas as pdnndf = pd.read_csv(""https://raw.githubusercontent.com/wesm/pydata-book/master/ch08/tips.csv"" sep='')nngroupbyvalue = 'sex' 'smoker'nfieldstoaggregate = 'tip''total_bill'ndfformula = ""r.tip/r.total_bill""nn(df.groupby(groupbyvalue)fieldstoaggregate.sum().apply(lambda r: eval(dfformula) axis = 1))nnnThe output would be as followsnnsex     smokernFemale  No        0.153189n        Yes       0.163062nMale    No        0.157312n        Yes       0.136919ndtype: float64nn'",['pandas'],['pandas']
40097711,"'Making a list of mouse over event functions in Tkinter' 'I'm making a GUI for a medical tool as a class project. Given a condition it should output a bunch of treatment options gathered from different websites like webMD. I would like to be able to handle mouseover events on any of the treatments listed to give a little more information about the treatment (such as the category of drug whether it is a generic or not etc).nnThe labels are stored in a list as I have no idea how many different treatments will be returned beforehand. So my question is how can I make these mouseover events work. I can't write a function definition for every single possible label they would number in the hundreds or thousands. I'm sure there's a very pythonic way to do it but I have no idea what.nnHere's my code for creating the labels:nn    def search_click():n        """"""n        Builds the search results after the search button has been clickedn        """"""n        self.output_frame.destroy()                                                 # Delete old resultsn        build_output()                                                              # Rebuild output framesn        treament_list = mockUpScript.queryConditions(self.condition_entry.get())    # Get treatment datan        labels = n        frames = self.onceFrame self.twiceFrame self.threeFrame self.fourFrame # holds the list of framesn        for treament in treament_list:                                              # For each treatment in the listn            label = ttk.Label(framestreament1 - 1 text=treament0)            # Build the label for treatmentnn            labels.append(label)                                                    # Add the treatment to the listn            label.pack()        nnnand here is what the GUI looks like (don't judge -; )nnThe text ""Hover over drugs for information"" should be changed depending on which drug your mouse is hovering over.n' 'n  I can't write a function definition for every single possible label they would number in the hundreds or thousands. I'm sure there's a very pythonic way to do it but I have no idea what.nnnCheck out lambda functions which are nearly identical to what you want.nnIn your case something like:nndef update_bottom_scroll_bar(text):n    # whatever you want to do to update the text at the bottomnnfor treatment in treament_list:  # For each treatment in the listn    label = ttk.Label(framestreatment1 - 1 text=treatment0)  # Build the label for treatmentnn    label.bind(""<Enter>"" lambda event t=treatment: update_bottom_scroll_bar(text=t))n    label.bind(""<Leave>"" lambda event: update_bottom_scroll_bar(text='Default label text'))nn    labels.append(label)  # Add the treatment to the listn    label.pack()nnnAlso please spell your variables right I corrected treament to treatment...n'","['list', 'tkinter']","['tkinter', 'python-2.7']"
40097863,"'How to remove the all the curly bracket in dictionary of dictionaries' ""I wish to remove all the curly brackets from my current output. My current output as shown below:nn {'Chin PTE LTD': {'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89} 'COQ nSEAFOOD': {'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1n}}nnnMy current code as shown below:nnfor merchant product quantity in big_list:n    dmerchantproduct += quantitynnprint ({ k:dict(v) for kv in d.items() })nnnMy desired output:nn'Chin PTE LTD': 'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89 'COQ n    SEAFOOD': 'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1nnnAs I am still new to python may I ask if i wish to remove the all the curly brackets in the dictionary of dictionaries. Would my desired output be achievable? If so how should I go about doing it? Any suggestions / ideas would be appreciated. Thank you.n"" 'You can do this by converting the dictionary first to a string and then replacing all the brackets with empty strings:nnd = {'Chin PTE LTD': {'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89} 'COQSEAFOOD': {'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1}}nnprint(str(d).replace(""{"""""").replace(""}"" """"))nnnwhich will print what you are looking for:nn'Chin PTE LTD': 'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89 'COQSEAFOOD': 'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1nn' ""Build up the string like sonnd = {'Chin PTE LTD': {'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89} 'COQ SEAFOOD': {'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1}}nnst = ' '.join('%r: %s' % (k ' '.join('%r: %r' % (sk sv) for sk sv in v.items())) for k v in d.items())nprint(st)nnnThis code builds the string by first iterating over the outer dict. It appends the key to the string (plus a ':' in keeping with your formatting requirements). Then it iterates over the inner dict and appends the key and value the same way. It uses the %r format specifier which means that the elements being printed are converted using their repr function. This gives the strings their quotes without having to manually add them.nnYou can't count on the order being fixed though. So for different runs you'll get slightly different orders. nnOutput looks likennn  'Chin PTE LTD': 'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89 'COQ SEAFOOD': 'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1 nnnSomeone could probably wrap it up into a giant join/comprehension to make it more functional if they really wanted to.n"" ""d = {'Chin PTE LTD': {'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89} 'COQ SEAFOOD': {'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1}}nn' '.join('{}: {}'.format(merchant ' '.join('{}: {}'.format(product quantity) for product quantity in products.items())) for merchant products in d.items())nnnif you are using python2 instead of python3 replace items with iteritemsn"" 'import renresult={'Chin PTE LTD': {'Carrot Cake': 22 'Chocolate Cake': 12 'Beer': 89} 'COQ SEAFOOD': {'GRILLED AUSTRALIA ANGU': 1 'CRISPY CHICKEN WINGS': 1}}nnexpected_output=re.sub(""}|{""""""str(result))nn'",['dictionary'],['dictionary']
40097975,"'list.sort() not sorting values correctly by second tuple parameter' ""I am trying to sort a list of tuples by the second parameter in the tuple in Python 3.5.2 to find which algorithms take the least -> most time in ascending order however for some reason the looks to be sorting by random. My code:nnimport mathnndef speeds(n):nn    new_dictionary = {}nn    six_n_log_n = 6 * n * math.log(n 2)n    thr_n_exp05 = 3 * (n ** 0.5)n    four_expn = 4 ** nn    ceil_sqrt_n = math.ceil(math.sqrt(n))n    five_n = 5 * nn    n_cubed = n ** 3n    log_log_n = math.log(math.log(n 2))n    n_exp_01 = n ** 0.01n    floor_2_n_log_exp2_n = math.floor(2 * n * (math.log(n 2)**2))n    n_exp2_log_n = (n ** 2) * math.log(n 2)n    log_exp2_n = math.log(n 2) ** 2n    one_div_n = 1 / nn    two_exp_n = 2 ** nn    four_exp_logn = 4 ** (math.log(n 2))n    two_exp_logn = 2 ** (math.log(n 2))n    four_n_exp_threehalves = 4 * (n ** (3/2))n    n_exp2 = n ** 2n    sqrt_log_n = math.sqrt(math.log(n 2))nn    new_dictionary0 = six_n_log_nn    new_dictionary1 = thr_n_exp05n    new_dictionary2 = four_expnn    new_dictionary3 = ceil_sqrt_nn    new_dictionary4 = five_nn    new_dictionary5 = n_cubedn    new_dictionary6 = log_log_nn    new_dictionary7 = n_exp_01n    new_dictionary8 = floor_2_n_log_exp2_nn    new_dictionary9 = n_exp2_log_nn    new_dictionary10 = log_exp2_nn    new_dictionary11 = one_div_nn    new_dictionary12 = two_exp_nn    new_dictionary13 = four_exp_lognn    new_dictionary14 = two_exp_lognn    new_dictionary15 = four_n_exp_threehalvesn    new_dictionary16 = n_exp2n    new_dictionary17 = sqrt_log_nnn    sorted_list = n    for key in new_dictionary:n        sorted_list.append((key new_dictionarykey))nn    sorted_list.sort(key=lambda x: x1)nn    for i x in sorted_list:n        print(sorted_listi)nn    return sorted_listnnn = 15nspeeds(n)nnnThe expected output should be tuples in ascending order by the second parameter but instead I receive this:nn(15 232.379000772445)n(10 15.263794126054286)n(14 15.000000000000002)n(2 1073741824)n(17 1.9765855902562173)n(7 1.027450511266727)n(9 879.0503840119167)n(13 225.00000000000006)n(3 4)n(12 32768)n(8 457)n(5 3375)n(11 0.06666666666666667)n(4 75)n(16 225)n(1 11.618950038622252)n(0 351.6201536047667)n(6 1.3627418135330593)nnnCan anyone tell me why I'm getting a seemingly random order from this? Can't seem to find where my problem is.n"" 'If you examine sorted_list following the sort you will see that it has been sorted correctly.nn(11 0) (7 1.027450511266727) (6 1.3627418135330593) (17 1.9765855902562173) (3 4.0) (1 11.618950038622252) (14 15.000000000000002) (10 15.263794126054286) (15 60) (4 75) (16 225) (13 225.00000000000006) (0 351.6201536047667) (8 457.0) (9 879.0503840119167) (5 3375) (12 32768) (2 1073741824)nnnThe error occurs in the following line:nnfor i x in sorted_list:nnnYou are not iterating over the keys and values as you think. Rather this is unpacking each tuple in the list and assigning its first component to i and its second component to x. You are then accessing the element at the ith position in the list which leads to what appears to be a random ordering. You can instead write:nnfor i x in enumerate(sorted_list):nnnOr more simply you can print the tuple you are trying to displaynnfor item in sorted_list:n    print(item)nn' 'When you iterate over your tuples you want to print the tuple itself:nnfor tup in sorted_list:n    print(tup)nnnotherwise you are printing the values at the index based on the first value of the index. For example the first value in the sorted list is:nn(11 0)nnnis actually looking for:nnsorted_list11nnnwhich is why you see the improper first value.n'",['python-3.x'],"['list', 'python-3.x']"
40098058,"'Plot each column of Pandas dataframe pairwise against one column' ""I have a pandas dataframe where one of the columns is a set of labels that I would like to plot each of the other columns against in subplots. In other words I want the y-axis of each subplot to use the same column called 'labels' and I want a subplot for each of the remaining columns with the data from each column on the x-axis. I expected the following code snippet to achieve this but I don't understand why this results in a single nonsensical plot:nnexamples.plot(subplots=True layout=(-1 3) figsize=(20 20) y='labels' sharey=False)nn"" 'The problem with that code is that you didn't specify an x value. It seems nonsensical because it's plotting the labels column against an index from 0 to the number of rows. As far as I know you can't do what you want in pandas directly. You might want to check out seaborn though it's another visualization library that has some nice grid plotting helpers.nnHere's an example with your data:nnimport pandas as pdnimport seaborn as snsnimport numpy as npnnexamples = pd.DataFrame(np.random.rand(104) columns='a' 'b' 'c' 'labels')ng = sns.PairGrid(examples x_vars='a' 'b' 'c' y_vars='labels')    ng = g.map(plt.plot)nnnThis creates the following plot:nnnObviously it doesn't look great with random data but hopefully with your data it will look better. n'",['pandas'],"['pandas', 'matplotlib']"
40098091,"'Error when creating superuser in Django' 'I'm very new to Python and even newer to Django. I'm using Visual Studio and trying to create a new Django Web Project and receiving the error below:nnExecuting manage.py createsuperusernTraceback (most recent call last):n  File ""c:usersgweathersbydocumentsPython ExperimentsSRC Project Mngrmanage.py"" line 17 in <module>n    execute_from_command_line(sys.argv)n  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libsite-packagesdjangocoremanagement__init__.py"" line 367 in execute_from_command_linen    utility.execute()n  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libsite-packagesdjangocoremanagement__init__.py"" line 316 in executen    settings.INSTALLED_APPSn  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libsite-packagesdjangoconf__init__.py"" line 53 in __getattr__n    self._setup(name)n  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libsite-packagesdjangoconf__init__.py"" line 41 in _setupn    self._wrapped = Settings(settings_module)n  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libsite-packagesdjangoconf__init__.py"" line 97 in __init__n    mod = importlib.import_module(self.SETTINGS_MODULE)n  File ""C:UsersgweathersbyAppDataLocalContinuumAnaconda2libimportlib__init__.py"" line 37 in import_modulen    __import__(name)nImportError: No module named SRC Project Mngr.settingsnThe Python REPL process has exitednnnI've done some searching online and have seen that other folks have had this issue but to be honest none of the solutions make sense to me because I'm so new. Could someone advise with simple steps as to how to remedy?n' nan","['django', 'python-2.7']",['django']
40098142,"'Taking fast screenshot Winapi and Opencv' 'I need to take very fast screenshots of a game for an OpenCV project I am working on. I can use PIL easily for example:nndef take_screenshot1(hwnd):n    rect = win32gui.GetWindowRect(hwnd)n    img = ImageGrab.grab(bbox=rect)n    img_np = np.array(img)n    return cv2.cvtColor(img_np cv2.COLOR_RGB2BGR)nnnBut it takes on average of 0.05 seconds which isn't fast enough for real time capture.nnI can use the answer posted here but that only saves the bitmap to a file. That is over 10 times faster than by using PIL but I am unsure of any methods within OpenCV to convert it to a bgr/hsv image.nndef take_screenshot(hwnd):n    wDC = win32gui.GetWindowDC(hwnd)n    dcObj=win32ui.CreateDCFromHandle(wDC)n    cDC=dcObj.CreateCompatibleDC()n    dataBitMap = win32ui.CreateBitmap()n    dataBitMap.CreateCompatibleBitmap(dcObj 500 500)n    cDC.SelectObject(dataBitMap)n    cDC.BitBlt((0 0) (500 500) dcObj (0 0) win32con.SRCCOPY)nn    dataBitMap.SaveBitmapFile(cDC ""foo.png"")nn    dcObj.DeleteDC()n    cDC.DeleteDC()n    win32gui.ReleaseDC(hwnd wDC)n    win32gui.DeleteObject(dataBitMap.GetHandle())n    im = cv2.imread(""foo.png"")n    return cv2.cvtColor(im cv2.COLOR_RGB2BGR)nnnEDIT:The size of the window is 500x500 so it is saving the same area in both examples.nnEven if I save the image and then reopen it with OpenCV it is still faster than PIL but surely there is an easier way?nnEDIT: Ok so using the comments and doing some research on winapi I now can access the bitmap data directly as follows:nndef take_screenshot1(hwnd):nwDC = win32gui.GetWindowDC(hwnd)ndcObj=win32ui.CreateDCFromHandle(wDC)ncDC=dcObj.CreateCompatibleDC()ndataBitMap = win32ui.CreateBitmap()ndataBitMap.CreateCompatibleBitmap(dcObj 500 500)ncDC.SelectObject(dataBitMap)ncDC.BitBlt((0 0) (500 500) dcObj (0 0) win32con.SRCCOPY)nnim = dataBitMap.GetBitmapBits(True)  # Tried False alsonimg = np.array(im)ncv2.cvtColor(img cv2.COLOR_RGB2BGR)nprint(img)nndcObj.DeleteDC()ncDC.DeleteDC()nwin32gui.ReleaseDC(hwnd wDC)nwin32gui.DeleteObject(dataBitMap.GetHandle())nnnBut i'm not sure how to convert the returned bitmap to a form that OpenCV understands as there are no methods to convert bitmap to rgb/bgr in OpenCVn' nan",['numpy'],"['python-2.7', 'numpy']"
40098280,"'What does  mean' ""Here's the code:nndef my_func(f arg):n  return f(arg)nnprint((lambda x: 2*x*x (5)))nn>>>(<function <lambda> at 0x10207b9d8> 5)nnnHow to solve the error and can some please explain in a clear language what exactly that error means.n"" 'There is no error; you simply supplied two arguments to print the lambda x: 2*x*x and 5. You're not calling your anonymous function rather just passing it to print.nnprint will then call the objects __str__ method which returns what you see:nn>>> str(lambda x: 2*x*x)  # similarly for '5'n'<function <lambda> at 0x7fd4ec5f0048>'nnnInstead fix your parenthesis to actually call the lambda with the 5 passed as the value for x:nnprint((lambda x: 2*x*x)(5))nnnwhich prints out 50.nnnnn  What's the general meaning of <function at 0x ...>?nnnThat's simply the way Python has chosen to represent function objects when printed. Their str takes the name of the function and the hex of the id of the function and prints it out. E.g:nndef foo(): passnprint(foo) # <function foo at 0x7fd4ec5dfe18>nnnIs created by returning the string:nn""<function {0} at {1}>"".format(foo.__name__ hex(id(foo)))nn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40098300,"'Use a list to conditionally fill a new column based on values in multiple columns' 'I am trying to populate a new column within a pandas dataframe by using values from several columns. The original columns are either 0 or '1' with exactly a single 1 per series. The new column would correspond to df'A''B''C''D' by populating new_col = 1 3 7 10 as shown below. (A 1 at A means new_col = 1; if B=1new_col = 3 etc.)nndf    n         A    B    C    Dn1        1    0    0    0n2        0    0    1    0n3        0    0    0    1n4        0    1    0    0nnnThe new df should look like this.nndf    n         A    B    C    D   new_coln1        1    0    0    0         1n2        0    0    1    0         7n3        0    0    0    1        10n4        0    1    0    0         3nnnI've tried to use map loc and where but can't seem to formulate an efficient way to get it done. Problem seems very close to this. A couple other posts I've looked at 1 2 3. None of these show how to use multiple columns conditionally to fill a new column based on a list.n' ""It's not the most elegant solution but for me it beats the if/elif/elif loop:nnd = {'A': 1 'B': 3 'C': 7 'D': 10}ndef new_col(row):n    k = rowrow == 1.index.tolist()0n    return dknndf'new_col' = df.apply(new_col axis=1)nnnOutput:nn    A   B   C   D   new_coln1   1   0   0   0   1n2   0   0   1   0   7n3   0   0   0   1   10n4   0   1   0   0   3nn"" 'I can think of a few ways mostly involving argmax or idxmax to get either an ndarray or a Series which we can use to fill the column.nnWe could drop down to numpy find the maximum locations (where the 1s are) and use those to index into an array version of new_col:nnIn 148: np.take(new_colnp.argmax(df.values1))nOut148: array( 1  7 10  3)nnnWe could make a Series with new_col as the values and the columns as the index and index into that with idxmax:nnIn 116: pd.Series(new_col index=df.columns).locdf.idxmax(1).valuesnOut116: array( 1  7 10  3)nnnWe could use get_indexer to turn the column idxmax results into integer offsets we can use with new_col:nnIn 117: np.array(new_col)df.columns.get_indexer(df.idxmax(axis=1))nOut117: array( 1  7 10  3)nnnOr (and this seems very wasteful) we could make a new frame with the new columns and use idxmax directly:nnIn 118: pd.DataFrame(df.values columns=new_col).idxmax(1)nOut118: n0     1n1     7n2    10n3     3ndtype: int64nn'","['list', 'python-2.7', 'pandas']",['pandas']
40098500,"'The `or` operator on dict.keys()' 'As I've been unable to find any documentation on this so I'll ask here. nnAs shown in the code below I found that the or operator (|) worked as such:nna = {""a"": 1""b"": 2 2: 3}nb = {""d"": 10 ""e"": 11 11: 12}nnkeys = a.keys() | b.keys()naonce = a.keys() | a.values()nbonce = b.keys() | b.values()nnfor i in keys:n    print(i end="" "")nprint()nfor i in aonce:n    print(i end="" "")nprint()nfor i in bonce:n    print(i end="" "")nprint()nnnWhich produces the result in some order:nn2 d 11 a b e   n3 1 2 a b   n10 e 11 12 d   nnnInitially I assumed these iterable was compatible with | similar to the way sets are however. Testing with other iterable such as a list.__iter__() threw an error. Even;  nnvalues = a.values() | b.values()nfor i in values:n    print(i end="" "") nprint()nnnWhich I'd assume worked due to the use of dict.values() in the previous examples threw an error.nnSo my question is; What on earth have I come across and more importantly how reliable is it? What subclass does my arguments need to be for me to be able to use this?n' 'The Python 3 Documentation notes that the dict.keys method is set-like and implements collections.abc.Set.nnNote that dict.values is not set-like even though it might appear to be so in your examples:nnaonce = a.keys() | a.values()nbonce = b.keys() | b.values()nnnHowever these are leveraging off the fact that the keys view implements __or__ (and __ror__) over arbitrary iterables.nnFor example the following will not work:nn>>> a.values() | b.values()nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>nTypeError: unsupported operand type(s) for |: 'dict_values' and 'dict_values'nn'",['python-3.x'],"['python-3.x', 'dictionary', 'python-2.7']"
40098535,"'Controlling contour label formatting in pyplot' 'I'm making a plot where I have contours at 2000 4000 6000 8000.  The contours are labeled as 2000.000 4000.000 etc.  I'd like to get rid of all those trailing zeros.  The best option I can find right now is here: http://matplotlib.org/examples/pylab_examples/contour_label_demo.html which suggests defining a new class for the labels which controls how they are displayed and then using that class.  I've never seen such a convoluted option in python before.  Is there no more direct way?nnHere is the code provided as an example of defining a class for the labels.nnimport matplotlibnimport numpy as npnimport matplotlib.cm as cmnimport matplotlib.mlab as mlabnimport matplotlib.ticker as tickernimport matplotlib.pyplot as pltnnmatplotlib.rcParams'xtick.direction' = 'out'nmatplotlib.rcParams'ytick.direction' = 'out'nn##################################################n# Define our surfacen##################################################ndelta = 0.025nx = np.arange(-3.0 3.0 delta)ny = np.arange(-2.0 2.0 delta)nX Y = np.meshgrid(x y)nZ1 = mlab.bivariate_normal(X Y 1.0 1.0 0.0 0.0)nZ2 = mlab.bivariate_normal(X Y 1.5 0.5 1 1)n# difference of GaussiansnZ = 10.0 * (Z2 - Z1)nn##################################################n# Make contour labels using creative float classesn# Follows suggestion of Manuel Metzn##################################################nplt.figure()nn# Basic contour plotnCS = plt.contour(X Y Z)nnn# Define a class that forces representation of float to look a certain wayn# This remove trailing zero so '1.0' becomes '1'nclass nf(float):n    def __repr__(self):n        str = '%.1f' % (self.__float__())n        if str-1 == '0':n            return '%.0f' % self.__float__()n        else:n            return '%.1f' % self.__float__()nn# Recast levels to new classnCS.levels = nf(val) for val in CS.levelsnn# Label levels with specially formatted floatsnif plt.rcParams""text.usetex"":n    fmt = r'%r %%'nelse:n    fmt = '%r %%'nplt.clabel(CS CS.levels inline=True fmt=fmt fontsize=10)nn' ""The fmt parameter can be either a classic format string or a callable that converts a scalar to a string.nnIf you don't have fancy requirements you could just pass fmt='%d' instead of a custom class.nnFor common formats you should be also able to resort to the default formatters in matplotlib.ticker before having to implement your own. n""",['matplotlib'],['matplotlib']
40098680,"'pandas Dataframe columns doing algorithm' ""I have a dataframe like this:nndf = pd.DataFrame({n    'A': 'a' 'a' 'a' 'a' 'a'n    'lon1': 128.0 135.0 125.0 123.0 136.0n    'lon2': 128.0 135.0 139.0 142.0 121.0n    'lat1': 38.0 32.0 38.0 38.0 38.0n    'lat2': 31.0 32.0 35.0 38.0 29.0n    'angle': 0 0 0 0 0n})nnnI want to count the angle of each row by this function and save back to the angle columnnndef angle(lon1lat1lon2lat2):n    dx = lon2 - lon1n    dy = lat2 - lat1n    direction = 0;n    if ((dx == 0) & (dy == 0)):  # same positionn    return directionn    if (dx > 0.0) :    n        direction = 90-np.arctan2(dydx)*180/np.pin    elif (dy > 0.0 ) :    n        direction = 180+(270-(np.arctan2(dydx)*180/np.pi))n    else :   n        direction = 360-(270+(np.arctan2(dydx)*180/np.pi))n        if (direction < 0) :n            direction += 360nn    return (direction.astype(int) % 360)  nnnI tried nndf.ixdf'A'.notnull() 'angle' =angle(n    dfdf'A'.notnull()'lon1'n    dfdf'A'.notnull()'lat1'n    dfdf'A'.notnull()'lon2' n    dfdf'A'.notnull()'lat2') nnnand I got an errornnn  ValueError: The truth value of a Series is ambiguous. Use a.empty a.bool() a.item() a.any() or a.all().nnnI tried for indexrow in df.iterrows(): the result of for loop is ok but it took terribly long long time(original data is about 10 million rows ) nncould anyone kindly give some efficient methods?n"" 'It seems like you are trying to apply function angle(...) to every row of your dataframe.nnFirst it is necessary to cast all your string-typed numbers into float so as to calculate.nndf1.loc: ""lon1"" = df1.loc: ""lon1"".astype(""float"")ndf1.loc: ""lon2"" = df1.loc: ""lon2"".astype(""float"")ndf1.loc: ""lat1"" = df1.loc: ""lat2"".astype(""float"")ndf1.loc: ""lat2"" = df1.loc: ""lat2"".astype(""float"")nnnThere you go.nndf1.loc: ""angle"" = df1.apply(lambda x: angle(x""lon1"" x""lat1"" x""lon2"" x""lat2"") axis = 1)nnnAs for performance concern here are some tips for you.nnnProfiling. nUse numba for JIT compilation and automatic vectorization of your function.nn' ""I'm sure there's a more vectorized solution but here is a solution using the row-wise version of the apply method which only slightly alters your function:nndef angle(row):n    dx = row.lon2 - row.lon1n    dy = row.lat2 - row.lat1n    direction = 0;n    if ((dx == 0) & (dy == 0)):  # same positionn        return directionn    if (dx > 0.0) :    n        direction = 90-np.arctan2(dydx)*180/np.pin    elif (dy > 0.0 ) :    n        direction = 180+(270-(np.arctan2(dydx)*180/np.pi))n    else :   n        direction = 360-(270+(np.arctan2(dydx)*180/np.pi))n    if (direction < 0) :n        direction += 360nn    return (direction.astype(int) % 360)  nndf'angle' = df.apply(angle axis=1)nnnOutput:nn    A   angle   lat1    lat2    lon1    lon2n0   a   180     38.0    31.0    128.0   128.0n1   a   0       32.0    32.0    135.0   135.0n2   a   102     38.0    35.0    125.0   139.0n3   a   90      38.0    38.0    123.0   142.0n4   a   239     38.0    29.0    136.0   121.0nn""",['pandas'],['pandas']
40098820,'Python code to return total count of no. of positions in which items are differing at same index' 'A=123456789nB=123746589nnI have to compare these two lists and return the count of no. of location in which items are differing using one line python code.nnFor example: nthe output should be 4 for given arrays because at index (3456) the items are differing.So program should return 4.nnMy way of doing this is comparing each and every location using for loop:nncount=0nfor i in range(0len(A)):n   if(Ai==Bi):n     continuen   else:n     count+=1nprint(count)nnnPlease help me in writing one line python code for this.n' 'count = sum(a != b for a b in zip(A B))nprint(count)nnnor just print sum(a != b for a b in zip(A B))nnyou can check about zip/lambda/map here those tools are very powerfull and important in python..nnHere you can also check others kind of ways to use those tools.nnHave fun!!n' 'There are many ways to do this. If you're using numpy you could just use np.count_nonzero:nn>>> a = np.array(1 2 3 4 5 6 7 8 9)n>>> b = np.array(1 2 3 7 4 6 5 8 9)n>>> a != bnarray(False False False  True  True False  True False False dtype=bool)n>>> np.count_nonzero(a != b)n3nnnNote that a != b returns an array containing true and false depending upon how the condition evaluates at each index.nnHere's a speed comparison:nn>>> %timeit np.count_nonzero(a != b)nThe slowest run took 40.59 times longer than the fastest. This could mean that an intermediate result is being cached.n1000000 loops best of 3: 752 ns per loopnn>>> %timeit sum(i != j for i j in zip(a b))nThe slowest run took 5.86 times longer than the fastest. This could mean that an intermediate result is being cached.n100000 loops best of 3: 18.5 Âµs per loopnnnThe caching obscures the timing but 40.59 * 0.752 = 30.52Âµs while 5.86 * 18.5 = 108.41Âµs so numpy's slowest still seems significantly faster than pure python's slowest run.nnThis is much clearer with larger arrays:nn>>> n = 10000n>>> a = np.arange(n)n>>> b = np.arange(n)n>>> k = 50n>>> ids = np.random.randint(0 n k)n>>> aids = 0n>>> ids = np.random.randint(0 n k)n>>> bids = 0n>>> %timeit np.count_nonzero(a != b)nThe slowest run took 20.50 times longer than the fastest. This could mean that an intermediate result is being cached.n100000 loops best of 3: 11.5 Âµs per loopn>>> %timeit sum(i != j for i j in zip(a b))n100 loops best of 3: 15.6 ms per loopnnnThe difference is much more stark with numpy taking at most 235 micro-seconds while pure python takes 15.6 milli-seconds on average!n',"['python-2.7', 'python-3.x', 'numpy']",['numpy']
40098963,"'Python Update Dictionary values to reference dataframes with the same name' ""I have many dataframes with names such as 'ABC' 'XYZ'...nnI also have a dictionary with keys where each key has a list of 200 values which are the names of the dataframes i.e. 'ABC''XYZ'...nnI want to update this dictionary so instead of containing the names of the dataframes it contains the dataframes themselves as a nested dictionary.nnTHis will enable me to iterate over a specific key of the main dictionary dictionary and access each of its 200 dataframes  by namenni.e. dictionarykey1ABC would print out the ABC dataframe.nnAny ideas? :)n"" 'What are the keys currently in this dictionary? / Where are your dataframes currently stored? You probably want something like this: nndfDict ={dfName: <df>} #assuming a bit herennewDict = {}nfor key value in oldDict.items():n    newDictkey = { dfName:dfDictdfName for dfName in value }nn' ""Easy enough use eval:nnu v w x y z = 1 2 3 4 5 6nframes = {}nnames = {'a' : 'u' 'v'n         'b' : 'w' 'x'n         'c' : 'y' 'z'}nfor key in names:n    frameskey = dict(zip(nameskey eval(name) for name in nameskey))nframesn# Output:n{'a': 1 2 'b': 3 4 'c': 5 6}nn""","['pandas', 'dictionary']","['dictionary', 'pandas']"
40099111,'What is the most efficient module for the display of an updating matrix' 'I am trying to make a python copy of Conway's Game of Life I've used numpy matrix to get the data together but I'm having trouble displaying the information. I first tried using turtle (because it is the only gui module I know) But It is extremely slow (30 to 60 seconds to display a 1000x1000 cell frame even though it takes about .02 seconds to calculate it)nnimport numpy as np turtle as t timenfrom scipy.signal import convolve2dnnt.tracer(00)nt.pu()nt.shape('square')nt.shapesize(.05)nndef DrawCells(m):n    offset = (GridSize//2)n    m = np.where(m == True)n    for x in range(len(m0)):n        t.goto(((m0x)-offset)*2((m1x)-offset)*2)n        t.stamp()nnGridSize = eval(input('grid size (Grid will be closest even number to input): '))nGridSize = (GridSize//2)*2ngrid = np.random.randint(2 size=(GridSize GridSize))nnframe = 0nnwhile True:nn    s = time.time()n    frame += 1nn    DrawCells(grid)n    t.update()n    NiGrid = convolve2d(gridnp.ones((33)dtype='b')'same') - gridn    grid = ((grid == 0) & (NiGrid == 3)) + ((grid == 1) & ((NiGrid == 2) + (NiGrid == 3)))n    t.clear()n    t.title('Frame: {}. time for frame: {}.'.format(frametime.time()-s))nnnI am happy to write my own code I just need a pointer to the correct direction to a better module.nnThanks for any help~ n' nan,"['python-3.x', 'numpy']",['numpy']
40099239,"'Python - convert list into dictionary in order to reduce complexity' 'Let's say I have a big list:nnword_list = elt.strip() for elt in open(""bible_words.txt"" ""r"").readlines() nnn//complexity O(n) --> proporcional to list length ""n""nnI have learned that hash function used for building up dictionaries allows lookup to be much faster like so:nnword_dict = dict((elt 1) for elt in word_list) nnn// complexity O(l) ---> constant.nnusing word_list is there a most efficient way which is recommended to reduce the complexity of my code?n' 'The code from the question does just one thing: fills all words from a file into a list. The complexity of that is O(n).nnFilling the same words into any other type of container will still have at least O(n) complexity because it has to read all of the words from the file and it has to put all of the words into the container.nnWhat is different with a dict?nnFinding out whether something is in a list has O(n) complexity because the algorithm has to go through the list item by item and check whether it is the sought item. The item can be found at position 0 which is fast or it could be the last item (or not in the list at all) which makes it O(n).nnIn dict data is organized in ""buckets"". When a key:value pair is saved to a dict hash of the key is calculated and that number is used to identify the bucket into which data is stored. Later on when the key is looked up hash(key) is calculated again to identify the bucket and then only that bucket is searched. There is typically only one key:value pair per bucked so the search can be done in O(1).nnFor more detils see the article about DictionaryKeys on python.org.nnHow about a set?nnA set is something like a dictionary with only keys and no values. The question contains this code:nnword_dict = dict((elt 1) for elt in word_list) nnnThat is obviously a dictionary which does not need values so a set would be more appropriate.nnBTW there is no need to create a word_list which is a list first and convert it to set or dict. The first step can be skipped:nnset_of_words = {elt.strip() for elt in open(""bible_words.txt"" ""r"").readlines()}nnnAre there any drawbacks?nnAlways ;)nnnA set does not have duplicates. So counting how many times a word is in the set will never return 2. If that is needed don't use a set.nA set is not ordered. There is no way to check which was the first word in the set. If that is needed don't use a set.nObjects saved to sets have to be hashable which kind-of implies that they are immutable. If it was possible to modify the object then its hash would change so it would be in the wrong bucket and searching for it would fail. Anyway str int float and tuple objects are immutable so at least those can go into sets.nWriting to a set is probably going to be a bit slower than writing to a list. Still O(n) but a slower O(n) because it has to calculate hashes and organize into buckets whereas a list just dumps one item after another. See timings below.nReading everything from a set is also going to be a bit slower than reading everything from a list.nnnAll of these apply to dict as well as to set.nnSome examples with timingsnnWriting to list vs. set:nn>>> timeit.timeit('n for n in range(1000000)' number=10)n0.7802875302271843n>>> timeit.timeit('{n for n in range(1000000)}' number=10)n1.025623542189976nnnReading from list vs. set:nn>>> timeit.timeit('989234 in values' setup='values=n for n in range(1000000)' number=10)n0.19846207875508526n>>> timeit.timeit('989234 in values' setup='values={n for n in range(1000000)}' number=10)n3.5699193290383846e-06nnnSo writing to a set seems to be about 30% slower but finding an item in the set is thousands of times faster when there are thousands of items.n'","['list', 'dictionary']","['dictionary', 'list']"
40099264,"""Why can I make a numpy array that's (apparently) bigger than my computer's memory?"" ""When I run code below:nnimport scipy.sparsenx = scipy.sparse.random(100000 100000 1e-4)ny = x.toarray()nprint(y.nbytes)nnnI get an output of 80000000000 bytes = 80 GB. And yet I am using a Macbook Air with only 4 GB of RAM. Can someone explain how I am (apparently) creating a NumPy array larger than my memory size? Is y somehow a view of x rather than a copy? I didn't find anything about this in the scipy.sparse documentation. Unsurprisingly if I do something like y.copy() I crash Python... I can't expect to do something to an array of size 10^10. Thanks!nnVersions:nPython 3.5.2 via Anaconda 4.1.1 SciPy 0.17.1 NumPy 1.11.1.n"" 'This is because numpy doesn't actually allocate all that space. Most likely sparse arrays and matrices are represented with triplets linked nodes or some other means of ignoring all the empty space between. The bytes are calculated based on the assigned dimensions of the matrix/array not the actual data in memory.n'",['numpy'],['numpy']
40099351,"""Why isn't readline() working properly?"" 'I have a file called untitled.txt with the following lines:nnLine 1: ATTCTGGAnnLine 2: CGCCCGAATCCAGAACGCATTCCCATATTTCGGGACCACTGGCCTCCACGGTACGGACGTCAATCAAATnnnWhen I enter code for finding the positions where sp (line 1) appears in p (line 2) with a maximum of d errors I get the output 27 which is only one of the correct positions.nncode using only readline():nnnWhen I define ""sp = 'ATTCTGGA'"" directly within the code however I get 6 7 26 27 which is the correct answer.nnnnWhy does ""sp = text.readline()"" not get the same result?n' 'Because readline() provides the whole line including the trailing newline character.  You should strip the trailing newline:nnsp = text.readline().rstrip(""n"") np = text.readline().rstrip(""n"")nn'",['python-3.x'],['python-2.7']
40099363,"'How to use REGEX with multiple filters' 'There are three DAYs described by text variable: nntext = """"""nDAY {n foo 12 5 An foo n 12345n}nDAY {n day 1n day 2n file = ""/Users/Shared/docs/doc.txt""n day 3n end of the monthn}nDAY {n 01.03.2016 11:15n 01.03.2016 11:16n 01.03.2016 11:17n}""""""nnnAll three DAY definitions begin with the word DAY (at the beginning of line) then a space and a curly bracket. The end is indicated with the closing bracket always placed at the beginning of the line.nSo we can say the boundaries of each DAY is defined within the curly brackets {}. nnUsing regex I need to ""find"" the DAY that contains file = ""/Users/Shared/docs/doc.txt"" line inside of its boundary. nnI started writing a regex expression:nnstring = """"""DAY {n A-Za-z0-9+}""""""nnresult = re.findall(string text)nnBut the expression stops finding the text at the end of foo right before the white space character. How to modify the expression so it returns the second DAY that has file = ""/Users/Shared/docs/doc.txt"" in its body so the result would look like:nnDAY {n day 1n day 2n file = ""/Users/Shared/docs/doc.txt""n day 3n end of the monthn}nn' 'To perform regular expression matching on multiline text you need to compile your regex with parameter re.MULTILINE.nnThis piece of code should work as you requested.nnregex = re.compile(""""""(DAYs*{^{}*file = ""/Users/Shared/docs/doc.txt""^{}*})"""""" re.MULTILINE)nregex.findall(text)nnnResult:nn'DAY {n day 1n day 2n file = ""/Users/Shared/docs/doc.txt""n day 3n end of the monthn}'nn'",['regex'],['regex']
40099432,'Is it possible to use DictVectorizer on chunked data?' 'I am trying to import chunked data using python pandas csv readerto overcome memory error and use DicVectorizer to transform string to float dtypes. But I could see two different strings are having same codes after transformation. Do we have alternative/option to do the data type transformation on chunked data?n' 'In Pandas 0.19 you can declare columns as Categorial in read_csv. See documentaion.nnSo as an example for the doc you can type a column named col1 in your csv like this and reduce memory footprint:nnpd.read_csv(StringIO(data) dtype={'col1': 'category'})nn',['pandas'],['pandas']
40099459,"'Python Scrambler Program' 'This program takes words in a sentence and scrambles them.nThe rules are:n- first and last letter remain the samen- punctuation at the end of a word stays the samen- punctuation with a word is scrambled like the middle lettersnnMy problem is that if I have multiple punctuation at the end of a word it does not scramble it.nnEx) testing!!! should be something like t!ste!nig! or t!est!nig!nbut not tstenig!!!nnHow can I fix that?nnimport randomnimport stringnnoriginal_text = input(""Enter your text: "").split(' ')nseed = int(input(""Enter a seed (0 for random): ""))nnpunctuation = nfor c in string.punctuation:n    punctuation.append(c)nnif seed is not 0:n    random.seed(seed)nnrandomized_list = nndef scramble_word(word):n    alpha = word0n    end_punctuation = ''nn    if word-1 in punctuation:n        x = -1n        while wordx in punctuation:n            end_punctuation += wordxn            x -= 1n        omega = wordxn        middle = word1: xn    else:n        omega = word-1n        middle = word1:-1n        end_punctuation = """"n    middle_list = list(middle)n    random.shuffle(middle_list)n    shuffled_text = """".join(middle_list)n    new_words = alpha + shuffled_text + omega + end_punctuationn    return new_wordsnfor item in original_text:n    if len(item) <= 3:n        randomized_list.append(item)n    else:n        randomized_list.append(scramble_word(item))nnew_words = "" "".join(randomized_list)nprint(new_words)nn' 'The problem is that you don't add in the punctuation to the shuffle; see the two amended lines below:nnif word-1 in punctuation:n    x = -1n    while wordx in punctuation:n        end_punctuation += wordxn        x -= 1n    omega = wordxn    middle = word1: x + end_punctuation1: # Include all except the final charactern    end_punctuation = end_punctuation0  # Just use the final characternelse:n    omega = word-1n    middle = word1:-1n    end_punctuation = """"nnnThat does the trick for me:nnIn 63: scramble_word('hello!?$')nOut63: 'hle?l!o$'nnIn 64: scramble_word('hello!?$')nOut64: 'h?!ello$'nnIn 65: scramble_word('hello!?$')nOut65: 'hlel!?o$'nnIn 66: scramble_word('hello!')nOut66: 'hlleo!'nnIn 67: scramble_word('hello!')nOut67: 'hello!'nnIn 68: scramble_word('hello!')nOut68: 'hlleo!'nnIn 69: scramble_word('hello')nOut69: 'hlelo'nnnBy the way you don't need the punctuation variable; wordx in string.punctuation will work the same.n' 'My take on it can shorten the code a bit. (In Python 3.5.1)nnimport randomnnwords = input(""Enter your text: "")nndef scramble(words):n    for x in words.split():n        middle = x1:-1n        middle_list = list(middle)n        random.shuffle(middle_list)n        shuffled = """".join(middle_list)n        print ("""".join(x0+shuffled+x-1)"""" end="""")nnnscramble(words)nnnMy output was for example from:nnMasterson!!%& makes baking%$ potatoes great!nntonMent!osrs!a%& mkeas bigkna%$ patooets gerat! nnI'm sure someone could shorten it even more dramatically.n'",['python-3.x'],"['python-3.x', 'list']"
40099585,"'Python Multiprocessing data output wrong' ""I am trying Multiprocessing in Python. I have written some code which does vector add but couldn't get the output out of the function. Which mean the output Z prints out 0 rather than 2.nnfrom multiprocessing import Processnimport numpy as npnnnumThreads = 16nnum = 16nnnumIter = num/numThreadsnnX = np.ones((num 1))nY = np.ones((num 1))nZ = np.zeros((num 1))nndef add(XYZj):n    Zj = Xj + Yjnnif __name__ == '__main__':n  jobs = n  for i in range(numThreads):n    p = Process(target=add args=(X Y Z i))n    jobs.append(p)nn  for i in range(numThreads):n    jobsi.start()nn  for i in range(numThreads):n    jobsi.join()nn  print Z0nnnEdit: Took advice of clocker and changed my code to this:nnimport multiprocessingnimport numpy as npnnnumThreads = 16nnumRows = 32000nnumCols = 2nnumOut = 3nnstride = numRows / numThreadsnnX = np.ones((numRows numCols))nW = np.ones((numCols numOut))nB = np.ones((numRows numOut))nY = np.ones((numRows numOut))nndef conv(idx):n  Yidx*stride:idx*stride+stride = Xidx*stride:idx*stride+stride.dot(W) + Bidx*stride:idx*stride+stridennif __name__=='__main__':n  pool = multiprocessing.Pool(numThreads)n  pool.map(conv range(numThreads))n  print YnnnAnd the output is Y instead of a Saxp.n"" 'The reason your last line print Z0 returns 0 instead of 2 is that each of the processes makes an independent copy of Z (or may be Zj - not completely sure about that) before modifying it. Either way a separate process run will guarantee that your original version will be unchanged.nnIf you were to use the threading module instead the last line would indeed return 2 as expected but that is not multi-processing. nnSo you probably want to use multiprocessing.Pool instead. Going along your experiment purely for illustration one could do the following:nnIn 40: pool = multiprocessing.Pool()nIn 41: def add_func(j):n   ....:     return Xj + YjnIn 42: pool = multiprocessing.Pool(numThreads)nIn 43: pool.map(add_func range(numThreads))nOut43: narray( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)n array( 2.)nnnHave fun!nnFor your second part to your question the problem is that the conv() function does not return any value. While the process pool gets a copy of X B and W for pulling values from the Y inside conv() is local to each process that is launched. To get the new computed value of Y you would use something like this:nndef conv(idx):n    Ylocal_section = Xidx*stride:idx*stride+stride.dot(W) +  Bidx*stride:idx*stride+striden    return Ylocal_section nnresults = pool.map(conv range(numThreads)) # then apply each result to Ynfor idx in range(numThreads):n    Yidx*stride:idx*stride+stride = resultsidx nnnParallelism can get complicated really fast and at this point I would evaluate existing libraries that can perform fast 2D convolution. numpy and scipy libraries can be super efficient and might serve your needs better.n'",['numpy'],['numpy']
40099614,"'How to convert nested OrderedDict to Object' ""I have dictionary like thisnndata = OrderedDict(('name' 'NewIsland') ('Residents' OrderedDict(('name' 'paul') ('age' '23'))))nnnand I want to convert it to class object.nnHere are my django models.nnclass Country(models.Model):n    name = models.CharField(max_length=20)nnclass Residents(models.Model):n    name = models.CharField(max_length=20)n    age = models.PositiveSmallIntegerField()n    country = models.ForeignKey('Country' related_name='residents')nnnWhen I code like thisnnresult = Country(**data)nnnI got exception nnn  'residents' is an invalid keyword argument for this functionnnnHow can I convert it to class object that I can access residents with result.residentsidx?n"" ""You can do it by manually creating child objectsnnresidents_data = data.pop('Residents')    nresult = Country(**data)nfor rdata in residents_data:n    result.residents.add(Residents(**rdata) bulk=False)nn""",['django'],['django']
40099762,"'Individual/Population selection in Genetic Algorithm using Pandas' ""I have a dataframe that consists of a (big) number of records. Each row represents a different record and each column some of the record characteristics and the record itself (its X Y Z directions).nnIn my effort of finding the optimum scale and suite of records I am going to use a genetic algorithm. As the first step is to generate a population I am looking for a good methodology to organize my population. My initial dataframe is 'df'nnThe code I have so far is:nncombinations = 10nminscale = 0.5nmaxscale = 3.0nndef selectrandomunique(dataf):n    d2 = dataf.sample(n=10).drop_duplicates('ID')n    while len(d2) != 10:n        d2 = dataf.sample(n=10).drop_duplicates('ID')n    return d2nnpopulation = nfor i in range(0 combinations):n    sf = np.random.random_integers(int(minscale*100) int(maxscale*100) 1)/100n    df2 = selectrandomunique(df)n    if i == 0:n        population = sf df2n    else:n        population = np.vstack((populationsf df2))nnnThis however produces difficulties in further data manipulation as in order to evaluate the fitness function I need to access an array element in the dataframe which is in turn an array element.nnI was wondering if you can think of something more efficient.nnThanks!n"" nan",['pandas'],['pandas']
40099777,"'??? .head() displays 5 rows without mentioning it' ""I'm confused here. nBelow is command to view the dataset shape:nn   In df_faa_dataset.shapen   Out (83 42)nnnNow I want to see first 5 rows and entered command:nnIn df_faa_dataset.head()nOut (displayed output with 5 rows Ãx97 42 columns)nnnHow come by default .head() method took 5 rows without mentioning in the bracket? n"" 'link to official docsnnlink to stackoverflow docsnncopied from documentation nnnDataFrame.head(n=5)nReturns first n rowsnnnnIt is how we establish default parameter values in python.  For the head method n=5 means that the default value is 5 and consequently if you do not pass a parameter value yourself then 5 is used.n'",['pandas'],['pandas']
40099817,"'What is the best way to ""force"" users to use a certain file extension with argparse?' 'I have a script which users include the pathnames for the input and output files. nnimport argparsennparser = argparse.ArgumentParser()nparser.add_argument(""i"" help = ""input path"")nparser.add_argument(""o"" help = ""output path"")nargs = parser.parse_args()nfile_input = args.inputnfile_output = args.outputnnnNow I want to make sure that users create an output file that is a text file with extension .txt. nn(1) I could possible through an error telling users that they must use a txt extension. nn(2) I could check whether a .txt extension has been used. If not I would simply add it. nnThe first is relatively easy:nnimport argparsennparser = argparse.ArgumentParser()nparser.add_argument(""i"" help = ""input path"")nparser.add_argument(""o"" help = ""output path"")nargs = parser.parse_args()nfile_input = args.inputnfile_output = args.outputnif file_output.endswith(""txt"") != True:n    raise argparse.ArgumentTypeError('File must end in extension .txt!')nnnHow would one accomplish the latter? n' ""You could define a type function that adds the required extension e.g.nndef txtname(astr):n    if not astr.endswith('.txt'):n        astr += '.txt'n    return astrnnIn 724: parser=argparse.ArgumentParser()nIn 725: parser.add_argument('-i'type=txtname);nIn 726: parser.add_argument('-o'type=txtname);nIn 728: parser.parse_args('-i''inname''-o''oname.txt')nOut728: Namespace(i='inname.txt' o='oname.txt')nnnThat function could also raise a ValueError if you don't like certain extensions or forms of filename.n""",['python-3.x'],"['python-3.x', 'python-2.7']"
40099866,"'slicing the last second word in python' ""i need to write a python script that will count the next-to-last word . my code is:nnwith open('/tmp/values.txt') as f:n    for sentence in f:n        list_sentecne = sen for sen in sentence.rstrip().split(' ')nnprint (list_sentecne)nop = list_sentecne-2:-2nprint (op)nnnoutput i got is:-nn'some' 'line' 'with' 'text'nnnnoutput that i need to get is :nnwithnnnMy idea is to use slicing  so i used -2:-2 such that it will print 2nd word from last in the list but when i run the script i am getting 'empty list' at the output.n"" ""Yo need to print from 2nd last element from list - nn>>> list_sentecne = 'some' 'line' 'with' 'text'n>>> op = list_sentecne-2:n>>> print (op)n'with' 'text'nnnif only the 2nd last element nn>>> list_sentecne = 'some' 'line' 'with' 'text'n>>> op = list_sentecne-2n>>> print (op)n'with'nn""","['python-2.7', 'python-3.x']","['list', 'python-2.7']"
40099924,"'Drop ""faulty"" lines of pandas dataframe based on their type and value' ""I have a dataset that includes a column of date and time values and another column containing some measured values (float). However during some measurements an error occured resulting in some weird entries - example below (these include a repeated part of the datetime object which is interpreted as string incomplete datetime object a completely random string a missing value or a value for the other column which is way out of range (measured values are mostly between 10 and 50 but sometimes I get a zero or a value like 100).nnextract from the large dataset (loaded as pandas dataframe):nn                                      t                          baaan0                      13/11/2014 23:43                          17.6n1                      13/11/2014 23:44                          17.7n2   2014-11-13 23:452014-11-13 23:45:00                          17.7n3                      13/11/2014 23:46                          17.7n4                      14/11/2014 00:34                            16n5                      14/11/2014 00:35                          15.9n6                                   :00                          17.7n7                      14/11/2014 01:25                          14.9n8                      14/11/2014 01:26                          14.9n9                                     0                            80n10                     14/11/2014 02:16                          14.3n11                     14/11/2014 02:17                          14.3n12                                  NaN  AA550112209500080009002855AAn13                     14/11/2014 03:09                            13n14                      009000B002B55AA                           NaNn15                     14/11/2014 02:19                          14.3n16                     14/11/2014 03:59                          12.6n17                     14/11/2014 04:00                          12.6n18                     14/11/2014 05:41                          11.7n19                     14/11/2014 05:42                          11.7n20                                    0                           140n21                     14/11/2014 04:53                          12.2nnnexamples of all types of faulty entries are here.nHow can I get rid of the faulty lines?nMy idea was to do an if loop setting the condition that the 't' column should be a datetime object and the 'baaa' columns should be a float > 0 and < 60. If the condition is not fulfilled I would replace the value with np.nan and eventually use the dropna function. nndf't' = pd.to_datetime(df't' format = '%d/%m/%Y %H:%M' errors='coerce')ndf.iloc:1 = pd.to_numeric(df.iloc:1 errors='coerce')    nfor line in df.iloc:1:  n    if (line < 60) & (line > 0):n       line = linen   else:n       line = np.nann    # not assigning this new value! :( nn    df = df.dropna(subset = df.columns.values how='any' inplace=True)nnnThis seems to have solved most of the problems except the condition that the line needs to be lower than 60.nI must have a wrong syntax? Or what is wrong here?nThanks!n"" 'I think you need boolean indexing for filtering instead dropna you can add new (third) condition with notnull - get all not NaN values in column t. NaN values in first column are filtered by first and second condition:nndf't' = pd.to_datetime(df't' format = '%d/%m/%Y %H:%M' errors='coerce')ndf.iloc:1 = pd.to_numeric(df.iloc:1 errors='coerce')  ndf = df(df.iloc:1 < 60) & (df.iloc:1 > 0) & (df't'.notnull())nnprint (df)n                     t  baaan0  2014-11-13 23:43:00  17.6n1  2014-11-13 23:44:00  17.7n3  2014-11-13 23:46:00  17.7n4  2014-11-14 00:34:00  16.0n5  2014-11-14 00:35:00  15.9n7  2014-11-14 01:25:00  14.9n8  2014-11-14 01:26:00  14.9n10 2014-11-14 02:16:00  14.3n11 2014-11-14 02:17:00  14.3n13 2014-11-14 03:09:00  13.0n15 2014-11-14 02:19:00  14.3n16 2014-11-14 03:59:00  12.6n17 2014-11-14 04:00:00  12.6n18 2014-11-14 05:41:00  11.7n19 2014-11-14 05:42:00  11.7n21 2014-11-14 04:53:00  12.2nn'",['pandas'],['pandas']
40099936,"""First django projectshowing error no module named 'polls'"" ""I followed the Django official documentand I am writing the poll app.nnAnd  in the mysite package it says   No module named 'polls' when I run ithow can I solve it?nnmy python is 3.6my Django is 1.10.2nnthis is my directorynnâx94x9câx94x80âx94x80 db.sqlite3nâx94x9câx94x80âx94x80 manage.pynâx94x9câx94x80âx94x80 mysitenâx94x82   âx94x9câx94x80âx94x80 __init__.pynâx94x82   nâx94x82   âx94x9câx94x80âx94x80 __pycache__nâx94x82   âx94x9câx94x80âx94x80 settings.pynâx94x82   nâx94x82   âx94x9câx94x80âx94x80 urls.pynâx94x82   âx94x94âx94x80âx94x80 wsgi.pynâx94x94âx94x80âx94x80 pollsn    âx94x9câx94x80âx94x80 __init__.pyn    âx94x9câx94x80âx94x80 __pycache__n    âx94x9câx94x80âx94x80 admin.pyn    âx94x9câx94x80âx94x80 models.pyn    âx94x9câx94x80âx94x80 tests.pyn    âx94x9câx94x80âx94x80 urls.pyn    âx94x9câx94x80âx94x80 views.pyn    âx94x94âx94x80âx94x80 apps.pynnnmysiteurls.pynnfrom django.conf.urls import include urlnfrom django.contrib import adminnimport pollsnurlpatterns = n    url(r'^polls/' include('polls.urls'))n    url(r'^admin/' admin.site.urls)n   nnnINSTALLED_APPS in settings.pynn INSTALLED_APPS = n'django.contrib.admin'n'django.contrib.auth'n'django.contrib.contenttypes'n'django.contrib.sessions'n'django.contrib.messages'n'django.contrib.staticfiles'n'polls'nn nnnAnd there is another problem in the documentthe document types:nnfrom django.conf.urls import urlnnfrom . import viewsnnurlpatterns = nurl(r'^$' views.index name='index')n   nnnWhen i run itit says cannot import name 'views'i delete the from .then it works.But the problem above still don't solvecan anyone tell me why??n"" ""Sounds like you don't have the polls app installed.nnGo to settings.py inside it find INSTALLED_APPS = ... and add 'polls' to that list.n"" ""I have a feeling this problem is related to the setup environment. nnFor your first problem try url(r'^polls/' include('mysite.polls.urls'))nnFor your second problem try from polls import views or just stick with import views.nnIf this doesn't work I suggest restarting the tutorial because clearly the environment has not been setup accordingly. The code is perfectly fine in the other hand.n""",['django'],['django']
40100159,"'Python: multithreading setting the variable once' 'Does the following code thread-safe?nWill only one/first thread set the variable set_this_var_only_once?  nnset_this_var_only_once = Nonenndef worker():n    global set_this_var_only_oncen    if set_this_var_only_once is None:n        set_this_var_only_once = ""not None""nnfor i in range(10):n    t = threading.Thread( target=worker )n    t.daemon=Truen    t.start()nn' 'Absolutely not.nnIt is quite possible that two threads execute this line before executing the next one:nn    if set_this_var_only_once is None:nnnAfter that both threads will execute the next line:nn        set_this_var_only_once = ""not None""nnnYou can use locks to prevent that:nnlock = threading.Lock()nndef worker():n    lock.acquire()n    if set_this_var_only_once is None:n        set_this_var_only_once = ""not None""n    lock.release()nnnOnly one thread will be able to acquire the lock. If another thread tries to acquire it while it is locked the call to lock.acquire() will block and wait until the lock is released by the first thread. Then the lock will be acquired by the other thread.nnThat way it is ensured that the code between lock.acquire() and lock.release() is executed in one thread at a time.nnEDITnnAs Gerhard pointed in the other answer you can use the context management protocol with locks:nnwith lock:n    if set_this_var_only_once is None:n        set_this_var_only_once = ""not None""nnnThat will also make sure the lock is correctly released in case of an exception within the locked block.n' 'No it's not. nnn  If another thread gets control after the current thread has fetchedn  the variable it may fetch the variable increment it and write itn  back before the current thread does the same thing. And since theyâx80x99ren  both seeing the same original value only one item will be accountedn  for.nnnHere's this good article about it. nnP.S. Also the following line is needed in the worker(): nnglobal set_this_var_only_once nn' 'You need to lock the variable like this:nnfrom threading import Locknnlock = Lock()nset_this_var_only_once = Nonenndef worker():n    with lock:n        if set_this_var_only_once is None:n            set_this_var_only_once = ""not Nonenn'",['python-2.7'],['python-2.7']
40100176,"'Can dask parralelize reading fom a csv file?' 'I'm converting a large textfile to a hdf storage in hopes of a faster data access. The conversion works allright however reading from the csv file is not done in parallel. It is really slow (takes about 30min for a 1GB textfile on an SSD so my guess is that it is not IO-bound). nnIs there a way to have it read in multiple threads in parralel?nSice it might be important I'm currently forced to run under Windows -- just in case that makes any difference.nnfrom dask import dataframe as ddfndf = ddf.read_csv(""data/Measurements*.csv""n             sep=';' n             parse_dates=""DATETIME"" n             blocksize=1000000n             )nndf.categorize( 'Type'n                'Condition'               n          )nndf.to_hdf(""data/data.hdf"" ""Measurements"" 'w')nn' 'Yes dask.dataframe can read in parallel.  However you're running into two problems:nnPandas.read_csv only partially releases the GILnnBy default dask.dataframe parallelizes with threads because most of Pandas can run in parallel in multiple threads (releases the GIL).  Pandas.read_csv is an exception especially if your resulting dataframes use object dtypes for textnndask.dataframe.to_hdf(filename) forces sequential computationnnWriting to a single HDF file will force sequential computation (it's very hard to write to a single file in parallel.)nnSolutionnnBecause your dataset likely fits in memory use dask.dataframe.read_csv to load in parallel with multiple processes then switch immediately to Pandas.nnimport dask.dataframe as ddnimport dask.multiprocessingnndf = df = ddf.read_csv(""data/Measurements*.csv""  # read in paralleln             sep=';' n             parse_dates=""DATETIME"" n             blocksize=1000000n             )nndf = df.compute(get=dask.multiprocessing.get)     # convert to pandasnndf'Type' = df'Type'.astype('category')ndf'Condition' = df'Condition'.astype('category')nndf.to_hdf('data/data.hdf' 'Measurements' format='table' mode='w')nn'",['pandas'],['pandas']
40100199,"'Django display a photo from a model' 'I've tried several of methods on how to retrieve an image from a model with no luck this is where I'm at so far. I'd like to have the image show and when the user clicks on it it opens a modal showing a projects detail.nnmodels.pynnclass Project(models.Model):n   author = models.ForeignKey('auth.User')n   title = models.CharField(max_length=200)n   client = models.CharField(max_length=200)n   date = models.DateField(timezone.now())n   service = models.CharField(max_length=200)n   info = models.TextField()n   photo = models.ImageField(upload_to='ports/static/img/'n                          default='ports/static/img/port_photo.png'n                          height_field='photo_height'n                          width_field='photo_width')n   photo_height = models.PositiveIntegerField(blank=True default=900)n   photo_width = models.PositiveIntegerField(blank=True default=650)n   created_date = models.DateTimeField(n    default=timezone.now)n   published_date = models.DateTimeField(n    blank=True null=True)nnnnnindex.htmlnn<section id=""portfolio"">n    {% for project in projects %}n        <div class=""row"">n            <div class=""col-lg-12 text-center"">n                <h2>Portfolio</h2>n                <hr class=""star-primary"">n            </div>n        </div>n        <div class=""row"">n            <div class=""col-sm-4 portfolio-item"">n                <a href=""#portfolioModal1"" class=""portfolio-link"" data-toggle=""modal"">n                    <div class=""caption"">n                        <div class=""caption-content"">n                            <i class=""fa fa-search-plus fa-3x""></i>n                        </div>n                    </div>n                    <img src=""{{ projects.photo.url }}"" class=""img-responsive"" alt="""">n                </a>n            </div>n        </div>n    </div>n    {% endfor %}n</section>nnnviews.pynnfrom django.shortcuts import rendernfrom .forms import ContactFormnfrom django.utils import timezonenfrom .models import Projectn# Create your views here.nnndef index(request):n    form_class = ContactFormn    projects = Project.objects.filter(published_date__lte=timezone.now()).order_by('-published_date')n    return render(request 'ports/index.html' {'form': form_class 'projects': projects})nn' 'Look at your img tag. In the src attribute you are using {{ projects.photo.url }}. So you cannot get image from a queryset you can only do so from an object of Project model. Use {{ project.photo.url }}n'",['django'],['django']
40100256,'How to use python diff_match_patch to create a patch and apply it' 'I'm looking for a pythonic way to compare two files file1 and file2 obtain the differences in form of a patch file and merge their differences into file2. The code should do something like this:nndiff file1 file2 > diff.patchnapply the patch diff.patch to file2 // this must be doing something like git apply.nnnI have seen the following post Implementing Google's DiffMatchPatch API for Python 2/3 on google's python API dif_match_patch to find the differences but I'm looking for a solution to create and apply patch. nnThanks in advance.n' nan,['python-3.x'],['python-2.7']
40100340,'numpy multivariate_normal bug when dimension too high' 'I am working on a homework assignment and I noticed that when the dimension of mean and covariance is very high multivariate_normal will occupy all CPU forever without generating any results. nnAn example code snippet nn    cov_true  = np.eye(p)n    mean_true = np.zeros(p)n    beta_true = multivariate_normal(mean_true cov_true size=1).Tnnnwhen p=5000 this will run forever. nenvironment python3.4 and python3.5 numpy 1.11.0 nnIs it really a bug or did I miss something? n' nan,['numpy'],"['numpy', 'python-3.x']"
40100341,"'Django where in queryset with comma separated slug in url' 'I have a Post Modelnnmodels.pynnclass Category(models.Model):n    title = models.CharField(max_length=100null=Trueblank=False)n    slug = models.SlugField(max_length=150null=Trueblank=False)nnclass Post(models.Model):n    title = models.CharField(max_length=256null=Trueblank=False)n    categories = models.ManyToManyField(Category)nnnSo in view I need to query all the posts with specific category for examplenThis is the url http://example.com/?category=slug1slug2 or http://example.com/?category=12 - PK or slug will be usednnviews.pynnclass PostList(TemplateView):n    ...n    def get(selfrequest*args**kwargs):n        categories = request.GET.get('category')n        post_list = Post.objects().filter(categories__in=categories)n    ...nnnThe above view throws error as invalid literal for int() with base 10: '' because of passing comma separated strings but how can I achieve this?n' ""Comma separated you're going to have to do this by hand:nncategories = request.GET.get('category').split('')nnThe more Django way to do this it so change your query string to benn?category=slug1&category=slug2.  nnThen you could usenncategories = request.GET.getlist('category')n""",['django'],['django']
40100405,"'Python 2.7: Variable ""is not defined""' 'I'm using Physionet's data base for some tasks related to ECG signal analysis. I wanted to read .MAT files extract the MLII readings on the file (located throughout row 1) adjust the signal to mV using ""gain"" and ""base"" (located in the .INFO filed also supplied by Physionet) and finally print the signal values and its period.nnI wanted to write a script that could do all of those things to all the files in one folder. Before this I wrote one in which I could do everythin mentioned above and it worked nicely. nnBut the script that would manage all the .mat and .info files in my folder is giving me problems with the variables. I tried using the 'global' command in the very beginning of my succession of IFs but it kept sending a similar error message. nnThis is the code:nnimport osnimport scipy.io as sionimport numpy as npnimport renimport matplotlib.pyplot as pltnnfor file in os.listdir('C:blablablablablaMultiple .mat files'):n    if file.endswith("".mat""):n        file_name=os.path.splitext(file)n        ext_txt="".txt""n        ext_info="".info""n        if file.endswith("".info""):n            f=open(file_name0+ext_info'r')n            k=f.read()n            f.close()n            j=re.findall('d+' k)n            Fs=j9n            gain=j13n            base=j14nn        RawData=sio.loadmat(file)n        signalVectors=RawData'val'n        ab=signalVectors.shapen        signalVectors_2=np.true_divide((signalVectors-gain)base)n        ecgSignal=signalVectors_211:n        T=np.true_divide(np.linspace(1bnum=b-1)Fs)n        txt_data=np.array(ecgSignal T)n        txt_data=txt_data.Tn        f=open(file_name0+ext_name'w')n        np.savetxt(file_name0+ext_txttxt_datafmt='%.8f''%.8f')n        f.close()nnnThe error message I get is: nn> File ""C:blablablablablaMultiple .mat filesecg_mat_multi.py"" line 24 in <module>n    signalVectors_2=np.true_divide((signalVectors-gain)base)nNameError: name 'gain' is not definednnnThe problem comes with the variables 'gain' 'base' and 'Fs'. I tried to define them as global variables but that didn't make a difference. Can you help me fix this error please?nnThanks a lot for your time and help.nnEDIT 1: copied the error message below the script. nEDIT 2: Changed the post title and erased additional questions. n' 'Use two loops and extract the info before processing the data filesnnfor filepath in os.listdir('C:blablablablablaMultiple .mat files'):n    if filepath.endswith("".info""):n        Fs gain base = get_info(filepath)n        breaknfor file in os.listdir('C:blablablablablaMultiple .mat files'):n    if file.endswith("".mat""):n        file_name=os.path.splitext(file)n        ...n        RawData=sio.loadmat(file)n        signalVectors=RawData'val'n        ...nnnnnI was working off your first edit so I'll include this even though the question has been streamlinednn# foo.infonSource: record mitdb/100 Start: 00:00:10.000nval has 2 rows (signals) and 3600 columns (samples/signal)nDuration: 0:10nSampling frequency: 360 Hz Sampling interval: 0.002777777778 secnRow Signal  Gain    Base    Unitsn1   MLII    200 1024    mVn2   V5  200 1024    mVnnTo convert from raw units to the physical units shownnabove subtract 'base' and divide by 'gain'.nnnI would also write a function that returns the info you want. Using a function to extract the info makes the code in your loop more readable and it makes it easier to test the extraction.nnSince the file is well structured you could probably iterate over the lines and extract the info by counting lines and using str.split and slices.nnThis function uses regex patterns to extract the info:nn# regex patternsnhz_pattern = r'frequency: (d+) Hz'nmlii_pattern = r'MLIIt(d+)t(d+)'nndef get_info(filepath):n    with open(filepath) as f:n        info = f.read()n    match = re.search(hz_pattern info)n    Fs = match.group(1)n    match = re.search(mlii_pattern info)n    gain base = match.groups()n    return map(int (Fs gain base))nnnnnIf there are multiple .info and .mat files in a directory you want to ensure you extract the correct info for the data.  Since the .info file has the same name as the .mat file that it belongs to sort the directory list by name then group by name -this will ensure you are operating on the two files that are related to each other.nnimport itertoolsndef name(filename):n    name extension = filename.split('.')n    return namennfiles = os.listdir('C:blablablablablaMultiple .mat files')nfiles.sort(key = name)nfor fname _ in itertools.groupby(files key = name):n    fname_info = name + '.info'n    fname_data = name + '.mat'n    Fs gain base = get_info(fname_info)n    # process datafilenn'",['python-2.7'],"['python-2.7', 'numpy']"
40100419,"'Variables in import statement python' 'I'm trying to convert a script I had from bash to python. The way the program worked is that it had a Master script in the top folder and then in the subfolder Scripts a series of smaller more specialised scripts. These smaller scripts might have names such as foo_bar.x bar_foo.x foo_baz.x foo_qux.x bar_qux.x and so on. The Master script would collect the variables (as defined in files or from command line arguments) and execute the appropriate script with this sort of syntax:nnVAR1=foonVAR2=barn./Scripts/${VAR1}_${VAR2}.xnnnThis would execute Scripts/foo_bar.xnnNow I'm trying to do the same but in python. The scripts are now modules in the folder Modules named foo_bar.py foo_qux.py and so on. For now the only thing they have is:nndef test():n        print ""This is foo_bar.""nnn(or whichever).nnIf use these commands this happens:nn>>> import Modules.foo_barn>>> Modules.foo_bar.test()nThis is foo_bar.n>>> import Modules.foo_quxn>>> Modules.foo_qux.test()nThis is foo_qux.n>>> a = Modules.foo_barn>>> a.test()nThis is foo_bar.nnnWhich is fine. However I can't get the syntax right if I want to use variables in the import statement. The first variable is defined as the string output of a command and the second is a dictionary entry. Trying to use them in an import command gives an error.nn>>> var1 = a_file.read_value()n>>> print var1nfoon>>> print dict'var2'nbarn>>> import Modules.var1_dict'var2'n  File ""<stdin>"" line 1n    import Modules.var1_dict'var2'n                            ^nSyntaxError: invalid syntaxnnnI assume it's a question of having the correct quotes or parentheses to properly invoke the variables. I've tried a bunch of combinations involving single quotes curly brackets square brackets whatever but no dice. What am I missing?n' ""If you want to import a module whose name is in a variable you need to use __import__.nnFor example let's create a dictionary whose values are the names of modules:nn>>> d = { 1:'re' 2:'numpy' }nnnNow let's import one of them:nn>>> x = __import__(d1)n>>> xn<module 're' from '/usr/lib/python2.7/re.pyc'>nnnWe can use the module as long as we refer to it by the name we have given it:nn>>> s='jerry'; x.sub('j' 'J' s)n'JerrynnnAnd to import the other:nn>>> y = __import__(d2)n>>> yn<module 'numpy' from '/home/jll/.local/lib/python2.7/site-packages/numpy/__init__.pyc'>n>>> y.array(132)narray(1 3 2)nn"" ""You can use the importlib library. And use like this:nn...nimport importlibn...nn    function_call = 'Modules.' + var1 + dict'var2'n    function_call = importlib.import_module(function_call) n    function_call.test()nn"" 'How about executing your import statement dynamically? nnDummy example :nnd = {""a"" : ""path""}nexec(""import os.%s""%d""a"")nprint os.path.abspath(__file__)nn'",['python-2.7'],['python-2.7']
40100446,'Django API query optimization' 'I have a Django application wherein I need to do a POST operation on an API. As the time taken for POST operation is high I was reading this nice material to gain more insight into the situation.nnI have a question here. I am using select_related and prefetch_related in my code to reduce the number of database trips but I see that the queries get more and more complex with things like JOIN etc.nnSo I wanted to know the following:nnWhich is better with respect to time?? A very complex SQL query for a single database trip or 2 simple SQL queries for 2 database trips.n' nan,['django'],['django']
40100447,'Django writes to DB before each GET http request.' 'I am using django via scalearc for the database ScaleArc establishes connection to respective database depending on read/write Query.nWhen I do GET call django is sending following query to database due to that its always connecting to Write database.   nnSET NAMES utf8  nset autocommit=0  nset autocommit=1  nSET SQL_AUTO_IS_NULL = 0  nnnHow do I avoid these calls in Django?n' nan,['django'],['django']
40100856,"'More pythonic way of updating an existing value in a dictionary' ""Lets assume I got a dictionary _dict and a variable n.nn_dict = {'a': 9 'b': 7 'c': 'someValue'}nn = 8nnnI want to update just a single entry e.g. {'b': 7} only if the value of n is greater than the actual value of b.nThe solution I got so far isnn_dict.update({'b': n for key value in _dict.items() if key == 'b' and n > value})nnnWhich provides the desired result of {'a': 9 'b': 8 'c': 'someValue'}. So now to my question: Is there a shorter more pythonic way of doing this? (preferably without importing additional modules)n"" ""Its as simple as thatnnif n > _dict'b':n    _dict'b' = nnn"" ""if n > _dict'b':n   _dict'b' = nnn"" ""There is no point in looping if you just need to update one key:nn_dict'b' = max(_dict'b' n)nnnThe above sets 'b' to the highest value of the two.n""",['dictionary'],"['dictionary', 'python-2.7']"
40101130,"'how do I calculate a rolling idxmax' ""consider the pd.Series snnimport pandas as pdnimport numpy as npnnnp.random.seed(31415)ns = pd.Series(np.random.randint(0 10 10) list('abcdefghij'))nsnna    0nb    2nc    7nd    3ne    8nf    7ng    0nh    6ni    8nj    6ndtype: int64nnnI want to get the index for the max value for the rolling window of 3nns.rolling(3).max()nna    NaNnb    NaNnc    7.0nd    7.0ne    8.0nf    8.0ng    8.0nh    7.0ni    8.0nj    8.0ndtype: float64nnnWhat I want isnna    Nonenb    Nonenc       cnd       cne       enf       eng       enh       fni       inj       indtype: objectnnnWhat I've donenns.rolling(3).apply(np.argmax)nna    NaNnb    NaNnc    2.0nd    1.0ne    2.0nf    1.0ng    0.0nh    0.0ni    2.0nj    1.0ndtype: float64nnnwhich is obviously not what I wantn"" 'There is no simple way to do that because the argument that is passed to the rolling-applied function is a plain numpy array not a pandas Series so it doesn't know about the index.  Moreover the rolling functions must return a float result so they can't directly return the index values if they're not floats.nnHere is one approach:nn>>> s.indexs.rolling(3).apply(np.argmax)2:.astype(int)+np.arange(len(s)-2)nIndex(u'c' u'c' u'e' u'e' u'e' u'f' u'i' u'i' dtype='object')nnnThe idea is to take the argmax values and align them with the series by adding a value indicating how far along in the series we are.  (That is for the first argmax value we add zero because it is giving us the index into a subsequence starting at index 0 in the original series; for the second argmax value we add one because it is giving us the index into a subsequence starting at index 1 in the original series; etc.)nnThis gives the correct results but doesn't include the two ""None"" values at the beginning; you'd have to add those back manually if you wanted them.nnThere is an open pandas issue to add rolling idxmax.n' 'Here's an approach using broadcasting -nnmaxidx = (s.valuesnp.arange(s.size-3+1):None + np.arange(3)).argmax(1)nout = s.indexmaxidx+np.arange(maxidx.size)nnnThis generates all the indices corresponding to the rolling windows indexes into the extracted array version with those and thus gets the max indices for each window. For a more efficient indexing we can use NumPy strides like so -nnarr = s.valuesnn = arr.strides0nmaxidx = np.lib.stride_tricks.as_strided(arr n                   shape=(s.size-3+13) strides=(nn)).argmax(1)nn' 'I used a generatornndef idxmax(s w):n    i = 0n    while i + w <= len(s):n        yield(s.iloci:i+w.idxmax())n        i += 1nnpd.Series(idxmax(s 3) s.index2:)nnc    cnd    cne    enf    eng    enh    fni    inj    indtype: objectnn' ""You can also simulate the rolling window by creating a DataFrame and use idxmax as follows: nnwindow_values = pd.DataFrame({0: s 1: s.shift() 2: s.shift(2)})ns.indexnp.arange(len(s)) - window_values.idxmax(1)nnIndex('a' 'b' 'c' 'c' 'e' 'e' 'e' 'f' 'i' 'i' dtype='object' name=0)nnnAs you can see the first two terms are the idxmax as applied to the initial windows of lengths 1 and 2 rather than null values. nIt's not as efficient as the accepted answer and probably not a good idea for large windows but just another perspective. n""","['pandas', 'numpy']","['pandas', 'numpy']"
40101257,"'Serving excel file via django' 'Hello I have seen many similar posts like this but I am not able to solve my problem. So from client side i am uploading a excel file (.xls) and then in django view i am performing some task and then want to return the same excel file with some errors written at the end of the same file as response. nnI have two problem firstly how to write on the same file and returning into the response without saving it. secondly the file i am recieving at the client side is encoded i am not able to decode.nnMy client side for uploading file is:nn<form id=""upload_excel"" method=""post"" enctype=""multipart/form-data"">n    <p>File Upload</p><br>n    <p>Select File</p><br>n    <input id=""csv"" name=""csv"" type=""file"" />n    <input type=""submit"" value=""submit""/> n</form>nnnHandling it in djangonnclass Upload(APIView):n""""""Handle upload files.""""""nndef post(self request *args **kwargs):n    """"""POST call.""""""n    error_list = n    filehandle = request.FILES.get('csv')nn    data = filehandle.read()n    book = xlrd.open_workbook(file_contents=data encoding_override='utf8')n    wb_sheet = book.sheet_by_index(0)n    for rownum in range(1 wb_sheet.nrows):nn        try:n            row = wb_sheet.row_values(rownum)nn            // some taskn    wb = copy(book)n    wb_sheet = wb.get_sheet(0)nn    for errors in error_list:n        wb_sheet.write(last_row 0 errors)n        last_row += 1nn    wb.save(""output.xls"") // this i don't want to donn    res = HttpResponse(data content_type='application/vnd.ms-excel')n    res'Content-Disposition' = 'attachment; filename=""Output_Report.xls""'nn    return resnnnNow at client side I am handling like thisnn  $('#upload_excel').submit(function(event){n  event.preventDefault();nn  var formData = new FormData($(this)0);n  console.log(formData);n  $.ajax({n      url: domain_address + ""/upload""n      type: ""POST""n      data: formDatan      headers: {n      processData: false // tell jQuery not to process the datan      contentType: falsen      enctype: 'multipart/form-data'n      success: function(jqXHR data textStatus errorThrown) {n        var charset = ""utf-8"";nn        blob = new Blob(jqXHR { type: 'application/vnd.ms-excel; charset=utf-8' });n        saveAs(blob ""Output_Report.xls"");n        console.log(blob);n        console.log(""success"");n      }n      error: function(jqXHR data textStatus errorThrown) {n          alert(data);n          // window.location.reload();n      }n  });n  });nnnI am using FileSaver.js to save the file. But i am getting encoded file.nResponse headers are:nnAllow:POST OPTIONSnContent-Disposition:attachment; filename=""Output_Report.xls""nContent-Type:application/vnd.ms-excelnDate:Tue 18 Oct 2016 06:40:24 GMTnServer:WSGIServer/0.1 Python/2.7.6nVary:Accept CookienX-Frame-Options:SAMEORIGINnn' nan",['django'],['django']
40101329,"'Python - change all specific values in a dictionary' 'I have some problem with constructing a phonebook I have a function that adds names and number a function that makes an alias for the person (two numbers have two diffrent names). And a change function which im having problems with. I want the function to change the number for one person and all its aliases. My code looks like this:nnclass Phonebook: #vi skapar en klassnn    def __init__(self): #fÃ¶r att initiera scriptet (constructor)n        self.pb={} #dictionarynn    def add(selfnamnnummer):n        if namn in self.pb:n            print ""Name already in contacts!"" #kolla om namnet finnsn        elif nummer in self.pb.viewvalues(): #kolla om numret finnsn            print ""Number already exists for a contact!""n        else:n            self.pbnamn=nummer #lÃ¤gga till namn med tel.nrnn    def lookup(selfnamn):n        if namn in self.pb:n            printn            print self.pbnamn #skriver ut numret till namnetn            printn        else:n            print ""Name is not in contacts""n            print nn    def alias(selfnamnnummer):n        self.pbnummer=self.pbnamn #tvÃ¥ namn fÃ¥r samma nummernn    def change(selfnamnnummer):n        if namn in self.pb:n            for godtyckligt in self.pb:n                if self.pbnamn==self.pbgodtyckligt:n                    self.pbgodtyckligt=nummernnnWhat can I change in my change function and/or in my alias function? Thanks.n' 'If I understood you correctly you need to replace old number for some name then add the new number as an alias set it to the name and then remove the old number as alias:nndef change(selfnamnnummer):n    old_number = '' n    if namn in self.pb:n        for godtyckligt in self.pb:n            if self.pbnamn==self.pbgodtyckligt:n                old_nummer = self.pbgodtyckligtn                self.pbgodtyckligt=nummern                self.pbnummer=godtyckligt    n                del self.pb.pop(old_nummer)nnnYour alias method should be like this:nn#You need to define another dict aliasesn#aliases = {}nndef alias(self name0 name1):n    self.aliasesname0.append(name1)nnnAnd then change the lookup method:nndef lookup(selfnamn):n    if namn in self.pb:n        printn        print self.pbnamn #skriver ut numret till namnetn        printn        returnnn    else:n        for name in aliases:n            if namn in aliasesname:n                printn                print self.pbnamn #skriver ut numret till namnetn                printn                returnnn    print ""Name is not in contacts""n    print     n    returnnn'",['dictionary'],"['python-2.7', 'python-3.x']"
40101371,'How to replace each array element by 4 copies in Python?' 'How do I use numpy / python array routines to do this ?nnE.g. If I have array  1234  the output should be nn1122n 1122n 3344n 3344nnnThus the output is array of double the row and column dimensions. And each element from original array is repeated three times. nnWhat I have so far is thisnndef operation(matstep=2):n    result = np.array(matcopy=True)n    result::2::2 = matn    return resultnnnThis gives me array nn 98.+0.j   0.+0.j  40.+0.j   0.+0.jn   0.+0.j   0.+0.j   0.+0.j   0.+0.jn  29.+0.j   0.+0.j  54.+0.j   0.+0.jn   0.+0.j   0.+0.j   0.+0.j   0.+0.jnnnfor the inputnn98 40n 29 54nnnThe array will always be of even dimensions.n' 'Use np.repeat():nnIn 9: A = np.array(1 2 3 4)nIn 10: np.repeat(np.repeat(A 2).reshape(2 4) 2 0)nOut10: narray(1 1 2 2n       1 1 2 2n       3 3 4 4n       3 3 4 4)nnnExplanation: nnFirst off you can repeat the arrya items:nn  In 30: np.repeat(A 3)n  Out30: array(1 1 1 2 2 2 3 3 3 4 4 4)nnnthen all you need is reshaping the result (based on your expected result this can be different):nn  In 32: np.repeat(A 3).reshape(2 3*2)n  array(1 1 1 2 2 2n         3 3 3 4 4 4)nnnAnd now you should repeat the result along the the first axis:nn  In 34: np.repeat(np.repeat(A 3).reshape(2 3*2) 3 0)n  Out34: n  array(1 1 1 2 2 2n         1 1 1 2 2 2n         1 1 1 2 2 2n         3 3 3 4 4 4n         3 3 3 4 4 4n         3 3 3 4 4 4)nn' 'Another approach could be with np.kron -nnnp.kron(a.reshape(-12)np.ones((22)dtype=int))nnnBasically we reshape input array into a 2D array keeping the second axis of length=2. Then np.kron essentially replicates the elements along both rows and columns for a length of 2 each with that array : np.ones((22)dtype=int).nnSample run -nnIn 45: anOut45: array(7 5 4 2 8 6)nnIn 46: np.kron(a.reshape(-12)np.ones((22)dtype=int))nOut46: narray(7 7 5 5n       7 7 5 5n       4 4 2 2n       4 4 2 2n       8 8 6 6n       8 8 6 6)nnnIf you would like to have 4 rows use a.reshape(2-1) instead.n' 'The better solution is to use numpy but you could use iteration also:nna = 1 2 3 4nnv = iter(a0)nnb = nfor i in v:n    n = next(v)n    b.append(i for k in range(2) + n for k in range(2)) for j in range(2)nnprint bnn>>> 1 1 2 2 1 1 2 2 3 3 4 4 3 3 4 4nn',['numpy'],['numpy']
40101519,'Plotting event density in Python with ggplot and pandas' 'I am trying to visualize data of this form:nn  timestamp               senderIdn0     735217  106758968942084595234n1     735217  114647222927547413607n2     735217  106758968942084595234n3     735217  106758968942084595234n4     735217  114647222927547413607n5     etc...nnngeom_density works if I don't separate the senderIds:nndf = pd.read_pickle('data.pkl')ndf.columns = 'timestamp' 'senderId'nplot = ggplot(aes(x='timestamp') data=df) + geom_density()nprint plotnnnThe result looks as expected:nnnnHowever if I want to show the senderIds separately as is done in the doc it fails:nn> plot = ggplot(aes(x='timestamp' color='senderId') data=df) + geom_density()nValueError: `dataset` input should have multiple elements.nnnTrying out with a larger dataset (~40K events):nn> plot = ggplot(aes(x='timestamp' color='senderId') data=df) + geom_density()nnumpy.linalg.linalg.LinAlgError: singular matrixnnnAny idea? There are some answers on SO for those errors but none seems relevant.nnThis is the kind of graph I want (from ggplot's doc):nnn' nan,['pandas'],"['pandas', 'matplotlib']"
40101544,"'Python error with flattening list of lists' ""Hi I'm trying to flatten the following list of lists but I always get the following error:nn'int' object is not iterable nnI also tried chain from itertools but still not working. I guess the solution is easy but I really cannot see it! Anybody can help?nnThanksnn from itertools import chainnnimport operatornnlista = 123456789101112nnlistone = lista00-x0 for x in lista:2nn#sumlistone = chain.from_iterable(listone)nnsumlistone = x for sublist in listone for x in sublistnnprint listonennprint sumlistonenn"" 'Is this what you need?nnlista = 123456789101112nlistb = nnfor sub in lista:n    listb.extend(sub)    # Modification suggested by @Dinesh Pundkar nnprint(listb)nprint(sum(listb))nn'",['list'],"['list', 'python-2.7']"
40101631,"'How do I get a tkinter window to launch when running a program in PyCharm?' 'I recently started using PyCharm rather than IDLE for the programming course I am doing with the promise of being able to run programs without constantly having to save them and then go to the menu to type ""run in module"" to do so and to also have multiple files open in tabs to easily swap between.nnWhile this has been good for the later and I finally fixed a directory problem for the former the current project I am working on involves tkinter and PyCharm refuses to launch a tkinter window when the file is run. It can print statements fine and do calculations but it will not launch a tkinter window. The program works fine in IDLE but I'd rather not do all my editing in PyCharm only to constantly have to open and run it in IDLE to make the bloody window pop up. I'm using python 3.5.nnDoes anyone have a solution?n' nan","['python-3.x', 'tkinter']","['tkinter', 'python-3.x']"
40101705,'Unable to run Geany compiler' 'I am unable to run Geany python 3.5 (32 bit) compiler. Each time I hit execute I get the following response:  nnn  SyntaxError: invalid syntax.n  22:33:12: Could not open file C: UsersHowellDropboxPython35python (File not found)nnnI have verified that the file path is correct using windows 10 command prompt. I can also open python 3.5 with windows explorer using above path.n' nan,['python-3.x'],['python-3.x']
40101925,"'How to match rows based on certain columns in pandas?' ""I have a dataframe like this:nnid     date          event    name     timen1      2016-10-01    A        leader   12:45n2      2016-10-01    A        AA       12:87n3      2016-10-01    A        BB       12:45nnnThere are rows for each member in the event but one row has the leader data as well. I want to exclude the rows with the data about the leader and add a column is_leader to indicate whether a member is the leader or not. Something like this:nnid     date          event    name     time    is_leadern2      2016-10-01    A        AA       12:87   0n3      2016-10-01    A        BB       12:45   1nnnSo I know at id=3 is the leader based on the time which is 12:45 for both here. We can assume that this time won't be the same for any other members. nnWhat is an efficient way to accomplish this in pandas. Here I have just one event as an example but I'll have several of these and I need to do this for each event.n"" 'You can use groupby with custom function f which return new column is_leader with True for all rows where is same time as time of row with text leader in column name:nnprint (df)n   id       date event    name   timen0   1 2016-10-01     A  leader  12:45n1   2 2016-10-01     A      AA  12:87n2   3 2016-10-01     A      BB  12:45n3   1 2016-10-01     B  leader  12:15n4   2 2016-10-01     B      AA  12:15n5   3 2016-10-01     B      BB  12:45nndef f(x):n    x'is_leader' = x.time == x.ixx'name' == 'leader' 'time'.iloc0n    return xnndf= df.groupby('event').apply(f)nprint (df)n   id       date event    name   time is_leadern0   1 2016-10-01     A  leader  12:45      Truen1   2 2016-10-01     A      AA  12:87     Falsen2   3 2016-10-01     A      BB  12:45      Truen3   1 2016-10-01     B  leader  12:15      Truen4   2 2016-10-01     B      AA  12:15      Truen5   3 2016-10-01     B      BB  12:45     FalsennnnnOne row solution with lambda function:nndf'is_leader' = df.groupby('event')n                    .apply(lambda x: x.time == x.ixx'name' == 'leader' 'time'.iloc0)n                    .reset_index(drop=True level=0)nprint (df)n   id       date event    name   time is_leadern0   1 2016-10-01     A  leader  12:45      Truen1   2 2016-10-01     A      AA  12:87     Falsen2   3 2016-10-01     A      BB  12:45      Truen3   1 2016-10-01     B  leader  12:15      Truen4   2 2016-10-01     B      AA  12:15      Truen5   3 2016-10-01     B      BB  12:45     FalsennnThen remove rows with leader by boolean indexing and cast boolean column to int:nndf = dfdf.name != 'leader'ndf.is_leader = df.is_leader.astype(int)nprint (df)n   id       date event name   time  is_leadern1   2 2016-10-01     A   AA  12:87          0n2   3 2016-10-01     A   BB  12:45          1n4   2 2016-10-01     B   AA  12:15          1n5   3 2016-10-01     B   BB  12:45          0nn'",['pandas'],['pandas']
40102141,"'Performance issues in simulation with python lists' ""I'm currently writing a simulation in python 3.4 (miniconda).nThe entire simulation is quite fast but the measurement of some simulation data is bloody slow and takes about 35% of the entire simulation time. I hope I can increase the performance of the entire simulation if I could get rid of that bottleneck. I spend quite some time to figure out how to do that but unfortunately with little success. The function MeasureValues is called in every period of the simulation run.nnIf anybody has an idea how to improve the code I would be really grateful.nnThank you guys.nndef MeasureValues(self CurrentPeriod):n    if CurrentPeriod > self.WarmUp:n        self.ValueOneCurrentPeriod = self.FixedValueOne if self.FuturevalueCurrentPeriod + self.Reload > 0 else 0n        self.ValueTwoCurrentPeriod = self.VarValueTwo * self.AmountValueTwoCurrentPeriodn        self.ValueThreeCurrentPeriod = self.VarValueThree  * self.AmountValueThreeCurrentPeriodn        self.SumOfValuesCurrentPeriod = self.ValueOneCurrentPeriod + self.ValueTwoCurrentPeriod + self.ValueThreeCurrentPeriodn        self.TotalSumOfValues += self.SumOfValuesCurrentPeriodnn        self.HelperSumValueFour += self.ValueFourCurrentPeriodn        self.HelperSumValueTwo += self.AmountValueTwoCurrentPeriodn        self.HelperSumValueFive += self.ValueFiveCurrentPeriodnn        self.RatioOneCurrentPeriod = (1 - (self.HelperSumValueFour / self.HelperSumValueFive )) if self.HelperSumValueFive > 0 else 1n        self.RatioTwoCurrentPeriod = (1 - (self.HelperSumValueTwo  / self.HelperSumValueFive )) if self.HelperSumValueFive > 0 else 1nn"" 'The code looks basic enough that there aren't any obvious gaps for optimisation without substantial restructuring (which I don't know enough about your overall architecture to suggest).nnTry installing cython - I believe nowadays you can install it with pip install cython - then use it to see if you can speed up your code any.n' 'As stated in the comments the function is quite simple and with the provided code I don't see a way to change optimize it directly.nnYou can try different approaches:nnnPyPy this may works depending on your current codebase and external dependecies.nCython as suggested by holdenweb but you need to redefine a lot of stuff to be static-typed (using cdef) or nothing will change.nrewrite the function in C as a Python extension this may take some time especially if you have no experience in C programming.nnnThe PyPy way seems the most reasonable if it works you will gain a boost for all the simulations code.n'","['list', 'python-3.x']",['python-3.x']
40102274,"'Using a C function in Python' 'I've tried all the solutions mentioned on the internet so far nothing worked for me.nnI have a python code to speed it up I want that my code runs the heavy calculations in a C function.nI already wrote this C function.nnThen to share the library I did this in the terminal :nngcc -shared -Wl-install_nametestlib.so -o testlib.so -fPIC myModule.cnnnwhich returns no error. The problem; comes when i try to launch the C function in python. Let's consider the following simple function in C :nnint multiplier(int a int b)n{nnint lol = 0;nnlol = a*b;nnreturn lol;n}nnnI launch python3 (3.5.2) and then :nnimport ctypesnzelib = ctypes.CDLL(""/Users/longeard/Desktop/Codes/DraII/testlib.so""ctypes.RTLD_GLOBAL)nnnThe library should be ready to use in python by doing :nnres = zelib.multiplier(23)nnnWhen doing that it works and python returns nn6nnnProblem is that the function i want to use ( the multiplier function I use is just for the example ) is supposed to take floats as input and return a float. But if I now consider the same multiplier function as before but with float :nnfloat multiplier(float a float b)n{nnfloat lol = 0.0;nnlol = a*b;nnreturn lol;n}nnnI recompile using gcc I reimport ctypes and re-do ctypes.CDLL and I do in python3 :nnzelib.multiplier(ctypes.c_float(2)ctypes.c_float(3))nnn(the types.c_float are here to convert the 2 in python into a float in C ) python will return :nn2nnnThis is weird because if I add a printf within the function to print lol python will print :nn  6.0nnnbut still return 2 or 18 sometimes. Even though I printf and return the same variable ""lol"".nnI tried a lot of things and none of it worked. Do somebody have a idea please ? Thank You.n' 'You need to specify restype argtypes of the function:nnzelib = ctypes.CDLL('...')nzelib.multiplier.restype = ctypes.c_float   # return typenzelib.multiplier.argtypes = ctypes.c_float ctypes.c_float  # argument typesnnnAccording to Specifying the required argument types (function prototypes):nnn  It is possible to specify the required argument types of functions exported from DLLs by setting the argtypes attribute.nnnand Return types in ctypes module documentation:nnn  By default functions are assumed to return the C int type. Other return types can be specified by setting the restype attribute of the function object.nnnnn# without specifying typesn>>> import ctypesn>>> zelib = ctypes.CDLL('testlib.so')n>>> zelib.multiplier(2 3)n0nn# specifying typesn>>> zelib.multiplier.restype = ctypes.c_floatn>>> zelib.multiplier.argtypes = ctypes.c_float ctypes.c_floatn>>> zelib.multiplier(2 3)n6.0nn' ""While @falsetru's answer is the better way of doing it an alternative is to simply write your C function to use doubles.nnFloats are automatically promoted to double when  calling a function without a parameter list.n""",['python-3.x'],"['python-3.x', 'python-2.7']"
40102285,"'Pickling error in passing Pandas DataFrame to method call in multi processing' 'I was scratching my head over past few days why my method call in multiprocessing was failing and after drilling down further I realized that it was due to some DataFrames being passed as arguments to method which wasn't getting pickled. So as alternative to that I parsed the DataFrame to csv in my parent method passed the name of csv file to child method where I read csv to get the data. But this is pretty inefficient method so let me know where I did wrong. The following are my codes.nnDataFrames: 2 No.nnDataFrame: annFIELD_NAME                    objectnDEST_LOC_NBR                 float64nAPPT_NBR                     float64nSEQ_NBR                      float64nFIELD_NBR                    float64nCREATE_TS             datetime64nsnCREATE_USERID_V               objectnBEFORE_FIELD_VALUE            objectnAFTER_FIELD_VALUE             objectnCHNG_ORIGIN_I                float64nAPPT_ STAT_ NBR              float64nDESCRPTN                      objectnLOC_NBR_x                    float64nLOCN_ABBR_x                   objectnLOC_NBR_y                     objectnLOCN_ABBR_y                   objectnFRGT_TYP_NBR_x               float64nFRGT_TYP_DESC_x               objectnFRGT_TYP_NBR_y                objectnFRGT_TYP_DESC_y               objectnnnDataFrame: d1nnAPPT_NBR                             float64nAPPT_MERGE_F                          objectnAPPT_STAT_NBR                         objectnDEST_LOC_NBR                         float64nAPPT_TYP_NBR                         float64nLOC_NBR                              float64nFRGT_TYP_NBR                         float64nAPPT_FRT_TYP_AFTER_ARVL_TS            objectnAPPT_EMPTY_F                          objectnAPPT_ACTL_ARVL_TS             datetime64nsnAPPT_SCHD_ARVL_TS             datetime64nsnAPPT_NBR_OF_CNTRS                    float64nAPPT_NBR_OF_GOHS                     float64nCREATE_TS                     datetime64nsnLAST_UPD_TS                           objectnVERSION_NBR                          float64nAPPT_CLOSE_TS                         objectnAPPT_OPEN_TS                          objectnAPPT_UNCNFRMD_TS                      objectnAPPT_ORG_SCH_AR_TS                    objectnAPPT_CNCL_TS                          objectnAPPT_SUSP_TS                          objectnAPPT_ARCHV_TS                         objectnCARRIER                               objectnVND_NBR                              float64nYARD_AREA_NBR                        float64nCREATE_USERID_V                       objectnAPPT_ACTL_ARVL_D                      objectnAPPT_SCHD_ARVL_D                      objectndtype: objectnnnI tried even manually pickling on parent method and unpickle in child like I do for csv files but the same error raises.nnI first create random file names as this is Multi-threading process hence file name can't be same:nnfname = ''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(5))nfnames = dict()nfnames'a' = '{}_a.pkl'.format(fname)nfnames'd1' = '{}_d1.pkl'.format(fname)nfnames'file' = fnamennnAnd I pickle dataframes using the following:nnd1.to_pickle(fnames'd1')na.to_pickle(fnames'a')nnnAnd the following is my method call:nnp = multiprocessing.Process(target=ParallelLoopTest args=(dd fnames return_list final_col_dates d final_col_dates_mod iter self.DC self.start_hour_of_day))nnnWhile my method ParallelLoopTest definition is as follows:nndef ParallelLoopTest(dd fnames days_out_vars final_col_dates d final_col_dates_mod iter DC start_hour_of_day store):nn    a = pd.read_pickle(fnames'a')n    d1 = pd.read_pickle(fnames'd1')nn    df = pd.read_pickle('{}_df.pkl'.format(fnames'file'))nnnAnd I face the following error:nnTraceback (most recent call last):n  File ""C:UsersdkanharAnaconda3libmultiprocessingprocess.py"" line 249 in _bootstrapn    self.run()n  File ""C:UsersdkanharAnaconda3libmultiprocessingprocess.py"" line 93 in runn    self._target(*self._args **self._kwargs)n  File ""E:ProjectsPredictive Inbound Cartoon Estimation-MLOPythondataprepDataPrep.py"" line 497 in ParallelLoopTestn    a = pd.read_pickle(fnames'a')n  File ""C:UsersdkanharAnaconda3libsite-packagespandasiopickle.py"" line 63 in read_picklen    return try_read(path encoding='latin1')n  File ""C:UsersdkanharAnaconda3libsite-packagespandasiopickle.py"" line 57 in try_readn    return pc.load(fh encoding=encoding compat=True)n  File ""C:UsersdkanharAnaconda3libsite-packagespandascompatpickle_compat.py"" line 118 in loadn    return up.load()n  File ""C:UsersdkanharAnaconda3libpickle.py"" line 1039 in loadn    dispatchkey0(self)n  File ""C:UsersdkanharAnaconda3libsite-packagespandascompatpickle_compat.py"" line 73 in load_newobjn    obj = cls.__new__(cls *args)nTypeError: function takes at most 0 arguments (1 given)nnnSo as you can see Pandas fail to unpickle the DatFrame no matter what I try. I tried picking manually using pickly.dump() and pickle.load() but even that failed with similar error. (TypeError Function takes 0 arguments (1 given))nnI also feel this is due to DataFrame problem as I created a random DataFrame using:nndf = pd.DataFrame(np.random.randint(0 100 size=(100000 4)) columns=list('ABCD'))nnnPickling it and unpickling on other end and that worked.nnSo what must be issue with DataFrame? Possible scenarios where DataFrame can't be pickled? nnNote that its around 200mb pickle file for Dataframe a and 25mb for pickled DataFrame d1.nnAlso is there way to post head of whole DataFrame? It has around 50 columns which wont be printed and hence cant be added here but in meanwhile I'm adding dtypes of both DataFrames.nnAny help would be really helpful.nnPS: The following link is for my previous post which described the error while Passed DataFRame directly to Method call instead of picking and unpickling:nSimilar errors in MultiProcessing. Mismatch number of arguments to functionnnUpdate:nThe following is link to Google spreedsheet with head n = 50 for both the DataFrames in concern.nnhttps://docs.google.com/spreadsheets/d/1bGkpmV0__aPVUtc0HSeuRQpufu1T4pmKB4YxsQsPO50/edit?usp=sharingn' nan",['pandas'],['pandas']
40102311,"'Python Matplotlib: Clear figure when figure window is not open' ""I'm working with matplotlib plotting and use ioff() to switch interactive mode off to suppress the automatic opening of the plotting window on figrue creation. I want to have full control over the figure and only see it when explicitely using the show() command.nnNow apparently the built-in commands to clear figures and axes do not work properly anymore.nnExample:nnimport numpy as npnimport matplotlib.pyplot as mppnnclass PlotTest:nn    def __init__(selfnx=1ny=1):n        # Switch off interactive mode:n        mpp.ioff()nn        # Create Figure and Axes:n        self.createFigure(nx ny)nn    def createFigure(selfnx=1ny=1):n        self.fig self.axes = mpp.subplots(nxny)n        if nx*ny == 1:n            self.axes = np.array(self.axes)nn    def linePlot(self):n        X = np.linspace(02021)n        Y = np.random.rand(21)     n        self.axes0.plot(XY)nnP = PlotTest()nP.linePlot()nP.fig.show()nnnNow I was thinking I could use P.fig.clear() any time to simply clear P.fig but apparently that's not the case.nnWriting P.fig.clear() directly into the script and execute it together it works and all I see is an empty figure. However that's rather pointless as I never get to see the actual plot like that.nnDoing P.fig.clear() manually in the console does not do anything regardless if the plot window is open or not all other possible commands fail as well:nnP.fig.clf()nP.axes0.clear()nP.axes0.cla()nmpp.clf()nmpp.cla()nmpp.close(P.fig)nnnWrapping the command into a class method doesn't work either:nndef clearFig(self):n    self.fig.clear()nnnEDIT ================nnAfter a clear() fig.axes is empty yet show() still shows the old plot with the axes still being plotted.nn/EDIT ================nnIs it because I switched off interactive mode?n"" 'If you add a call to plt.draw() after P.fig.clear() it clears the figure. From the docsnnn  This is used in interactive mode to update a figure that has been altered but not automatically re-drawn. This should be only rarely needed but there may be ways to modify the state of a figure with out marking it as stale. Please report these cases as bugs.nnnI guess this is not a bug as you have switched off interactive mode so it is now your responsibility to explicitly redraw when you want to.nnYou can also use P.fig.canvas.draw_idle() which could be wrapper in the class as clearFigure method.n'",['matplotlib'],['matplotlib']
40102549,"'ValueError: zero length field name in format with python 2.6.6. I dont want to use python2.7' 'I wanted to use pykwalify which supports python from 2.7 version onwards. nMy OS is shipped with 2.6.6 and hence I don't want to impose this dependency on my application.nnWith python 2.6.6 I am able to install pykwalify after upgrading setup-tools.nBut in the code when I try to use pykwalify it is throwing this error.nnfrom pykwalify.core import Coren>>> ret = Core(source_file=""yaml/vns_data.yaml"" schema_files=""yaml/vns_schema.yaml"")nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""pykwalify/core.py"" line 54 in __init__n    raise CoreError(u""Provided source_file do not exists on disk: {}"".format(source_file))nValueError: zero length field name in format  nn' nan",['python-2.7'],['python-2.7']
40102711,"'Percentage format in elements of python graph' ""Im executing the below code and I would like the numbers in the second graph to be percentage format with a two digit precision (0.3333 --> 33.33%). I have tried a ton of different version where I use '{percent .2%}'.format() in lambda functions on the arrays etc but I dont get it all the way. All input is appriciated!nnimport seaborn as snsnimport matplotlib.pyplot as pltnimport matplotlibnimport numpy as npnfrom sklearn.tree import DecisionTreeClassifiernfrom sklearn import datasetsnn%matplotlib inlinenniris = datasets.load_iris()nx = iris'data'ny = iris'target'nnx = iris_x: :2nnclf_tree = DecisionTreeClassifier(random_state = 1)nfit_clf = clf_tree.fit(x y)nny_pred_proba = fit_clf.predict_proba(x)ny_pred = fit_clf.predict(x)nnconf_mat = confusion_matrix(y_true = y y_pred = y_pred)nnfig ax = plt.subplots(figsize = (15 9))nax.matshow(conf_mat cmap = plt.cm.Blues alpha = 0.3)nnfor i in range(conf_mat.shape0):n    for j in range(conf_mat.shape1):n        ax.text(x = j y = in               s = conf_mati jn               va = 'center'n                ha = 'center')nnplt.xlabel('Predicted')nplt.ylabel('Actual')nplt.show()nnnconf_mat_prc = conf_mat/len(y)nnfig ax = plt.subplots(figsize = (15 9))nax.matshow(conf_mat_prc cmap = plt.cm.Blues alpha = 0.3)nnnfor i in range(conf_mat_prc.shape0):n    for j in range(conf_mat_prc.shape1):n        ax.text(x = j y = in               s = conf_mat_prci jn               va = 'center'n                ha = 'center')nnplt.xlabel('Predicted % dist')nplt.ylabel('Actual % dist')nplt.show()nnnMany thanks in advancenn--swepabn"" 'There are (at least) two problems in your code: nnnWhat is iris_x in line 14? I think you meant x: :2 instead of iris_x: :2nconf_mat_prc should be defined as conf_mat_prc = conf_mat/float(len(y)) instead of conf_mat_prc = conf_mat/len(y) to get float instead of 0 (int). nnnFinally for the second graph (line 48) use str(round(conf_mat_prci j*100precision)) + ""%"" in which precision defines the number of floating point digits.nnHere's the new code: nnimport seaborn as snsnimport matplotlib.pyplot as pltnimport matplotlibnimport numpy as npnfrom sklearn.tree import DecisionTreeClassifiernfrom sklearn import datasetsnfrom sklearn.metrics import confusion_matrixnn# %matplotlib inlinenniris = datasets.load_iris()nx = iris'data'ny = iris'target'nnx = x: :2nnclf_tree = DecisionTreeClassifier(random_state = 1)nfit_clf = clf_tree.fit(x y)nny_pred_proba = fit_clf.predict_proba(x)ny_pred = fit_clf.predict(x)nnconf_mat = confusion_matrix(y_true = y y_pred = y_pred)nnfig ax = plt.subplots(figsize = (15 9))nax.matshow(conf_mat cmap = plt.cm.Blues alpha = 0.3)nnfor i in range(conf_mat.shape0):n    for j in range(conf_mat.shape1):n        ax.text(x = j y = in               s = conf_mati jn               va = 'center'n                ha = 'center')nnplt.xlabel('Predicted')nplt.ylabel('Actual')nplt.show()nnnnconf_mat_prc = conf_mat/float(len(y))nnfig ax = plt.subplots(figsize = (15 9))nax.matshow(conf_mat_prc cmap = plt.cm.Blues alpha = 0.3)nnnprecision = 2nfor i in range(conf_mat_prc.shape0):n    for j in range(conf_mat_prc.shape1):n        ax.text(x = j y = in               s = str(round(conf_mat_prci j*100precision)) + ""%""n               va = 'center'n                ha = 'center')nnplt.xlabel('Predicted % dist')nplt.ylabel('Actual % dist')nplt.show()nnnHere's the new second graph :nnn'",['numpy'],"['matplotlib', 'pandas']"
40102757,"'Prevent initializing model form when creating' 'In a Django form I encountered a strange python behavior. I have a model form which I want to populate with some existing data. Because one field is meant to be a comma separated list of an m2m field I have to initialize it separately.nnclass SomeModel(models.Model):n    confirming_stuff = models.ManyToManyField(OtherModelrelated_name='confirming')nn    def get_confirming(self):n    return ''.join(l.pmid for l in self.confirming_stuff.all())nn class SomeForm(ModelForm):n    def __init__(self *args **kwargs):n        super(SomeForm self).__init__(*args **kwargs)n        self.initial'confirming_field' = self.instance.get_confirming()nnnEverything works fine with an update. The field is populated with comma separated entries as expected. The problem arises with creation. As the instance does not yet exist the field cannot be filled with data so I tried to skip this step. But it doesn't work. Instead I encountered a strange behavior of the python code.nnclass SomeForm(ModelForm):n    def __init__(self *args **kwargs):n        super(SomeForm self).__init__(*args **kwargs)n        if self.instance:n            print ""Self instance: ""self.instancen            self.initial'some_field' = self.instance.get_some_field()nnnproduces the same error. Additionally the printout on the debug screen shows:nnn  Self instance: NonennnI tried several other logical expressions nnif self.instance != None:nif not self.instance == None:nif self.instance > 0:nnnbut the result remains the same.nnIt remains a mystery to me why the instance is printed as 'None' but cannot be tested properly as such. n' 'You will always have an instance object just check if its saved.nnif self.instance.id:n    #do stuffnnnThanks.n'",['django'],['django']
40102772,"'Python: Applying function to list of tems' 'I have following code snippet that helps me to get Google Trends data (see https://github.com/GeneralMills/pytrends):nntrend_payload = {'q': 'Dogs Cats Catfood Dogfood''date': '01/2015 12m'}ntrend = pytrend.trend(trend_payload)ndf = pytrend.trend(trend_payload return_type='dataframe')ndfnnnAs this query has the disadvantage that Google Trends normalizes all data based on the queried data I prefer to make each a single call and chain the df next to each other. I thought about a function like this:nnqueries = 'Cats' 'Dogs' 'Catfood''Dogfood'nnfunction(queries)n    trend_payload = {'q': queries 'date': '01/2015 12m'}n    trend = pytrend.trend(trend_payload)n    df = pytrend.trend(trend_payload return_type='dataframe')nn# then put every df of each query next to each othernnnHow can I do this?n' ""You can work on this: nnqueries = 'Cats' 'Dogs' 'Catfood''Dogfood'nndef function(queries):n    trend_payload = {'q': queries 'date': '01/2015 12m'}n    trend = pytrend.trend(trend_payload)n    df = pytrend.trend(trend_payload return_type='dataframe')n    return df nnlist_of_df = function(query) for query in queries nnnthen you have to concat the data frames in the list. nnMore elegantly you can call: nnlist_of_df = map(function queries)nnnin this case you should rewrite function so that it accepts a single item.nIf you don't want to modify function you can write this: nnlist_of_df = map(lambda x: function(x) queries) nn"" 'I would simply concatenate DFs as jimifiki has already proposed:nndf = pd.concat(pytrend.trend({'q': x 'date': '01/2015 12m'}n                              return_type='dataframe')n                for x in queries axis=1)nnnor in function:nndef get_trends(queries dt):n    return pd.concat(pytrend.trend({'q': x 'date': dt}n                                    return_type='dataframe')n                      for x in queries axis=1)nndf = get_trends(queries '01/2015 12m')nnnDemo:nnIn 24: df = get_trends(queries '01/2015 12m')nnIn 25: dfnOut25:n            cats   dogs  catfood  dogfoodnDaten2015-01-04  74.0   85.0     65.0     47.0n2015-01-11  74.0   84.0     60.0     52.0n2015-01-18  72.0   82.0     49.0     57.0n2015-01-25  69.0   78.0     45.0     37.0n2015-02-01  73.0   77.0     51.0     52.0n...          ...    ...      ...      ...n2015-11-29  83.0   80.0     47.0     49.0n2015-12-06  80.0   79.0     70.0     50.0n2015-12-13  83.0   84.0     67.0     49.0n2015-12-20  89.0   91.0     61.0     58.0n2015-12-27  90.0  100.0     58.0     45.0nn52 rows x 4 columnsnn'",['pandas'],['pandas']
40102786,"'How not to stop the execution of other function in python in case of Exception/Error' ""I have a script in python which works as shown below. Each function performs a completely different task and not related to each other. My problem is if function2() is having an issue during the execution process then function3() function4() function5() will not execute. I know you will say to handle this by catching the exception (try..except) but then i have to catch every exception which is not i am looking for. In a nutshell how do i code where my other functions are not impacted if any of the function is having issue. Ideally it should exclude that problematic function and let the other function to execute.nndef function1():n    some codenndef function2():n    some codenndef function3():n    some codenndef function4():n    some codenndef function5():n    some codennif __name__ == '__main__':n    function1()n    function2()n    function3()n    function4()n    function5()nn"" 'No need to write multiple try/except. Create a list of your function and execute them. For example you code should be like:nnif __name__ == '__main__':n    func_list = function1 function2 function3 function4 function5nn    for my_func in func_list:n        try:n            my_func()n        except:n            passnnnnnOR create a decorator and add that decorator to each of your function. Check A guide to Python's function decorators. For example your decorator should be like:nndef wrap_error(func):n    def func_wrapper(*args **kwargs):n        try:n           return func(*args **kwargs)n        except:n           passn    return func_wrappernnnNow add this decorator with your function definition as:nn@wrap_errorndef function1():n    some codennnFunctions having this decorator added to them won't raise any Exceptionn' ""You can use exception and catch all sort of exceptions like thisnnif __name__ == '__main__':n    try:n        function1()n    except:n        passn    try:n        function2()n    except:n        pass    n    try:n        function3()n    except:n        pass    n    try:n        function4()n    except:n        passnnnfor large number of functions you can usennfunc_dict = {n func1 : {n     param1 : valn     param2 : valn   }n func1 : {n     param1 : valn     param2 : valn   }n}nnnthus you can iterate over the keys of the dictionary for the function and iterate on the parameters n""",['python-2.7'],['python-2.7']
40102975,"'Python: Finding the longest path' ""I have a simple graph created as such in the belownnclass Job():n    def __init__(self name weight):n        self.name = namen        self.weight = weightn        self.depends = nn    def add_dependent(self dependent):n        self.depends.append(dependent)nnnjobA = Job('A' 0)njobB = Job('B' 4)njobC = Job('C' 2)njobD = Job('D' 10)njobE = Job('E' 3)njobF = Job('F' 11)nnjobA.add_dependent(jobB)njobA.add_dependent(jobC)njobB.add_dependent(jobD)njobC.add_dependent(jobE)njobD.add_dependent(jobF)njobE.add_dependent(jobF)nnnso we have two possible pathsnnA->B->D->F  0+4+10+11 = 25nA->C->E->F  0+2+3+11 = 16nnnso the longest paths would be the formernnIs there an easy way to gather the longest path A->B->D->F?nndef longest_path(root):n    paths = n    # some logic heren    return pathsnnprint longest_path(jobA) # should print A->B->D->Fnn"" 'Not the most efficient solution but here is one that should work:nnimport operatornndef longest_path(root):n    def _find_longest(job):n        costs = _find_longest(depend) for depend in job.dependsn        if costs:n            # Find most expensive:n            path cost = max(costs key=operator.itemgetter(1))n            return (job.name + path job.weight + cost)n        else:n            return (job.name job.weight)n    return ""->"".join(_find_longest(root)0)nn' ""If you use OO solution it's easy to provide a way to store only the heaviest path.nThis is the solution I came up with - using a callable classnnIn 111: class Heaviest(object):n     ...:     def __init__(self job):n     ...:         self.path = ''n     ...:         self.weight = 0n     ...:         self.job = jobn     ...:     def _find_heaviest(self job path='' weight=0):n     ...:         path += job.namen     ...:         weight += job.weightn     ...:         if not job.depends:n     ...:             if weight > self.weight:n     ...:                 self.weight = weightn     ...:                 self.path = pathn     ...:         else:n     ...:             for job in job.depends:n     ...:                 self._find_heaviest(job path weight)n     ...:     def __call__(self):n     ...:         self._find_heaviest(self.job)n     ...:         return '->'.join(list(self.path)) self.weightn     ...:                 nnIn 112: Heaviest(jobA)()nOut112: ('A->B->D->F' 25)nnnAn afterthought:nnIt occurred to me last night that in case of cyclic dependency (see my comment) the solution above will not yield an answer stopping with exception when maximum recursion depth is reached. Just adding the line below will blow any tree traversing algorithm - not just this one.nnIn 226: jobF.add_dependent(jobA)nnIn 227: Heaviest(jobA)()n---------------------------------------------------------------------------nRuntimeError                              Traceback (most recent call last)n<ipython-input-227-94e994624b4e> in <module>()n----> 1 Heaviest(jobA)()nn<ipython-input-111-1ff9f69480a9> in __call__(self)n     15                 self._find_heaviest(job path weight)n     16     def __call__(self):n---> 17         self._find_heaviest(self.job)n     18         return '->'.join(list(self.path)) self.weightn     19 nn<ipython-input-111-1ff9f69480a9> in _find_heaviest(self job path weight)n     13         else:n     14             for job in job.depends:n---> 15                 self._find_heaviest(job path weight)n     16     def __call__(self):n     17         self._find_heaviest(self.job)nn... last 1 frames repeated from the frame below ...nn<ipython-input-111-1ff9f69480a9> in _find_heaviest(self job path weight)n     13         else:n     14             for job in job.depends:n---> 15                 self._find_heaviest(job path weight)n     16     def __call__(self):n     17         self._find_heaviest(self.job)nnRuntimeError: maximum recursion depth exceedednnnWhile I leave attempt to mend the implementation to you - if you wish - simple safeguard can fix thatnndef _find_heaviest(self job path='' weight=0):n    if not job.name in path:n        path += job.namen        weight += job.weightn        stop_search = not job.dependsn    else:n        stop_search = Truen    if stop_search:n        if weight > self.weight:nnn.....nnProblem solvednnIn 230: Heaviest(jobA)()nOut230: ('A->B->D->F' 25)nn""",['python-2.7'],"['python-3.x', 'python-2.7']"
40102984,"'trying to change the state of button after the all the entry are updated' 'trying to get my head around how to enable the state of the button after the entries are written. I am trying to get a new window Toplevel. Wherein there are three entry widgets. After they are filled with values the RUN button should be enabled. I know i gotta use the trace method to attach observer callbacks to the variables. This is what i have done so far.nnclass appl:n    def __init__(self master):n        self.master = mastern        self.frame = tk.Frame( self.master width=800 height=700 )n        self.var = tk.IntVar( )n        self.func1 = tk.Radiobutton( self.frame text='fun1' value=1 variable=self.varcommand=self.new_window )n        self.func1.pack( )n        self.frame.pack( )n    def new_window(self):n        self.newWindow = tk.Toplevel(self.master)n        self.intvar1 = tk.IntVar()n        self.intvar2 = tk.IntVar()n        self.intvar3 = tk.IntVar()n        self.ent = tk.Button( self.newWindow text='ENTER' state='disabled' command=self.validate_check ).grid(row=3 column=1 )n        self.intvar1.trace( 'w' self.validate_check )n        self.intvar2.trace( 'w' self.validate_check )n        self.intvar3.trace( 'w' self.validate_check )n        self.X = tk.Entry( self.newWindowtextvariable=self.intvar1 )n        self.Y = tk.Entry( self.newWindow textvariable=self.intvar2)n        self.Z = tk.Entry( self.newWindow textvariable=self.intvar3)n        self.X.grid( row=0 column=1 )n        self.Y.grid( row=1 column=1 )n        self.Z.grid( row=2 column=1 )n        tk.Label( self.newWindow text="" X"" ).grid( row=0 )n        tk.Label( self.newWindow text="" Y"" ).grid( row=1 )n        tk.Label( self.newWindow text="" Z"" ).grid( row=2 )n    def validate_check(self *args):n        x = self.intvar1.get()n        y = self.intvar2.get()n        z = self.intvar3.get()n        if x and y and z:n            self.ent.config(state=NORMAL)n        else:n            self.ent.config(state=DISABLED)ndef main():n    root = tk.Tk()n    app = appl(root)n    root.mainloop()nif __name__ == '__main__':n    main() nn' ""Your code is almost working except:nnself.ent = tk.Button( self.newWindow text='ENTER' state='disabled' command=self.validate_check ).grid(row=3 column=1 )nnnshould be:nnself.ent = tk.Button( self.newWindow text='ENTER' state='disabled' command=self.validate_check )nself.ent.grid(row=3 column=1 )nnnAlso when you input something other than 0-9 in the entry boxes validate_check(...) will raise exception because the entry text cannot be converted to integer value.  Try changing validate_check(...) to:nndef validate_check(self *args):n    try:n        x = self.intvar1.get()n        y = self.intvar2.get()n        z = self.intvar3.get()n        # all three entries are valid integers enable the buttonn        self.ent.config(state=tk.NORMAL)n    except:n        # something wrong on the entries disable the buttonn        self.ent.config(state=tk.DISABLED)nn""",['tkinter'],['tkinter']
40103053,"'what is a for loop doing on file objects?' 'I have a question related to Python for loops and files. nnIn this code: nnfile = raw_input(""input a text file "")nnf = open(file) #  creates a file object of filennfor line in f:n    # prints each line in the filen    print line nnnnprint fnn# prints <open file 'MVL_ref.txt' mode 'r' at 0x0267D230>nnprint f.read() # same output of the for-cyclenprint f.readline() # same output of the for-cyclennnThe for-loop is printing each line that is present in my text nfile. However if I print the file object I get something totally different.nThis puzzles me because I would expect that I had to use something like:nnfor line in f.read():n    print line nnnbut of course this is not the case.nIf I use the read or readline methods without a for-loop I get the same output of the for-loop. nnIs the for-loop doing some magic like calling read() or readline() by default on the file object? I am learning how to code with python but I fell I don't really understand much of what the code is doing ""behind my back"".   nnThank you for all the explanations that will come.n' 'Since file object in Python is iterable you can iterate over it to get lines of file one-by-one. nnHowever File is not a collection but object - you won't see all lines by printing this like when outputting collectionnnl = ""line1"" ""line2""nprint l nnnbut you will see entity descriptionnn<open file 'path_to_the_file' mode 'r' at 0x0245D020>nn'",['python-2.7'],"['python-2.7', 'python-3.x']"
40103119,"'Trying capture video to read frame by frame with OpenCV on MAC but my "".avi"" file has been encoded as mpeg4' ""I am able to read an avi file encoded as mjpeg but I can't succeed when the case for encoding is mpeg4 unfortunately. Any help from you would be really helpful and be appreciated. nHere is my code snippet:nnwhile(cap.isOpened()):n ret frame = cap.read()n if ret:n      frame=cv2.resize(frame(img_rowsimg_cols)interpolation=cv2.INTER_AREA)         n      gray = cv2.cvtColor(frame cv2.COLOR_BGR2GRAY)n      frames.append(gray)n      cv2.imshow('frame'gray)n if cv2.waitKey(1) & 0xFF == ord('q'):n                breakncap.release()ncv2.destroyAllWindows()nn"" nan",['python-2.7'],['python-2.7']
40103127,"'Python 2.7 encoding from csv file' ""I have a problem with Python 2.7 encoding I have a csv file with some french characters (mangÃ© parlÃ© prÃªtre ...) the code I'm using is the following:nnimport pandas as pdnpath_dataset = 'P:Version_pythonDatasetdata_set - Copy.csv'ndataset = pd.read_csv(path_dataset sep=';')nnfor lab row in dataset.iterrows():n    print(row'Summary')nnnI tried to add encoding to read_csv() it didn't work. I tried unicode decode(UTF-8) ... Nothing worked.nnThen I tried to concatenate those extracted words with some text and I got a utf-8 error I don't know how to deal with that. Thanksn"" 'You can use codecs in python2.7nnimport codecsnfile = codecs.open(filename encoding=""utf-8"")nn' 'Here is a list of standard python encodingsnnStandard Python 2.7 encodingsnnutf-8 does not work but you can try some other encodings on the link above.nnJust tested latin_1 works. So the code should be:nndataset = pd.read_csv(path_dataset sep=';' encoding='latin_1')nn'","['python-2.7', 'pandas']","['pandas', 'python-2.7']"
40103226,'kNN - How to locate the nearest neighbors in the training matrix based on the calculated distances' 'I am trying to implement k-nearest neighbor algorithm using python. I ended up with the following code. However I am struggling with finding the index of the items that are the nearest neighbors. The following function will return the distance matrix. However I need to get the indices of these neighbors in the features_train (the input matrix to the algorithm). nndef find_kNN(k feature_matrix query_house):n    alldistances = np.sort(compute_distances(feature_matrix query_house))n    dist2kNN = alldistances0:k+1n    for i in range(klen(feature_matrix)):n        dist = alldistancesin        j = 0n        #if there is closer neighborn        if dist < dist2kNNk:n        #insert this new neighbor n            for d in range(0 k):n                if dist > dist2kNNd:n                    j = d + 1n            dist2kNN = np.insert(dist2kNN j dist)n            dist2kNN = dist2kNN0: len(dist2kNN) - 1n    return dist2kNN    nnprint find_kNN(4 features_train features_test2)nnnOutput is:nn 0.0028605   0.00322584  0.00350216  0.00359315  0.00391858nnnCan someone help me to identify these nearest items in the  features_train?n' 'I will suggest to use the python library sklearn that has a KNeighborsClassifier from which once fitted you can retrieve the nearest neighbors you are looking for :nnTry this out:nn# Importnfrom sklearn.neighbors import KNeighborsClassifiernn# Instanciate your classifiernneigh = KNeighborsClassifier(n_neighbors=4) #k=4 or whatever you wantn# Fit your classifiernneigh.fit(X y) # Where X is your training set and y is the training_outputn# Get the neighborsnneigh.kneighbors(X_test return_distance=False) # Where X_test is the sample or array of samples from which you want to get the k-nearest neighborsnn',['numpy'],"['numpy', 'python-2.7']"
40103514,"'Recursive dictionary walking in python' 'I am new to python and trying to create a recursive dictionary walker that outputs a path to each item in the dictionary.nnBelow is my code including some sample data.  The goal is to import weather data from weather underground and publish into mqtt topics on a raspberry pi.  (The mqtt code all runs fine and is independent of this for this I just need to generate the paths)nnThe issue that I am having is that when I reach the 'forecastday' element of the dict my function is returning what looks like json data instead of recursing further into the path.nnI have tried a few methods of walking the dict but when the examples started getting into 'generators' etc things were starting to get above my head a little.nn(The test data does not contain any private information it is the general weather report for my nearest town)nnThanksnnimport jsonnndef print_path(root data path):nn    for element in data.keys():n        if not isinstance(dataelement dict):n            print root + path + element dataelementn        else:n            print_path(root dataelement element+""/"")nnjson_string = u'{""response"":{""version"":""0.1""""termsofService"":""http://www.wunderground.com/weather/api/d/terms.html""""features"":{""almanac"":1""astronomy"":1""conditions"":1""forecast"":1}}""current_observation"":{""image"":{""url"":""http://icons.wxug.com/graphics/wu2/logo_130x80.png""""title"":""Weather Underground""""link"":""http://www.wunderground.com""}""display_location"":{""full"":""Llanelli United Kingdom""""city"":""Llanelli""""state"":""""""state_name"":""United Kingdom""""country"":""UK""""country_iso3166"":""GB""""zip"":""00000""""magic"":""11""""wmo"":""03605""""latitude"":""51.67610931""""longitude"":""-4.15666723""""elevation"":""17.00000000""}""observation_location"":{""full"":""Llanelli CARMARTHENSHIRE""""city"":""Llanelli""""state"":""CARMARTHENSHIRE""""country"":""GB""""country_iso3166"":""GB""""latitude"":""51.679951""""longitude"":""-4.140789""""elevation"":""40 ft""}""estimated"":{}""station_id"":""ICARMART4""""observation_time"":""Last Updated on October 18 8:07 AM BST""""observation_time_rfc822"":""Tue 18 Oct 2016 08:07:38 +0100""""observation_epoch"":""1476774458""""local_time_rfc822"":""Tue 18 Oct 2016 08:07:44 +0100""""local_epoch"":""1476774464""""local_tz_short"":""BST""""local_tz_long"":""Europe/London""""local_tz_offset"":""+0100""""weather"":""Mostly Cloudy""""temperature_string"":""49.0 F (9.4 C)""""temp_f"":49.0""temp_c"":9.4""relative_humidity"":""90%""""wind_string"":""From the West at 4.5 MPH Gusting to 6.9 MPH""""wind_dir"":""West""""wind_degrees"":272""wind_mph"":4.5""wind_gust_mph"":""6.9""""wind_kph"":7.2""wind_gust_kph"":""11.1""""pressure_mb"":""1019""""pressure_in"":""30.09""""pressure_trend"":""0""""dewpoint_string"":""46 F (8 C)""""dewpoint_f"":46""dewpoint_c"":8""heat_index_string"":""NA""""heat_index_f"":""NA""""heat_index_c"":""NA""""windchill_string"":""47 F (9 C)""""windchill_f"":""47""""windchill_c"":""9""""feelslike_string"":""47 F (9 C)""""feelslike_f"":""47""""feelslike_c"":""9""""visibility_mi"":""6.2""""visibility_km"":""10.0""""solarradiation"":""--""""UV"":""0""""precip_1hr_string"":""0.00 in ( 0 mm)""""precip_1hr_in"":""0.00""""precip_1hr_metric"":"" 0""""precip_today_string"":""0.07 in (2 mm)""""precip_today_in"":""0.07""""precip_today_metric"":""2""""soil_moisture"":""255.0""""icon"":""mostlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/mostlycloudy.gif""""forecast_url"":""http://www.wunderground.com/global/stations/03605.html""""history_url"":""http://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID=ICARMART4""""ob_url"":""http://www.wunderground.com/cgi-bin/findweather/getForecast?query=51.679951-4.140789""""nowcast"":""""}""forecast"":{""txt_forecast"":{""date"":""7:03 AM BST""""forecastday"":{""period"":0""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""title"":""Tuesday""""fcttext"":""Sun and clouds mixed. High around 55F. Winds WNW at 10 to 20 mph.""""fcttext_metric"":""Sun and clouds mixed. High 12C. Winds WNW at 15 to 30 km/h.""""pop"":""0""}{""period"":1""icon"":""nt_partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/nt_partlycloudy.gif""""title"":""Tuesday Night""""fcttext"":""Partly cloudy skies. Low 43F. Winds WNW at 5 to 10 mph.""""fcttext_metric"":""Partly cloudy. Low 6C. Winds WNW at 10 to 15 km/h.""""pop"":""10""}{""period"":2""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""title"":""Wednesday""""fcttext"":""Partly cloudy skies in the morning will give way to cloudy skies during the afternoon. High 56F. Winds NW at 10 to 15 mph.""""fcttext_metric"":""Partly to mostly cloudy. High 13C. Winds NW at 15 to 25 km/h.""""pop"":""10""}{""period"":3""icon"":""nt_partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/nt_partlycloudy.gif""""title"":""Wednesday Night""""fcttext"":""A few clouds. Low 41F. Winds N at 5 to 10 mph.""""fcttext_metric"":""Partly cloudy. Low around 5C. Winds N at 10 to 15 km/h.""""pop"":""10""}{""period"":4""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""title"":""Thursday""""fcttext"":""Intervals of clouds and sunshine. High 59F. Winds N at 5 to 10 mph.""""fcttext_metric"":""Partly cloudy skies. High around 15C. Winds N at 10 to 15 km/h.""""pop"":""10""}{""period"":5""icon"":""nt_partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/nt_partlycloudy.gif""""title"":""Thursday Night""""fcttext"":""Partly cloudy. Low 41F. Winds NE at 5 to 10 mph.""""fcttext_metric"":""Partly cloudy. Low near 5C. Winds NE at 10 to 15 km/h.""""pop"":""10""}{""period"":6""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""title"":""Friday""""fcttext"":""Intervals of clouds and sunshine. High 58F. Winds E at 5 to 10 mph.""""fcttext_metric"":""Sunshine and clouds mixed. High 14C. Winds E at 10 to 15 km/h.""""pop"":""10""}{""period"":7""icon"":""nt_partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/nt_partlycloudy.gif""""title"":""Friday Night""""fcttext"":""Partly cloudy. Low 44F. Winds E at 5 to 10 mph.""""fcttext_metric"":""Partly cloudy. Low 6C. Winds E at 10 to 15 km/h.""""pop"":""10""}}""simpleforecast"":{""forecastday"":{""date"":{""epoch"":""1476813600""""pretty"":""7:00 PM BST on October 18 2016""""day"":18""month"":10""year"":2016""yday"":291""hour"":19""min"":""00""""sec"":0""isdst"":""1""""monthname"":""October""""monthname_short"":""Oct""""weekday_short"":""Tue""""weekday"":""Tuesday""""ampm"":""PM""""tz_short"":""BST""""tz_long"":""Europe/London""}""period"":1""high"":{""fahrenheit"":""55""""celsius"":""13""}""low"":{""fahrenheit"":""43""""celsius"":""6""}""conditions"":""Partly Cloudy""""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""skyicon"":""""""pop"":0""qpf_allday"":{""in"":0.00""mm"":0}""qpf_day"":{""in"":0.00""mm"":0}""qpf_night"":{""in"":0.00""mm"":0}""snow_allday"":{""in"":0.0""cm"":0.0}""snow_day"":{""in"":0.0""cm"":0.0}""snow_night"":{""in"":0.0""cm"":0.0}""maxwind"":{""mph"":20""kph"":32""dir"":""WNW""""degrees"":293}""avewind"":{""mph"":16""kph"":26""dir"":""WNW""""degrees"":293}""avehumidity"":71""maxhumidity"":0""minhumidity"":0}{""date"":{""epoch"":""1476900000""""pretty"":""7:00 PM BST on October 19 2016""""day"":19""month"":10""year"":2016""yday"":292""hour"":19""min"":""00""""sec"":0""isdst"":""1""""monthname"":""October""""monthname_short"":""Oct""""weekday_short"":""Wed""""weekday"":""Wednesday""""ampm"":""PM""""tz_short"":""BST""""tz_long"":""Europe/London""}""period"":2""high"":{""fahrenheit"":""56""""celsius"":""13""}""low"":{""fahrenheit"":""41""""celsius"":""5""}""conditions"":""Partly Cloudy""""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""skyicon"":""""""pop"":10""qpf_allday"":{""in"":0.00""mm"":0}""qpf_day"":{""in"":0.00""mm"":0}""qpf_night"":{""in"":0.00""mm"":0}""snow_allday"":{""in"":0.0""cm"":0.0}""snow_day"":{""in"":0.0""cm"":0.0}""snow_night"":{""in"":0.0""cm"":0.0}""maxwind"":{""mph"":15""kph"":24""dir"":""NW""""degrees"":318}""avewind"":{""mph"":12""kph"":19""dir"":""NW""""degrees"":318}""avehumidity"":79""maxhumidity"":0""minhumidity"":0}{""date"":{""epoch"":""1476986400""""pretty"":""7:00 PM BST on October 20 2016""""day"":20""month"":10""year"":2016""yday"":293""hour"":19""min"":""00""""sec"":0""isdst"":""1""""monthname"":""October""""monthname_short"":""Oct""""weekday_short"":""Thu""""weekday"":""Thursday""""ampm"":""PM""""tz_short"":""BST""""tz_long"":""Europe/London""}""period"":3""high"":{""fahrenheit"":""59""""celsius"":""15""}""low"":{""fahrenheit"":""41""""celsius"":""5""}""conditions"":""Partly Cloudy""""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""skyicon"":""""""pop"":10""qpf_allday"":{""in"":0.00""mm"":0}""qpf_day"":{""in"":0.00""mm"":0}""qpf_night"":{""in"":0.00""mm"":0}""snow_allday"":{""in"":0.0""cm"":0.0}""snow_day"":{""in"":0.0""cm"":0.0}""snow_night"":{""in"":0.0""cm"":0.0}""maxwind"":{""mph"":10""kph"":16""dir"":""N""""degrees"":2}""avewind"":{""mph"":7""kph"":11""dir"":""N""""degrees"":2}""avehumidity"":78""maxhumidity"":0""minhumidity"":0}{""date"":{""epoch"":""1477072800""""pretty"":""7:00 PM BST on October 21 2016""""day"":21""month"":10""year"":2016""yday"":294""hour"":19""min"":""00""""sec"":0""isdst"":""1""""monthname"":""October""""monthname_short"":""Oct""""weekday_short"":""Fri""""weekday"":""Friday""""ampm"":""PM""""tz_short"":""BST""""tz_long"":""Europe/London""}""period"":4""high"":{""fahrenheit"":""58""""celsius"":""14""}""low"":{""fahrenheit"":""44""""celsius"":""7""}""conditions"":""Partly Cloudy""""icon"":""partlycloudy""""icon_url"":""http://icons.wxug.com/i/c/k/partlycloudy.gif""""skyicon"":""""""pop"":10""qpf_allday"":{""in"":0.00""mm"":0}""qpf_day"":{""in"":0.00""mm"":0}""qpf_night"":{""in"":0.00""mm"":0}""snow_allday"":{""in"":0.0""cm"":0.0}""snow_day"":{""in"":0.0""cm"":0.0}""snow_night"":{""in"":0.0""cm"":0.0}""maxwind"":{""mph"":10""kph"":16""dir"":""E""""degrees"":91}""avewind"":{""mph"":7""kph"":11""dir"":""E""""degrees"":91}""avehumidity"":79""maxhumidity"":0""minhumidity"":0}}}""moon_phase"":{""percentIlluminated"":""93""""ageOfMoon"":""17""""phaseofMoon"":""Waning Gibbous""""hemisphere"":""North""""current_time"":{""hour"":""8""""minute"":""07""}""sunrise"":{""hour"":""7""""minute"":""46""}""sunset"":{""hour"":""18""""minute"":""15""}""moonrise"":{""hour"":""20""""minute"":""10""}""moonset"":{""hour"":""10""""minute"":""24""}}""sun_phase"":{""sunrise"":{""hour"":""7""""minute"":""46""}""sunset"":{""hour"":""18""""minute"":""15""}}""almanac"":{""airport_code"":""EGFF""""temp_high"":{""normal"":{""F"":""55""""C"":""12""}""record"":{""F"":""66""""C"":""18""}""recordyear"":""1997""}""temp_low"":{""normal"":{""F"":""46""""C"":""7""}""record"":{""F"":""33""""C"":""0""}""recordyear"":""1998""}}}'nnweather_report = json.loads(json_string)nnprint_path(""dev/blah/weather/"" weather_report """")nnnEDIT>>nnThis is some of the output that I get from the scriptnn...ndev/blah/weather/sunrise/minute 46ndev/blah/weather/sunrise/hour 7ndev/blah/weather/sunset/minute 15ndev/blah/weather/sunset/hour 18ndev/blah/weather/sunrise/minute 46ndev/blah/weather/sunrise/hour 7ndev/blah/weather/txt_forecast/date 7:03 AM BSTndev/blah/weather/txt_forecast/forecastday {u'title': u'Tuesday' u'icon_url': u'http://icons.wxug.com/i/c/k/partlycloudy.gif' u'fcttext_metric': u'Sun and clouds mixed. High 12C. Winds WNW at 15 to 30 km/h.' u'period': 0 u'pop': u'0' u'fcttext': u'Sun and clouds mixed. High around 55F. Winds WNW at 10 to 20 mph.' u'icon': u'partlycloudy'} {u'title': u'Tuesday Night' u'icon_url': u'http://icons.wxug.com/i/c/k/nt_partlycloudy.gif' u'fcttext_metric': u'Partly cloudy. Low 6C. Winds WNW at 10 to 15 km/h.' u'period': 1 u'pop': u'10' u'fcttext': u'Partly cloudy skies. Low 43F. Winds WNW at 5 to 10 mph.' u'icon': u'nt_partlycloudy'} {u'title': u'Wednesday' u'icon_url': u'http://icons.wxug.com/i/c/k/partlycloudy.gif' u'fcttext_metric': u'Partly to mostly cloudy. High 13C. Winds NW at 15 to 25 km/h.' u'period': 2 u'pop': u'10' u'fcttext': u'Partly cloudy skies in the morning will give way to cloudy skies during the afternoon.nnnFor the last entry here it should saynndev/blah/weather/txt_forecast/forecastday/0/title Tuesdayndev/blah/weather/txt_forecast/forecastday/0/icon partlycloudynnnbut instead it showsnn{u'title': u'Tuesday' u'icon_url': u'http://icons.wxug.com/i/c/k/partlycloudy.gif' u'fcttext_metric': u'Sun and clouds mixed. High 12C. Winds WNW at 15 to 30 km/h.' u'perio...nn' 'Just mix-in a regular for-loop into that recursion to iterate over the lists. nndef print_path(root data path):nn    for element val in data.items():n        if isinstance(val dict):n            print_path(root val element+""/"")n        elif isinstance(val list):n            list_path = path+element+""/""n            for i item in enumerate(val):n                print_path(root item list_path+str(i)+""/"")n        else:n            print root + path + element valnnnShould see dev/blah/weather/txt_forecast/forecastday/0/title Tuesday in the outputn'",['dictionary'],['python-2.7']
40103817,"'python post request not working with Minio server import' 'I have a problem with POST request with Python/Django and Minio server this is the codennfrom django.http import HttpResponsenimport jsonnfrom minio import MinionnminioClient = Minio('mypath:9000'n                access_key='mykey'n                secret_key='mysecret'n                secure=False)nnndef getMessage(request):n   if request.method == 'POST':nn       data = json.loads(request.body.decode('utf-8'))nn       for obj in data'files':n           ...do some stuff....nn           minioClient.fget_object(myvar myvar2 '/tmp/processing')nn    return HttpResponse(file)nnnThe problem is that the request won't work if I don't remove the import at the beginning and I can't understand why. This is the error generated:nnHTTPConnectionPool(host='myhost' port=8001): nMax retries exceeded with url: /myurl/ n(Caused NewConnectionErrorn('<requests.packages.urllib3.connection.HTTPConnection object at 0x7fcbeab21160>: nFailed to establish a new connection: Errno 111 Connection refused'))nnnand this is the script that make the request is this one:nn.... some code....ntry:n   r = requests.post(""http://myurl:8001/mypath/"" data=my_data timeout=1)nexcept Exception as e:n   print(e)nnnI've already tried to increase the timeout but it's not working and of course I've tested the Minio part in another script the import it's generating this error only in this request script.nnThanks for the helpn' 'From docs for urllib3: nnn  request(method url fields=None headers=None **urlopen_kw)Â¶ Make an  request using urlopen() with the appropriate encoding of fields basedn  on the method used.nnnMaybe you could try something like this:nnr = http.request('POST' ""http://myurl:8001/mypath/""n                 headers={'Content-Type': 'application/json'}n                 body=encoded_data)nn'",['django'],['django']
40103855,"'Alternative for matshow()' 'I have a 101x101 matrix that I want to visualize graphically. So far I used the function matshow from matplotlib.pyplot as below:nnimport numpy as npnimport randomnimport matplotlib.pyplot as pltnnA = np.zeros((101101))n# do stuff to randomly change some values of Anplt.ion()nplt.matshow(Acmap='PuBuGn')nplt.colorbar()nplt.show()nnnThe output looks like this:nnnYou should view this as an interaction matrix between species and as you can see there are only three species strongly interacting. That is why it looks appropriate to consider a visualization like the following graph I found in a paper but I do not know if and how this can be implemented in Python:nnn' 'This should do the trick:nnimport numpy as npnimport matplotlib.pyplot as pltnndef old_graph(A):n    plt.matshow(Acmap='PuBuGn')n    plt.colorbar()n    plt.title(r""abs$left(leftmathbf{A}_{ij} right  right )$ ; SIS=%d""%(sis) va='bottom')n    plt.show()nndef new_graph(A sis_list=np.zeros(0int) symmetric=True fig=None pos=111):n    #create and edit figure:n    if fig is None:n        fig = plt.figure()n    ax = fig.add_subplot(pos projection='polar')n    ax.set_rgrids(1' ')n    ax.set_rmax(1)n    ax.set_thetagrids()n    ax.set_title(r""abs$left(leftmathbf{A}_{ij} right  right )$ ; SIS=%d""%(sis) va='bottom')n    colormap = plt.get_cmap('PuBuGn')nn    # make each species an angle value:n    n_species = A.shape0n    angles = np.linspace(0 2*np.pi n_species+1)n    # the radius will always be r_max and each linen    # will always unite two points:n    r = np.ones((2))n    # prepare list of lines to sort:n    unordered_pairs_and_values = n    for index_line in xrange(n_species):n        for index_column in xrange(index_line):n            if symmetric:n                value = Aindex_lineindex_columnn            else: # not symmetricn                value= abs(Aindex_lineindex_column- Aindex_columnindex_line)n            unordered_pairs_and_values.append(anglesindex_lineanglesindex_column value)n    # sort the lines (otherwise white lines would cover the 'important' ones):n    ordered_pairs_and_values = sorted(unordered_pairs_and_values key=lambda pair: pair1)n    # get the maximum value for scaling:n    I_max = ordered_pairs_and_values-11n    # plot every line in order:n    for pair in ordered_pairs_and_values:n        ax.plot(pair0 r color=colormap(pair1/I_max) linewidth=2 alpha=0.8)n    # don't know how to add the colorbar:n    #fig.colorbar(orientation='horizontal')n    # mark the angles:n    ax.plot(angles np.ones(angles.shape) 'ko')n    # mark the important angles (comment if you don't know which ones are these):n    ax.plot(anglessis_list  np.ones(sis_list.shape) 'ro')n    fig.show()nnif __name__ == '__main__':n    n_species = 51n    sis = 3 # strongly interacting speciesn    sis_factor = 4.n    A = np.zeros((n_speciesn_species))n    # do stuff to randomly change some values of A:n    for index_line in xrange(n_species):n        for index_column in xrange(index_line+1):n            Aindex_lineindex_column = np.random.random()n            Aindex_columnindex_line = Aindex_lineindex_columnnn    sis_list = np.random.randint(0n_speciessis)n    for species in sis_list:n        Aspecies: *= sis_factorn        A:species *= sis_factorn        for species2 in sis_list: # correct crossingsn            Aspeciesspecies2 /= sis_factorn    # stuff to randomly change some values of A donen    old_graph(A=A)n    new_graph(A=A sis_list=sis_list symmetric=True)nnnOld graph:nnnNew graph:nnI still don't know:nnnhow to enter the colorbar since it requires a plot that was mapped using a colormap.nhow to remove the r-ticks without rescaling the graph (you can try uncomment #ax.set_rticks())nnnAnd the plot looks better with less interacting species:n n'",['matplotlib'],['matplotlib']
40103978,"'The tkinter loggin system does not work' 'import tkinter as tknimport tkinter.messagebox as tmnnLARGE_FONT= (""Verdana"" 12)nn# The log in button doesn't work when its clicked it switches to the next page it doesn't check if the username or password is correct.nnclass SeaofBTCapp(tk.Tk):nn    def __init__(self *args **kwargs):nn        tk.Tk.__init__(self *args **kwargs)n        container = tk.Frame(self)nn        container.pack(side=""top"" fill=""both"" expand = True)nn        container.grid_rowconfigure(0 weight=1)n        container.grid_columnconfigure(0 weight=1)nn        self.frames = {}nn        for F in (StartPage PageOne):nn            frame = F(container self)nn            self.framesF = framenn            frame.grid(row=0 column=0 sticky=""nsew"")nn        self.show_frame(StartPage)nn    def show_frame(self cont):nn        frame = self.framescontn        frame.tkraise()nnnclass StartPage(tk.Frame):nn    def __init__(self parent controller):n        tk.Frame.__init__(selfparent)n        label = tk.Label(self text=""UserName"" font=LARGE_FONT).grid(row=0 sticky=""E"")nn        label2 = tk.Label(self text=""Password"" font=LARGE_FONT).grid(row=1 sticky=""E"")nn        entry = tk.Entry(self).grid(row=0 column=1)n        entry2 = tk.Entry(selfshow=""*"").grid(row=1 column=1)nn        button = tk.Button(self text=""Log in""n                            command=lambda: controller.show_frame(PageTwo))n        button.grid(columnspan=2)n    def login(self parent controller):nnn        username = entry.get()n        password = entry1.get()n        if username == (""A"") and password == (""123""):n            tm.showinfo(""Login info""""Welcome Doan"")n        else:n            tm.showerror(""Login error""""Incorrect username"")nnnnnclass PageOne(tk.Frame):nn    def __init__(self parent controller):n        tk.Frame.__init__(self parent)n        label = tk.Label(self text=""Page One!!!"" font=LARGE_FONT)n        label.pack(pady=10padx=10)nn        button1 = tk.Button(self text=""Back to Home""n                            command=lambda: controller.show_frame(StartPage))n        button1.pack()nn        button2 = tk.Button(self text=""Page Two""n                            command=lambda: controller.show_frame(PageTwo))n        button2.pack()n        button3 = tk.Button(self text=""Tricep Workout""n                            command=lambda: controller.show_frame(PageThree)).pack()n        button2.pack()n        button4= tk.Button(self text=""Bicep Workout""n                            command=lambda: controller.show_frame(PageFour)).pack()n        button5= tk.Button(self text=""Back Workout""n                            command=lambda: controller.show_frame(PageFive)).pack()nn        button6= tk.Button(self text=""Chest Workout""n                            command=lambda: controller.show_frame(PageSix)).pack()nn' nan",['tkinter'],['tkinter']
40104130,"'Serializing a JSON object for a Django URL' 'I have a JSON object that looks like this:nnvar obj = {  n   ""selection"":  n      {  n         ""author"":""John Doe""n         ""articles"":  n            ""Article One""n            ""Article Two""n         n      }n   n}nnnI want to pass this object to Django to render a view that displays 'Article One' and 'Article Two' upon render. I first serialize the JSON object so that it can be appended to a URL; I use $.param(obj) for serialization. Now the JSON object looks something like this:nn""selection%5B0%5D%5Bauthor%5D=John+Doe&selection%5B0%5D%5Barticles%5D%5B%5D=Article+One&selection%5B0%5D%5Barticles%5D%5B%5D=Article+Two""nnnNow I can append this to a path and use window.open(url) the view will handle everything else. On the Django end I was surprised to see that the structure of the JSON object has changed to this:nn""selection0author=John+Doe&selection0articles=Article+One&selection0articles=Article+Two""nnnI want to be able to use the JSON object as a dict e.g.:nnobj = request.GET.get('selection')nobj = json.loads(obj)nprint(obj0.author)n...nnnHow should I handle this JSON structure on the Django side of things?n' 'You are not properly serializing the object to JSON even if you say you do. The correct way would be to use JSON.stringify() as @dunder states.nnThan you parse it back to an object with JSON.parse(strignifiedJson).nnvar obj = {  n   ""selection"":  n      {  n         ""author"":""John Doe""n         ""articles"":  n            ""Article One""n            ""Article Two""n         n      }n   n}n// Stringify and encodenvar objAsParam = encodeURIComponent(JSON.stringify(obj));nn// Send as a param for example like http://example.com?obj=YourStringifiedObject...nn// Parse it back:nvar parsedObj = JSON.parse(decodeURIComponent(objAsParam));nn'",['django'],['django']
40104259,"""How can i run a command on the command prompt with a batch file and keep running it for 'n' seconds?"" ""How can i run a command on the command prompt with a batch file and keep running it for 'n' seconds ? and then close it automatically ? (All in Background i.e without opening the console)n"" 'Use the subprocess module. You may be interested in subprocess.run and its timeout argument if you are using a newer version of Python (i.e. 3.5.x). If not take a look at subprocess.Popen.nnn  The timeout argument is passed to Popen.communicate(). If the timeout expires the child process will be killed and waited for. The TimeoutExpired exception will be re-raised after the child process has terminated.nnnnnReference: https://docs.python.org/3/library/subprocess.html#subprocess.runn' 'Create any python(.py) file and run it likennc:python27python.exe <path_of_the_file>/filename.pynnTo keep running it over say 1000 times:nnfor /l %x in (1 1 1000) do c:python27python.exe <path_of_the_file>/filename.pynnNote: Assuming your python is installed at c:python27n'","['python-2.7', 'python-3.x']","['python-3.x', 'python-2.7']"
40104291,"'Django admin foreign key values custom form' 'So I have a model Puzzle and a model Piece. Piece has as foreignKey to Puzzle. And on the admin on puzzle form to add a new element i have a stackedInLine for pieces. But i can only add more if I enter all the data from the piece. Is there a way to add new Pieces to the puzzle by choosing from a dropdown with the Piece values already stored on the DB ?? I google'd forever and found nothing....thanks. So what I have is:nnclass Puzzle(models.Model):n     name = models.CharField(max_length=200)nnclass Piece(models.Model):n     name = models.CharField(max_length=200)n     puzzle = models.ForeignKey(Puzzle null=True)nnnAnd on the django backend when I am editing a puzzle I would like to choose from a dropdown of all the Piece models stored on the DB and ""assign"" them to the current puzzle i'm editing. Is this possible? I'm at the moment using: nnclass PieceInline(admin.StackedInline):n      model = Piecen      extra = 1nclass PuzzleAdmin(admin.ModelAdmin):n      model = Piecen      inlines = (PieceInLine )nnnSo I have a stackedinline of pieces on the puzzle form but I can only create new ones...n' ""What if you create a new model say:nnfrom django.dispatch import receivernnnclass PieceSelector(models.Model):n    piece = models.ForeignKey(Piece)nn    def __unicode__(self):n        return piece.some_fieldnn@receiver(post_save sender=Piece)ndef piece_post_save_signal_receiver(sender **kwargs):n    if kwargs'created':n        PieceSelector.objects.create(piece=kwargs'instance')nnnNow when you create a Piece model object you should create PieceSelector object too. You can do it using post_save signal of the Piece model and it will provide all the pieces in a dropdown.nnWhen in the admin.py use PieceSelector as a StackedInline for Puzzle model.n""",['django'],['django']
40104449,'Pandas - Calculating daily differences relative to earliest value' 'This is probably pretty easy but for some reason I am finding it quite difficult to complete. Any tips would be greatly appreciated. I have some time series data consisting of 5-minute intervals each day ala:nnDate                   Valuesn2012-12-05 09:30:00    5n2012-12-05 09:35:00    7n2012-12-05 09:40:00    3n2012-12-05 09:45:00    2n2012-12-05 09:50:00    15n2012-12-06 09:30:00    4n2012-12-06 09:35:00    3n2012-12-06 09:40:00    8n2012-12-06 09:45:00    1nnnI would like to calculate the differences relative to the first value of the day (which in this case always will be the 9:30 value) ie. end up with this DataFrame:nnDate                   Valuesn2012-12-05 09:30:00    0n2012-12-05 09:35:00    2n2012-12-05 09:40:00    -2n2012-12-05 09:45:00    -3n2012-12-05 09:50:00    10n2012-12-06 09:30:00    0n2012-12-06 09:35:00    -1n2012-12-06 09:40:00    4n2012-12-06 09:45:00    -3nn' 'You can use broadcasting:nndf.Values - df.Values.iloc0nn' 'You need substract by Series created transform with groupby by Series.dt.date and first:nnprint (df.Values.groupby(df.Date.dt.day).transform('first'))n0    5n1    5n2    5n3    5n4    5n5    4n6    4n7    4n8    4nName: Values dtype: int64nndf.Values = df.Values - df.Values.groupby(df.Date.dt.day).transform('first')nnprint (df)n                 Date  Valuesn0 2012-12-05 09:30:00       0n1 2012-12-05 09:35:00       2n2 2012-12-05 09:40:00      -2n3 2012-12-05 09:45:00      -3n4 2012-12-05 09:50:00      10n5 2012-12-06 09:30:00       0n6 2012-12-06 09:35:00      -1n7 2012-12-06 09:40:00       4n8 2012-12-06 09:45:00      -3nn',['pandas'],['pandas']
40104510,"'modify lists removing elements without making a mess' ""I'm trying to resolve now a task that sounds like that:nnn  ''write a function modi(la lb) that takes in input 2 lists la and lb that have the same number of elements inside. The function should modify lists la and lb camparing elements with the same indexes in two lists and deleting a bigger one if elements are equal function delete both of them. ''nnnFor example:nnnla = 'bear' 'tiger' 'wolf' 'whale' 'elephant' nlb = 'swan' 'cat' 'dog' 'duck' 'rabbit'nnnSo the functin should return:n'bear''elephant'n'cat''dog''duck'nnI have wrote the next code but it doesn't modify lists but create new ones and add there elements. Some ideas how can i do that?nndef confront(s1 s2):   nn    if s1 < s2:   # condition that tells which element to choose latern        return 0n    elif s2 < s1:n        return 1n    else:n        return 2nnndef modi(lalb):nn    latemp = nn    lbtemp = nn    i = 0nn    while i < len(la):nnn        q = confront(lai lbi)n        if q == 0:n            latemp.append(lai)nn        elif q == 1:n            lbtemp.append(lbi)nnn        i +=1  n    la = latempn    lb = lbtempn    return la lbnnnI have tried remove() but it have created a big messn"" ""You should use del to delete list item. Also you should iterate from end to the beginning because if you will go from the beginning and delete let say 1st element the element that was on the 3rd place will be now on the 2ndnnIt should look likenn#you need to handle what if len of lists is 0 if lens are not the same and so on...ndef compare_and_delete(list1 list2):n    i = len(list1) -1n    while i >= 0:n        if list1i > list2i:n            del list1in        elif list2i > list1i:n            del list2in        else:n            del list1in            del list2inn        i-=1nn        return list1 list2nnl1 l2 = compare_and_delete('bear' 'tiger' 'wolf' 'whale' 'elephant' 'swan' 'cat' 'dog' 'duck' 'rabbit')nn"" 'You can take advantage of the fact that assigning to a slice modifies the list:nnla: = latempnlb: = lbtempnn' ""Generally when you're mutating a list while iterating over it. It's good practice to iterate over a copy instead. Below is an example of what you would do to mutate one list.nnlist = nlist_copy = list:nfor i in list_copy:n    list.remove(i)nreturn listnnnThis allows you to maintain the correct index per iteration.nnBelow is my attempt to explain what I meant and using a for loop to get your expected result. Hope it helps.nndef confront(s1 s2):nnif s1 < s2:   # condition that tells which element to choose latern    return 0nelif s2 < s1:n    return 1nelse:n    return 2nnndef modi(lalb):n    la_copy = la:n    lb_copy = lb:nn    for i in range(len(la_copy)):n        q = confront(la_copyi lb_copyi)n        if q == 0:n            lb.remove(lb_copyi)n        elif q == 1:n            la.remove(la_copyi)nn    return la lbnnnla = 'bear' 'tiger' 'wolf' 'whale' 'elephant'nlb = 'swan' 'cat' 'dog' 'duck' 'rabbit'nnnCalling it via a print() will get the returned two lists.nnNote: this returns a tuple. IF you'd like seperate lists call it via the following.nnlist1 list2 = modi(lalb)nprint(list1)nprint(list2)n'bear' 'elephant'n'cat' 'dog' 'duck'nn"" ""This will solve your problem. I think it's easier than all other solutions.nndef modi(la lb):n    new_la = n    new_lb = n    for a b in zip(la lb):n        if a == b:n            continuen        if a > b:n            new_lb.append(b)n        if a < b:n            new_la.append(a)n    return new_la new_lbnnnIf You however want to change EXISTING lists You could do this:nndef modi(la lb):n    del_la = n    del_lb = n    for i (a b) in enumerate(zip(la lb)):n        if a == b:n            del_la.append(i)n            del_lb.append(i)n        if a > b:n            del_la.append(i)n        if a < b:n            del_lb.append(i)n    for x in del_la-1::-1:n        del laxn    for x in del_lb-1::-1:n        del lbxn    return la lbnn"" ""In your own code la = latemp and lb = lbtemp create references to the two new lists that are local to the function they have no bearing on the lists that you pass in to the function. According to your specs you should be mutating the lists passed in not reassigning or creating new lists.nnSince you are doing an elementwise comparison you could use zip and remove from each list according to your specs:nndef modi(la lb):n    for i j in zip(la lb):n        # both the samen        if i == j:n            la.remove(i) n            lb.remove(i)n        # element from la is biggern        elif i > j:n            la.remove(i)n        # else element from lb must be biggern        else:n            lb.remove(j)nnnla = 'bear' 'tiger' 'wolf' 'whale' 'elephant'nlb = 'swan' 'cat' 'dog' 'duck' 'rabbit'nnmodi(la lb) # will modify the lists passed in.nnprint(la lb) nn"" ""Essentially you need to keep track of how many times you've deleted from each list and offset your indexing by that amount. Here's a basic approach:nn>>> an'bear' 'tiger' 'wolf' 'whale' 'elephant'n>>> bn'swan' 'cat' 'dog' 'duck' 'rabbit'n>>> i = j = 0n>>> for k (str1str2) in enumerate(zip(ab)):n...     if len(str1) == len(str2):n...         del ak-i bk-jn...         i += 1n...         j += 1n...     elif len(str1) > len(str2):n...         del ak-in...         i += 1n...     else:n...         del bk-jn...         j += 1n... n>>> ann>>> bn'cat' 'dog' 'duck' 'rabbit'n>>> nn""","['list', 'python-3.x']","['list', 'dictionary', 'python-2.7']"
40104587,"'Why does my plot not disappear on exit in ipython mode?' 'I'm showing some plots using matplotlib in the ipython prompt. When closing the plot window it does not disappear but gets ""stuck"" in the background and does not respond to user actions. You can try it out yourself with the following code: nn# test.pynimport matplotlib.pyplot as pltnndef f(): n    plt.plot(1 2 3 4 3 5)n    plt.show()nnnand in the promptnnpingul $ ipythonnPython 3.5.2 (default Jun 27 2016 03:10:38) nType ""copyright"" ""credits"" or ""license"" for more information.nnIPython 5.1.0 -- An enhanced Interactive Python.nnIn 1: import testnIn 2: test.f()n### Trying to close it now doesn't worknnnIs this a bug or can I fix it somehow?nnRunning the same code with the normal python prompt works as expected.n' 'You should be a bit careful with using pyplot in ipython.  Especially plt.show() is blocking the ipython terminal.  You should use fig.show() since it does not block ipython.  If you really want to use pyplot one work-around is to use plt.gcf().show() which will get the current figure (gcf=get current figure) and only show that figure.  However I would recommend creating the figure as fig = plt.figure() and then use fig.show(). nnPlease note that if you run it with python you need plt.show()!  Otherwise the figure will show and then close immediately! n' ""Try running %matplotlib before plotting so that IPython integrates with the GUI event loop showing the plots.nnThis shouldn't be necessary once matplotlib 2.0 is released because it has some code to detect when it's running inside IPython.n""",['matplotlib'],['matplotlib']
40104592,"'Remove HTML tags in script' 'I've found this piece of code on the internet. It takes a sentence and makes every single word into link with this word. But it has weak side: if a sentence has HTML in it this script doesn't remove it.nnFor example: it replaces '<b>asserted</b>' with 'http://www.merriam-webster.com/dictionary/<b>asserted</b>'nnCould you please tell me what to change in this code for it to change '<b>asserted</b>' to 'http://www.merriam-webster.com/dictionary/asserted'.nnvar content = document.getElementById(""sentence"").innerHTML;nnvar punctuationless = content.replace(/./#!$%Øx9f^?&*;:{}=-_`~()âx80x9dâx80x9c""/g """");nvar mixedCase = punctuationless.replace(/s{2}/g);nvar finalString = mixedCase.toLowerCase();nnvar words = (finalString).split("" "");nnvar punctuatedWords = (content).split("" "");nnvar processed = """";nfor (i = 0; i < words.length; i++) {n    processed += ""<a href = ""http://www.merriam-webster.com/dictionary/"" + wordsi + """">"";n    processed += punctuatedWordsi;n    processed += ""</a> "";n}nndocument.getElementById(""sentence"").innerHTML = processed;nn' 'function stripAllHtml(str) {n  if (!str || !str.length) return ''nn  str = str.replace(/<script.*?>.*?</script>/igm '')nn  let tmp = document.createElement(""DIV"");n  tmp.innerHTML = str;nn  return tmp.textContent || tmp.innerText || """";n}nnstripAllHtml('<a>test</a>')nnnThis function will strip all the HTML and return only text.nnHopefully this will work for youn' 'This regex /<{1}^<>{1}>{1}/g should replace any text in a string that is between two of these <> and the brackets themselves with a white space. Thisnnrnrn  var str = ""<hi>How are you<hi><table><tr>I<tr><table>love cake<g>""rn  str = str.replace(/<{1}^<>{1}>{1}/g"" "")rn  document.writeln(str);rnrnrnnnwill give back "" How are you I love cake"".nnIf you paste thisnnvar stripHTML = str.mixedCase(/<{1}^<>{1}>{1}/g"""")nnnjust below thisnnvar mixedCase = punctuationless.replace(/s{2}/g);nnnand replace mixedCase with stripHTML in the line after it will probably workn'",['regex'],"['dictionary', 'regex']"
40104730,"""Vertical Bar chart using rotation='vertical' not working"" 'From the matplot lib example lines_bars_and_markersnusing rotation='vertical' does not make it vertical. What am I doing wrong?nn""""""nSimple demo of a horizontal bar chart.n""""""nimport matplotlib.pyplot as pltnplt.rcdefaults()nimport numpy as npnimport matplotlib.pyplot as pltnnn# Example datanpeople = ('Tom' 'Dick' 'Harry' 'Slim' 'Jim')ny_pos = np.arange(len(people))nperformance = 3 + 10 * np.random.rand(len(people))nerror = np.random.rand(len(people))nnplt.barh(y_pos performance xerr=error align='center' alpha=0.4)nplt.yticks(y_pos people)nplt.xlabel('Performance')nplt.title('How fast do you want to go today?')nnplt.show()nrotation='vertical'nn' ""barh is for horizontal bar charts change to bar and then swap around the data for the axes. You can't simply write rotation='vertical' because that isn't telling the matplotlib library anything it's just creating a string that is never used. nnimport matplotlib.pyplot as pltnplt.rcdefaults()nimport numpy as npnimport matplotlib.pyplot as pltnnn# Example datanpeople = ('Tom' 'Dick' 'Harry' 'Slim' 'Jim')nx_pos = np.arange(len(people))nperformance = 3 + 10 * np.random.rand(len(people))nerror = np.random.rand(len(people))nnplt.bar(x_pos performance yerr=error align='center' alpha=0.4)nplt.xticks(x_pos people)nplt.ylabel('Performance')nplt.title('How fast do you want to go today?')nnplt.show()nn""","['numpy', 'matplotlib']",['matplotlib']
40104737,"'scrapy starting a new project' 'I have installed python 2.7.12 version on a Windows 7 system. I have also installed pywin32 and Visual C++. When I enter the command pip --version it does not generate any output the cursor moves to the next line and blinks.nnBut when I use the command python -m pip --version the version of pip is displayed. Also to install scrapy I had to use the command python -m pip install scrapy. Scrapy got installed successfully. nnI have set the path in the environment variables correctly - C:Python27;C:Python27Scripts;nnWhen I had to start my new project in scrapy I used the command scrapy startproject project_name. Again the cursor moved to the next line and blinked. No result is generated not even any error message.nnWhen I tried again and again it created the folder in the directory with the respective files.nnWhen I developed a code and tried to run the spider by the command scrapy crawl name again the same problem appeared - No response.nnNow again I am not able to create a new project as the same issue is arising.nnIf someone could please suggest the possible reasons for the error and the solution for this.nnIt worked out nwhen i used the command python -m scrapy <command> <arguments? to follow the scrapy tutorial. however it was fine until i run the crawl command. when i use the python -m scrapy.cmdline shell 'http://quotes.toscrape.com/page/1/' command it shows error nnC:UsersMinorMiraclesDesktoptutorial>python -m scrapy.cmdline crawl quotesn2016-10-19 10:26:15 scrapy INFO: Scrapy 1.2.0 started (bot: tutorial)n2016-10-19 10:26:15 scrapy INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tuntorial.spiders' 'SPIDER_MODULES': 'tutorial.spiders' 'ROBOTSTXT_OBEY': Truen 'BOT_NAME': 'tutorial'}n2016-10-19 10:26:16 scrapy INFO: Enabled extensions:n'scrapy.extensions.logstats.LogStats'n 'scrapy.extensions.telnet.TelnetConsole'n 'scrapy.extensions.corestats.CoreStats'n2016-10-19 10:26:17 scrapy INFO: Enabled downloader middlewares:n'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'n 'scrapy.downloadermiddlewares.retry.RetryMiddleware'n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware'n 'scrapy.downloadermiddlewares.stats.DownloaderStats'n2016-10-19 10:26:17 scrapy INFO: Enabled spider middlewares:n'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'n 'scrapy.spidermiddlewares.referer.RefererMiddleware'n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'n 'scrapy.spidermiddlewares.depth.DepthMiddleware'n2016-10-19 10:26:17 scrapy INFO: Enabled item pipelines:nn2016-10-19 10:26:17 scrapy INFO: Spider openedn2016-10-19 10:26:17 scrapy INFO: Crawled 0 pages (at 0 pages/min) scraped 0 intems (at 0 items/min)n2016-10-19 10:26:17 scrapy DEBUG: Telnet console listening on 127.0.0.1:6023n2016-10-19 10:26:18 scrapy DEBUG: Crawled (404) <GET http://quotes.toscrape.conm/robots.txt> (referer: None)n2016-10-19 10:26:18 scrapy DEBUG: Crawled (200) <GET http://quotes.toscrape.conm/page/1/> (referer: None)n2016-10-19 10:26:18 quotes DEBUG: Saved file quotes-1.htmln2016-10-19 10:26:18 scrapy DEBUG: Crawled (200) <GET http://quotes.toscrape.conm/page/2/> (referer: None)n2016-10-19 10:26:19 quotes DEBUG: Saved file quotes-2.htmln2016-10-19 10:26:19 scrapy INFO: Closing spider (finished)n2016-10-19 10:26:19 scrapy INFO: Dumping Scrapy stats:n{'downloader/request_bytes': 675n 'downloader/request_count': 3n 'downloader/request_method_count/GET': 3n 'downloader/response_bytes': 5974n 'downloader/response_count': 3n 'downloader/response_status_count/200': 2n 'downloader/response_status_count/404': 1n 'finish_reason': 'finished'n 'finish_time': datetime.datetime(2016 10 19 4 56 19 56000)n 'log_count/DEBUG': 6n 'log_count/INFO': 7n 'response_received_count': 3n 'scheduler/dequeued': 2n 'scheduler/dequeued/memory': 2n 'scheduler/enqueued': 2n 'scheduler/enqueued/memory': 2n 'start_time': datetime.datetime(2016 10 19 4 56 17 649000)}n2016-10-19 10:26:19 scrapy INFO: Spider closed (finished)nnC:UsersMinorMiraclesDesktoptutorial>python -m scrapy.cmdline shell 'http://qnuotes.toscrape.com/page/1/'n2016-10-19 11:11:40 scrapy INFO: Scrapy 1.2.0 started (bot: tutorial)n2016-10-19 11:11:40 scrapy INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tuntorial.spiders' 'ROBOTSTXT_OBEY': True 'DUPEFILTER_CLASS': 'scrapy.dupefiltersn.BaseDupeFilter' 'SPIDER_MODULES': 'tutorial.spiders' 'BOT_NAME': 'tutorial'n 'LOGSTATS_INTERVAL': 0}n2016-10-19 11:11:40 scrapy INFO: Enabled extensions:n'scrapy.extensions.telnet.TelnetConsole'n 'scrapy.extensions.corestats.CoreStats'n2016-10-19 11:11:40 scrapy INFO: Enabled downloader middlewares:n'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'n 'scrapy.downloadermiddlewares.retry.RetryMiddleware'n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware'n 'scrapy.downloadermiddlewares.stats.DownloaderStats'n2016-10-19 11:11:40 scrapy INFO: Enabled spider middlewares:n'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'n 'scrapy.spidermiddlewares.referer.RefererMiddleware'n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'n 'scrapy.spidermiddlewares.depth.DepthMiddleware'n2016-10-19 11:11:40 scrapy INFO: Enabled item pipelines:nn2016-10-19 11:11:40 scrapy DEBUG: Telnet console listening on 127.0.0.1:6023n2016-10-19 11:11:40 scrapy INFO: Spider openedn2016-10-19 11:11:42 scrapy DEBUG: Retrying <GET http://'http:/robots.txt> (fainled 1 times): DNS lookup failed: address ""'http:"" not found: Errno 11004 getadndrinfo failed.n2016-10-19 11:11:45 scrapy DEBUG: Retrying <GET http://'http:/robots.txt> (fainled 2 times): DNS lookup failed: address ""'http:"" not found: Errno 11004 getadndrinfo failed.n2016-10-19 11:11:47 scrapy DEBUG: Gave up retrying <GET http://'http:/robots.tnxt> (failed 3 times): DNS lookup failed: address ""'http:"" not found: Errno 1100n4 getaddrinfo failed.n2016-10-19 11:11:47 scrapy ERROR: Error downloading <GET http://'http:/robots.ntxt>: DNS lookup failed: address ""'http:"" not found: Errno 11004 getaddrinfo fnailed.nDNSLookupError: DNS lookup failed: address ""'http:"" not found: Errno 11004 getnaddrinfo failed.n2016-10-19 11:11:49 scrapy DEBUG: Retrying <GET http://'http://quotes.toscrapen.com/page/1/'> (failed 1 times): DNS lookup failed: address ""'http:"" not found:nErrno 11004 getaddrinfo failed.n2016-10-19 11:11:51 scrapy DEBUG: Retrying <GET http://'http://quotes.toscrapen.com/page/1/'> (failed 2 times): DNS lookup failed: address ""'http:"" not found:nErrno 11004 getaddrinfo failed.n2016-10-19 11:11:54 scrapy DEBUG: Gave up retrying <GET http://'http://quotes.ntoscrape.com/page/1/'> (failed 3 times): DNS lookup failed: address ""'http:"" notn found: Errno 11004 getaddrinfo failed.nTraceback (most recent call last):n  File ""C:Python27librunpy.py"" line 174 in _run_module_as_mainn    ""__main__"" fname loader pkg_name)n  File ""C:Python27librunpy.py"" line 72 in _run_coden    exec code in run_globalsn  File ""C:Python27libsite-packagesscrapycmdline.py"" line 161 in <module>n    execute()n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 142 in executen    _run_print_help(parser _run_command cmd args opts)n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 88 in _run_printn_helpn    func(*a **kw)n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 149 in _run_commnandn    cmd.run(args opts)n  File ""C:Python27libsite-packagesscrapycommandsshell.py"" line 71 in runnn    shell.start(url=url)n  File ""C:Python27libsite-packagesscrapyshell.py"" line 47 in startn    self.fetch(url spider)n  File ""C:Python27libsite-packagesscrapyshell.py"" line 112 in fetchn    reactor self._schedule request spider)n  File ""C:Python27libsite-packagestwistedinternetthreads.py"" line 122 inn blockingCallFromThreadn    result.raiseException()n  File ""<string>"" line 2 in raiseExceptionntwisted.internet.error.DNSLookupError: DNS lookup failed: address ""'http:"" not fnound: Errno 11004 getaddrinfo failed.nnncan anyone tell me what is wrongn' 'Using the alternative command python -m scrapy.cmdline <command> <arguments> (e.g. python -m scrapy.cmdline version -v) workednnthanks Pauln'",['python-2.7'],['python-2.7']
40104831,"'django required file field validation' 'Working with django form in which i have two file uploads fields one for artist image and another for event poster both of these fields are required. nnclass CreateEventStepFirstForm(forms.Form):n    event_title = forms.CharField(required = True max_length=20 widget=forms.TextInput(attrs={n        'class' : 'custome-input promote-input' n        'autocomplete' : 'off'n        'data-empty-message':'This field is required' n    }))n    ticket_title = forms.CharField(required = True max_length=225 widget=forms.TextInput(attrs={n        'class' : 'custome-input promote-input' n        'autocomplete' : 'off'n        'data-empty-message':'This field is required' n    }))n    artist_image = forms.FileField(required = True widget=forms.FileInput(attrs={n        'class' : 'upload-img'n        'data-empty-message':'Please upload artist image this field is required'n    }))n    event_poster = forms.FileField(required = True widget=forms.FileInput(attrs={n        'class' : 'upload-img'n        'data-empty-message':'Please upload artist image this field is required'n    }))nnnProblem is that all fields are validated properly except these two file fields when i select images for both artist_image and event_poster it don't validate the fields and give ""This field is required"" error even i select both images.nnn' 'You need to add request.FILES as follows:nnform = CreateEventStepFirstForm(request.POST request.FILES)nn'",['django'],['django']
40104946,"'How to get date after subtracting days in pandas' ""I have a dataframe:nnIn 15: dfnOut15: n        date  dayn0 2015-10-10   23n1 2015-12-19    9n2 2016-03-05   34n3 2016-09-17   23n4 2016-04-30    2nnnI want to subtract the number of days from the date and create a new column.nnIn 16: df.dtypesnOut16: ndate    datetime64nsnday              int64nnnDesired output something like:nnIn 15: dfnOut15: n        date  day date1n0 2015-10-10   23 2015-09-17n1 2015-12-19    9 2015-12-10n2 2016-03-05   34 2016-01-29n3 2016-09-17   23 2016-08-25n4 2016-04-30    2 2016-04-28nnnI tried but this does not work:nndf'date1'=df'date'+pd.Timedelta(df'date'.dt.day-df'day')nnnit throws error :nnn  TypeError: unsupported type for timedelta days component: Seriesnn"" ""import dateutil.relativedeltandef calculate diff(v):n    return v'date' - dateutil.relativedelta.relativedelta(day=v'day')ndf'date1'=df.apply(calculate_diff axis=1)nnngiven that v'date' is datetime objectn"" 'You can use to_timedelta:nndf'date1' = df'date' -  pd.to_timedelta(df'day' unit='d')nnprint (df)n        date  day      date1n0 2015-10-10   23 2015-09-17n1 2015-12-19    9 2015-12-10n2 2016-03-05   34 2016-01-31n3 2016-09-17   23 2016-08-25n4 2016-04-30    2 2016-04-28nnnIf need Timedelta use apply but it is slowier:nndf'date1' = df'date' -  df.day.apply(lambda x: pd.Timedelta(x unit='D'))nnprint (df)n        date  day      date1n0 2015-10-10   23 2015-09-17n1 2015-12-19    9 2015-12-10n2 2016-03-05   34 2016-01-31n3 2016-09-17   23 2016-08-25n4 2016-04-30    2 2016-04-28nnnTimings:nn#5000 rows x 2 columnsndf = pd.concat(df*1000).reset_index(drop=True)nnIn 252: %timeit df'date' -  df.day.apply(lambda x: pd.Timedelta(x unit='D'))n10 loops best of 3: 45.3 ms per loopnnIn 253: %timeit df'date' -  pd.to_timedelta(df'day' unit='d')n1000 loops best of 3: 1.71 ms per loopnn'",['pandas'],['pandas']
40105027,"'Reg ex remove non alpha characters keeping spaces' 'I've written a simple function that strips a string of all non-alpha characters keeping spaces in place.nnCurrently it relies on using two regular expressions. However in in interest of brevity I'd like to reduce those two reg exs into one. Is this possible?nnimport renndef junk_to_alpha(s):n  reg = r""^A-Za-z""n  p = re.compile(reg)n  s = re.sub(p "" "" s)n  p = re.compile(r""s+"")n  s = re.sub(p "" "" s)n  return snnprint junk_to_alpha(""Spoons! 12? /@# .1 12 Yeah? {}"")nn# Spoons Yeahnn' 'You may enclose the ^a-zA-Z+ with s*:nnimport renndef junk_to_alpha(s):n  s = re.sub(r""s*^A-Za-z+s*"" "" "" s)n  return snnprint junk_to_alpha(""Spoons! 12? /@# .1 12 Yeah? {}"")nnnSee the online Python demonnThe pattern details:nnns* - zero or more whitespacesn^A-Za-z+ - 1 or more characters other than ASCII lettersns* - see above.nn'","['regex', 'python-2.7']",['regex']
40105086,"'Disable Persistence in Flask Routes' 'I'm having a weird problem with my Flask web application.nnI'm building a REST API with Flask and the Google App Engine I can get it all to work par for a weird problem that wherever I've looked I've only found people that want to have what I want to disable.nnBelow is a sample piece to explain my problem:nnapp = Flask(__name__ static_url_path="""")nncounter = 0nn@app.route('/api/v1.0/' methods=""POST"" ""OPTIONS"")ndef api_base():n    global countern    counter += 1n    return counternnnI'd expect the output from the above to always be 1 as the instance is not persisted but at the moment I keep getting an incremental number from any call I do be it from different machines or incognito or anything. The only way to get back a counter = 1 is by restarting the server.nnIs there a way in Flask to define which variables should be persisted and which should be not?  I'd like session and DB instances to be persisted but not everything since it is causing race conditions in some of the more complex data processing.nnI'm using Flask v0.11.n' nan",['python-2.7'],"['python-2.7', 'python-3.x']"
40105090,"'Find pre/post-decessor in pandas for each group' 'To reduce the complexity I reworked the whole post:nnSo what do I want to achieve:nFor a list of campaigns with given start at end dates I want to return the previous campaign. Previous means that a campaign starts after the end day of the previous one. However if there are several previous campaings I want to return the campaign with the same type. This shall be done for every campaign I have (typically I will have grouped data (think of item/campaign pairs where one campaing has several items and I'm interested in the previous campaign for a single item)nnConsider the following datannCampaign | StartDay | EndDay | Typen---------|----------|--------|------n    1    |    1     |   10   |  1n    2    |    5     |   15   |  1n    3    |    7     |   15   |  2n    4    |   11     |   20   |  1n    5    |   16     |   25   |  2nnnSo in this case the desired output is the followingnnCampaign | PreviousCampaignn---------|-----------------n    1    |     NANn    2    |     NANn    3    |     NANn    4    |      1n    5    |      3nnnIf the first entries vanish it's ok. Note that the predecessor of 5 is 3 due to the type condition.nnI'm able to do this merging the table on itself via campaign querying the correct rows and several steps to ensure that the type costraint is satisfied.nWithout the type type constraint this is a bit easier.nnHowever studying ""modern pandas"" by tom augspurger I have the feeling that pivoting stacking melting or a combination should work. But I haven't figured out how yet.n' nan",['pandas'],['pandas']
40105197,"'Python TksimpleDialog positioning next to the root window' 'I am trying to open a simple dialog window in which the user enters a choice based on a menu presented on the root window. When I run the code however the dialog opens directly above the menu in the root window obscuring it from sight. Is there a way to open the dialog so it opens next to the root window as shown in the attached image. nnnnI have checked this link and it does not seem there is any positioning arguments for simple dialogs. I have also tried with toplevel but it got messy with multiple windows open. nnMy code is as follows: nnfrom Tkinter import *nimport tkSimpleDialognnroot = Tk()nroot.lift()nnnLabel(root text = ""Menu Choices:"").grid(row=1 column =0)nLabel(root text='1. Baloney and cheese').grid(row=2 column=0 pady=4)nLabel(root text='2. Roast chicken and gravy').grid(row=3 column=0 pady=4)nLabel(root text='3. Pear salad').grid(row=4 column=0 pady=4)nLabel(root text='4. Cateloupe and brocoli soup').grid(row=5 column=0 pady=4)nnpeople = ""Liam""""Henry""""Paula""nnmenuChoice = nnfor i in people:n    c = tkSimpleDialog.askinteger('Franks Restaurant' 'Please choose your meal?' parent = root)n    menuChoice.append(c)nnroot.mainloop()nn' nan","['python-2.7', 'tkinter']",['tkinter']
40105328,"'How to split an RDD into two RDDs and save the result as RDDs with PySpark?' ""I'm looking for a way to split an RDD into two or more RDDs and save the results obtained as two separated RDDs. Given for exemple :nnrdd_test = sc.parallelize(range(50) 1)nnnMy code :nndef split_population_into_parts(rdd_test):nn    N = 2n    repartionned_rdd = rdd_test.repartition(N).distinct()n    rdds_for_testab_populations = repartionned_rdd.glom()nn    return rdds_for_testab_populationsnnrdds_for_testab_populations = split_population_into_parts(rdd_test)nnnWhich gives :nn0n  2n  4n  6n  8n  10n  12n  14n  16n  18n  20n  22n  24n  26n  28n  30n  32n  34n  36n  38n  40n  42n  44n  46n  48n 1n  3n  5n  7n  9n  11n  13n  15n  17n  19n  21n  23n  25n  27n  29n  31n  33n  35n  37n  39n  41n  43n  45n  47n  49nnNow I want to associate avery list here to a new RDD. RDD1 and RDD2 for exemple. What to do ? Thx !n"" ""I got the solutions.nndef get_testab_populations_tables(rdds_for_testab_populations):ni = 0nwhile i < len(rdds_for_testab_populations.collect()):n    for testab_table in rdds_for_testab_populations.toLocalIterator():n        namespace = globals()n        namespace'tAB_%d' % i = sc.parallelize(testab_table)n        i += 1nnreturn;nnnThen you can do :nnprint tAB_0.collect()nprint tAB_1.collect()netc.nn""",['list'],['python-2.7']
40105414,"""python - 'the truth value of an array with more than one element is ambiguous' - what truth value?"" ""first post! I've looked through a lot of other posts on this problem but can't find anything that applies to my code.nnI'm trying to read an audio file and then find the max and min values of the array of samples x.nwavread() is a function defined in another module that I've imported.nIt returns fs x.nx is a one-dimensional array (x.shape = (150529).)nndef minMaxAudio(inputFile):n    (fs x) = wavread(inputFile)n    max_val = numpy.amax(x)n    min_val = numpy.amin(x) n    return (min_val max_val)nnnwhen I type these lines individually into ipython I get the result I want. but when I call this function from an imported .py file I get the error:nnValueError: The truth value of an array with more than one element is ambiguous.   nUse a.any() or a.all()nnnIt highlights the last line (return statement) as the location of the error.nnEvery other post on this that I've looked at includes some sort of evaluation or comparison operator in the code. Mine doesn't have one... does it?!nnThanks!n"" ""Have you noticed that if your WAV file has more than one channel say it is stereo min_val and max_val will be arrays themselves?nnSuch a code would trigger the error you encounter:nnmin max = minMaxAudio('acdc.wav')n# Assuming floatsnif max > 1:n    print('saturation')nnnWhereas the following will work:nnmin max = minMaxAudio('acdc.wav')n# Assuming floatsnif np.any(max > 1):n    print('saturation')nn""",['numpy'],['numpy']
40105470,"'Python Django Template cannot get name from model function' 'While I understood that I can call a function definition from our models I can't seem to extract the file name of my uploaded document. Below I tried the following template format but either results from my desired output:nn.html Version 1nn<form action=""."" method=""GET"">n{% if documents %}n   <ul>n      {% for document in documents %}n        <li> {{ document.docfile.filename }}n        <input type = ""submit"" name=""load-data"" value=""Add to Layer""/>n        </li>n      {% endfor %}n  </ul>nnnResult: It just shows the button.nn.html Version 2nn<form action=""."" method=""GET"">n{% if documents %}n   <ul>n      {% for document in documents %}n        <li> {{ document.filename }}n        <input type = ""submit"" name=""load-data"" value=""Add to Layer""/>n        </li>n      {% endfor %}n  </ul>nnnResult: It just shows the button.nn.html Version 3nn<form action=""."" method=""GET"">n{% if documents %}n   <ul>n      {% for document in documents %}n        <li> {{ document.docfile.name }}n        <input type = ""submit"" name=""load-data"" value=""Add to Layer""/>n        </li>n      {% endfor %}n  </ul>nnnResult: Prints the complete pathname (eg: /documents/2016/10/08/filename.csv) together with the buttonnnHere's the rest of my code:nnmodels.pynnclass Document(models.Model):n     docfile = models.FileField(upload_to='document/%Y/%m/%d')nn     def filename(self):n        return os.path.basename(self.file.name)nnnviews.pynndocuments = Document.objects.all()nreturn render(request 'gridlock/upload-data.html'n              {n               'documents' : documentsn               'form': formn              })nnnI hope someone can explain why everything I tried:n{{ document.docfile.filename }} or {{document.file.filename}} or {{document.filename}} won't work either for me? Thanks!n' 'I think you got pretty close with {{ document.filename }} except in your models you need to change nndef filename(self):n    return os.path.basename(self.file.name)nnnintonndef filename(self):n    # try printing the filename here to see if it worksn    print (os.path.basename(self.docfile.name))n    return os.path.basename(self.docfile.name)nnnin your models the field is called docfile so you need to use self.docfile to get its value.nnsource: django filefield return filename only in templaten'",['django'],['django']
40105581,'Is playing back an ongoing recording possible?' 'I want to record the audio being captured by the mic of my laptop and then say after some delay play it back through the headphones connected to laptop. What I tried is recording the incoming audio in batches of 10 sec as background process & after the 1st audio clip of 10 sec is recorded start playing it back in the background through the headphones. The problem that I am facing is that when in the end of recording I combine all the batches of sound clips some sound samples are lost in the process of stopping one recording & restarting the recording of next incoming sound.nnSo is it possible to let the recording continue & after some samples are collected start playing that ongoing recording ? Or is there any other work around to this samples being lost?n' nan,['python-2.7'],['python-2.7']
40105929,"'Finding solution to a crypt equation in python' ""Consider the equation ABCBA = D * BE * BFFA.The task is to determine where A B C D E and F which are distinct digits. The equation with numerical values is 91819 = 7 * 13 * 1009 hence the program should print {'A':9 'B':1 'C':8  'D':7'E':3 'F':0}.nHere is the code i didnnresult=nfor A in range (10):n    for B in range(10):n        for C in range(10):n            for D in range(10):n                for E in range(10):n                   for F in range(10):n                       if int(str(A)+str(B)+str(C)+str(B)+str(A)) == D * int(str(B)+str(E)) * int(str(B)+str(F)+str(F)+str(A)):n                             result.append({'A':A'B':B'C':C'D':D'E':E'F':F})nprint((resultlen(result)-1))nnnNow that it works for the equation in the example.How sholud I modify my code so that it works for any equationwhich is to be input by the user?n"" ""If you only need your last output and want to discard everything else you can just overwrite the same variable over and over again:nnresult = {}nfor B in range(10):n    for C in range(10):n        for D in range(10):n            for E in range(10):n                for F in range(10):n                    if int(str(A)+str(B)+str(C)+str(B)+str(A)) == D * int(str(B)+str(E)) * int(str(B)+str(F)+str(F)+str(A)):n                        result = {'A':A'B':B'C':C'D':D'E':E'F':F}nnpprint(result)nnnIf you want to keep all results but only print the last one use a list:nnresult = nfor B in range(10):n    for C in range(10):n        for D in range(10):n            for E in range(10):n                for F in range(10):n                    if int(str(A)+str(B)+str(C)+str(B)+str(A)) == D * int(str(B)+str(E)) * int(str(B)+str(F)+str(F)+str(A)):n                        result.append({'A':A'B':B'C':C'D':D'E':E'F':F})nnpprint(result-1)nn"" ""I don't think @Khris's answer is 100% correct as you do need a loop for A and your original question listed that first digit of any number could not be 0; hence A B and D cannot be 0 so if A and D and B: is added for this.nnwhich then results in (printing all results you can pick from there):nnfrom pprint import pprintnnresults = nfor A in range(10):n    for B in range(10):n        for C in range(10):n            for D in range(10):n                for E in range(10):n                    for F in range(10):n                        if A and D and B:n                            if int(str(A)+str(B)+str(C)+str(B)+str(A)) == D * int(str(B)+str(E)) * int(str(B)+str(F)+str(F)+str(A)):n                                results.append({'A':A'B':B'C':C'D':D'E':E'F':F})nnfor result in results:n    pprint(result)nnnYou further state the following:nnn  The last of many outputs of pprint gives the correct result.Cann  somebody edit it to print only the last(correct) result?nnnWhich is incorrect based on the equation ABCBA = D * BE * BFFA: the following results would all be valid:nn{'A': 1 'B': 1 'C': 0 'D': 1 'E': 1 'F': 0}  # 11011 = 1 * 11 * 1001 n{'A': 2 'B': 1 'C': 3 'D': 1 'E': 6 'F': 3}  # 21312 = 1 * 16 * 1332 n{'A': 2 'B': 1 'C': 9 'D': 1 'E': 1 'F': 9}  # 21912 = 1 * 11 * 1992 n{'A': 5 'B': 1 'C': 3 'D': 3 'E': 1 'F': 5}  # 51315 = 3 * 11 * 1555 n{'A': 9 'B': 1 'C': 8 'D': 7 'E': 3 'F': 0}  # 91819 = 7 * 13 * 1009nn""",['python-3.x'],"['python-2.7', 'python-3.x', 'list']"
40106074,"'remove control character whitespaces from dataframe' ""I have a dataframe df by which I am getting list of list by using thisnndata = list(map(strn.tolist())) for n in df.valuesnnnafter that I replace specific control character from data like this nndata =  e.replace(u'xa0' u'') for e in tempval  for tempval in data nnnThis works fine but I want this to be done in dataframe itself  please suggest something.n"" 'You can use DataFrame.replace:nndf = pd.DataFrame({'A':'xa0''s''w'n                   'B':'s''w''v'n                   'C':'e''d''xa0'})nnprint (df)n   A  B  Cn0     s  en1  s  w  dn2  w  v  nnnThen for creating list of lists convert DataFrame to numpy array by values and then tolist:nndf.replace(u'xa0'u'' regex=True inplace=True)n#if need cast all values to str add astypenprint (df.astype(str).values.tolist())n'' 's' 'e' 's' 'w' 'd' 'w' 'v' ''nn'","['list', 'pandas']",['pandas']
40106080,"'alternately appending elements from two lists' 'I have three lists with elements :nna = 0123...nb = 5678...nnc = nnnI want to append elements from a and b into c to get:nnc =  01562378.... nn' ""Basic approach:nn>>> a = 0123n>>> b = 5678n>>> c = n>>> for pair in zip(ab):n...   c.extend(pair)n... n>>> cn0 1 5 6 2 3 7 8n>>> nnnThis breaks if the lengths aren't equal. But you can deal with that case as an exercise.n"" 'Consider:nnmerged = nfor a_element b_element in zip(a b):n    merged.append(a_element)n    merged.append(b_element)nnnUnless you have very stringent performance requirements the simplest approach is the right approach.n' 'You could zip the two lists and then reduce them to a flat list:nnimport operatornc = reduce(operator.concat zip(a b))nn' ""Assuming len(a) == len(b) and you're adding them one by one in turn:nnfor i in range(len(a)):n        c.append(ai)n        c.append(bi)nnnHowever I would recommend to use c = deque(). Since deques are much quicker if you are making a lot of appends.n"" 'Assuming the two lists are the same length the most compact way to do this uses itertools.chain and zip.nnfrom itertools import chainnna = 012310111213nb = 567815161718nnc = *chain(*zip(a b))nprint(c)nnnoutputnn0 1 5 6 2 3 7 8 10 11 15 16 12 13 17 18nnnnnAs juanpa.arrivillaga mentions in the comments that syntax will not work on older versions of Python. Instead you can donnc = list(chain(*zip(a b)))nnnHere's another option which doesn't use imports or the * splat operator:nnc = u for t in zip(a b) for u in tnnnnnIf you need to handle input lists of unequal length take a look at the roundrobin function in Itertools Recipes. Egnnc = list(roundrobin(a b))nn' 'Another very simple approach using string slicing (and most performance efficient) as:nn>>> a = 0123n>>> b = 5678n>>> c = a + b # create a list with size = len(a) + len(b)n>>> c::2 c1::2 = a b  # alternately insert the valuen>>> cn0 1 5 6 2 3 7 8nnnBelow is the comparison of results with timeit for the answers mentioned here (Python version: 2.7):nnnUsing string slicing: 0.586 usec per loopnnmoin@moin-pc:~$ python -m ""timeit"" -s ""a = 0123; b = 5678;"" ""c = a + b; c::2 c1::2 = a b""n1000000 loops best of 3: 0.586 usec per loopnnUsing itertools.chain(): 1.89 usec per loop nnmoin@moin-pc:~$ python -m ""timeit"" -s ""from itertools import chain; a = 0123; b = 5678;"" ""c = list(chain(*zip(a b)))""n1000000 loops best of 3: 1.89 usec per loopnnUsing reduce(): 0.829 usec per loopnnmoin@moin-pc:~$ python -m ""timeit"" -s ""import operator; a = 0123; b = 5678;"" ""c = reduce(operator.concat zip(a b))""n1000000 loops best of 3: 0.829 usec per loopnnUsing list.extend(): 0.824 usec per loopnn moin@moin-pc:~$ python -m ""timeit"" -s ""a = 0123; b = 5678; c="" ""for pair in zip(ab): c.extend(pair)""n 1000000 loops best of 3: 0.824 usec per loopnnUsing list.append() twice: 1.04 usec per loopnnmoin@moin-pc:~$ python -m ""timeit"" -s ""a = 0123; b = 5678; c="" ""for a_element b_element in zip(a b): c.append(a_element); c.append(b_element)""n1000000 loops best of 3: 1.04 usec per loopnnn' 'Using more_itertools which implements the itertools roundrobin recipenn>>> from more_itertools import roundrobinn>>> a = 0123n>>> b = 5678n>>> list(roundrobin(a b))n0 1 5 6 2 3 7 8nn'",['list'],"['list', 'python-2.7']"
40106166,"'How to bind the return key to a function on the frame/form itself' 'I'm making an app which has a sort of splash screen made in tkinter and I would like it to close and call and run another part of the app however i cannot for the life of me figure out why my bind won't work.nnDo keep in mind I started python about 2 weeks ago so I'm still very much a learner any help would be greatly appreciated! nI am aware that similar questions have been answered on here however none of the questions have the windows as part of a class and I'm having a hard time implementing the solutions into my code as a result.nnThe code:nnfrom Tkinter import *nfrom PIL import ImageTknfrom PIL import Imagenimport timenclass intro(Frame):n    global mastern    master = Tk()n    #master.attributes(""-fullscreen"" TRUE)n    global imgn    img = ImageTk.PhotoImage(Image.open(""dorina.jpeg""))nn    def __init__(self master=None):n        Frame.__init__(self master)n        self.grid()n        self.nameLabel = Label(master image=img)n        self.nameLabel.grid()n        checker = Falsen        self.bind(""<Return>"" lambda e: self.destroy())nnnnnnif __name__ == ""__main__"":n    guiFrame = intro()n    guiFrame.mainloop()nn' 'This time as an answer and I hope it helps.nnThe following works for me:nnimport Tkinter as tknnclass simpleapp_tk(tk.Tk):n    def __init__(self parent):n        ## class derives from Tkinter --> call its constructorn        tk.Tk.__init__(self parent)n        ## keep track of the parentn        self.parent = parentnn    self.bind(""<Return>"" lambda x: self.destroy())nnnif __name__ == ""__main__"":n    app = simpleapp_tk(None)n    app.title('test')n    #app.wm_attributes('-topmost' 1) # always on topn    app.mainloop()nn'",['tkinter'],['tkinter']
40106179,"'How can I make this loop stop at a certain variable occurs' ""I need to write a script that generates random numbers between 1-257000 and stops when a certain number occurs telling me how many numbers it generated so far.nni manged to get this far but can't seem to get it to stop or countnnx=1nwhile x < 257000:n    import itertoolsn    import randomnn    def random_gen(low high):n        while True:n            yield random.randrange(1 257000)nn    gen = random_gen(1 100)n    items = list(itertools.islice(gen 10))nn    print itemsn    x = x+1nnnThank you so much for your help n"" ""Huh. A few flaws (or at least unclear spots) in your code.nnnYou run your loop max 257000 times. Even though the probability is low there is a chance that you don't hit the number you seek in the loop.nMove your import statements out of your loop no need to have python check loaded modules each round.nYou use a generator for choices of a list (randrange) where you can simply use a randint() call.nYou define a closed function within your loop which creates a new function at a new memory address each round.nYou slice your results into lists of 10 elements each; is this for printing or do you actually need your random integers grouped into such lists?nnnA very simple and straightforward implementation of your described problem could be:nnimport randomnnum = 0 # Our counterncertain_number = 123456 # The number we seeknnwhile True: # Run until we breakn    # Increment for each new stepn    num += 1nn    # Generate a single number from the given rangen    random_number = random.randint(1 257000)nn    if random_number == certain_number:n        # Break if we hit itn        breaknnprint('Hit after {} tries.'.format(num))nn>>> Hit after 382001 tries.nn"" ""First put your import statements and your function definitons outside your while-loop. That's being super redundant.nn>>> def random_gen(lowhigh):n...   while True:n...     yield random.randrange(lowhigh)n... n>>> lucky = 7n>>> rg = random_gen()   n>>> rg = random_gen(11000)                 n>>> next(itertools.dropwhile(lambda t: t1 != lucky enumerate(rg 1)))n(811 7)n>>> nnnHere's another run just for fun:nn>>> rg = random_gen(1257000)n>>> nL = next(itertools.dropwhile(lambda t: t1 != lucky enumerate(rg 1)))n>>> nn22602n>>> Ln7n>>>nn""",['python-2.7'],"['list', 'python-2.7']"
40106437,"'Python IndexError handling' 'def kindDetector(list):n    for i in range(0len(list)):n        if type(listi) != type('a'):n            return 0n    return 1nndef findWords(listi):n    if i == 0:n        return list0n    if listi < findWords(listi-1):n        return list.pop(i)n    else:n        return list.pop(i-1)nndef sortWords(listi):n    result=n    while i >= 0:n        result.append(findWords(listi))n        i -=1n    print(result)nnnlist = input('Enter your words with a space between.t').split()ni = len(list)-1nif kindDetector(list):n    sortWords(listi)nnnBut here i only can enter 2 words when i try it with 3 this happens:nnTraceback (most recent call last):n  File ""C:/Users/honey/Desktop/python/selfMade/sortWords.py"" line 26 in <module>n    sortWords(listi)n  File ""C:/Users/honey/Desktop/python/selfMade/sortWords.py"" line 18 in sortWordsn    result.append(findWords(listi))n  File ""C:/Users/honey/Desktop/python/selfMade/sortWords.py"" line 10 in findWordsn    if listi < findWords(listi-1):nIndexError: list index out of rangenn' ""You have mixed BubbleSort (i.e. comparing neighbors and trying to shift them one at a time until the list is sorted) with SelectionSort (i.e. find the smallest item from an unsorted list and append it to the front of a resulting list).nnAnd there are a few more problems here:nnnPython passes variables by reference which means that your functions receive a handle for the original list instead of a copy. If you change the list (what your pop() calls do) while iterating you will run into index errors.nYour findWords function is flawed. You iterate from back to front and check whether the current element is lexicographically smaller than its predecessor (i.e. left neighbor). You probably want to change the pop-calls to return statements don't you?nnnI have quickly implemented a few basic sorting algorithms (no error handling type comparator usage etc whatsoever):nndef is_list_of_strings(lst):n    for i in range(0len(lst)):n        if type(lsti) not in (str unicode):n            return Falsen    return Truenndef is_sorted(lst):n    if len(lst) < 2:n        return Truen    for i in range(len(lst) - 1):n        if not lsti < lsti + 1:n            return Falsen    return Truenndef selection_sort(lst):n    l = lst: # Copy!n    r = n    while len(l):n        r.append(l.pop(l.index(min(l))))n    return rnndef insertion_sort(lst):n    l = lst1: # Copy!n    r = lst0n    for e in l:n        inserted = Falsen        for w in r:n            if e < w:n                r.insert(r.index(w) e)n                inserted = Truen                breakn        if not inserted:n            r.append(e)n    return rnndef bubble_sort(lst):n    l = lst: # Copy!n    while not is_sorted(l):n        for i in range(len(l) - 1):n            if li > li + 1:n                tmp = lin                li = li + 1n                li + 1 = tmpn    return lnnif __name__ == '__main__':n    lst = 'aaa' 'aba' 'aab' 'baz' 'bar'nn    print('Valid list of strings?' is_list_of_strings(lst))n    print(lst is_sorted(lst))nn    bbl = bubble_sort(lst)n    ins = insertion_sort(lst)n    sel = selection_sort(lst)nn    print(bbl is_sorted(bbl))n    print(ins is_sorted(ins))n    print(sel is_sorted(sel))nnnHave a look at them try to understand them and have a read about these three techniques online. And then try to re-implement them using your own functions. Have fun coding :)n""",['python-3.x'],"['list', 'python-2.7']"
40106537,"'Theano shared variable constructor error' 'weights is a list of Numpy ndarray  nnWEIGHTS =   nfor weight in weights:  n    WEIGHTS.append(Theano.shared(Numpy.array(weight) dtype = Theano.config.floatX))nnnError:nn No suitable SharedVariable constructor could be found. Are you sure all kwargs are supported? We do not support the parameter dtype or type. value=""-0.59437655 -0.66183091 -0.49330967  0.5341272  -0.71235842 -0.5309111n  -0.41950136  0.76606105  0.63401357 -0.66799208 -0.13825129 -0.64355341n  -0.08321964  0.78879952  0.38723046 -0.80254236n -0.00340653 -0.68424882  0.73717993 -0.03259952  0.01908119 -0.27347914n  -0.54578049 -0.64197806 -0.70909294 -0.8278319  -0.54029437 -0.41299341n   0.50841491 -0.4404315   0.0034083  -0.81478237n -0.20577933 -0.09402267 -0.51729256  0.13291719 -0.18898014 -0.54618225n  -0.38046483  0.91222028 -0.32784083  0.54191663  0.59148461 -0.34773102n  -0.71356567  0.75372991  0.57200978 -1.00560169n  0.97094749 -1.04304354 -0.15371007  0.73932224 -0.7284857   0.17841782n  -0.05476279 -0.30589505 -0.67929633  0.8480269   0.22350553 -0.04623159n  -0.84297018  0.25937871 -0.46716392  0.51133557n  0.00915791 -0.04072289  0.38978791 -0.12274089 -0.30497646  0.16863023n  -0.16831554  0.10480249 -0.82082575  0.0604674   0.61837916 -0.71897132n  -0.63089596 -0.29704382  0.66048502  0.05797768n -0.00160207  0.19007147  0.1006495   0.39384944 -0.67329269 -0.37062895n   0.78985188  0.72247071  0.72813554 -0.23919282 -0.54938919 -0.70114392n   0.83733916 -0.15144549 -0.81298212  0.34608201n -0.37888527  0.57368407 -0.23682759 -0.02748364  0.21932119  0.68937528n  -0.57860715 -0.84222829  0.00630163  0.24761677  0.85834009  0.77399599n   0.57457557  0.73063443 -0.3520059  -0.04101319n  0.58357881  0.49840153 -0.33299835  0.43245037 -0.49692561  0.08307794n  -0.39417695  0.45403968 -0.2331192  -0.44734402  0.63857672  0.11523024n  -0.00893871  0.25680397 -0.57907839  0.15743863n  0.31255415  0.58321199 -0.30659539  0.17275353 -0.78450044 -0.63778058n  -0.36795226 -0.19436784 -0.44348407  0.77695667 -0.71754174  0.4312374n  -0.48059778 -0.45765487 -0.44493203  0.00242202"". parameters=""{'dtype': 'float64'}""nn' ""The shared function don't support the dtype parameter. It is numpy that support it.nError Resolved!n""",['numpy'],['numpy']
40106858,"""'QuerySet' object doesn't support item deletion Error"" 'I am trying to delete an Item in the QuerySet by Index. I am able to display the items of the QuerySet using print q_setcode_id - 1 but can not delete it using del q_setcode_id - 1. I want to permanently delete the item and not filter excluding that item.nnI am getting this error: nnTypeError at /lessons/customcode/5/deletenn'QuerySet' object doesn't support item deletionnnnviews.pynn...n    def customcode_view(request):n        global q_setn        try:n            u = User.objects.get(username=request.user)n        except:n            return render(request""login_required.html""{})nn        q_set = customcode.objects.filter(user=u)nnn        if request.method == ""POST"":n            form = CustomcodeForm(request.POST)n            if form.is_valid():n                cc = form.save(commit=False)n                cc.user = un                cc.save()n                return HttpResponseRedirect('#BOTTOM')n        else:n            form = CustomcodeForm()nn        return render(request ""customcode.html""  {'q_set':q_set'form':form})nnn    def deletecode(requestcode_id):n        code_id = int(code_id)n        del q_setcode_id - 1 #this is the problemn        return redirect('customcode_view')nn...nnnmodels.pynn...nn    class customcode(models.Model):n        user = models.ForeignKey(User)n        name = models.CharField(blank=Falsemax_length=250)n        sourcecode = models.TextField(blank=False)nn        def __unicode__(self):n            return self.namen...nn' 'To permanently get rid of the entry you don't want to remove the item from the queryset (which is just a volatile view onto your data) but delete the row from the database:nnq_setcode_id - 1.delete()nnnHthndtkn'",['django'],['django']
40106923,"'How to plot one column in different graphs?' ""I have the following problem. I have this kind of a dataframe:nnf = pd.DataFrame('Meyer' 2 'Mueller' 4 'Radisch' math.nan 'Meyer' 2'Pavlenko' math.nan)nnnis there an elegant way to split the DataFrame up in several dataframes by the first collumn? So I would like to get a dataframe where first column = 'MÃ¼ller' and another one for first column = Radisch. nnThanks in advancennErikn"" 'You can loop by unique values of column A with boolean indexing:nndf = pd.DataFrame('Meyer' 2 'Mueller' 4 n                   'Radisch' np.nan 'Meyer' 2n                   'Pavlenko' np.nan)ndf.columns = list(""AB"")nprint (df)n          A    Bn0     Meyer  2.0n1   Mueller  4.0n2   Radisch  NaNn3     Meyer  2.0n4  Pavlenko  NaNnnprint (df.A.unique())n'Meyer' 'Mueller' 'Radisch' 'Pavlenko'nnfor x in df.A.unique():n    print(dfdf.A == x)nn       A    Bn0  Meyer  2.0n3  Meyer  2.0n         A    Bn1  Mueller  4.0n         A   Bn2  Radisch NaNn          A   Bn4  Pavlenko NaNnnnThen use dict comprehension - get dictionary of DataFrames:nndfs = {x:dfdf.A == x.reset_index(drop=True) for x in df.A.unique()}    nprint (dfs)n{'Meyer':        A    Bn0  Meyer  2.0n1  Meyer  2.0 'Radisch':          A   Bn0  Radisch NaN 'Mueller':          A    Bn0  Mueller  4.0 'Pavlenko':           A   Bn0  Pavlenko NaN}nnprint (dfs.keys())ndict_keys('Meyer' 'Radisch' 'Mueller' 'Pavlenko')nnprint (dfs'Meyer')n       A    Bn0  Meyer  2.0n1  Meyer  2.0nnprint (dfs'Pavlenko')n          A   Bn0  Pavlenko NaNnn'",['pandas'],['pandas']
40107452,"'Python tkinter change variable label state and statusbar' 'I do have a little problem here. It's about the exchange of variables of a label in TKinter. My program won't refresh the value's.nnclass Application(Frame):n    def __init__(selfparent**kw):n         Frame.__init__(selfparent**kw)n         self.x = Nonen         self.directory = Nonen         self.autostate = Nonen         self.state = ""closed""n         self.GUI2()nn     def state(self):n         #change statesn         self.stateVar=""open""n         self.statusbar = ""Status: Opening gate...""nn         #update tkintern         self.group.update_idletasks()n         self.w.update_idletasks()nn     def GUI2(self):nn         self.statusbar = ""Status:...""nn         # menu leftn         self.menu_left = tk.Frame(root width=150 bg=""red"" bd=1 relief=RIDGE)n         self.menu_left_upper = tk.Frame(self.menu_left width=300 height=900 bg=""#C0C0C0"")n         self.menu_left_lower = tk.Frame(self.menu_left width=300 bd=1 relief=GROOVE)nn         self.label1 = tk.Label(self.menu_left_lower relief=FLAT bg=""blue"" )n         self.button1 = Button(self.menu_left_lower text=""RUN"")n         self.test = tk.Label(self.menu_left_upper text=""info"" bg=""#C0C0C0"")nnn         self.menu_left_upper.pack(side=""top"" fill=""both"" expand=TRUE)n         self.menu_left_lower.pack(side=""top"" fill=""both"" expand=FALSE)nn         # right arean         self.some_title_frame = tk.Frame(root bg=""#dfdfdf"" bd=1 relief=RIDGE)n         self.some_title = tk.Label(self.some_title_frame text=""some title"" bg=""#dfdfdf"")n         self.text_area = Listbox(root width=50 height=10 background=""#ffffff"" relief=GROOVE)nn         #Label and Buttonn         self.group = LabelFrame(self.menu_left_upper text=""info"" height=70)n         self.group.pack(side=""top"" fill=""both"" expand=TRUE)n         Button(self.menu_left_lower text='Press' command=self.state).pack(side=""bottom"")n         self.w = Label(self.group text='State='+self.stateVar)    #text printed!n         self.w.pack(expand=TRUE)nn         # status barn         self.status_frame = tk.Frame(root)n         self.status = tk.Label(self.status_frame text=self.statusbar bd=1 relief=SUNKEN)    #statusbar printed heren         self.status.pack(fill=""both"" expand=True)n         self.menu_left.grid(row=0 column=0 rowspan=2 sticky=""nsew"")n         self.status_frame.grid(row=2 column=0 columnspan=2 sticky=""ew"")n         root.grid_rowconfigure(1 weight=1)n         root.grid_columnconfigure(1 weight=1)nn #Starts the main loop and causes the class to interact with the init functionn if __name__ == '__main__':n    root = Tk()n    root.title(""simulation"")n    app = Application(root)n    app.grid()n    root.mainloop()nnnHere you can see the whole code.nnIt's importend to check # tab1 in there will be the button. This button refers to the def state(self): This one needs to change the label and the statusbar. wich are packed in self.w and self.status in the program I added a #text printed! after the line.n' 'Below is an example program that should help you figure out how to change the text of labels. They key thing is creating a StringVar and pointing the label towards this so that the label is updated when the StringVar is.nnfrom Tkinter import *nnclass Application(Frame):n    def __init__(selfparent**kw):n        Frame.__init__(selfparent**kw)n        # Create a String variable to store our status stringn        self.stateVar = StringVar()n        self.stateVar.set(""Initial Value"")nn        # Create a label to display the statusn        self.label1 = Label(textvariable=self.stateVar)n        self.label1.grid()nn        # Create a button which will change the statusn        self.button = Button(text=""Press me"" command=self.change)n        self.button.grid()nn    def change(self):n        """"""Called when the button is pressed""""""n        self.stateVar.set('You pressed the button')nnnif __name__ == '__main__':n    root = Tk()n    root.title(""simulation"")n    app = Application(root)n    app.grid()n    root.mainloop()nn' ""The error is in the Label arguments: a tekst arguments is not updated if the input-variable is updated. You should assign the stateVar to the Label's textvariable keyword argument and use no text argument.n""",['tkinter'],"['tkinter', 'python-2.7']"
40107591,'Indexing and slicing dataframe by date and time in python' 'I have time a series datasets. I can select data from march to may by this code:  nndf(df.index.month >=3) & (df.index.month<=5)nnnBut the problem is how to select the data from march-15 to may-15?nAny help will be highly appreciated.nnand my dataframe looks like:nn2000-02-25   0.01n2000-02-26   0.03n2000-02-27   1.0n2000-02-28   1.52n2000-02-29   0.23n2000-03-01   0.45n2000-03-05   2.15n2000-03-06   1.75n.................n.................nn' 'You can use helper Series s where all years are replaced to same - e.g. 2000:nnprint (df)n               An2001-02-25  0.01n2002-02-26  0.03n2003-02-27  1.00n2004-02-28  1.52n2005-03-29  0.23n2006-03-01  0.45n2007-03-05  2.15n2008-03-06  1.75nns = pd.Series(df.index.map(lambda x: pd.datetime(2000 x.month x.day)))nnmask = (s.dt.date > pd.datetime(2000315).date()) & n       (s.dt.date < pd.datetime(2000515).date())nmask.index = df.indexnprint (mask)n2001-02-25    Falsen2002-02-26    Falsen2003-02-27    Falsen2004-02-28    Falsen2005-03-29     Truen2006-03-01    Falsen2007-03-05    Falsen2008-03-06    Falsendtype: boolnndf = dfmasknprint (df)n               An2005-03-29  0.23nn',"['pandas', 'numpy']",['pandas']
40107637,"'Why does 1 provide a different answer than 2 in this program for the area in which 1 should be the same?' 'I have this code meant to calculate compound interest with yearly deposits. The problem is the number in the slot where running the code with 1 in t's place gives me a different answer than when running it with a 2. These should be giving me yearly answers for the total. Below is the code.nnP = input(""Input principal "")nR = input(""Input rate "")nT = input(""Input time "")nt1 = float(input(""Input times per year ""))np = float(P)nr = float(R)nt = float(T)nd = float(input(""deposit""))nnzed = nfor num in range(int(t) + 1):n    zed.append(num)nnn# (1 + r/n)nbody = 1 + (r / t1)n# ntnexponent = t1 * tn# P(1 + r/n)^ntnre = p * pow(body exponent)nnked = nfor var in zed:n    body = 1 + (r / t1)n    exponent = t1 * tn    idekvar = (p + (d * var)) * pow(body exponent)n    ked.append(idekvar)n    print (idekvar)nn""""""print (""With principal"")nprint (re)nprint (""Without principal"")nprint (re-p)""""""nnnIt gives me an output ofnnn  3.5999999999999996n  9.6n  3.5999999999999996 9.6nnnwhen I use p = 3 r = .2 t=1 t1 = 1 and dep = 5 it gives me a different answer for what SHOULD be the same space but using t = 2 instead.nnn  4.32n  11.52n  18.72n  4.32 11.52 18.72nnnWhy does it do this? nIf you happen to have any code that does this would you mind sharing so I can compare mine to it?n' nan",['python-3.x'],"['python-3.x', 'python-2.7']"
40107657,"'(possibly grouped) Row Values to Columns' ""Let's say after some groupby operation I have a dataframe like this:nndata = pd.DataFrame(columns='Key' 'Subkey' 'Value')ndata.loc0 = 'foo1' 'bar1' 20ndata.loc1 = 'foo1' 'bar2' 10ndata.loc2 = 'foo1' 'bar3' 5ndata.loc3 = 'foo2' 'bar1' 50ndata.loc4 = 'foo2' 'bar2' 100ndata.loc5 = 'foo2' 'bar3' 50nnnWhat I then have is a dataframe that looks like this:nn|Key |Subkey | Value |n+----+-------+-------+n|foo1|bar1   |20     |n|foo1|bar2   |10     |n|foo1|bar3   |5      |n|foo2|bar1   |50     |n|foo2|bar2   |100    |n|foo2|bar3   |50     |nnnWhat I would like to have is a new dataframe where the subkey is a new column containing the same value as in the grouped frame above like:nn|Key |bar1 |bar2  |bar3  |n+----+-----+------+------+n|foo1| 20  |  10  | 5    |n|foo2| 50  | 100  | 50   |nnnIs there a one-line solution to this or do I need to transform the dataframe programmatically?n"" 'You can use pivot:nnprint (data.pivot(index='Key' columns='Subkey' values='Value'))nSubkey  bar1   bar2  bar3nKey                      nfoo1    20.0   10.0   5.0nfoo2    50.0  100.0  50.0nnnThen you can cast float values to int reset_index and remove column names Subkey:nnprint (data.pivot(index='Key' columns='Subkey' values='Value')n           .astype(int)n           .reset_index()n           .rename_axis(None axis=1))nn    Key  bar1  bar2  bar3n0  foo1    20    10     5n1  foo2    50   100    50nn'",['pandas'],['pandas']
40107690,"'finding a special path string in HTML text in python' 'I'm trying to extract a path in an HTML file that I read.nIn this case the path that I'm looking for is a logo from google's main site.nnI'm pretty sure that the regular expression I defined is right but I guess I'm missing something.nnThe code is:nnimport renimport urllibna=urllib.urlopen ('https://www.google.co.il/')nText = a.read(250)nprint Textnprint 'nn'nb= re.search (r'""/a-z0-9 *'Text)nnprint format(b.group(0))nnnThe actual text that I want to get is:nn/images/branding/googleg/1x/googleg_standard_color_128dp.pngnnI'd really appreciate it if someone could point me in the right directionn' 'this can help you:nnre.search(r'""/.+""'Text).group(0)nnnresult:nn>>> re.search(r'""/.+""'Text).group(0)n'""/images/branding/googleg/1x/googleg_standard_color_128dp.png""'nn' 'Here's my answer:nnimport renimport urllibnna=urllib.urlopen ('https://www.google.co.il/')ntext = a.read(250)nprint textnprint 'nn'nb= re.search (r'""(/a-z0-9_. +)+""'text)nnnprint format(b.group(0))nnnRun gives:nn>>> python stackoverflow.pyn<!doctype html><html dir=""rtl"" itemscope="""" itemtype=""http://schema.org/WebPage"" lang=""iw""><head><meta content=""text/html; charset=UTF-8"" http-equiv=""Content-Type""><meta content=""/images/branding/googleg/1x/googleg_standard_color_128dp.png"" itemprop=nnnn""/images/branding/googleg/1x/googleg_standard_color_128dp.png""nnnExplanation o the regex ""(/a-z0-9_. +)+"" : firstly in the string name of the picture you miss . and _. You need to add these two into the square brackets as well since they appear in the path. /a-z0-9_. + matches a patter with / followed by some string wtih length at least 1. (/a-z0-9_. +)+ replicates the previous match to allow for multiple matches of paths that have more than 1 folders. Finally you add the two "" at the beginning and end.n'",['regex'],['regex']
40107819,"'list comprehension does not return empty list' ""I tried to find the relevant question but couldn't find so creating a new one. nMy program creates a new list using list comprehension in python as per a simple if condition. nn  Newone =  temp for temp in Oldone if temp % 2 != 0 nnnIt works fine but when in some situation it doesn't work. For example this one nn Oldone = 1n Newone =  temp for temp in Oldone if temp % 2 != 0 nnnThis returns 1 but i am expecting Newone to be  n"" ' 1%2 == 1nnnSo your your condition: temp % 2 != 0 is True therefore it is included in the list. If you want an empty list you should change it temp % 2 == 0.n' ""If you are not sure what's happening. Your list comprehension:nn Newone =  temp for temp in Oldone if temp % 2 != 0 nnnMeans; put in my new list Newone all temp values from my existing list Oldone which satisfy the condition temp % 2 != 0 (Essentially keep only odd numbers since the remainder is 1 whenever an odd number is divided by 2)n""",['list'],"['list', 'python-2.7']"
40108025,"'Incomplete list pop in list comprehention' 'I have been trying to pop elements in list comprehention using takewhile function and I came into things that is for me hard to understand. My terminal session looks like this:nnnnHowever when i tried the same thing with strings then problem didn't occur:nnnnCan someone explain to me that happened in the first scenario? Why g.pop(0) has returned only 1 2?nnTranscript for copying (why Stack doesn't have collapsible sections ):nn>>> from itertools import takewhilenfrom itertools import takewhilen>>> g = 12345n>>> a for a in takewhile(lambda x: x < 4 g)n1 2 3n>>> g.pop() for _ in takewhile(lambda x: x < 4 g)n5 4 3n>>> g = 12345n>>> g.pop(0) for _ in takewhile(lambda x: x < 4 g)n1 2nn>>> g = '1' '2' '3' '4' '5'n>>> a for a in takewhile(lambda x: x != '4' g)n'1' '2' '3'n>>> g.pop() for _ in takewhile(lambda x: x != '4' g)n'5' '4' '3'n>>> g = '1' '2' '3' '4' '5'n>>> g.pop(0) for _ in takewhile(lambda x: x != '4' g)n'1' '2' '3'nn' ""I figured it out because i've tried to use deque which raised RuntimeError: deque mutated during iteration.nnExecution goes like this:nnng0 = 1 < 4; g.pop(0) => 1ng1 = 3 < 4; g.pop(0) => 2ng2 = 5 > 4; breaknnnThis also explains why it worked in 2nd case because during iteration '4' hasn't been hit.n""",['python-2.7'],"['list', 'python-2.7']"
40108043,"'How to check if a server is up or not in Python?' ""In PHP I just did: $fp = @fsockopen(irc.myserver.net 6667 $errno $errstr 2);nnDoes Python 2.X also have a function like PHP's fsockopen()? If not how else can I check if a server on port 6667 is up or not?n"" 'The socket module can be used to simply check if a port is open or not.nnimport socket;nsock = socket.socket(socket.AF_INET socket.SOCK_STREAM)nresult = sock.connect_ex(('irc.myserver.net'6667))nif result == 0:n   print ""Port is open""nelse:n   print ""Port is not open""nn'",['python-2.7'],['python-2.7']
40108274,"'Writing to a JSON file and updating said file' 'I have the following code that will write to a JSON file:nnimport json    nndef write_data_to_table(word hash):n    data = {word: hash}n    with open(""rainbow_tablerainbow.json"" ""a+"") as table:n        table.write(json.dumps(data))nnnWhat I want to do is open the JSON file add another line to it and close it. How can I do this without messing with the file?nnAs of right now when I run the code I get the following:nnwrite_data_to_table(""test1"" ""0123456789"")nwrite_data_to_table(""test2"" ""00123456789"")nwrite_data_to_table(""test3"" ""000123456789"")nn#<= {""test1"": ""0123456789""}{""test2"": ""00123456789""}{""test3"": ""000123456789""}nnnHow can I update the file without completely screwing with it?nnMy expected output would probably be something along the lines of:nn{n  ""test1"": ""0123456789""n  ""test2"": ""00123456789""n  ""test3"": ""000123456789""n}nn' ""You may read the JSON data with :nnparsed_json = json.loads(json_string)nnnYou now manipulate a classic dictionary. You can add data with :nnparsed_json.update({'test4': 0000123456789})nnnThen you can write data to a file using :nnwith open('data.txt' 'w') as outfile:n    json.dump(parsed_json outfile)nn"" 'If you are sure the closing ""}"" is the last byte in the file you can do this:nn>>> f = open('test.json' 'a+')n>>> json.dump({""foo"": ""bar""} f)  # create the filen>>> f.seek(0)n>>> f.read()n'{""foo"": ""bar""}'n>>> f.seek(-1 2)n>>> f.write('n' f.write('n' + json.dumps({""spam"": ""bacon""})1:))n>>> f.seek(0)n>>> print(f.read())n{""foo"": ""bar""n""spam"": ""bacon""}nnnSince your data is not hierarchical you should consider a flat format like ""TSV"".n'",['python-2.7'],"['python-2.7', 'python-3.x']"
40108521,"'Difficulty with python while installing YouCompleteMe in vim' 'I've followed these instructions in order to install YouCompleteMe in Vim but when I issue:nn./install.py --clang-completernnnThe following error message comes up:nnSearching Python 2.7 libraries...nERROR: found static Python library (/usr/local/lib/python2.7/config/libpython2.7.a) but a dynamic one is required. You must use a Python compiled with the --enable-shared flag. If using pyenv you need to run the command:n  export PYTHON_CONFIGURE_OPTS=""--enable-shared""nbefore installing a Python version.nTraceback (most recent call last):n  File ""./install.py"" line 44 in <module>n    Main()n  File ""./install.py"" line 33 in Mainn    subprocess.check_call(  python_binary build_file  + sys.argv1: )n  File ""/usr/local/lib/python2.7/subprocess.py"" line 540 in check_calln    raise CalledProcessError(retcode cmd)nsubprocess.CalledProcessError: Command ''/usr/local/bin/python' u'/home/anmol/.vim/bundle/YouCompleteMe/third_party/ycmd/build.py' '--clang-completer'' returned non-zero exit status 1nnnand now I'm stuck what should I do?n' 'The plugin builds for me on the same operating system. The relevant line from the configuration looks like this:nnFound PythonLibs: /usr/lib/python2.7/config-x86_64-linux-gnu/libpython2.7.sonnnThe shared object can be identified as belonging to libpython2.7 package:nnapt-file search /usr/lib/python2.7/config-x86_64-linux-gnu/libpython2.7.sonlibpython2.7: /usr/lib/python2.7/config-x86_64-linux-gnu/libpython2.7.sonnnSo I would check if you have the file named if not try sudo apt install libpython2.7 and otherwise try moving away the static version or let us know how you installed Python.n' 'I checked YouCompleteMe's build system and it uses a custom build script that uses the Python module distutils to find the paths to Python's library and include directories. Your /usr/local/ installation of Python is probably included in your PATH variable before the official /usr installation so just running python probably runs your custom installation making distutils return its directories.nnTo check whether this is true try running which python. I assume it will return something like /usr/local/bin/python.nnAt this point I see several options.nnnTry running YCM's install script by specifying which Python executable should run it explicitly: /usr/bin/python ./install.py --clang-completernEdit the script third_party/ycmd/build.py in YouCompleteMe's plugin directory to hardcode the paths for your custom Python installation. For instance you could replace the existing FindPythonLibraries function with the following:nndef FindPythonLibraries():n    return ('/usr/lib/python2.7/config-x86_64-linux-gnu/libpython2.7.so'n            '/usr/include/python2.7')nnnNote that this will make it harder to update YouCompleteMe since you'll have to ensure it doesn't get overwritten when you update its source.nUpdate your custom installation of Python with one built as a shared library. The details of this will depend on how you installed this Python version in the first place. You can check whether you installed it through a package by using dpkg -S /usr/local/lib/python2.7/config/libpython2.7.a. This command will tell you which package installed that file unless you installed it manually (bypassing the package manager).nRemove your custom /usr/local Python installation while ensuring you have a Python from the official repositories installed (packages python2.7 and libpython2.7).nnnIn the long run you would probably be better off by using the official Python packages.n'",['python-2.7'],['python-2.7']
40108544,"'How to resize an image while uploading and saving it automaticly django?' 'I'm unable to save the image that is either being resized or uploading directly through my admin panel. I want to resize it through PLP or any other way!nndef get_product_image_folder(instance filename):nnreturn ""static/images/product/%s/base/%s"" %(instance.product_id filename)nproduct_image  = StringIO.StringIO(i.read())nimageImage = Image.open(product_image)nnthumbImage = imageImage.resize((100100))nnthumbfile = StringIO()nthumbImage.save(thumbfile ""JPEG"")nnthumbcontent = ContentFile(thumbfile.getvalue())nnnewphoto.thumb.save(filename thumbcontent)nnew_photo.save()nn' 'This can be done either in the save method of the model the save_model method of the admin or the save method of the form.nnI recommend the last one since it lets you decouple form/validation logic from the model and admin interface. nnThis could look something like the following:nnclass MyForm(forms.ModelForm):n    model = MyModelnn    ...n    def save(self *args **options):n        if self.cleaned_data.get(""image_field""):n            image = self.cleaned_data'image_field'n            image = self.resize_image(image)n            self.cleaned_data'image_field' = imagen        super(MyForm self).save(*args **options)nn    def resize_image(self image):n        filepath = image.file.pathn        pil_image = PIL.Image.open(filepath)n        resized_image = # **similar steps to what you have in your questionn        return resized_imagennnYou can either put this new image in the cleaned_data dictionary so that it saves itself or you can save it to a new field (something like ""my_field_thumbnail"") that has editable=False on the model.nnMore info on the actual process of resizing an image with PIL can be found in other SO questions eg:nHow do I resize an image using PIL and maintain its aspect ratio?n'",['django'],['django']
40108553,"'validate the size and format if uploaded image and resize it in django' ""I am uploading an image in django i want to validate it's format and size in forms.pynnclass CreateEventStepFirstForm(forms.Form):n    user_image = forms.ImageField(required = True widget=forms.FileInput(attrs={n        'class' : 'upload-img'n        'data-empty-message':'Please upload artist image this field is required'n    }))nnnWhile uploading this image i want to first validate it's format form allows user only to upload png and jpeg image and also user will have to upload an image upto 700*500 dimensions if image is lower than this dimensions then this form should not be validated and if image is greater than 1200*1000 pixels in this case it should resize image to 700*500 without affecting the image quality.nnView i am using for uploading file is :-nndef create_new_event(request steps):n    if request.method == 'POST':n        stepFirstForm = CreateEventStepFirstForm(request.POST request.FILES)n        if stepFirstForm.is_valid():nn            myfile = request.FILES'user_image'n            fs = FileSystemStorage()n            filename = fs.save('event_artists_images/'+myfile.name myfile)n            uploaded_file_url = fs.url(filename)nn        return render(request 'home/create-new-event.html' {'stepFirstForm':stepFirstForm})nn"" 'You should look at writing your own custom validator.  You can read about them here in the documentation nnOnce you've created a validator that checks against those values then you can attach it to the form in a couple of different ways.n'",['django'],['django']
40108833,"""Error 'cannot import name post_revision_commit'"" 'Hi everyone I move my project to a server I now I try to load the database npython manage.py loaddata resource/ddbb/20160817_db.json n or even run the server but I obtain this error.nnFile ""manage.py"" line 10 in <module>n    execute_from_command_line(sys.argv)n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/django/core/management/__init__.py"" line 354 in execute_from_command_linen    utility.execute()n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/django/core/management/__init__.py"" line 328 in executen    django.setup()n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/django/__init__.py"" line 18 in setupn    apps.populate(settings.INSTALLED_APPS)n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/django/apps/registry.py"" line 108 in populaten    app_config.import_models(all_models)n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/django/apps/config.py"" line 198 in import_modelsn    self.models_module = import_module(models_module_name)n  File ""/usr/lib64/python2.7/importlib/__init__.py"" line 37 in import_modulen    __import__(name)n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/cms/models/__init__.py"" line 3 in <module>n    from .pagemodel import *  # nopyflakesn  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/cms/models/pagemodel.py"" line 1453 in <module>n    _reversion()n  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/cms/models/pagemodel.py"" line 1449 in _reversionn    exclude_fields=exclude_fieldsn  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/cms/utils/helpers.py"" line 135 in reversion_registern    from cms.utils import reversion_hacksn  File ""/home/mxp1217/django1101/lib/python2.7/site-packages/cms/utils/reversion_hacks.py"" line 18 in <module>n    from reversion.models import Revision Version post_revision_commit  # NOQA  # nopyflakesnImportError: cannot import name post_revision_commitnnnThis is my installation in my environment on the servernncmsplugin-filer==1.1.3ndj-database-url==0.4.1nDjango==1.8.15ndjango-appconf==1.0.2ndjango-classy-tags==0.8.0ndjango-cms==3.4.1ndjango-filer==1.2.5ndjango-formtools==1.0ndjango-mptt==0.8.6ndjango-polymorphic==0.8.1ndjango-reversion==2.0.6ndjango-sekizai==0.10.0nDjango-Select2==4.3.2ndjango-treebeard==4.0.1ndjangocms-admin-style==1.2.5ndjangocms-attributes-field==0.1.1ndjangocms-column==1.7.0ndjangocms-googlemap==0.5.2ndjangocms-inherit==0.2.2ndjangocms-installer==0.9.1ndjangocms-link==2.0.1ndjangocms-snippet==1.9.1ndjangocms-style==1.7.0ndjangocms-text-ckeditor==3.3.0ndjangocms-video==2.0.2ndjangorestframework==3.4.7neasy-thumbnails==2.3nfeedparser==5.2.1nhtml5lib==0.9999999nMySQL-python==1.2.5nPillow==3.4.1npytz==2016.7nsix==1.10.0ntzlocal==1.3nUnidecode==0.4.19nnnAny idea How I can solvent this problem.n' 'It looks like the django-cms version you are using doesn't support django-reversion 2.0+.  The comments in the django-cms source seem to affirm this.  I would try installing the latest 1.x version of django-reversion and see if that doesn't work. n' 'You should be on latest djnago-reversion. Because post_revision_commit signal has been removed since 2.0.0 and added back in the latest version. Referencen'",['django'],['django']
40108897,'What is the best way to use TCP FastOpen extension with asyncio?' 'Do I need to write custom logic via select+sockets and make it into a separate thread or there is a more elegant solution?n' nan,['python-3.x'],"['python-3.x', 'python-2.7']"
40108906,"'Python function: variable and string' 'I have following formula to check (Thanks for helping me on this!).nnqueries = 'dog''cat''hamster'nn    def get_trends(queries):n        return pd.concat(pytrend.trend({'q': x 'date': '01/2015 12m'} return_type='dataframe')n    for x in queries axis=1)nnget_trends(queries)nnnThis function fires a Google Trends query for each item in the list and puts the returning dataframes next to each other. What I need to do now is to do exactly the same but have each one static variable (pet) in the query.nnFor example a query without the formula would bennreturn pytrend.trend({'q': 'pet dog' 'date': '01/2015 12m'} return_type='dataframe')nnnI know I could trynnqueries = 'pet dog''pet cat''pet hamster'nnnBut maybe there's a more elegant way?nnI tried nnstatic ='pet'nreturn pytrend.trend({'q': ''' + static + x + ''' 'date': '01/2015 12m'} return_type='dataframe')nnnbut wasn't successful with that.n' ""You can do it this way:nnIn 54: %pastenstatic = 'animals'nanimals = 'dog''cat''hamster'nqueries = '{} {}'.format(static x) for x in animalsn## -- End pasted text --nnIn 55: queriesnOut55: 'animals dog' 'animals cat' 'animals hamster'nnnnow you can pass queries to your function:nnget_trends(queries)nn""",['list'],['pandas']
40109185,"'I want to make a variable in my views.py which changes depending the name of the urlpattern used' ""Here's my code. whatever urlpattern is chosen: I want the name of it to be stored as url in views.py. Which is then used in queryset filter().nnurls.pynnurl(r'^news/' BoxesView.as_view() name='news')nurl(r'^sport/' BoxesView.as_view() name='sport')nurl(r'^cars/' BoxesView.as_view() name='cars')nnnviews.pynnclass BoxesView(ListView):n    url = #urlname to go heren    def get_queryset(self):n        queryset_list = Post.objects.all().filter(category=url)nnnmodels.pynncategory = models.CharField(choices=CATEGORY_CHOICES)nnnchoices.pynnCATEGORY_CHOICES = (n    ('1' 'news')n    ('2' 'sport')n    ('3' 'cars')nn)nnnAny idea?n"" ""I would replace your url.py by something like this:nnurl(r'(?P<keyword>w+)/$' BoxesView.as_view())nnnThis changes your address into an url parameter which you can then access the in your methods like this:nndef get_queryset(self):n            url = self.kwargs'keyword'n            queryset_list = Post.objects.all().filter(category=url)nn"" 'You can use this to get the name of the viewnn url = resolve(self.request.path_info).url_namennnUPDATE: Added ""self."" which is needed when using generic views. And don't forget to import:nn from django.core.urlresolvers import resolvenn'",['django'],['django']
40109204,"'%s showing strange behavior in regex' ""I have a string in which I want to find some words preceding a parenthesis. Lets say the string is - nnn  'there are many people in the world having colorectal cancer (crc) who also have the depression syndrome (ds)'nnnI want to capture at most 5 words before a parenthesis. I have a list acronym_list of abbreviations which are inside the brackets - (crc) (ds). So I am using the following code - nnacrolen=5nrt=nfor acro in acronym_list:n    find_words= re.findall('((?:w+W+){1%d}%s)'  %(acrolen acro) text re.I)n    for word in find_words:n            rt.append(word)nprint rtnnnBut this gives this result - nn('the world having colorectal cancer (crc' 'crc')n('also have the depression syndrome (ds' 'ds')nnnWhereas if I use the regex -nnfind_words= re.findall('((?:w+W+){1%d}(crc))'  %(acrolen)s re.I)nnThen it is able to find exactly what I want i.e. - nnthe world having colorectal cancer (crc)nnnThe question is - why using %s for the string here causing the regex match to be so vastly different (having unnecessary brackets around it repeating the acronym etc..)nnHow can I use the 1st regex properly so that I can automate the process using a loop rather than having to enter the exact string every time in the regex ?n"" 'You need to make sure the variables you pass are escaped correctly so as to be used as literal text inside a regex pattern. Use re.escape(acro):nnimport rentext = ""there are many people in the world having colorectal cancer (crc) who also have the depression syndrome (ds)""nacrolen=5nrt=nacronym_list = ""(crc)"" ""(ds)""nfor acro in acronym_list:n    p = r'((?:w+W+){1%d}%s)' %(acrolen re.escape(acro))n    # Or use format:n    # p = r'((?:w+W+){{1{0}}}{1})'.format(acrolen re.escape(acro))n    find_words= re.findall(p text re.I)n    for word in find_words:n        rt.append(word)nprint rtnnnSee the Python demonnAlso note you do not need to enclose the whole pattern with a capturing group re.findall will return match values if no capturing group is defined in the pattern.nnIt is also recommended to use raw string literals when defining regex patterns to avoid ambiguous situations.n'",['regex'],"['regex', 'python-2.7']"
40109257,"'Django creating wrong type for fields in intermediate table (manytomany)' 'I have a model in Django which the pk is not an integer and it has a field which is a manytomany. This manytomany references the model itself.nnWhen I ran makemigration I didn't realize but it did not create the fields in the intermediate table as char(N). In fact it create as an integer. nn# models.pynclass Inventory(models.Model):n    sample_id = models.CharField(max_length=50 primary_key=True)n    parent_id = models.ManyToManyField(""self"")nnnThis throws errors whenever I try to add objects to my parent modelnn>>> p = Inventory.objects.get(sample_id='sample01')n>>> child = Inventory.objects.get(sample_id='sample02')n>>> p.parent_id.add(child)nnnI get the errornnpsycopg2.DataError: invalid input syntax for integer: ""sample02""nLINE 1: ...HERE (""inventory_parent_id"".""to_inventory_id"" IN ('sample...nnnI saw the fields in the intermediate table inventory_parent_id created by Django and their types are not correct.nnColumns (3)n|--id (integer)n|--from_inventory_id (integer)n|--to_inventory_id (integer)nnnMy questions are: Is it bad if I change the types manually? Will it break the migrations? Or did I have to do something so Django can catch this misleading type?n' ""Try to re-create migrations (unapply migrations by using ./manage.py migrate YOURAPP PREVIOUS_MIGRATION_NUMBER or ./manage.py migrate YOURAPP zero if it's initial migration) remove migration file (don't forget about .pyc file) and generate it again.nnIf that doesn't help you can try to create custom through table with proper migration fields and then recreate that migration.n""",['django'],['django']
40109368,"'how to log all request in tastypie django' ""I have used tastypie in django to handle REST api request. When ever I do GET/POST request it comes to dehydrate method by default. But for DELETE/PUT request it doesn't have any method tastypie handles it so there is no way to log request information.nnclass ProjectResource(ModelResource):n    allowed_methods = 'get' 'put' 'post' 'delete'n    resource_name = 'project'n    queryset = Project.objects.all()n    validation = FormValidation(form_class=ProjectForm)n    always_return_data = Truen    filtering = {n        'id': ALLn        'slug': ALLn        }nndef dehydrate(self bundle):n    import pdb;pdb.set_trace()   #--> get/post request hit this functionn    logger.log('app.main''debug' 'Project info' bundle)n    bundle.data'name' = cgi.escape(bundle.obj.name)n    return bundlennnIs there any function to override ModelResource in tastypie.resource module? so that for all request i get the bundle data first and then i will pass that to logger before it is processed.n"" nan",['django'],['django']
40109379,"'How do I link python 3.4.3 to opencv?' ""So I have OpenCV on my computer all sorted out I can use it in C/C++ and the Python 2.7.* that came with my OS.nnMy computer runs on Linux Deepin and whilst I usually use OpenCV on C++ I need to use Python 3.4.3 for some OpenCV tasks.nnProblem is I've installed python 3.4.3 now but whenever I try to run an OpenCV program on it it doesn't recognize numpy or cv2 the modules I need for OpenCV. I've already built and installed OpenCV and I'd rather not do it againnnIs there some way I can link my new Python 3.4.3 environment to numpy and the opencv I already built so I can use OpenCV on Python 3.4.3?nnThanks in advancen"" 'You can try:nnnDownload the OpenCV modulenCopy the ./opencv/build/python/3.4/x64/cv2.pyd file nTo the python installation directory path: ./Python34/Lib/site-packages.nnnI hope this helpsn'","['python-2.7', 'python-3.x', 'numpy']","['python-3.x', 'numpy']"
40109400,"'Django AppsNotLoaded' 'I'm trying to make a python script to put some things in my database;nnfrom django.conf import settingsnsettings.configure()nimport django.dbnfrom models import Hero #Does not work..?nheroes = name for name in open('hero_names.txt').readlines()nnnnames_in_db = hero.hero_name for hero in Hero.objects.all() #ALready existing heroesnfor heroname in heroes:n    if heroname not in names_in_db:n        h = Hero(hero_name=heroname portraid_link='/static/heroes/'+heroname)n        h.save()nnnThe import throws the followingnnTraceback (most recent call last):n  File ""heroes_to_db.py"" line 4 in <module>n    from models import Heron  File ""C:Userstoft_Desktopd2-patchnotes-masterdota2notespatchmodels.py"" line 5 in <module>n    class Hero(models.Model):n  File ""C:Python27libsite-packagesdjangodbmodelsbase.py"" line 105 in __new__n    app_config = apps.get_containing_app_config(module)n  File ""C:Python27libsite-packagesdjangoappsregistry.py"" line 237 in get_containing_app_confign    self.check_apps_ready()n  File ""C:Python27libsite-packagesdjangoappsregistry.py"" line 124 in check_apps_readyn    raise AppRegistryNotReady(""Apps aren't loaded yet."")ndjango.core.exceptions.AppRegistryNotReady: Apps aren't loaded yet.nnnI know I can do python manage.py --shell and write the code for hand but to be honest I dont want to. What am I missing ?n' 'Django must configure all installed applications before you can use any models. To do this you must call django.setup()nnimport djangondjango.setup()nnnFrom the documentation:nnn  This function is called automatically:n  n  n  When running an HTTP server via Djangoâx80x99s WSGI support.n  When invoking a management command.n  n  n  It must be called explicitly in other cases for instance in plain Python scripts.nn'",['django'],['django']
40109509,"'VirtualBox command works correct in bash but does not work in nginx' 'We have a project on nginx/Django using VirtualBox.nWhen we try to run command VBoxManage list runningvms in nginx we have the next error:nnFailed to initialize COM because the global settings directory '/.config/VirtualBox' is not accessible!nnnIf we run this command in console it works fine. nnWhat can we do to make it working good in nginx?nnOther details: nnginx is runned by user ""www-data"" console - by the other user (Administrator).  n' 'We have fixed the issue.nnnThere was wrong environment variable ""Home"" (os.environ'HOME'). We changed it and so the problem was gone.  nUsing Python API for VB instead of ssh can really help you with that problem as RegularlyScheduledProgramming suggested - we added Python API too. nnnThanks!n'",['django'],['django']
40109850,"'How to use Adobe afm fonts in matplotlib text?' 'I want to add a text to a figure using an AFM font. I know that I can pass the fontproperties or the fontname keyword argument when creating a text. nnRegarding the usage of AFM fonts in matplotlib I found this and this. nnI can't pass a Font instance create by matplotlib.font_manager.afmFontProperty as fontproperties kwarg.nnThe font I intend to use is URW Chancery L and located in /usr/share/fonts/type1/gsfonts/z003034l.afm. How can I make matplotlib use this font?nnAlso I looked for converters from afm to ttf but could not find any maybe you have a suggestion?nnI'm using matplotlib 1.5.3 on Ubuntu 16.04.n' 'What is an ""AFM font""? AFM files are Adobe Font Metrics files which only contain metadata around glyph bounds kerning pairs etc. as a convenient lookup mechanism when you don't want to mine the real font file for that information (handy for typesetting where having the metrics available as separate resource makes things a hell of a lot faster) they are not themselves fonts in any way. You would still need a (now mostly defunct) .pfa or .pfb font file (""printer font; ascii"" and ""printer font; binary"" respectively) to do any kind of actual text rendering. Without those all you can do is mark the appropriate region in which text would be drawn if you also had the font itself available =)nn(this is actually what TeX and PDF do - they use the font metrics to construct ""empty boxes"" inside of which text will ultimately be rendered once all the typesetting has been determined and the boxes no longer move around)n'",['matplotlib'],['matplotlib']
40109915,"'Python numpy.fft changes strides' 'Dear stackoverflow community!nnToday I found that on a high-end cluster architecture an elementwise multiplication of 2 cubes with dimensions 1921 x 512 x 512 takes ~ 27 s. This is much too long since I have to perform such computations at least 256 times for an azimuthal averaging of a power spectrum in the current implementation. I found that the slow performance was mainly due to different stride structures (C in one case and FORTRAN in the other). One of the two arrays was a newly generated boolean grid (C order) and the other one (FORTRAN order) came from the 3D numpy.fft.fftn() Fourier transform of an input grid (C order). Any reasons why numpy.fft.fftn() changes the strides and ideas on how to prevent that except for reversing the axes (which would be just a workaround)? With similar strides (ndarray.copy() of the FT grid) ~ 4s are achievable a tremendous improvement.nnThe question is therefore as following:nnConsider the array:nnran = np.random.rand(1921 512 512)nran.stridesn(2097152 4096 8)nna = np.fft.fftn(ran)na.stridesn(16 30736 15736832)nnnAs we can see the stride structure is different. How can this be prevented (without using a = np.fft.fftn(ran axes = (10)))? Are there any other numpy array routines that could affect stride structure? What can be done in those cases?nnHelpful advice is as usual much appreciated!n' ""You could use scipy.fftpack.fftn (as suggested by hpaulj too) rather than numpy.fft.fftn looks like it's doing what you want. It is however slightly less performing:nnimport numpy as npnimport scipy.fftpacknnran = np.random.rand(192 51 51)  # not much memory on my laptopna = np.fft.fftn(ran)nb = scipy.fftpack.fftn(ran)nnran.stridesn(20808 408 8)na.stridesn(16 3072 156672)nb.stridesn(41616 816 16)nntimeit -n 100 np.fft.fftn(ran)n100 loops best of 3: 37.3 ms per loopntimeit -n 100 scipy.fftpack.fftn(ran)n100 loops best of 3: 41.3 ms per loopnn"" 'n  Any reasons why numpy.fft.fftn() changes the strides and ideas on how to prevent that except for reversing the axes (which would be just a workaround)?nnnComputing the multidimensionnal DFT of an array consists in successively computing 1D DTFs over each dimensions. There are two strategies:nnnRestrict 1D DTF computations to contiguous 1D arrays. As the array is contiguous problem related to latency/cache misses will be reduced. This strategy has a major drawback: the array is to be transposed between each dimension. It is likely the strategy adopted by numpy.fft. At the end of computations the array has been transposed. To avoid unnecessary computations the transposed array is returned and strides are modified.nEnable 1D DDFT computations for strided arrays. This might trigger some problem related to latency. It is the strategy of fftw avaible through the interface pyfftw. As a result the output array features the same strides as the input array.nnnTiming numpy.fftn and pyfftw.numpy.fftn as performed here and there or there will tell you whether FFTW is really the Fastest Fourier Transform in the West or not...nnnTo check that numpy uses the first strategy take a look at numpy/fft/fftpack.py. At line 81-85 the call to work_function(a wsave) (i.e. fftpack.cfftf from FFTPACK arguments documented there) is enclosed between calls to numpy.swapaxes() performing the transpositions.nscipy.fftpack.fftn does not seem to change the strides... Nevertheless it seems that it makes use of the first strategy. scipy.fftpack.fftn() calls scipy.fftpack.zfftnd() which calls zfft() based on zfftf1 which does not seem to handle strided DFTs. Moreover zfftnd() calls many times the function flatten() which performs the transposition.nAnother example: for parallel distributed memory multidimensionnal DFTs FFTW-MPI uses the first strategy to avoid any MPI communications between processes during 1D DTFs. Of course functions to transpose the array are not far away and a lot a MPI communications are involved in the process.nnnn  Are there any other numpy array routines that could affect stride structure? What can be done in those cases?nnnYou can search the github repository of numpy for swapaxes: this funtion is only used a couple of times. Hence to my mind this ""change of strides"" is particular to fft.fftn() and most numpy functions keep the strides unchanged.nnFinally the ""change of strides"" is a feature of the first strategy and there is no way to prevent that. The only workaround is to swap the axes at the end of the computation which is costly. But you can rely on pyfftw since fftw implements the second strategy in a very efficient way. The DFT computations will be faster and subsequent computations will be faster as well if the strides of the different arrays become consistent.n'",['numpy'],['numpy']
40110228,"'Python Error on Item for pubdate' 'where it can be wrong in item'pubdate'? nThis is my pubdate item which follow as: nnitem'pubdate' = process_date_item(self response PUBDATE_XPATH   DATE_FORMAT_STRING single=True)0nnnGET http://www.mckinsey.com/business-functions/strategy-and-corporate-   finance/>n2016-10-18 16:37:05 scrapy DEBUG: Redirecting (301) to <GET      http://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-   insights> from <GET http://www.mckinsey.com/business-functions/strategy-and-   corporate-finance>n2016-10-18 16:37:07 scrapy DEBUG: Crawled (200) <GET      http://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-   insights> (referer: None)n2016-10-18 16:37:07 scrapy ERROR: Spider error processing <GET    http://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-   insights> (referer: None)nTraceback (most recent call last):nFile ""/home/nik/project/lib/python3.5/site-   packages/twisted/internet/defer.py"" line 587 in _runCallbacksncurrent.result = callback(current.result *args **kw)nFile ""/home/nik/project/lib/python3.5/site-   packages/twisted/internet/defer.py"" line 587 in _runCallbacksncurrent.result = callback(current.result *args **kw)nFile ""/home/nik/project/scrapers-master/content/content/spiders/newkerala.py"" line 53 in parsenitem'pubdate' = process_date_item(self response PUBDATE_XPATH    DATE_FORMAT_STRING single=True)0nFile ""/home/nik/project/scrapers-master/content/content/item_functions.py""      line 65 in process_date_itemnpubdate = ''.join(date_node) nTypeError: can only join an iterablecan only join an iterablenn' nan",['python-3.x'],"['python-3.x', 'python-2.7']"
40110306,"'Reading a binary file with memoryview' 'I read a large file in the code below which has a special structure - among others two blocks that need be processed at the same time. Instead of seeking back and forth in the file I load these two blocks wrapped in memoryview callsnnwith open(abs_path 'rb') as bsa_file:n    # ...n    # load the file record block to parse latern    file_records_block = memoryview(bsa_file.read(file_records_block_size))n    # load the file names blockn    file_names_block = memoryview(bsa_file.read(total_file_name_length))n    # close the filenfile_records_index = names_record_index = 0nfor folder_record in folder_records:n    name_size = struct.unpack_from('B' file_records_block file_records_index)0n    # discard null terminator belown    folder_path = struct.unpack_from('%ds' % (name_size - 1)n        file_records_block file_records_index + 1)0n    file_records_index += name_size + 1n    for __ in xrange(folder_record.files_count):n        file_name_len = 0n        for b in file_names_blocknames_record_index::n            if b != 'x00': file_name_len += 1n            else: breakn        file_name = unicode(struct.unpack_from('%ds' % file_name_lenn            file_names_blocknames_record_index)0)n        names_record_index += file_name_len + 1nnnThe file is correctly parsed but as it's my first use of the mamoryview interface I am not sure I do it right. The file_names_block is composed as seen by null terminated c strings.nnnIs my trick file_names_blocknames_record_index: using the memoryview magic or do I create some n^2 slices ? Would I need to use islice here ?nAs seen I just look for the null byte manually and then proceed to unpack_from. But I read in How to split a byte string into separate bytes in python that I can use cast() (docs ?) on the memory view - any way to use that (or another trick) to split the view in bytes ? Could I just call split('x00') ? Would this preserve the memory efficiency ?nnnI would appreciate insight on the one right way to do this (in python 2).n' ""A memoryview is not going to give you any advantages when it comes to null-terminated strings as they have no facilities for anything but fixed-width data. You may as well use bytes.split() here instead:nnfile_names_block = bsa_file.read(total_file_name_length)nfile_names = file_names_block.split(b'00')nnnSlicing a memoryview doesn't use extra memory (other than the view parameters) but if using a cast you do produce new native objects for the parsed memory region the moment you try to access elements in the sequence.nnYou can still use the memoryview for the file_records_block parsing; those strings are prefixed by a length giving you the opportunity to use slicing. Just keep slicing bytes of the memory view as you process folder_path values there's no need to keep an index:nnfor folder_record in folder_records:n    name_size = file_records_block0  # first byte is the length indexing gives the integern    folder_path = file_records_block1:name_size.tobytes()n    file_records_block = file_records_blockname_size + 1:  # skip the nullnnnBecause the memoryview was sourced from a bytes object indexing will give you the integer value for a byte .tobytes() on a given slice gives you a new bytes string for that section and you can then continue to slice to leave the remainder for the next loop.n""",['python-2.7'],"['python-2.7', 'python-3.x']"
40110309,"'Django queryset with isnull=True in get_object_or_404' 'I have 2 records in the posts table one of the row in table has rating as NULL and the other has rating as 2 both have same user_id say 5nnI implement this firstnnviews.pynnclass Rating(TemplateView):n    template_name = 'base/rating.html'n    def get(selfrequestslug*args**kwargs):n        user_id = request.user.idn        post = get_object_or_404(Post.objects.filter(user_id=user_idrating__isnull=True))n        return render(requestself.template_name)nnnurls.pynnurl(r'^post/addRating/(?P<slug>.+?)/$'views.Rating.as_view()name=""post_rating"")nnnn  So the actual concept is not to render the view if rating column isn  not nullnnnSo the first record with rating null should return 404 page but it is not and the second record display properlynnCan any one help me to fix it?n' 'You need read more carefully the django doc the above code is incorrect.nTo use get_object_or_404 you have to write something like(from django doc)nnfrom django.shortcuts import get_object_or_404ndef my_view(request):n    my_object = get_object_or_404(MyModel pk=1)nnnFor your propurse you should write something like:nnposts = Post.objects.filter(user_id=user_idrating__isnull=True)npost = posts and posts0nn'",['django'],['django']
40110389,"'Checking input of URLfield for broken links' 'I'm using modelform_factory to generate forms in my administration panel.nNow I'd like to check if there's a URLfield in the model / form in question and if so validate it to see if it's broken.nnHere is a part of my view.py generating and treating the form and post request.nnmodel_name = apps.get_model(""product"" model)nEditForm = modelform_factory(model_name fields=(""__all__""))nif request.method == ""POST"":n    formset = EditForm(request.POST request.FILES instance=model_name.objects.get(id=object_id))n    if formset.is_valid():n        formset.save()n        #Success - redirect to all objects from modeln    else:n        formset = EditForm(instance=model_name.objects.get(id=object_id))n        return render(request 'product/admin/edit.html' {'model': model 'object_id': object_id 'formset': formset})nelse:n     formset = EditForm(instance=model_name.objects.get(id=object_id))n     return render(request 'product/admin/edit.html' {'model': model 'object_id': object_id 'formset': formset})nn' nan",['django'],['django']
40110468,"'How to check if a string contains a dictionary' 'I want to recursively parse all values in a dict that are strings with ast.literal_eval(value) but not do that eval if the string doesn't contain a dict. I want this because I have a string in a dict that is a dict in itself and I would like the value to be a dict. Best to give an examplennmy_dict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': 'another string'}""}nnnNow I don't want a do to ast.literal_eval(my_dict'c') I want a generic solution where I can do convert_to_dict(my_dict)nnI wanted to write my own method but I don't know how to check if a string contains a dict and then ast.literal_eval will fail hence the question.n' 'If you need to handle nested str defining dict json.loads with an object_hook might work for you:nnimport jsonnndef convert_subdicts(d):n    for k v in d.items():n        try:n            # Try to decode a dictn            newv = json.loads(v object_hook=convert_subdicts)n        except Exception:n            continuen        else:n            if isinstance(newv dict):n                dk = newv  # Replace with decoded dictn    return dnnorigdict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': 'another string'}""}nnewdict = convert_subdicts(origdict.copy())  # Omit .copy() if mutating origdict okaynnnThat should recursively handle the case where the contained dicts might contain strs values that define subdicts. If you don't need to handle that case you can omit the use of the object_hook or replace json.loads entirely with ast.literal_eval.n' 'The general idea referenced in my above comment is to run thru the dictionary and try and evaluate. Store that in a local variable and then check if that evaluated expression is a dictionary. If so then reassign it to the passed input. If not leave it alone. nnmy_dict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': 'another string'}""}nndef convert_to_dict(d):n    for key val in d.items():n        try:n            check = ast.literal_eval(val)n        except:n            continue n        if isinstance(check dict):n            dkey = check n    return dnnconvert_to_dict(my_dict)nn' 'You can check if you have a dict after using literal_eval and reassign:nnfrom ast import literal_evalnndef reassign(d):n    for k v in d.items():n        try:n            evald = literal_eval(v)n            if isinstance(evald dict):n                dk = evaldn        except ValueError:n            passnnnJust pass in the dict:nnIn 2: my_dict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': 'another strin   ...: ng'}""}nnIn 3: reassign(my_dict)nnIn 4: my_dictnOut4: {'a': 42 'b': 'my_string' 'c': {'d': 33 'e': 'another string'}}nnIn 5: my_dict = {'a': '42' 'b': ""my_string"" '5': ""{'d': 33 'e': 'another stn...: ring' 'other_dict':{'foo':'bar'}}""}nIn 6: reassign(my_dict)  nIn 7: my_dictnOut7: n{'5': {'d': 33 'e': 'another string' 'other_dict': {'foo': 'bar'}}n 'a': '42'n 'b': 'my_string'}nnnYou should also be aware that if you had certain other objects in the dict like datetime objects etc.. then literal_eval would fail so it really depends on what your dict can contain as to whether it will work or not.nnIf you need a recursive approach all you need is to call reassign on the new dict.nndef reassign(d):n    for k v in d.items():n        try:n            evald = literal_eval(v)n            if isinstance(evald dict):n                dk = evaldn                reassign(evald)n        except ValueError:n            passnnnAnd again just pass the dict:nnIn 10: my_dict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': ""{'f' : 64}n    ...: ""}""}nnIn 11: reassign(my_dict)nnIn 12: my_dictnOut12: {'a': 42 'b': 'my_string' 'c': {'d': 33 'e': {'f': 64}}}nnnAnd if you want a new dict:nnfrom ast import literal_evalnfrom copy import deepcopynndef reassign(d):n    for k v in d.items():n        try:n            evald = literal_eval(v)n            if isinstance(evald dict):n                yield k dict(reassign(evald))n        except ValueError:n            yield k deepcopy(v)nnnWhich will give you a new dict:nnIn 17: my_dict = {'a': 1 2 3 'b': ""my_string"" 'c': ""{'d': 33 'e': ""{n    ...: 'f' : 64}""}""}nnIn 18: new =  dict(reassign(my_dict))nnIn 19: my_dict""a""-1.append(4)nnIn 20: newnOut20: {'a': 1 2 3 'b': 'my_string' 'c': {'d': 33 'e': {'f': 64}}}nnIn 21: my_dictnOut21: n{'a': 1 2 3 4n 'b': 'my_string'n 'c': '{'d': 33 'e': ""{'f' : 64}""}'}nnnYou need to make sure to deepcopy objects or you won't get a true independent copy of the dict when you have nested object like  the list of lists above.n' 'Here is a proposition that handles recursion. As it was suggested in the comments it tries to eval everything then check if the result is a dict if it is we recurse else we skip the value . I sligthly altered the initial dict to show that it hanldes recusion fine :nnimport astnmy_dict = {'a': 42 'b': ""my_string"" 'c': ""{'d': 33 'e': ""{'f' : 64}""}""}nndef recursive_dict_eval(old_dict):n    new_dict = old_dict.copy()n    for keyvalue in old_dict.items():n        try:n            evaled_value=ast.literal_eval(value)n            assert isinstance(evaled_valuedict)n            new_dictkey=recursive_dict_eval(evaled_value)nn        except (SyntaxError ValueError AssertionError):n            #SyntaxError ValueError are for the literal_eval exceptionsn            passn    return new_dictnnprint(my_dict)nprint(recursive_dict_eval(my_dict))nnnOutput:nn{'a': 42 'b': 'my_string' 'c': '{'d': 33 'e': ""{'f' : 64}""}'}n{'a': 42 'b': 'my_string' 'c': {'e': {'f': 64} 'd': 33}}nn'","['python-3.x', 'dictionary']",['dictionary']
40110574,"'sqlalchemy.exc.AmbiguousForeignKeysError after Inheritance' 'I'm using sqlacodegen for reflecting a bunch of tables from my database.nAnd i'm getting the following error:nnn  sqlalchemy.exc.AmbiguousForeignKeysError: Can't determine join between 'Employee' and 'Sales'; tables have more than one foreign key constraint relationship between them. Please specify the 'onclause' of this join explicitly.nnnHere's a simplified version of my tables.nI read in the documentation that I should use the foreign_keys parameter to resolve ambiguity between foreign key targets. Although I think this problem is because of the inheritance. Could someone help me understand what is going on.nn# coding: utf-8nfrom sqlalchemy import Column ForeignKey Integernfrom sqlalchemy.ext.declarative import declarative_basenfrom sqlalchemy.orm import relationshipnnBase = declarative_base()nnnclass Employee(Base):n    __tablename__ = 'Employee'nn    EmployeeId = Column(Integer primary_key=True)nnnclass Sales(Employee):n    __tablename__ = 'Sales'nn    EmployeeID = Column(ForeignKey('Employee.EmployeeId') primary_key=True)n    OldemployeeID = Column(ForeignKey('Employee.EmployeeId'))n    employee = relationship('Employee' foreign_keys=EmployeeID)n    old_employee = relationship(""Employee"" foreign_keys=OldemployeeID)nn' 'Just use backref and use Integer on both EmployeeID and OldemployeeID. Otherwise you will get an another error.nnclass Sales(Employee):n    __tablename__ = 'Sales'nn    EmployeeID = Column(Integer ForeignKey('Employee.EmployeeId') primary_key=True)n    OldemployeeID = Column(Integer ForeignKey('Employee.EmployeeId'))n    employee = relationship('Employee' foreign_keys=EmployeeID backref='Employee')n    old_employee = relationship(""Employee"" foreign_keys=OldemployeeID backref='Employee')nn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40110731,"'How can I tell if I have a file-like object?' ""I want to have a function that writes data to a file:nndef data_writer(data file_name):n    spiffy_data = data # ...n    with open(file_name 'w') as out:n        out.write(spiffy_data)nnnBut sometimes I have a file object instead of a file name. In this case I sometimes have a tempfile.TemporaryFile (which creates a file-like object that's writable).nnI'd like to be able to write something like:nndef data_writer(data file_thing):n    spiffy_data = data # ...n    if type(file_thing) is file_like:n        file_thing.write(spiffy_data)n    else:n        with open(file_name 'w') as out:n            out.write(spiffy_data)nnnWhat's a good way to do this?nnAlso does makes sense to do in Python?n"" 'While your approach is LBYL it's pythonic to assume it's EAFP. So you could just try to nnnwrite() to the file_thing you received ornopen() itnnnand except a potential exception depending on which you feel better represents the default case.nnEdit: Cf ShadowRanger's comment for why mixing the exception handling with a context manager is rather unelegant here.n' 'A function should do one thing and do that one thing well. In the case of data_writer its one thing is to write data to a file-like object. Let the caller worry about providing such an object. That said you can also provide that caller in the form of a wrapper that takes a file name and opens it for data_writer.nndef data_writer(data file_obj):n    spiffy_data = data # ...n    file_obj.write(spiffy_data)nndef write_data_to_file(data file_name):n    with open(file_name ""w"") as f:n        data_writer(f file_name)nn'",['python-3.x'],"['python-2.7', 'python-3.x']"
40110778,"'Foolproofing a Python calculator' 'I'm writing a basic calculator which works with two different numbers.nSo far I managed to write a working prototype but while dividing and foolproofing it I ran into a multitude of problems so I'm posting them nseparately. nnnnI want the program to repeat the question if the user doesn't provide an eligible operator. That's the code I have now: nndef optn_query():n    print(""Hulk can different things with number!"")n    print(""YOU!"")n    optn = input(""What Hulk do with number?! "")n    return optnnnnDo I use an if statement to determine if the input is correct?nnnnAlso I put return optn in there so the next function (gracefully called hulk_math) wouldn't fail midway but it still does: nnTraceback (most recent call last):n  File ""hulc.py"" line 57 in <module>n    main()n  File ""hulc.py"" line 13 in mainn    hulk_math()n  File ""hulc.py"" line 41 in hulk_mathn    if optn == ""+"":nNameError: name 'optn' is not definednnnWhat should I do to fix this?nnHere's hulk_math() itself: nndef hulk_math():n    if optn == ""+"":n        result = num1 + num2n        print(""Hulk ADDS!!! Hulk thinks it's {0}!"".format(result))n    elif optn == ""-"":n        result = num1 - num2n        print(""Hulk SUBTRACTS!!! Hulk thinks it's {0}!"".format(result))n    elif optn == ""*"":n        result = num1 * num2n        print(""Hulk MULTIPLIES!!! Hulk thinks it's {0}!"".format(result))n    elif optn == ""/"":n        result = num1 / num2n        print(""Hulk DIVIDES!!! Hulk thinks it's {0}!"".format(result))n    main()nn' 'You need to actually call your function:nndef hulk_math():n    optn = optn_query()n    #The rest of your codennnAlso unless num1 and num2 are defined elsewhere in your code such that they are in the scope of hulk_math your program is going to fail there too.n' 'Ok I fixed it by writing global optn instead of return optn. That way it makes the variable global so other functions can use it.n' ""Using global isn't the right way to do this.  Pass values from one function to another by saving their return values and passing them as arguments.nndef main():n    intro()n    num1 = num1_query()n    optn = optn_query()n    num2 = num2_query()n    hulk_math(num1 optn num2)nndef hulk_math(num1 optn num2):n    #Your original code will work as expectednn""",['python-3.x'],"['python-2.7', 'python-3.x']"
40110800,'Python backtest using percentage based commission' 'I'm writing a script to backtest some strategies for a set of stocks using the bt framework for python. In the bt documentation (backtest module) it says: nnn  commission (fn(quantity)): The commission function to be used.nnnSo when I run my code nnresult = bt.Backtest(strategy data initial_capital= 100000.00 commissions=)nnnI want to pass a function that returns a percentage based commission e.g. 0.5 % of the transaction. Since I don't know the size of the transactions is this even possible? How would it otherwise be solved using a set commission?n' 'Solved it by creating a function with parameters for quantity and price. Thus it was easy returning a percentage based on the transaction cost as follows:nndef my_comm(q p):n    return abs(q)*p*0.0025nn',['pandas'],"['python-2.7', 'python-3.x']"
40110816,"""AttributeError 'nonetype' object has no attribute 'recv'"" 'First of all I need to say I've never tried coding in python before... nnI'm trying to make a Twitch IRC bot working but I keep failing... nnMy bot.py code looks like this: nnfrom src.lib import irc as irc_nnfrom src.lib import functions_generalnnfrom src.lib import functions_commands as commandsnnfrom src.config import confignnclass PartyMachine:nn    def __init__(self config):n        self.config = confign        self.irc = irc_.irc(config)n        self.socket = self.irc.get_irc_socket_object()nnn    def sock(self):n        irc = self.ircn        sock = self.socketn        config = self.confign        kage = socknn        while True:n            data = sock.recv(2048).rstrip()nn            if len(data) == 0:n                pp('Connection was lost reconnecting.')n                sock = self.irc.get_irc_socket_object()nn            if config'debug':n                print (data)nnnmy config.py is here:nn'socket_buffer_size': 1024nnnMy irc.py is here:nndef get_irc_socket_object(self):n    sock = socket.socket(socket.AF_INET socket.SOCK_STREAM)n    sock.settimeout(10)nn    self.sock = socknn    try:n        sock.connect((self.config'server' self.config'port'))n    except:n        pp('Cannot connect to server (%s:%s).' % (self.config'server' self.config'port') 'error')n        sys.exit()nn    sock.settimeout(None)ndef sock_send(sock send self):n    sock.send('USER %srn' % self.config'username' sock.encode('utf-8') send.encode('utf-8'))n    sock.send('PASS %srn' % self.config'oauth_password')n    sock.send('NICK %srn' % self.config'username')nn    if self.check_login_status(sock.recv(1024)):n        pp('Login successful.')n    else:n        pp('Login unsuccessful. (hint: make sure your oauth token is set in self.config/self.config.py).' 'error')n        sys.exit()nnnand my serve.py is here:nnfrom sys import argvnfrom src.bot import *nfrom src.config.config import *nnbot = PartyMachine(config).sock()nnnIt keeps failing with ""AttributeError 'nonetype' object has no attribute 'recv'"". How can this be ? n' ""Your get_irc_socket_object(self) might be the problem. You call it with the line self.socket = self.irc.get_irc_socket_object(). This means that python expects the function get_irc_socket_object(self) to return a socket object but you don't return anything (you just write self.sock = sock which doesn't do anything because you use self.socket for the rest of your code). As a result the function returns none so now self.socket just has that as its value. Therefore when you make the call to recv you get your errornnAlso please clean up your variable names. Sock is used way too often in your code and makes it very hard to follow.n""",['python-3.x'],"['python-2.7', 'python-3.x']"
40110907,"'update threaded tkinter gui' 'I have a small display connected to my pi.nNow I have a Python script that measures the time between two events of the gpio headers.nI want to display this time (the script to get this time is working perfectly). For that I created a tkinter window.nThere I have a label that should display this time.nI have threaded the gui function to make it possible for the program to still listen to the GPIO pin.nndef guiFunc():n    gui = Tk()n    gui.title(""Test"")n    gui.geometry(""500x200"")n    app = Frame(gui)n    app.grid()n    beattime = Label(app text = ""test"")n    beattime.grid()n    gui.mainloop()nnngui_thread = threading.Thread(target = guiFunc)ngui_thread.start()nnnwhile True:n    time.sleep(.01)n    if (GPIO.input(3)):n        time = trigger()  #trigger is the function to trigger the 'stopwatch'n        global beattimen        beattime'text' = str(time)n        while GPIO.input(3): #'wait' for btn to release (is there a better way?)n            print ""btn_pressed""nnnSo the program isn't doing anything since I added these lines:nnglobal beattimenbeattime'text' = str(time)nnnWhat am I doing wrong?n' 'Use tkinter.StringVarnn# omitting linesnglobal timevarntimevar = StringVar()ntimevar.set(""Test"")nbeattime = Label(app textvariable=timevar)n# omitting linesnn#changing the text:nwhile True:n    time.sleep(.01)n    if (GPIO.input(3)):n       time = trigger()  #trigger is the    function to trigger the 'stopwatch'n       timevar.set(str(time))n       root.update() #just in casenn       while GPIO.input(3): #'wait' for btn to release (is there a better way?)n          print ""btn_pressed""nnnAnd you should run the gui in your main thread. Its not recommended to call gui calls from different threads.n'",['tkinter'],['tkinter']
40111091,"'dictionary to pandas DataFrame' ""I have this dictionary:nndiccionario = {'Monetarios':'B1''B2'n            'Monetario Dinamico':'B1''B2'n            'Renta fija corto plazo':'B1''B2'n            'Garantizados de RF':'B1''B2'n            'Renta Fija Largo Plazo':'B2''B3'n            'Garantizados de RV':'B2''B3'n            'Mixtos Renta Fija':'B2''B3'n            'Mixtos Renta Variable':'B3''B4'n            'Renta Variable':'B3''B4'n            'Alternativos':'B3''B4'n            'Fondos Inmobiliarios en Directo':'G3''G3'n            'IIC de Inversion Libre':'G4''G4'n            'IIC de IIC de Inversion Libre':'G4''G4'n            'Money Markets':'B1''B2'n            'Money Markets Enhanced':'B1''B2'n            'Fixed Income Short Term':'B1''B2'n            'Capital Guaranteed Funds':'B1''B2'n            'Fixed Income Long Term':'B2''B3'n            'Capital Guaranteed Equity Funds':'B2''B3'n            'Mixed Fixed Income Funds':'B2''B3'n            'Mixed Equity Funds':'B3''B4'n            'Equity':'B3''B4'n            'Alternatives':'B3''B4'n            'Real State':'G3''G4'n            'Hedge Funds':'G4''G4'n            'Funds of Hedge Funds':'G4''G4'n            'HARMONIZED':'G4'n            'HIGH_YLD_EMERGING_MARKETS':'B4'n           }nnnAnd i want a data frame with the words i am using as keys as the first column and the values assigned to those keys as other columns like this:nncol 1       col 2     col 3nMonetarios    B1        B2nMonetar din.  B1        B2nRent fija...  B1        B2nnn...n...nnI ve just got the first colum with this:n    df_dict =  pd.DataFrame(diccionario)nnk3 = list(df_dict.columns.values)nnnthanks in advancen"" 'I think you can use transpose by T with reset_index:nndf = pd.DataFrame.from_dict(diccionario).T.reset_index()ndf.columns = 'col1''col2''col3'nprint (df)n                               col1 col2 col3n0                      Alternatives   B3   B4n1                      Alternativos   B3   B4n2   Capital Guaranteed Equity Funds   B2   B3n3          Capital Guaranteed Funds   B1   B2n4                            Equity   B3   B4n5            Fixed Income Long Term   B2   B3n6           Fixed Income Short Term   B1   B2n7   Fondos Inmobiliarios en Directo   G3   G3n8              Funds of Hedge Funds   G4   G4n9                Garantizados de RF   B1   B2n10               Garantizados de RV   B2   B3n11                       HARMONIZED   G4   G4n12        HIGH_YLD_EMERGING_MARKETS   B4   B4n13                      Hedge Funds   G4   G4n14    IIC de IIC de Inversion Libre   G4   G4n15           IIC de Inversion Libre   G4   G4n16               Mixed Equity Funds   B3   B4n17         Mixed Fixed Income Funds   B2   B3n18                Mixtos Renta Fija   B2   B3n19            Mixtos Renta Variable   B3   B4n20               Monetario Dinamico   B1   B2n21                       Monetarios   B1   B2n22                    Money Markets   B1   B2n23           Money Markets Enhanced   B1   B2n24                       Real State   G3   G4n25           Renta Fija Largo Plazo   B2   B3n26                   Renta Variable   B3   B4n27           Renta fija corto plazo   B1   B2nn'","['pandas', 'dictionary']",['pandas']
40111271,"'dictionary convert to list and sort causing error python2.7' ""I have a dictionary which is a histogram of different hours in a day:nnn  {'11': 6 '10': 3 '15': 2 '14': 1 '04': 3 '16': 4 '19': 1 '18':n  1 '09': 2 '17': 2 '06': 1 '07': 1}nnnand I want to sort the dictionary based on the hours(first item) and produce something like:nnn  ('04' 3) ('06' 1) ('07' 1) ('09' 2) ('10' 3) ('11' 6)n  ('14' 1) ('15' 2) ('16' 4) ('17' 2) ('18' 1) ('19' 1)nnnI tried hours = list(dict.items()) and it works pretty well but when I tried earliernnfor hour freq in dict:n    count = (hour freq)n    lst.append(count)nlst.sort()nprint lstnnnI getnnn  ('0' '4') ('0' '6') ('0' '7') ('0' '9') ('1' '0') ('1'n  '1') ('1' '4') ('1' '5') ('1' '6') ('1' '7') ('1' '8')n  ('1' '9')nnnIt seems like only the first digit of the hours are recorded but I don't know why. The for loop worked well when I was counting frequency of a character in a given string. Can somebody please help me explain this? Thanks a lot.n"" ""When you do for ... in d the dict only iterates over the keys in the dictionary not the values.  Instead of getting a tuple of hour count you're getting a two-character string that's being split into first_character second_character Not that each of the pairs in the last output of your question are actually the keys split into tuples.n"" ""You can try something like this:nnd = {'11': 6 '10': 3 '15': 2 '14': 1 '04': 3 '16': 4 '19': 1 '18': 1 '09': 2 '17': 2 '06': 1 '07': 1}nl = list(d.iteritems())nl.sort()nprint lnnnThe output is:nn('04' 3) ('06' 1) ('07' 1) ('09' 2) ('10' 3) ('11' 6) ('14' 1) ('15' 2) ('16' 4) ('17' 2) ('18' 1) ('19'1)nn"" ""You'll want to use iteritemsnnfor hour value in dict.iteritems():n    etc.nnnOf course you shouldn't use the name 'dict' -- rename it to something else since it's already the name of the dict class. You can also use items() if you want -- it takes more space and is slightly faster but it shouldn't matter if you're using small amounts of data.n"" ""Go through both keys and values using dict.items(). Combine it with a list comprehension to get the list you want and finally sort it.nna = {'11': 6 '10': 3 '15': 2 '14': 1 '04': 3 '16': 4 '19': 1 '18': 1 '09': 2 '17': 2 '06': 1 '07': 1}nnb = sorted((x y) for x y in a.items())nprint(b)n# printsn# ('04' 3) ('06' 1) ('07' 1) ('09' 2) ('10' 3) ('11' 6) ('14' 1) ('15' 2) ('16' 4) ('17' 2) ('18' 1) ('19' 1)nn"" 'I think you are simply iterating over dictionary keys instead of pairs of key and value.nnHave a look at this post:nIterating over dictionaries using for loops in PythonnnYour code should work if updated as below:nnfor hour freq in dict.iteritems():n    count = (hour freq)n    lst.append(count)nlst.sort()nn'","['list', 'python-2.7', 'dictionary']","['dictionary', 'list']"
40111431,"'How to Convert URLField in a Image on Django' 'I have kept the url of an image on a URLField such that as well as I can display the image on the model of my home page and not the string of the URL I can not convert that direction ""www.google.es/images/car ""in an image of a car?nnmodels.pynnPhoto class (models.Model):nÂxa0Âxa0Âxa0Âxa0 name = models.CharField (max_length = 150)nÂxa0Âxa0Âxa0Âxa0 url = models.URLField ()nÂxa0Âxa0Âxa0Âxa0 __unicode def __ (self): # 0 parametersnÂxa0Âxa0Âxa0Âxa0Âxa0Âxa0Âxa0Âxa0 return self.namennnviews.pynndef home (request):nÂxa0Âxa0Âxa0Âxa0 photos = Photo.objects.all ()nÂxa0Âxa0Âxa0Âxa0 html = '<ul>'nÂxa0Âxa0Âxa0Âxa0 for photo in photos:nÂxa0Âxa0Âxa0Âxa0Âxa0Âxa0Âxa0Âxa0 html + = '<li>' + photo.url + '</ li>'nÂxa0Âxa0Âxa0Âxa0 html + = '</ ul>'nÂxa0Âxa0Âxa0Âxa0 return HttpResponse (html)nnnHow could i convert in a imagen photo.url into a Image.n' 'You cannot convert the string into image however you can use the url in src attribute inside <img> tagnnfor photo in photos:n     html + = '<li><img src=""' + photo.url + '""></ li>'nnnRemember that you are generating HTML for the website not rendering it's contentn' 'Try:nndef home (request):n     photos = Photo.objects.all ()n     html = '<ul>'n     for photo in photos:n         html + = '<li><img src=""{}""><li>'.format(photo.url)n     html + = '</ ul>'n     return HttpResponse (html)nnnPerhaps even better again relying on formatting instead of string concatenation:nndef home (request):n     photos = Photo.objects.all ()n     html = '<ul>{}</ul>'n     html_photos = n     for photo in photos:n         html_photos.append('<li><img src=""{}""><li>'.format(photo.url))n     html = html.format(""n"".join(html_photos))n     return HttpResponse (html)nn'",['django'],['django']
40111546,"'pandas - agg() function' ""The ordering of my age height and weight columns is changing with each run of the code.  I need to keep the order of my agg columns static because I ultimately refer to this output file according to the column locations.  What can I do to make sure age height and weight are output in the same order every time?nnd = pd.read_csv(input_file na_values='')ndf = pd.DataFrame(d)ndf.index_col = 'name' 'address'nndf_out = df.groupby(df.index_col).agg({'age':np.mean 'height':np.sum 'weight':np.sum})ndf_out.to_csv(output_file sep='')nn"" ""I think you can use subset:nndf_out = df.groupby(df.index_col)n           .agg({'age':np.mean 'height':np.sum 'weight':np.sum})'age''height''weight'nnnAlso you can use pandas functions:nndf_out = df.groupby(df.index_col)n           .agg({'age':'mean' 'height':sum 'weight':sum})'age''height''weight'nnnSample:nndf = pd.DataFrame({'name':'q''q''a''a'n                   'address':'a''a''s''s'n                   'age':78910n                   'height':1357n                   'weight':5368})nnprint (df)n  address  age  height name  weightn0       a    7       1    q       5n1       a    8       3    q       3n2       s    9       5    a       6n3       s   10       7    a       8ndf.index_col = 'name' 'address'ndf_out = df.groupby(df.index_col)n           .agg({'age':'mean' 'height':sum 'weight':sum})'age''height''weight'nnprint (df_out)n              age  height  weightnname address                     na    s        9.5      12      14nq    a        7.5       4       8nn""",['pandas'],['pandas']
40111624,"'Problems while transforming a python dict to a list of triples?' 'I have the following python dict:nn{'token_list': {'quote_level': '0' 'affected_by_negation': 'no' 'token_list': {'quote_level': '0' 'affected_by_negation': 'no' 'token_list': {'id': '21' 'analysis_list': {'tag': 'GNUS3S--' 'lemma': 'Robert Downey Jr' 'original_form': 'Robert Downey Jr'} 'form': 'Robert Downey Jr' 'type': 'phrase' 'syntactic_tree_relation_list': {'type': 'isSubject' 'id': '17'} 'separation': '_' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'token_list': {'id': '16' 'analysis_list': {'tag': 'NPUU-N-' 'sense_id_list': {'sense_id': '__12123288058840445720'} 'lemma': 'Robert Downey Jr' 'original_form': 'Robert Downey Jr'} 'sense_list': {'info': 'sementity/class=instance@type=Top>Person>FullName@confidence=unknown' 'form': 'Robert Downey Jr' 'id': '__12123288058840445720'} 'form': 'Robert Downey Jr' 'type': 'multiword' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '_' 'quote_level': '0' 'topic_list': {'entity_list': {'form': 'Robert Downey Jr' 'sementity': {'type': 'Top>Person>FullName' 'confidence': 'unknown' 'class': 'instance'} 'id': '__12123288058840445720'}} 'head': '15' 'inip': '0' 'affected_by_negation': 'no' 'endp': '15'} 'head': '16' 'inip': '0' 'affected_by_negation': 'no' 'endp': '15'} {'id': '17' 'analysis_list': {'tag': 'VI-S3PPA-N-N9' 'lemma': 'top' 'original_form': 'has topped'} 'form': 'has topped' 'type': 'multiword' 'syntactic_tree_relation_list': {'type': 'iof_isSubject' 'id': '21'} {'type': 'iof_isDirectObject' 'id': '24'} 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'head': '4' 'inip': '17' 'affected_by_negation': 'no' 'endp': '26'} {'id': '24' 'analysis_list': {'tag': 'GN-S3D--' 'lemma': 'list' 'original_form': ""Forbes magazine's annual list""} 'form': ""Forbes magazine's annual list"" 'type': 'phrase' 'syntactic_tree_relation_list': {'type': 'isDirectObject' 'id': '17'} 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'token_list': {'id': '22' 'analysis_list': {'tag': 'GN-S3---' 'lemma': 'magazine' 'original_form': 'Forbes magazine'} 'form': 'Forbes magazine' 'type': 'phrase' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '1' 'quote_level': '0' 'token_list': {'quote_level': '0' 'topic_list': {'entity_list': {'form': 'Forbes' 'semld_list': 'sumo:LastName' 'sementity': {'type': 'Top>Person>LastName' 'fiction': 'nonfiction' 'id': 'ODENTITY_LAST_NAME' 'class': 'instance'} 'id': '4a3369b337'} {'form': 'Forbes' 'semld_list': 'sumo:River' 'sementity': {'type': 'Top>Location>GeographicalEntity>WaterForm>River' 'fiction': 'nonfiction' 'id': 'ODENTITY_RIVER' 'class': 'instance'} 'id': '9752b8b5ee'} {'sementity': {'type': 'Top>Product>CulturalProduct>Printing>Magazine' 'fiction': 'nonfiction' 'id': 'ODENTITY_MAGAZINE' 'class': 'instance'} 'semgeo_list': {'country': {'form': 'United States' 'standard_list': {'value': 'US' 'id': 'ISO3166-1-a2'} {'value': 'USA' 'id': 'ISO3166-1-a3'} 'id': 'beac1b545b'} 'continent': {'form': 'AmÄx82Åxa0rica' 'id': '33fc13e6dd'}} 'semtheme_list': {'type': 'Top>SocialSciences>Economy' 'id': 'ODTHEME_ECONOMY'} 'semld_list': 'sumo:Magazine' 'form': 'Forbes' 'id': 'db0f9829ff'}} 'analysis_list': {'tag': 'NP-S-N-' 'sense_id_list': {'sense_id': 'db0f9829ff'} 'lemma': 'Forbes' 'original_form': 'Forbes'} {'tag': 'NP-S-N-' 'sense_id_list': {'sense_id': '9752b8b5ee'} 'lemma': 'Forbes' 'original_form': 'Forbes'} {'tag': 'NPUS-N-' 'sense_id_list': {'sense_id': '4a3369b337'} 'lemma': 'Forbes' 'original_form': 'Forbes'} 'separation': '1' 'sense_list': {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_LAST_NAME@type=Top>Person>LastNametsemld_list=sumo:LastName' 'form': 'Forbes' 'id': '4a3369b337'} {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_RIVER@type=Top>Location>GeographicalEntity>WaterForm>Rivertsemld_list=sumo:River' 'form': 'Forbes' 'id': '9752b8b5ee'} {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_MAGAZINE@type=Top>Product>CulturalProduct>Printing>Magazinetsemgeo_list/continent=AmÄx82Åxa0rica#id:33fc13e6dd@country=United States#id:beac1b545b#ISO3166-1-a2:US#ISO3166-1-a3:USAtsemld_list=sumo:Magazinetsemtheme_list/id=ODTHEME_ECONOMY@type=Top>SocialSciences>Economy' 'form': 'Forbes' 'id': 'db0f9829ff'} 'inip': '28' 'form': 'Forbes' 'affected_by_negation': 'no' 'endp': '33' 'id': '6' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': 'NC-S-N5' 'sense_id_list': {'sense_id': 'a0a1a5401f'} 'lemma': 'magazine' 'original_form': 'magazine'} 'separation': '1' 'sense_list': {'info': 'sementity/class=class@fiction=nonfiction@id=ODENTITY_MAGAZINE@type=Top>Product>CulturalProduct>Printing>Magazinetsemld_list=sumo:Magazine' 'form': 'magazine' 'id': 'a0a1a5401f'} 'inip': '35' 'form': 'magazine' 'affected_by_negation': 'no' 'endp': '42' 'id': '7' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} 'head': '7' 'inip': '28' 'affected_by_negation': 'no' 'endp': '42'} {'quote_level': '0' 'analysis_list': {'tag': 'WN-' 'lemma': ""'s"" 'original_form': ""'s""} 'separation': 'A' 'inip': '43' 'form': ""'s"" 'affected_by_negation': 'no' 'endp': '44' 'id': '14' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'id': '23' 'analysis_list': {'tag': 'GN-S3---' 'lemma': 'list' 'original_form': 'annual list'} 'form': 'annual list' 'type': 'phrase' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '1' 'quote_level': '0' 'token_list': {'quote_level': '0' 'analysis_list': {'tag': 'AP-N5' 'lemma': 'annual' 'original_form': 'annual'} 'separation': '1' 'inip': '46' 'form': 'annual' 'affected_by_negation': 'no' 'endp': '51' 'id': '10' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': 'NC-S-N5' 'lemma': 'list' 'original_form': 'list'} 'separation': '1' 'inip': '53' 'form': 'list' 'affected_by_negation': 'no' 'endp': '56' 'id': '11' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} 'head': '11' 'inip': '46' 'affected_by_negation': 'no' 'endp': '56'} 'head': '23' 'inip': '28' 'affected_by_negation': 'no' 'endp': '56'} 'separation': '_' 'analysis_list': {'tag': 'Z-----------' 'lemma': '*' 'original_form': ""Robert Downey Jr has topped Forbes magazine's annual list""} 'inip': '0' 'form': ""Robert Downey Jr has topped Forbes magazine's annual list"" 'type': 'phrase' 'endp': '56' 'id': '25' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': '1D--' 'lemma': '.' 'original_form': '.'} 'separation': 'A' 'inip': '57' 'form': '.' 'affected_by_negation': 'no' 'endp': '57' 'id': '12' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} 'separation': 'A' 'inip': '0' 'endp': '57' 'type': 'sentence' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'id': '18'} 'status': {'credits': '1' 'remaining_credits': '39848' 'code': '0' 'msg': 'OK'}}nnnHow can I extract in a new tuple all the analysis_list keys with them respective values?:nn((NPUU-N- Robert Downey Jr Robert Downey Jr)(NPUU-N- Robert Downey Jr Robert Downey Jr) (VI-S3PPA-N-N9 top has topped') (GN-S3D-- list Forbes magazine's annual list) (GN-S3--- magazine 'original_form': 'Forbes magazine') (NP-S-N- Forbes Forbes) ... (1D-- . .))nnnI tried the following with pandas:nnIn:nndf = json_normalize(data'token_list')ndata = df'token_list'.to_dict()ndata=data.values()nprint(data)nnnout:nndict_values({'quote_level': '0' 'analysis_list': {'tag': 'Z-----------' 'lemma': '*' 'original_form': ""Robert Downey Jr has topped Forbes magazine's annual list""} 'token_list': {'id': '21' 'analysis_list': {'tag': 'GNUS3S--' 'lemma': 'Robert Downey Jr' 'original_form': 'Robert Downey Jr'} 'form': 'Robert Downey Jr' 'type': 'phrase' 'syntactic_tree_relation_list': {'type': 'isSubject' 'id': '17'} 'separation': '_' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'token_list': {'id': '16' 'analysis_list': {'tag': 'NPUU-N-' 'sense_id_list': {'sense_id': '__12123288058840445720'} 'lemma': 'Robert Downey Jr' 'original_form': 'Robert Downey Jr'} 'sense_list': {'info': 'sementity/class=instance@type=Top>Person>FullName@confidence=unknown' 'form': 'Robert Downey Jr' 'id': '__12123288058840445720'} 'form': 'Robert Downey Jr' 'type': 'multiword' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '_' 'quote_level': '0' 'topic_list': {'entity_list': {'form': 'Robert Downey Jr' 'sementity': {'type': 'Top>Person>FullName' 'confidence': 'unknown' 'class': 'instance'} 'id': '__12123288058840445720'}} 'head': '15' 'inip': '0' 'affected_by_negation': 'no' 'endp': '15'} 'head': '16' 'inip': '0' 'affected_by_negation': 'no' 'endp': '15'} {'id': '17' 'analysis_list': {'tag': 'VI-S3PPA-N-N9' 'lemma': 'top' 'original_form': 'has topped'} 'form': 'has topped' 'type': 'multiword' 'syntactic_tree_relation_list': {'type': 'iof_isSubject' 'id': '21'} {'type': 'iof_isDirectObject' 'id': '24'} 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'head': '4' 'inip': '17' 'affected_by_negation': 'no' 'endp': '26'} {'id': '24' 'analysis_list': {'tag': 'GN-S3D--' 'lemma': 'list' 'original_form': ""Forbes magazine's annual list""} 'form': ""Forbes magazine's annual list"" 'type': 'phrase' 'syntactic_tree_relation_list': {'type': 'isDirectObject' 'id': '17'} 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'quote_level': '0' 'token_list': {'id': '22' 'analysis_list': {'tag': 'GN-S3---' 'lemma': 'magazine' 'original_form': 'Forbes magazine'} 'form': 'Forbes magazine' 'type': 'phrase' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '1' 'quote_level': '0' 'token_list': {'quote_level': '0' 'topic_list': {'entity_list': {'form': 'Forbes' 'semld_list': 'sumo:LastName' 'sementity': {'type': 'Top>Person>LastName' 'fiction': 'nonfiction' 'id': 'ODENTITY_LAST_NAME' 'class': 'instance'} 'id': '4a3369b337'} {'form': 'Forbes' 'semld_list': 'sumo:River' 'sementity': {'type': 'Top>Location>GeographicalEntity>WaterForm>River' 'fiction': 'nonfiction' 'id': 'ODENTITY_RIVER' 'class': 'instance'} 'id': '9752b8b5ee'} {'sementity': {'type': 'Top>Product>CulturalProduct>Printing>Magazine' 'fiction': 'nonfiction' 'id': 'ODENTITY_MAGAZINE' 'class': 'instance'} 'id': 'db0f9829ff' 'semgeo_list': {'country': {'form': 'United States' 'standard_list': {'value': 'US' 'id': 'ISO3166-1-a2'} {'value': 'USA' 'id': 'ISO3166-1-a3'} 'id': 'beac1b545b'} 'continent': {'form': 'AmÄx82Åxa0rica' 'id': '33fc13e6dd'}} 'semld_list': 'sumo:Magazine' 'semtheme_list': {'type': 'Top>SocialSciences>Economy' 'id': 'ODTHEME_ECONOMY'} 'form': 'Forbes'}} 'analysis_list': {'tag': 'NP-S-N-' 'sense_id_list': {'sense_id': 'db0f9829ff'} 'lemma': 'Forbes' 'original_form': 'Forbes'} {'tag': 'NP-S-N-' 'sense_id_list': {'sense_id': '9752b8b5ee'} 'lemma': 'Forbes' 'original_form': 'Forbes'} {'tag': 'NPUS-N-' 'sense_id_list': {'sense_id': '4a3369b337'} 'lemma': 'Forbes' 'original_form': 'Forbes'} 'id': '6' 'sense_list': {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_LAST_NAME@type=Top>Person>LastNametsemld_list=sumo:LastName' 'form': 'Forbes' 'id': '4a3369b337'} {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_RIVER@type=Top>Location>GeographicalEntity>WaterForm>Rivertsemld_list=sumo:River' 'form': 'Forbes' 'id': '9752b8b5ee'} {'info': 'sementity/class=instance@fiction=nonfiction@id=ODENTITY_MAGAZINE@type=Top>Product>CulturalProduct>Printing>Magazinetsemgeo_list/continent=AmÄx82Åxa0rica#id:33fc13e6dd@country=United States#id:beac1b545b#ISO3166-1-a2:US#ISO3166-1-a3:USAtsemld_list=sumo:Magazinetsemtheme_list/id=ODTHEME_ECONOMY@type=Top>SocialSciences>Economy' 'form': 'Forbes' 'id': 'db0f9829ff'} 'inip': '28' 'form': 'Forbes' 'affected_by_negation': 'no' 'endp': '33' 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': 'NC-S-N5' 'sense_id_list': {'sense_id': 'a0a1a5401f'} 'lemma': 'magazine' 'original_form': 'magazine'} 'id': '7' 'sense_list': {'info': 'sementity/class=class@fiction=nonfiction@id=ODENTITY_MAGAZINE@type=Top>Product>CulturalProduct>Printing>Magazinetsemld_list=sumo:Magazine' 'form': 'magazine' 'id': 'a0a1a5401f'} 'inip': '35' 'form': 'magazine' 'affected_by_negation': 'no' 'endp': '42' 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} 'head': '7' 'inip': '28' 'affected_by_negation': 'no' 'endp': '42'} {'quote_level': '0' 'analysis_list': {'tag': 'WN-' 'lemma': ""'s"" 'original_form': ""'s""} 'id': '14' 'inip': '43' 'form': ""'s"" 'affected_by_negation': 'no' 'endp': '44' 'separation': 'A' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'id': '23' 'analysis_list': {'tag': 'GN-S3---' 'lemma': 'list' 'original_form': 'annual list'} 'form': 'annual list' 'type': 'phrase' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'} 'separation': '1' 'quote_level': '0' 'token_list': {'quote_level': '0' 'analysis_list': {'tag': 'AP-N5' 'lemma': 'annual' 'original_form': 'annual'} 'id': '10' 'inip': '46' 'form': 'annual' 'affected_by_negation': 'no' 'endp': '51' 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': 'NC-S-N5' 'lemma': 'list' 'original_form': 'list'} 'id': '11' 'inip': '53' 'form': 'list' 'affected_by_negation': 'no' 'endp': '56' 'separation': '1' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} 'head': '11' 'inip': '46' 'affected_by_negation': 'no' 'endp': '56'} 'head': '23' 'inip': '28' 'affected_by_negation': 'no' 'endp': '56'} 'id': '25' 'type': 'phrase' 'inip': '0' 'form': ""Robert Downey Jr has topped Forbes magazine's annual list"" 'affected_by_negation': 'no' 'endp': '56' 'separation': '_' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}} {'quote_level': '0' 'analysis_list': {'tag': '1D--' 'lemma': '.' 'original_form': '.'} 'id': '12' 'inip': '57' 'form': '.' 'affected_by_negation': 'no' 'endp': '57' 'separation': 'A' 'style': {'isBold': 'no' 'isTitle': 'no' 'isItalics': 'no' 'isUnderlined': 'no'}})nnnAdditionally I tried:nnmyvalues = i'analysis_list' for i in data if 'analysis_list' in inprint(myvalues)nnnHowever I am getting confused with so much keys and values which is the recommended way to generate tuples from this dictionary?. I was thinking on using pandas or another alternative approach...n' 'You could use this code:nndef gettuples(data level = 0):n    if isinstance(data dict):n        if 'analysis_list' in data:n            yield data'analysis_list'0n        for val in data.values():n            yield from gettuples(val)n    elif isinstance(data list):n        for val in data:n            yield from gettuples(val)nnresult = obj'lemma' obj'original_form' obj'tag' for obj in gettuples(data)nprint(result)nnnSee it run on repl.itn'","['pandas', 'dictionary']",['list']
40111647,"'Extract values from pandas stream' ""I have very weird data coming via curl into my pandas dataframe. What I would like to do is extract values out of the column as described below. Can someone guide me how to extract the info?nncc = pd.read_csv(cc_curl)nprint(cc'srv_id')nnsrv_idn------nTicketID 14593_ServiceID 104731nServiceID nTicketID 14595_ServiceID 104732nTicketID 14609_ServiceID 0nTicketID 0_ServiceID 178282nnnnExtract 5 digit ticket id and 6 digit service id.nExtract nothing since there is no ticketID and service ID is blank.nExtract 5 digit ticket id and 6 digit service id.nExtract 5 digit ticket id only and service id should be blank since it is 0.nExtract 6 digit service id only and leave ticket ID blank since it is 0.nnnDesired outputnnsrv_idn------n14593 104731nn14595 104732n14609n 178282nn"" ""If you want to extract this information into two new columns you can do it this way:nnimport numpy as npnimport pandas as pdnnIn 22: df'TicketID''ServiceID' = (n    ...:   df.srv_id.str.extract(r'TicketIDs+(d+).*?ServiceIDs+(d+)' expand=True)n    ...:     .replace(r'b0b' np.nan regex=True)n    ...: )n    ...:nnIn 23: dfnOut23:n                            srv_id TicketID ServiceIDn0  TicketID 14593_ServiceID 104731    14593    104731n1                       ServiceID       NaN       NaNn2  TicketID 14595_ServiceID 104732    14595    104732n3       TicketID 14609_ServiceID 0    14609       NaNn4      TicketID 0_ServiceID 178282      NaN    178282nnnIf you want to replace your string with extracted numbers:nnIn 161: df'new_srv_id' = n              df.srv_id.replace(r'^d{5}+' r's*b0bs*' ' ' '' regex=True)nnIn 162: dfnOut162:n                            srv_id     new_srv_idn0  TicketID 14593_ServiceID 104731   14593 104731n1                       ServiceIDn2  TicketID 14595_ServiceID 104732   14595 104732n3       TicketID 14609_ServiceID 0          14609n4      TicketID 0_ServiceID 178282         178282nn""","['python-3.x', 'pandas']",['pandas']
40111698,"'Slider not changing a value when clicked?' 'I'm creating a simple drawpad in python using tkinter and python 3. nnI have a slider at the bottom of it that lets me change the size of the dot that is created however when I change the slider it does not execute the expected sub-routine. nnHow can I correct this?nnDotSize=0nScale = Scale(Buttons from_=1 to=100 orient=HORIZONTAL length=250 command=Size highlightcolor=""Red"")nScale.grid(row=1 column=7)nndef Size():n    global DotSizen    DotSize=Scale.get()nnnDotsize changes this:nndef draw(event):n    global DotSizen    Canvas.create_oval(event.x event.yevent.xevent.y fill=""black"" width=DotSize)nnnAt the moment I am having to use a button to execute Size() but that's just ugly and counter intuitive.n' nan","['python-3.x', 'tkinter']","['tkinter', 'python-3.x']"
40111730,"'How to use a dict to subset a DataFrame?' ""Say I have given a DataFrame with most of the columns being categorical data.nn> data.head()n  age risk     sex smokingn0  28   no    male      non1  58   no  female      non2  27   no    male     yesn3  26   no    male      non4  29  yes  female     yesnnnAnd I would like to subset this data by a dict of key-value pairs for those categorical variables.nntmp = {'risk':'no' 'smoking':'yes' 'sex':'female'}nnnHence I would like to have the following subset.nndata (data.risk == 'no') & (data.smoking == 'yes') & (data.sex == 'female')nnnWhat I want to do is:nndatatmpnnnWhat is the most python / pandas way of doing this?nnnnMinimal example:nnimport numpy as npnimport pandas as pdnfrom pandas import Series DataFramennx = Series(random.randint(0250) dtype='category')nx.cat.categories = 'no' 'yes'nny = Series(random.randint(0250) dtype='category')ny.cat.categories = 'no' 'yes'nnz = Series(random.randint(0250) dtype='category')nz.cat.categories = 'male' 'female'nna = Series(random.randint(206050) dtype='category')nndata = DataFrame({'risk':x 'smoking':y 'sex':z 'age':a})nntmp = {'risk':'no' 'smoking':'yes' 'sex':'female'}nn"" ""You could build a boolean vector that checks those attributes.  Probably a better way though: nndfrisk == 'no' and smoking == 'yes' and sex == 'female' for (age risk sex smoking) in df.itertuples()nn"" 'You can create a look up data frame from the dictionary and then do an inner join with the data which will have the same effect as query:nnfrom pandas import merge DataFramenmerge(DataFrame(tmp index =0) data)nnnn' 'I would use .query() method for this task:nnIn 103: qry = ' and '.join(""{} == '{}'"".format(kv) for kv in tmp.items())nnIn 104: qrynOut104: ""sex == 'female' and risk == 'no' and smoking == 'yes'""nnIn 105: data.query(qry)nOut105:n   age risk     sex smokingn7   24   no  female     yesn22  43   no  female     yesn23  42   no  female     yesn25  24   no  female     yesn32  29   no  female     yesn40  34   no  female     yesn43  35   no  female     yesnn' 'You can use list comprehension with concat and all:nnimport numpy as npnimport pandas as pdnnnp.random.seed(123)nx = pd.Series(np.random.randint(0210) dtype='category')nx.cat.categories = 'no' 'yes'ny = pd.Series(np.random.randint(0210) dtype='category')ny.cat.categories = 'no' 'yes'nz = pd.Series(np.random.randint(0210) dtype='category')nz.cat.categories = 'male' 'female'nna = pd.Series(np.random.randint(206010) dtype='category')nndata = pd.DataFrame({'risk':x 'smoking':y 'sex':z 'age':a})nprint (data)n  age risk     sex smokingn0  24   no    male     yesn1  23  yes    male     yesn2  22   no  female      non3  40   no  female     yesn4  59   no  female      non5  22   no    male     yesn6  40   no  female      non7  27  yes    male     yesn8  55  yes    male     yesn9  48   no    male      nonnnnntmp = {'risk':'no' 'smoking':'yes' 'sex':'female'}nmask = pd.concat(datax0.eq(x1) for x in tmp.items() axis=1).all(axis=1)nprint (mask)n0    Falsen1    Falsen2    Falsen3     Truen4    Falsen5    Falsen6    Falsen7    Falsen8    Falsen9    Falsendtype: boolnndf1 = datamasknprint (df1)n age risk     sex smokingn3  40   no  female     yesnnnnnL = (x0 x1) for x in tmp.items()nprint (L)n('smoking' 'yes') ('sex' 'female') ('risk' 'no')nnL = pd.concat(datax0.eq(x1) for x in tmp.items() axis=1)nprint (L)n  smoking    sex   riskn0    True  False   Truen1    True  False  Falsen2   False   True   Truen3    True   True   Truen4   False   True   Truen5    True  False   Truen6   False   True   Truen7    True  False  Falsen8    True  False  Falsen9   False  False   TruennnTimings: nnlen(data)=1M.  nnN = 1000000nnp.random.seed(123)nx = pd.Series(np.random.randint(02N) dtype='category')nx.cat.categories = 'no' 'yes'ny = pd.Series(np.random.randint(02N) dtype='category')ny.cat.categories = 'no' 'yes'nz = pd.Series(np.random.randint(02N) dtype='category')nz.cat.categories = 'male' 'female'nna = pd.Series(np.random.randint(2060N) dtype='category')nndata = pd.DataFrame({'risk':x 'smoking':y 'sex':z 'age':a})nn#1000000 rows x 4 columnsnprint (data)nnntmp = {'risk':'no' 'smoking':'yes' 'sex':'female'}nnnIn 133: %timeit (datapd.concat(datax0.eq(x1) for x in tmp.items() axis=1).all(axis=1))n10 loops best of 3: 89.1 ms per loopnnIn 134: %timeit (data.query(' and '.join(""{} == '{}'"".format(kv) for kv in tmp.items())))n1 loop best of 3: 237 ms per loopnnIn 135: %timeit (pd.merge(pd.DataFrame(tmp index =0) data.reset_index()).set_index('index'))n1 loop best of 3: 256 ms per loopnn' 'I think you can could use the to_dict method on your dataframe and then filter using a list comprehension:nndf = pd.DataFrame(data={'age':28 29 'sex':""M"" ""F"" 'smoking':'y' 'n'})nprint dfntmp = {'age': 28 'smoking': 'y' 'sex': 'M'}nnprint pd.DataFrame(i for i in df.to_dict('records') if i == tmp)nnn>>>    age sex smokingn0   28   M       yn1   29   F       nnn   age sex smokingn0   28   M       ynnnYou could also convert tmp to a series:nnts = pd.Series(tmp)nnprint pd.DataFrame(i1 for i in df.iterrows() if i1.equals(ts))nn'",['pandas'],['pandas']
40111822,'matplotlib image shows in black and white but I wanted gray' 'I have a small code sample to plot images in matplotlib and the image is shown as this :nnnnNotice the image in the black box has black background while my desired output is this :nnnnMy code to plot the image is this :nnplt.subplot(111)nplt.imshow(np.abs(img) cmap = 'gray')nplt.title('Level 0') plt.xticks() plt.yticks()nplt.show()nnnMy understanding is that cmap=grey should display it in grayscale. Below is a snippet of the matrix img being plotted :nn 192.77504036 +1.21392817e-11j  151.92357434 +1.21278246e-11jn   140.67585733 +6.71014111e-12j  167.76903747 +2.92050743e-12jn   147.59664180 +2.33718944e-12j   98.27986577 +3.56896094e-12jn    96.16252035 +5.31530804e-12j  112.39194666 +5.86689097e-12j....nnnWhat am I missing here ?n' 'The problem seems to be that you have three channels while there should be only one and that the data should be normalized between 0 1. I get a proper looking gray scaled image using this:nnimport matplotlib.pyplot as pltnimport matplotlib.image as mpimgnimport numpy as npnnimg = mpimg.imread('Lenna.png')n# The formula below can be changed -- the point is that you go from 3 values to 1nimgplot = plt.imshow(np.dot(img...:3 0.33 0.33 0.33) cmap='gray')nplt.show()nnnThis gives me:nnnnAlso a snapshot of the data:nn 0.63152942  0.63152942  0.63800002 ...  0.64705883  0.59658825 0.50341177n  0.63152942  0.63152942  0.63800002 ...  0.64705883  0.59658825 0.50341177n  0.63152942  0.63152942  0.63800002 ...  0.64705883  0.59658825 0.50341177n ...nn',['matplotlib'],['matplotlib']
40111872,"'Construct pandas dataframe from a .fits file' ""I have a .fits file that contains data. nnI would like to construct a pandas dataframe from this particular file but I don't know how to do it. nndata = fits.open('datafile')ndata.infonnngives: nnNo.    Name         Type      Cards   Dimensions   Formatn0    PRIMARY     PrimaryHDU       6   (12 250000)   float64 nnnand: nndata0.data.shapennngives:nn(250000 12)nn"" 'According to what you have in your question and the astropy docs (http://docs.astropy.org/en/stable/io/fits/) it looks like you just need to do: nnfrom astropy.io import fitsnimport pandasnwith fits.open('datafile') as data:n    df = pandas.DataFrame(data0.data)nnnEdit:nI don't have much experience we astropy but other have mentioned that you can read the fits files into a Table object which has a to_pandas() method:nnfrom astropy.table import Tablendat = Table.read('datafile' format='fits')ndf = dat.to_pandas()nnnMight be worth investigating.nnhttp://docs.astropy.org/en/latest/table/pandas.htmln'",['pandas'],['pandas']
40112003,"""Why won't values between 100 and 1000 work when playing Four is Magic excluding values by 100"" 'Everything works besides values between 100 and 999 except values divisible by 100 work.nnThe game is as follows:nnFour is magic. Write a Python program (called q3.py) that given an integer from 0 to 1000 does the âx80x9c4 is magicâx80x9d transformation. The steps are as follows:nnnConvert the integer n into English and count the number of letters (i.e. 21 is âx80x9ctwenty oneâx80x9d and consists of 9 letters 102 is âx80x9cone hundred twoâx80x9d and consists of 13 letters 1000 is âx80x9cone thousandâx80x9d and consists of 11 letters).nLet nlen be the length of the English word equivalent for the integer n.nna. If nlen is 4 output âx80x9cfour is magic.âx80x9d Then terminate the transformation process.nnb. Otherwise output âx80x9c is nlen.âx80x9d Repeatnstep (a) where the integer n is set to nlen.nnnSuppose the user inputs the integer 26. Then the transformation proceeds as follows.nnn26 is 9.  where twenty six is the 9-letter English word equivalent of 26.n9 is 4.  where nine is the 4-letter English word equivalent of 9.n4 is magic.nnn nndef convert(number_str):nn    # Enter your code here.n    count = 0n    index = 0n    x = 'zero''one''two''three''four''five''six''seven''eight''nine''ten''eleven''twelve''thirteen''fourteen''fifteen''sixteen''seventeen''eighteen''nineteen'n    y = 'zero''ten''twenty''thirty''forty''fifty''sixty''seventy''eighty''ninety'nn    while (number_str != '4'):n        if 0 <= int(number_str) <= 19:n            a = len(xint(number_str))n            print(xint(number_str)'is'a)n            number_str = str(a)n        elif 20 <= int(number_str) <= 99:n            if number_str1 == ""0"":n                a = len(yint(number_str0))n                print(yint(number_str0)'is'a)n                number_str = str(a)n            else:n                a = len(yint(number_str0)) + len(xint(number_str1))n                print(yint(number_str0) + ' ' + xint(number_str1)'is'a)n                number_str = an        elif 100 <= int(number_str) <= 999:n            rem = int(number_str) % 100n            div = int(number_str) // 100n            if rem == 0:n                a = len(xdiv) + 7n                print(xdiv + ' hundred is'a)n                number_str = str(a)n            else:n                if (number_str1 == '0'):n                    a = len(xdiv) + 7 + len(convert(str(rem)))n                    print(xdiv + ' hundred ' + convert(str(rem)) + ' is '+ str(a))n                    number_str = str(a)n                elif (number_str1 != '0'):n                    a = len(xdiv) + 6 + len(convert(str(rem)))n                    print(xdiv + ' hundred ' + convert(str(rem)) + ' is '+ str(a))n                    number_str = str(a)n        elif number_str == '1000':n            a = 11n            print('one thousand is '+ str(a))n            number_str = str(a)n    return 'four is magic'nndef main():n    ''' The program driver. '''nn    user_input = input('> ')n    while  user_input != 'quit':n        print(convert(user_input))n        user_input = input('> ')nnnmain()nnnMy question is what is wrong with this area:nnelse:n            if (number_str1 == '0'):n                a = len(xdiv) + 7 + len(convert(str(rem)))n                print(xdiv + ' hundred ' + convert(str(rem)) + ' is '+ str(a))n                number_str = str(a)n            elif (number_str1 != '0'):n                a = len(xdiv) + 6 + len(convert(str(rem)))n                print(xdiv + ' hundred ' + convert(str(rem)) + ' is '+ str(a))n                number_str = str(a)nn' 'convert always returns ""four is magic""  It looks like you want it to return some value based on its input.  n' 'def convert(number_str):nn    # Enter your code here.n    count = 0n    index = 0n    x = 'zero''one''two''three''four''five''six''seven''eight''nine''ten''eleven''twelve''thirteen''fourteen''fifteen''sixteen''seventeen''eighteen''nineteen'n    y = 'zero''ten''twenty''thirty''forty''fifty''sixty''seventy''eighty''ninety'nn    while (number_str != '4'):n        if 0 <= int(number_str) <= 19:n            a = len(xint(number_str))n            print(xint(number_str)'is'a)n            number_str = str(a)n        elif 20 <= int(number_str) <= 99:n            if number_str1 == ""0"":n                a = len(yint(number_str0))n                print(yint(number_str0)'is'a)n                number_str = str(a)n            else:n                a = len(yint(number_str0)) + len(xint(number_str1))n                print(yint(number_str0) + ' ' + xint(number_str1)'is'a)n                number_str = an        elif 100 <= int(number_str) <= 999:n            rem = int(number_str) % 100n            div = int(number_str) // 100 n            print(div)n            if rem == 0:n                a = len(xdiv) + 7n                print(xdiv + ' hundred is'a)n                number_str = str(a)n            else:n                if (number_str1 == '0'):n                    a = len(xdiv) + 7 + len(str(xrem))n                    print(xdiv + ' hundred ' + str(xrem) + ' is '+ str(a)) # error was heren                    number_str = str(a)n                elif (number_str1 != '0'):n                    a = len(xdiv) + 6 + len(str(xrem))n                    print(xdiv + ' hundred ' + str(xrem) + ' is '+ str(a)) # error was heren                    number_str = str(a)n        elif number_str == '1000':n            a = 11n            print('one thousand is '+ str(a))n            number_str = str(a)n    return 'four is magic'nnndef main():n    ''' The program driver. '''nn    user_input = input('> ')n    while  user_input != 'quit':n        print(convert(user_input))n        user_input = input('> ')nnnmain()nnnWhere I commented #error you were doing recursion which was not what you wanted ( I think). But fixed it and it should work now. When you call recursive functions (calling the same function) it execute the newest call on the stack returning the value it came back with which isn't how your program worked. nnAlso I noticed you weren't calling xrem like you were suppose to for a look up on the spelling fixed that too. nnNext time please include desired output instead of making us fish for information. n'",['python-3.x'],"['python-3.x', 'python-2.7']"
40112034,"'MailChimp bad request JSONParseError with Python' 'I am trying to hook up to MailChimp's api in my Django application to add an email to one of my lists. Seems pretty simple enough. I add my api key to the header of the request with the email address and other variable in the body of the request. every time I try and connect though I get a response status code of 400. The message says there is a JSON parsing error and that my JSON is either formatted incorrectly or there is missing data required for the request. I am making this same api call however with Postman and am getting a good response back. nnview functionnnimport requestsnndef join_newsletter(request email):n    # hash the user's email for mailchimp's APIn    # m = hashlib.md5()n    # c_email = emailn    # m.update(c_email.encode('utf-8'))n    # email_hash = m.hexdigest()nn    api_key = 'apikey ' + settings.MAILCHIMP_APIn    api_endpoint = api_endpointnn    data = {n        ""email_address"": emailn        ""status"": ""subscribed""n    }nn    header = {n        'Authorization': api_keyn    }nn    r = requests.post(api_endpoint data=data headers=header)nn    message = r.contentnn    return messagenn' nan",['django'],['django']
40112133,"'calcuale ----OverflowError: long int too large to convert to float' 'en_1 = 1nn = 1nfactorial = 1ninvfactorial = 1n    while en_1 > 1e-6 :n        en = en_1 +invfactorialn        n = n + 1n        factorial = factorial * nn        invfactorial = float(1.0/factorial)n        en_1 = en nprint ""e = %.5f""%ennnnI want to calculate e via this code but it cannot work. n' ""en_1 > 1e-6 will never evaluate to True.  en_1 just gets bigger and bigger.  At some point you end up with numbers so large that Python can't handle the conversions.  Instead compare to invfactorial > 1e-6:nnen_1 = 1nn = 1nfactorial = 1ninvfactorial = 1nwhile invfactorial > 1e-6:  # changed comparisonn    en = en_1 +invfactorialn    n = n + 1n    factorial = factorial * nn    invfactorial = float(1.0/factorial)n    en_1 = en # don't need both en_1 and ennnnThis could be made much simpler:nne = n = fac = 1nwhile 1.0/fac > 1e-6:n    fac *= nn    e += 1.0/facn    n += 1nn""",['python-2.7'],['python-2.7']
40112139,"'Efficiently handling duplicates in a Python list' ""I'm looking to compactly represent duplicates in a Python list / 1D numpy array. For instance say we have nn x = np.array(1 0 0 3 3 0)nnnthis array has several duplicate elements that can be represented with a nn group_id = np.array(0 1 1 2 2 1)nnnso that all duplicates in a given cluster are found with xgroup_id==<some_id>.nnThe list of duplicate pairs can be efficiently computed with sorting nns_idx = np.argsort(x)ndiff_idx = np.nonzero(xs_idx:-1 == xs_idx1:)0nnnwhere the pair s_idxdiff_idx <-> s_idxdiff_idx+1 correspond to the indices in the original array that are duplicates. n(here array(1 2 3) <-> array(2 5 4)).nnHowever I'm not sure how to efficiently calculate cluster_id from this linkage information for large arrays sizes (N > 10âx81¶).nnEdit: as suggested by @Chris_Rands this can indeed be done with itertools.groupbynn import numpy as npn import itertoolsnn def get_group_id(x):n     group_id = np.zeros(x.shape dtype='int')n     for i j in  itertools.groupby(x):n         j_el = next(j)n         group_idx==j_el = in     return group_idnnnhowever the scaling appears to be O(n^2) and this would not scale to my use case (N > 10âx81¶)nn  for N in 50000 100000 200000:n      %time _ = get_group_id(np.random.randint(0 N size=N))nn  CPU times: total: 1.53 sn  CPU times: total: 5.83 sn  CPU times: total: 23.9 snnnand I belive using the duplicate linkage information would be more efficient as computing duplicate pairs for N=200000 takes just 6.44 Âµs in comparison.n"" 'You could use numpy.unique:nnIn 13: x = np.array(1 0 0 3 3 0)nnIn 14: values cluster_id = np.unique(x return_inverse=True)nnIn 15: valuesnOut15: array(0 1 3)nnIn 16: cluster_idnOut16: array(1 0 0 2 2 0)nnn(The cluster IDs are assigned in the order of the sorted unique values not in the order of a value's first appearance in the input.)nnLocations of the items in cluster 0:nnIn 22: cid = 0nnIn 23: valuescidnOut23: 0nnIn 24: (cluster_id == cid).nonzero()0nOut24: array(1 2 5)nn' 'Here's an approach using np.unique to keep the order according to the first appearance of a number -nnunq first_idx ID = np.unique(xreturn_index=1return_inverse=1)nout = first_idx.argsort().argsort()IDnnnSample run -nnIn 173: xnOut173: array(1 0 0 3 3 0 9 0 2 6 0 0 4 8)nnIn 174: unq first_idx ID = np.unique(xreturn_index=1return_inverse=1)nnIn 175: first_idx.argsort().argsort()IDnOut175: array(0 1 1 2 2 1 3 1 4 5 1 1 6 7)nn'",['numpy'],['numpy']
40112202,"'EOF Error with ftplib only when connecting to GoDaddy hosted server' 'I'm having problems with FTP_TLS (ftplib) in Python 2.7.3.nnSummary of findings (all connection attempts performed over the internet):nnnFileZilla to home web server - worksnFileZilla to GoDaddy shared hosting server - worksnPython to home web server - worksnPython to GoDaddy shared hosting server - fails (see stack trace below)nnnThe following code shows how I reproduce the problem. When connecting to my home server this code generates an identical log on my personal FTP as FileZilla. (Only when connecting to the GoDaddy site does it result in an EOF exception).nnfrom ftplib import FTP_TLSno = FTP_TLS(ftpServerftpUsernameftpPasswordftpPort)no.voidcmd('SYST')no.voidcmd('FEAT')no.prot_p()no.voidcmd('PWD')no.retrbinary('MLSD' open('OUTTEST' 'wb').write)n>>> o.retrbinary('MLSD' open('OUTTEST' 'wb').write)nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""/usr/lib/python2.7/ftplib.py"" line 703 in retrbinaryn    return self.voidresp()n  File ""/usr/lib/python2.7/ftplib.py"" line 225 in voidrespn    resp = self.getresp()n  File ""/usr/lib/python2.7/ftplib.py"" line 211 in getrespn    resp = self.getmultiline()n  File ""/usr/lib/python2.7/ftplib.py"" line 197 in getmultilinen    line = self.getline()n  File ""/usr/lib/python2.7/ftplib.py"" line 187 in getlinen    if not line: raise EOFErrornnnI read that the EOF error is given when the server closes the pipe. It's also similar to what happens if you change to prot_p and then try to issue a plain text command (although as far as I can tell this isn't the case here).nnI don't understand what's different between my code and FileZilla. The fact that all attempts are performed over the internet reassures me that it isn't related to firewalls. Furthermore FileZilla works so from a technical perspective the connection is possible I'm just having a hard time achieving it with Python.nnMy code works with the GoDaddy FTP if I don't issue the prot_p switch.nnAdditional information:nnnGoDaddy doesn't provide technical FTP logs (only usage logs)nMy code has been working flawlessly for over a year this just started happening two months ago.nThe GoDaddy FTP server identifies as ""Pure-FTPd privsep TLS""nnnTypical FileZilla Server Log after running my code.nn(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> Connected on port 21 sending welcome message...n(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> 220-FileZilla Server 0.9.57 betan(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> 220-written by Tim Kosse (Tim.Kosse@gmx.de)n(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> 220 Please visit https://filezilla-project.org/n(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> AUTH TLSn(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> 234 Using authentication type TLSn(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> SSL connection establishedn(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> USER ********************n(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> 331 Password required for USER_NAMEn(000132)18/10/2016 15:44:19 - (not logged in) (IP_ADDRESS)> PASS ********************n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 230 Logged onn(000131)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> disconnected.n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> SYSTn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 215 UNIX emulated by FileZillan(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> FEATn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 211-Features:n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  MDTMn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  REST STREAMn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  SIZEn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  MODE Zn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  MLST type*;size*;modify*;n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  MLSDn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  AUTH SSLn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  AUTH TLSn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  PROTn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  PBSZn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  UTF8n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  CLNTn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  MFMTn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  EPSVn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)>  EPRTn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 211 Endn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> PBSZ 0n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 200 PBSZ=0n(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> PROT Pn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 200 Protection level set to Pn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> PWDn(000132)18/10/2016 15:44:19 - USER_NAME (IP_ADDRESS)> 257 ""/"" is current directory.n(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> TYPE In(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> 200 Type set to In(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> PASVn(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> 227 Entering Passive Mode (xxxxxxxxxxxxxxxxxx)n(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> MLSDn(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> 150 Opening data channel for directory listing of ""/""n(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> SSL connection for data connection establishedn(000132)18/10/2016 15:44:22 - USER_NAME (IP_ADDRESS)> 226 Successfully transferred ""/""nn' 'I think you need to set the FTP mode to passive here's a similar error but in PerlnnThe difference is explained in what-is-the-difference-between-active-and-passive-ftpn'",['python-2.7'],['python-2.7']
40112284,"'Accelerate or decelerate a movie clip' 'I am trying to accelerate and/or decelerate a movie clip with the help of Python's moviepy module but I can't seem to work it out properly. The script runs quite smoothly and without any errors but I do not see any effects. Might be my script is wrong and I can't detect the problem. Looking for help/tips from you. I do not need a complete solution any hints will be of great help. I have been working on this solution for sometime and I think I should post my problem here. Any help tips guidance will be greatly appreciated. Thank you.  nnfrom moviepy.editor import *nfrom moviepy.video.tools.drawing import color_splitnimport osnndir = os.path.split(os.path.realpath(__file__))0nimg = os.path.join('tmp' 'stock.jpg')nfolder = 'tmp'nnndef f_accel_decel(t old_d new_d abruptness=1 soonness=1.0):n    """"""n    abruptnessn      negative abruptness (>-1): speed up down upn      zero abruptness : no effectn      positive abruptness: speed down up downnn    soonnessn      for positive abruptness determines how soon then      speedup occurs (0<soonness < inf)n    """"""nn    a = 1.0+abruptnessn    def _f(t):n        f1 = lambda t: (0.5)**(1-a)*(t**a)n        f2 = lambda t: (1-f1(1-t))n        return (t<.5)*f1(t) + (t>=.5)*f2(t) nn    return old_d*_f((t/new_d)**soonness)nndef accel_decel(clip new_duration=None abruptness=1.0 soonness=1.0):n    """"""n    new_durationn      If None will be that of the current clip.n    abruptnessn      negative abruptness (>-1): speed up down upn      zero abruptness : no effectn      positive abruptness: speed down up downnn    soonnessn      for positive abruptness determines how soon then      speedup occurs (0<soonness < inf)n    """"""nn    if new_duration is None:n        new_duration = clip.durationnn    fl = lambda t : f_accel_decel(t clip.duration new_durationn                                   abruptness soonness)nn    return clip.fl_time(fl).set_duration(new_duration)nnnnduration = 30nnmain_clip = ImageClip(img duration=30)nWH = main_clip.sizenprint WHnnnnclip1 = (main_clipn             .subclip(0duration)n             .set_pos(lambda t:(max((0) (int(W-0.5*W*t))) ""center""))n             )nnnmodifiedClip1 = accel_decel(clip1 abruptness=5 soonness=1.3)nnncc = CompositeVideoClip(modifiedClip1 size=(19201080) bg_color=(2325418)).resize(0.5)ncc.preview(fps=24)n#cc.write_videofile(""mask.avi"" fps=25 codec=""libx264"" bitrate=""1000K"" threads=3)nn' 'I think the best way of accelerating and decelerating clip objects is using easing functions.nnSome reference sites:nnnhttp://easings.netnhttp://www.gizma.com/easing/nhttp://gsgd.co.uk/sandbox/jquery/easing/nnnHere's part of a script I made when trying to understand these functions.nMaybe you can use some of this concepts to solve your issue.nnfrom __future__ import divisionnfrom moviepy.editor import TextClip CompositeVideoClipnimport mathnnndef efunc(x0 x1 dur func='linear' **kwargs):n    # Return an easing function.n    # It will control a single dimention of the clip movement.n    # http://www.gizma.com/easing/nn    def linear(t):n        return c*t/d + bnn    def out_quad(t):n        t = t/dn        return -c * t*(t-2) + bnn    def in_out_sine(t):n        return -c/2 * (math.cos(math.pi*t/d) - 1) + bnn    def in_quint(t):n        t = t/dn        return c*t*t*t*t*t + bnn    def in_out_circ(t):n        t /= d/2;n        if t < 1:n            return -c/2 * (math.sqrt(1 - t*t) - 1) + bn        t -= 2;n        return c/2 * (math.sqrt(1 - t*t) + 1) + b;nn    def out_bounce(t):n        # http://gsgd.co.uk/sandbox/jquery/easing/jquery.easing.1.3.jsn        t = t/dn        if t < 1/2.75:n            return c*(7.5625*t*t) + bn        elif t < 2/2.75:n            t -= 1.5/2.75n            return c*(7.5625*t*t + .75) + bn        elif t < 2.5/2.75:n            t -= 2.25/2.75n            return c*(7.5625*t*t + .9375) + bn        else:n            t -= 2.625/2.75n            return c*(7.5625*t*t + .984375) + bnn    # Kept the (t b c d) notation found everywhere.n    b = x0n    c = x1 - x0n    d = durn    return locals()funcnnndef particle(x0 x1 y0 y1 d func='linear' color='black' **kwargs):n    # Dummy clip for testing.nn    def pos(t):n        return efunc(x0 x1 d func=func)(t) efunc(y0 y1 d func=func)(t)nn    return (n        TextClip('*' fontsize=80 color=color)n        .set_position(pos)n        .set_duration(d)n        )nn# Make a gif to visualize the behaviour of the functions:nneasing_functions = n    ('linear' 'red')n    ('in_out_sine' 'green')n    ('in_out_circ' 'violet')n    ('out_quad' 'blue')n    ('out_bounce' 'brown')n    ('in_quint' 'black')n    nnd = 4nx0 x1 = 0 370nclips = nfor i (func c) in enumerate(easing_functions):n    y = 40*in    clips.append(particle(x0 x1 y y d=d func=func color=c))n    clips.append(particle(x1 x0 y y d=d func=func color=c).set_start(d))nnclip = CompositeVideoClip(clips size=(400250) bg_color=(255255255))nclip.write_gif('easing.gif' fps=12)nnnnnThe output of the script:nnn'",['numpy'],['python-2.7']
40112448,"""Django KeyError kwargs.pop('pk')"" 'I'm using CBV in Django 1.9 and in CreateView when I try to pass an additional parameter ('pk') to my form using self.kwargs.pop('pk') i got ""Key Error"" but if I get the parameter by index it works here is my code:nndef get_form(self form_class=None **kwargs):n    self.project_version_pk = self.kwargs.pop('pk')n    form = super(HRCreateView self).get_form(form_class)n    form.fields'project_version'.queryset = form.fields'project_version'.queryset.filter(pk=self.project_version_pk)n    form.fields'project_version'.initial = self.project_version_pkn    return formnndef get(self request *args **kwargs):n    self.object = Nonen    form_class = self.get_form_class()n    form = self.get_form(form_class pk=self.kwargs'pk')nn    return self.render_to_response(n        self.get_context_data(form=form)nnnAnd I get this error:nnbuiltins.KeyErrornKeyError: 'pk'nnFile ""RelationView.py"" line 65 in get_formnnself.project_version_pk = self.kwargs.pop('pk')nnKeyError: 'pk'nnnBut if i read the key this way it works:nndef get_form(self form_class=None **kwargs):n    self.project_version_pk = self.kwargs'pk'n    form = super(HRCreateView self).get_form(form_class)n    form.fields'project_version'.queryset = form.fields'project_version'.queryset.filter(pk=self.project_version_pk)n    form.fields'project_version'.initial = self.project_version_pkn    return formnnnI don't really understand why the parameter is missing on pop() or which is the best practice for this.n' ""Firstly you shouldn't be overriding get. In a CreateView Django already calls get_form for you - inside get_context_data. This is the cause of the issue you are having; you call get_form and pop the pk so that it is no longer in kwargs; but Django calls it again in get_context_data but this second time it can't find the pk because you removed it the first time.nnSo don't use pop; but as I said don't do this at all. The only thing you actually need to override is get_form.n""",['django'],['django']
40112487,"""AttributeError: 'numpy.ndarray' object has no attribute 'median'"" 'I can perform a number of statistics on a numpy array but ""median"" returns an attribute error.  When I do a ""dir(np)"" I do see the median method listed.nn(newpy2) 7831c1c083a2:src scaldara$ pythonnPython 2.7.12 |Continuum Analytics Inc.| (default Jul  2 2016   17:43:17) nGCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00) on     darwinnType ""help"" ""copyright"" ""credits"" or ""license"" for more information.nAnaconda is brought to you by Continuum Analytics.nPlease check out: http://continuum.io/thanks and https://anaconda.orgnn>>> import numpy as npn>>> print(np.version.version)n1.11.2n>>> a = np.array(12345678910)n>>> print(a)n 1  2  3  4  5  6  7  8  9 10n>>> print(a.min())n1n>>> print(a.max())n10n>>> print(a.mean())n5.5n>>> print(a.std())n2.87228132327n>>> print(a.median())nTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>nAttributeError: 'numpy.ndarray' object has no attribute 'median'n>>> nn' 'Although numpy.ndarray has a mean max std etc. method it does not have a median method. For a list of all methods available for an ndarray see the numpy documentation for ndarray.nnIt is available as a function that takes the array as an argument:nn>>> import numpy as npn>>> a = np.array(12345678910)n>>> np.median(a)n5.5nnnAs you will see in the documentation for ndarray.mean ndarray.mean and np.mean are ""equivalent functions"" so this is just a matter of semantics.n'",['numpy'],['numpy']
40112545,"'Using nested dictionaries to store user defined graph' 'I am trying to get the user to enter a graph manually as opposed to using it 'pre-existing' in the code for use in my Dijkstra's Algorithm. nnI have done this but would like some feedback on its implementation and user friendliness. In addition is there a more efficient way of entering a graph into a nested dictionary ? If so how ?.nnKey points about codennnData must be stored using nested dictionaries nA loop would be a zero e.g b-b is 0 not left blank but this only occurs if a loop is present in user graph otherwise its ignored.nIdeally I would not like to use anything inside existing libraries before coding it myself to get a better understanding of what is happeningnnnMany Thanks. nEdit: repeat requirement no longer needed.nn{'A': {'C': 1 'B': 5} 'D': {} 'B': {'D': 2} 'C': {'D': 9}}nnn^ Desired output for nodes also current output.nnnodes = {}nnndef add_node():n    entered_graph = Falsen    while not entered_graph:n        source_node = input(""Enter a source node: "")n        num_neighbours = int(input(""Enter how many neighbours this node has""n                                   ""including previously entered nodes: ""))n        nodessource_node = {}n        for neighbour in range(num_neighbours):n            neighbour = input(""Enter neighbor node: "")n            distance = int(input(""Enter distance from source node to this neighbor node: ""))n            nodessource_nodeneighbour = distancen        end_loop = input(""Enter y to finish graph entry: "")n        end_loop = end_loop.lower()n        if end_loop == ""y"":n            entered_graph = Truennadd_node()nprint(nodes)nn' 'You really only want users to enter every edge once then you can just store it twice.nnedges = {}nwhile True:n    edge = input('Enter an edge as Node names separated by a space followed by a number (""exit"" to exit): ')n    if edge == 'exit':n        breakn    node1 node2 weight = edge.split()n    weight = float(weight)n    if node1 not in edges:n        edgesnode1 = {}n    if node2 not in edges:n        edgesnode2 = {}n    edgesnode1node2 = weightn    edgesnode2node1 = weightnnnUser enters each edge once as ""A B 3.5""n' 'Khanacademy has a pretty good page on different ways to represent graphs.nnFor an undirected graph (a => b and b => a) I would personally look at using an edge list. It can be sorted to improve lookup efficiency and it is more memory efficient than other methods such as an adjacency tablen' 'You could be more modular in your source as in ""add_node"" should only add a node. I think entering all neighbors with costs immediately in one line would be more user friendly so using the data structure you insist on:nnfrom itertools import tee          #For pairwise iterationnfrom collection import defaultdict #To add arcs to non-existing nodesnndef add_node(graph):n    source = input(""Please enter node ('quit' to stop):"")n    if node == 'quit': return Falsen    for neighbordist in zip(tee(input(""Please enter neighbors neighbor distance neighbor distance ..."").split())):n        graphsourceneighbor = int(dist)n        graphneighborsource = int(dist)n    return Truenndef add_graph(self):n    graph = defaultdict(dict)n    while add_node(graph): passnnprint add_graph()nnnThe defaultdict saves you checking and I think inputting this way is easier rather than neighbor by neighbor. You could even make this source neighbor cost neighbor cost ... - source ... - ... for a one line input.nnBeing modular makes it easier to add code to the 'graph' or to the 'node' if you insist on not making a class out of this.n'",['dictionary'],"['dictionary', 'python-2.7']"
40112571,'ATM program works on server and client by using Python?' 'I need to learn how to write ATM program working on server and client by using Python2.7. The calculations should be done by the server.n' nan,['python-2.7'],['python-2.7']
40112599,"'How python pymysql.cursors get INOUT return result from mysql stored procedure' 'I have mysql proc:nnCREATE DEFINER=`user`@`localhost` PROCEDURE `mysproc`(INOUT  par_a INT(10) IN  par_b VARCHAR(255)  IN  par_c VARCHAR(255) IN  par_etc VARCHAR(255))n    BEGINn        // bla... insert query heren        SET par_a = LAST_INSERT_ID();n    END$$nDELIMITER ;nnnto test that sp if i run:nnSET @par_a = -1;nSET @par_b = 'one';nSET @par_c = 'two';nSET @par_etc = 'three';nnCALL mysproc(@par_a @par_b @par_c @par_etc);nSELECT @par_a;nCOMMIT;nnnit return @par_a as what i want - so i assume my db is fine...nnthen...nni have pyhton as follow:nnimport pymysql.cursorsnndef someFunction(self args):n        # generate Queryn        query = ""SET @par_a = %s; n            CALL mysproc(@par_a %s %s %s); n            SELECT @par_a n            commit;""nn        try:n            with self.connection.cursor() as cursor:n                cursor.execute(query(str(par_a) str(par_b) str(par_c) str(par_etc)))n                self.connection.commit()n                result = cursor.fetchone()n                print(result) # <-- it print me 'none' how do i get my @par_a result from mysproc above?n                return resultn        except:n            raisen        finally:n            self.DestroyConnection()nnnresult: the stored proc executed as i can see record in.nnproblem: but i cant get my @par_a result in my python code from mysproc above?nnand if i change:nn# generate Querynquery = ""SET @par_a = '"" + str(-1) + ""'; n    CALL mysproc(@par_a %s %s %s); n    SELECT @par_a n    commit;""nnntonn# generate Querynquery = ""SELECT 'test' n    commit;""nnnandnncursor.execute(query)nnnstrangely it give me the correct result ('test')n' nan",['python-3.x'],"['python-2.7', 'python-3.x']"
40112638,"'How to register a user with Twitter django-AllAuth' 'My goal is to create users with Django-AllAuth. I would like my users to see a button they click that says sign up with Twitter. That is how they can sign up to use my application. I don't need email verification or anything else. nnsettings.py contains:nnINSTALLED_APPS = n    'django.contrib.admin'n    'django.contrib.auth'n    'django.contrib.contenttypes'n    'django.contrib.sessions'n    'django.contrib.messages'n    'django.contrib.staticfiles'n    'django.contrib.sites'n    'allauth'n    'allauth.account'n    'allauth.socialaccount'n    'allauth.socialaccount.providers.twitter'n    'myApp'    nn# Password validationn# https://docs.djangoproject.com/en/1.10/ref/settings/#auth-password-validatorsnnAUTH_PASSWORD_VALIDATORS = n    {n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator'n    }n    {n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator'n    }n    {n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator'n    }n    {n        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator'n    }nnn# This is where I'm setting up AllAuthnAUTHENTICATION_BACKENDS = (n    'django.contrib.auth.backends.ModelBackend'n    # `allauth` specific authentication methods such as login by e-mailn    'allauth.account.auth_backends.AuthenticationBackend'n)nACCOUNT_EMAIL_REQUIRED=FalsenSOCIALACCOUNT_AUTO_SIGNUP=TruenLOGIN_REDIRECT_URL = '/'nACCOUNT_LOGOUT_REDIRECT_URL = '/'nnnI also have a url from accounts set in my urls.pynnurl(r'^accounts/' include('allauth.urls'))    nnnI have followed the steps for activating my application with Twitter. I don't understand how to create a user based on these instructions. I have created a template with a button that shows my sign up button. nn{% if user.is_authenticated %}n    <a id=""logout"" href=""/accounts/logout"" class=""btn btn-success"">Logout</a>n{% else %} n    <a id=""twitter_login"" href=""/accounts/twitter/login"" class=""btn btn-success"">Sign in with Twitter</a>n{% endif %}nnnIs my next step to create a view at /accounts/twitter/login and then set parameters for User? Id like to create a User and a Profile on login and I have the first part of that going (I believe I'll also need to make ). nnclass Profile(models.Model):n    user = models.OneToOneField(User on_delete=models.CASCADE)nn' nan",['django'],['django']
40113072,"'How can I append a numpy array of N-Length to another array of N-dimensions?' 'SituationnnI assumed this would be easy - but turns out there are a few restrictions. nI have an empty array that at this point is empty and has unknown dimensions.nnmainArray = np.array()nnnlater on I want to append arrays to my main array which are of different lengths.nnI have triednn*Please assume all arrays I have attempted to append are the result of np.zeros(n)nnI have tried np.append() but this does not maintain the correct dimensions (assumes I want a linear array).nnI have tried np.concatenate() however this error nnTypeError: only length-1 arrays can be converted to Python scalarsnnnimplies I cannot concatenate to an empty array...?nnI have tried np.vstack() but getnnValueError: all the input array dimensions except for the concatenation axis must match exactlynnn...which implies I cannot have added arrays of different lengths?nnQuestionnnHow can I append n-length arrays to an empty n-dimensional array?nnupdatennHere is an example of an output:nn000000000000000nnnWhere length of 3 is a variablen' ""Your starting array is not empty (ok it does have 0 elements) and not of unknown dimensions.  It has a well defined shape and number of dimensions (1d).nnIn 704: a=np.array()nIn 705: a.shapenOut705: (0)nIn 706: a.ndimnOut706: 1nnnSome examples on concatenate that work with annIn 708: np.concatenate((aaaa)).shapenOut708: (0)nIn 709: np.concatenate((anp.zeros(3))).shapenOut709: (3)nnnAs a general rule don't start with an 'empty' array and try to append to it repeatedly.  That's a list approach and is not efficient with arrays.  And because of the dimensionality issue might not work.nnA correct way of doing a repeated append is something like:nnalist = nfor i in range(3):n     alist.append(123)nnp.array(alist)nnnAre the sublists all the same length or not?  In your last example they differ and the array version is  dtype=object.  It is 1d with pointers to lists else where in memory - i.e. glorified list.nnIn 710: np.array(000000000000000)nOut710: array(0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 dtype=object)nnnThis is a very different thing from what you'd get by vstack of 3 arrays of the same length.nnI think you need more practice with basic array construction and the meaning of shape and dimensions.  The title itself shows some confusion - array of length N array of N-dimensions. Those are very different descriptions.nn============nnThe basic point with concatenate is that a (n1m) array can be joined with a (n2m) array to produce a (n1+n2m) array.  Similarly for other dimensions.  If one array is 1d (m) it needs to be expanded to (1m) to perform this concatenation. vstack does this kind of expansion for you.nnThis means that a (0) shape array can be concatenated horizontally with other 1d arrays but can't participate in a 2d vertical concatenation except with a (n20) array.  A dimension may have size 0 but this is rarely useful since it doesn't contain any  data.n"" ""One of the key concepts of numpy's ndarray is that it is rectangular: all elements at a given depth have the same length. This allows simple indexing with a tuple of positions in each dimension to be mapped onto a single flat array:nnarrayxyz #where array.shape = (abc)n#is equivalent to:narray.flatb*c*x + c*y + znnnThis allows very fast and efficient operation in c for many algorithms.nnNumpy does technically support what you want to do but the implementation is basically reverting functionality back to native lists. The way to do it with numpy is to specify the array dtype=object.nn;TLDRnnArrays are intended to be created the correct size ahead of time and never change size. The functionality does exist but it bypasses some of the advantages of using numpy arrays in the first place.n""",['numpy'],['numpy']
40113089,"'Django rest framework pagination' 'I am trying to add pagination into my project couldn't find any clear documentation or tutorial.nnI have a list of officesnnmodelsnOffice.pynnclass Office(Model):n    name = CharField(_(""name"") default=None max_length=255 null=True)n    email = EmailField(_(""email"") default=None max_length=255 null=True)n    description = TextField(_(""description"") default=None null=True)nnnSerializernnclass OfficeSerializer(ModelSerializer):n     id = IntegerField(read_only=True)n     name = CharField(read_only=True)n     email = URLField(read_only=True)n     description = CharField(read_only=True)nnclass Meta:n    model = Officen    fields = (""id"" ""name"" ""email"" ""description"")nnnviews.pynn@api_view(""GET"")n@permission_classes((AllowAny))ndef offices(request):ninstance = Office.objects.filter():10nserializer = OfficeSerializer(instance many=True)nnreturn Response(serializer.data)nnnAny help with returning Office list with pagination ?n' 'http://www.django-rest-framework.org/api-guide/pagination/nnGET https://api.example.org/accounts/?limit=100&offset=400nnnResponse:nnHTTP 200 OKn{n    ""count"": 1023n    ""next"": ""https://api.example.org/accounts/?limit=100&offset=500""n    ""previous"": ""https://api.example.org/accounts/?limit=100&offset=300""n    ""results"": n       âx80¦n    n}nnnExample of settings.pynnREST_FRAMEWORK = {n    'PAGE_SIZE': 10n    'EXCEPTION_HANDLER': 'rest_framework_json_api.exceptions.exception_handler'n    'DEFAULT_PAGINATION_CLASS':n        'rest_framework_json_api.pagination.PageNumberPagination'n    'DEFAULT_PARSER_CLASSES': (n        'rest_framework_json_api.parsers.JSONParser'n        'rest_framework.parsers.FormParser'n        'rest_framework.parsers.MultiPartParser'n    )n    'DEFAULT_RENDERER_CLASSES': (n        'rest_framework_json_api.renderers.JSONRenderer'n        'rest_framework.renderers.BrowsableAPIRenderer'n    )n}nn' 'http://www.django-rest-framework.org/api-guide/pagination/nnn  Pagination is only performed automatically if you're using the genericn  views or viewsets. If you're using a regular APIView you'll need ton  call into the pagination API yourself to ensure you return a paginatedn  response. See the source code for the mixins.ListModelMixin andn  generics.GenericAPIView classes for an example.nnnhttps://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/mixins.py#L35nhttps://github.com/tomchristie/django-rest-framework/blob/master/rest_framework/generics.py#L166nnso I would suggest something like:nn@api_view(""GET"")n@permission_classes((AllowAny))ndef offices(request):n    pagination_class = api_settings.DEFAULT_PAGINATION_CLASSn    paginator = pagination_class()n    queryset = Office.objects.all()n    page = paginator.paginate_queryset(queryset request)nn    serializer = OfficeSerializer(page many=True)nn    return paginator.get_paginated_response(serializer.data)nn'",['django'],['django']
40113137,"'When I click the render button it starts not responding what should I do?' 'I'm trying to do a  small applet that renders a caustic when the details are given. The problem is I want it to go trough 3 panes and in the second pane it should show a little loading bar to show the progress it has done sadly I never see this loading bar because when I click my button to start my program it starts to not respond but when it finished doing all its calculations it starts responding again and it shows me my image. I tried introducing a time delay but it didn't help. What should I do so that it doesn't stop responding? If you need any help understanding the code please tell me.nnfrom tkinter import *nfrom tkinter import ttknfrom math import *nfrom colour import *nimport timennps1 = 1nbreite1 = 150nhoehe1 = 150ns1 = 0.01nr1 = int(hoehe1/2-5)nmatrix=nndef Pixel(pfrb):n        s0t0=int((breite1)/2)int((hoehe1)/2)n        xy=p0p1n        st=s0+xt0-yn        return canvas.create_rectangle(s-0.5*ps1 t-0.5*ps1 s+0.5*ps1 t+0.5*ps1 fill=frb outline=frb)nndef Runden(zn):n        if z>=0:n            return int(z/n+0.5)*nn        else:n            return -int(-z/n+0.5)*nnndef Strecke_Matrix(ab):n        s0t0=int((breite1)/2)int((hoehe1)/2)n        x0y0=Runden(a0ps1)Runden(a1ps1)n        x1y1=Runden(b0ps1)Runden(b1ps1)n        if x0==x1:n            yayb=min(y0y1) max(y0y1)n            y=yan            while y<=yb:n                lk=int((x0+s0)/ps1)int((t0-y)/ps1)n                if 0<=k<=len(matrix)-1 and 0<=l<=len(matrix0)-1:n                    matrixkl+=1n                y+=ps1n        else:n            if x0<x1:n                xaxb=x0x1n                yayb=y0y1n            else:n                xaxb=x1x0n                yayb=y1y0n            m=(yb-ya)/(xb-xa)n            if abs(m)<=1:n                x=xan                while x<=xb:n                    y=Runden(m*(x-xa)+yaps1)n                    lk=int((x+s0)/ps1)int((t0-y)/ps1)n                    if 0<=k<=len(matrix)-1 and 0<=l<=len(matrix0)-1:n                        matrixkl+=1n                    x+=ps1n            else:n                if yb-ya>0:n                    xnayna=yaxan                    xnbynb=ybxbn                else:n                    xnayna=ybxbn                    xnbynb=yaxan                mn=(ynb-yna)/(xnb-xna)n                x=xnan                while x<=xnb:n                    y=Runden(mn*(x-xna)+ynaps1)n                    xtempytemp=yxn                    lk=int((xtemp+s0)/ps1)int((t0-ytemp)/ps1)n                    if 0<=k<=len(matrix)-1 and 0<=l<=len(matrix0)-1:n                        matrixkl+=1n                    x+=ps1n            return matrixnndef PointLight_Matrix(s r n):n    w = -1*pin    while w < pi:n           a = 0n           while a <=  n:n                  p0 = cos(a*w)*r sin(a*w)*rn                  p1 = cos((a+1)*w)*r sin((a+1)*w)*rn                  Strecke_Matrix(p0p1)n                  a = a + 1n                  time.sleep(0.02)n           w = w + sn    r2 = 0n    for x in matrix:n           for z in x:n                  if z > r2:n                         r2 = zn    return r2nndef Matrix1(s r n):n    w = -0.5*pin    while w < 0.5*pi:n        a = 0n        while a <= n:n            p0 = cos(-a*pi + (2*a+1)*w)*r sin(-a*pi + (2*a+1)*w)*rn            p1 = cos(-(a + 1)*pi + (2*(a + 1)+1)*w)*r sin(-(a + 1)*pi + (2*(a +1)+1)*w)*rn            Strecke_Matrix(p0p1)n            a = a+1n            time.sleep(0.02)n        w = w + sn    r2 = 0n    for x in matrix:n           for z in x:n                  if z > r2:n                         r2 = zn    return r2nn##def maxi(matrix):n##        r2 = 0n##        for x in matrix:n##            for z in x:n##                if z > r2:n##                    r2 = zn##        return r2nnndef render():n              p2.forget(f1)n              p2.add(f2)n              s0t0=int((breite1)/2)int((hoehe1)/2)n              t1 = str(typ.get())n              n1 = int(n.get())n              g1 = str(g.get())n              b1 = int(b.get())n              if t1 == ""Parallel Light"":n                  r2 = Matrix1(s1 r1 n1)n              else:n                  r2 = PointLight_Matrix(s1 r1 n1)n              farbe = Color(g1)n              c = 0n              q = 0n              p = 100/(len(matrix))n              u = int((q*10)/10)n              p9""maximum"" = pn              for x in matrix:n                  z = 0n                  p9""value"" = un                  for a in x:n                      farbe.luminance = min(1(a/r2)*b1)n                      x y = z*ps1-s0  t0 - c*ps1n                      Pixel(x yfarbe)n                      z += 1n                  q += pn                  c += 1n              p2.forget(f2)n              p2.add(f3)nnnhor=int((breite1)/ps1)nver=int((hoehe1)/ps1)nmatrix=nfor i in range(ver):n    zeile=n    for j in range(hor):n        zeile.append(0)n    matrix.append(zeile)nnnroot = Tk()nroot.title(""App"")nnnmainframe = ttk.Frame(root padding=""3 3 12 12"")nmainframe.grid(column=0 row=0 sticky=(N W E S))nmainframe.columnconfigure(0 weight=1)nmainframe.rowconfigure(0 weight=1)nnp2 = ttk.Panedwindow(root orient=""horizontal"")nf1 = ttk.Labelframe(p2 text=""Settings"" height = 150 width = 300)nf2 = ttk.Labelframe(p2 text=""Renderingâx80¦"" height = 150 width = 300)nf3 = ttk.Labelframe(p2 text=""Caustic"" height = 200 width = 200)np2.grid(column=0 row=0 sticky=(N W E S))np2.columnconfigure(0 weight=1)np2.rowconfigure(0 weight=1)np2.add(f1)nnncanvas = Canvas(f3 height=hoehe1 width=breite1)ncanvas.grid(column=6 row=1 rowspan = 20 padx=10 pady=5)nnntyp = StringVar()nn = StringVar()ng = StringVar()nb = StringVar()nnÃ¨ = ttk.Label(f1 text=""Warning! The higher the number of reflections the longer it will take"")nÃ¨.grid(column = 1 row = 1 columnspan=4)nntype_ = ttk.Combobox(f1 textvariable=typ state=""readonly"")ntype_.grid(column=2 row=2 sticky=(W E))ntype_'values' = ('Point Light' 'Parallel Light')ntype_.current(0)nttk.Label(f1 text=""Type of Light:"").grid(column=1 row=2 sticky=W)nnq = ttk.Combobox(f1 textvariable=n)nq.grid(column=2 row=3 sticky=(W E))nq'values' = (12345)nq.current(0)nttk.Label(f1 text=""Number of reflections:"").grid(column=1 row=3 sticky=W)nng_entry = ttk.Entry(f1 width=7 textvariable=g)ng_entry.grid(column=2 row=4 sticky=(W E))nttk.Label(f1 text=""Color of the Image:"").grid(column=1 row=4 sticky=W)nns = ttk.Combobox(f1 textvariable=b state=""readonly"")ns.grid(column=2 row=5 sticky=(W E))ns'values' = (12345678910)ns.current(0)nttk.Label(f1 text=""Brightness:"").grid(column=1 row=5 sticky=W)nnp9 = ttk.Progressbar(f2 orient=""horizontal"" length=200 mode='determinate')np9.grid(column=6 row=21padx=5 pady=30)nnb3 = ttk.Button(f1 text=""Render"" command=render)nb3.grid(column=2 row=6 sticky=W)ntype_.focus()nnnroot.mainloop()nn' nan",['tkinter'],['tkinter']
40113276,"'Producing multi-level dictionary from word and part-of-speech' 'Given some Penn Treebank tagged text in this format:nn""David/NNP Short/NNP will/MD chair/VB the/DT meeting/NN ./. The/DT boy/NN sits/VBZ on/IN the/DT chair/NN ./.""nnI would like to produce a multi-level dictionary that has the word as a key and counts the frequency it appears tagged as each POS so we have 'Chair VB : 1 NN : 1' 'The DT : 3' etc. nnI figure I can use regexes to extract the word and the corresponding POS.nnr'A+Za+z+/' and r'/A+Z+'nnnBut can't work out how to put this together to make an entry for a word and its corresponding POS occurences. nnThoughts?n' 'You don't have to use regular expressions in this case.nnWhat you can do is to split by space and then by slash collecting the results into a defaultdict of defaultdict of int:nnIn 1: import rennIn 2: from collections import defaultdictnnIn 3: s = ""David/NNP Short/NNP will/MD chair/VB the/DT meeting/NN ./. The/DT boy/NN sits/VBZ on/IN the/DT chair/NNn   ...:  ./.""nnIn 4: d = defaultdict(lambda: defaultdict(int))nnIn 5: for item in s.split():n   ...:     word tag = item.split(""/"")n   ...:     word = word.lower()n   ...:     dwordtag += 1nnnNow the d would be:nnIn 6: for word word_data in d.items():n    ...:     for tag count in word_data.items():n    ...:         print(word tag count)n    ...:         n('boy' 'NN' 1)n('short' 'NNP' 1)n('on' 'IN' 1)n('david' 'NNP' 1)n('will' 'MD' 1)n('sits' 'VBZ' 1)n('chair' 'VB' 1)n('chair' 'NN' 1)n('.' '.' 2)n('meeting' 'NN' 1)n('the' 'DT' 3)nn'","['regex', 'dictionary']","['dictionary', 'regex', 'python-2.7']"
40113454,"""Can't push metric values to InfluxDB"" 'I try to push some test metrics to Influxdb in a following manner:nnimport randomnimport jsonnfrom datetime import datetimennfrom influxdb import InfluxDBClientnntest_client = InfluxDBClient(""localhost"" 8086 ""myuser"" ""mypassword"" ""test"")nndef generate_send_fake(measname):nn    fake_point = {n        ""measurement"": measnamen        ""fields"": {""value"": random.randint(0 100)}n        ""time"": json.dumps((datetime.now().replace(minute=0 second=0 microsecond=0)).isoformat()).replace('""' '')n    }nn    return fake_pointnntest_client.write_points(generate_send_fake('test_meas_one'))ntest_client.write_points(generate_send_fake('test_meas_two'))nnnThis code executes without errors/warnings. However when I try to check my data through InfluxDB console I see following:nn> use testnUsing database testn> show measurementsnname: measurementsn------------------nnamentest_meas_onentest_meas_twon> select * from ""test_meas_one""n> select * from ""test_meas_two""nnnIn other words there are no data points though metrics themselves were created. I use Ubuntu 16.04 (64-bit) and Python 3.5.nnInfluxDB log is empty if that matters.n' nan",['python-3.x'],['python-3.x']
40113507,"'UnicodeEncodeError in python3' 'Some of my application's libraries are depending on being able to print UTF-8 characters to stdout and stderr. Therefore this must not fail:nnprint('u2122')nnnOn my local machine it works but on my remote server it raises UnicodeEncodeError: 'ascii' codec can't encode character 'u2122' in position 0: ordinal not in range(128)nnI tried $ PYTHONIOENCODING=utf8 with no apparent effect.nnsys.stdout = codecs.getwriter(""utf-8"")(sys.stdout.detach())nnnworks for a while then stalls and finally fails with ValueError: underlying buffer has been detachednnsys.getdefaultencoding() returns 'utf-8' and sys.stdout.encoding returns 'ANSI_X3.4-1968'nnWhat can I do? I don't want to edit third-party libraries.n' 'I'm guessing you're on a UNIX-like system and your environment set LANG (or LC_ALL or whatever) to C.nnTry editing your default shell's startup file to set LANG to something like en_US.utf-8 (or whatever locale makes sense for you)? For example in bash edit ~/.bash_profile (or ~/.profile if you're using that instead for sh compatibility) and add:nnexport LANG=""en_US.utf-8""nnnFor (t)csh edit ~/.cshrc (or ~/.tcshrc if that's what you're using) to add:nnsetenv LANG ""en_US.utf-8""nnnMaking the changes ""live"" doesn't work because your shell is likely hosted in a terminal that has configured itself solely for ASCII display based on the LANG=C in effect when it was launched (and many terminals do session coalescence so even if you changed LANG and then launched a new terminal it would coalesce with the shared terminal process with the out-of-date LANG). So after you change ~/.bash_profile log out and then log back in so your root shell will set LANG correctly for every other process (since they all ultimately fork from the root shell).n' ""From @ShadowRanger's comment on my questionnnn  PYTHONIOENCODING=utf8 won't work unless you export it (or prefix the Python launch with it). Otherwise it's a local variable in bash that isn't inherited in the environment of child processes. export PYTHONIOENCODING=utf-8 would both set and export it in bash.nnnexport PYTHONIOENCODING=utf-8 did the trick UTF-8 characters no longer raise UnicodeEncodeErrorn""",['python-3.x'],['python-2.7']
40113520,"'Find missing data indices using python' 'What is the optimum way to return indices where 1-d array has missing data. The missing data is represented by zeros. The data may be genuinely zero but not missing. We only want to return indices where data is zero for more than or equal to 3 places at a time. For example for array 12340123000123 the function should only return indices for second segment where there are zeros and not the first instance.nnThis is actually an interview question :) challenge is to do most effeciently in one linen' 'Keep track of the count of zeros in the current run.  Then if a run finishes that has at least three zeros calculate the indexes.nndef find_dx_of_missing(a):n    runsize = 3 # 3 or more change to 4 if your need ""more than 3""n    zcount = 0n    for i n in enumerate(a):n        if n == 0:n            zcount += 1n        else:n            if zcount >= runsize:n                for j in range(i - zcount i):n                    yield jn            zcount = 0n    if zcount >= runsize: # needed if sequence ends with missingn        i += 1n        for j in range(i - zcount i):n            yield jnnnExamples:nn>>> a = 12340123000123n>>> list(find_dx_of_missing(a))n8 9 10nn>>> a = 00030500001000000n>>> list(find_dx_of_missing(a))n0 1 2 6 7 8 9 11 12 13 14 15nnnEdit: Since you need a one liner here are two candidates assuming a is your list and n is the smallest run of zeros that count as missing data:nnv for vals in (list(vals) for iszeros vals in itertools.groupby(xrange(len(a)) lambda dx a=a: adx==0) if iszeros) for v in vals if len(vals) >= nnnnOrnnsorted({dx for i in xrange(len(a)-n+1) for dx in xrange(i i+n) if set(ai:i+n) == {0}})nn'",['python-2.7'],['list']
40113552,"'Pandas: Create another column while splitting each row from the first column' 'Goal create a second column from the first columnnncolumn1 column2nHello World #HelloWordnUS Election #USElectionnnnI have a simple file that has a one columnnncolumnOnenHello WorldnUS ElectionnMovie NightnnnI wrote following functionnn>>> def newColumn(row):n...     r = ""#"" + """".join(row.split("" ""))n...     return rnnnthen I did following to create the second column using pandasnndf'column2' = df.apply (lambda row: newColumn(row)axis=1)nnnBut I end up with following error: nnTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""/Users/anuradha_uduwage/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py"" line 3972 in applyn    return self._apply_standard(f axis reduce=reduce)n  File ""/Users/anuradha_uduwage/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py"" line 4064 in _apply_standardn    resultsi = func(v)n  File ""<stdin>"" line 1 in <lambda>n  File ""<stdin>"" line 2 in newColumnn  File ""/Users/anuradha_uduwage/anaconda2/lib/python2.7/site-packages/pandas/core/generic.py"" line 2360 in __getattr__n    (type(self).__name__ name))nAttributeError: (""'Series' object has no attribute 'split'"" u'occurred at index 0')nnnso I change the split to following: nnr = """".join(row.str.split("" ""))nnnBut that didn't helpn' 'This should do the tricknndf'new_column' = df'old_column'.apply(lambda x: ""#""+x.replace(' ' ''))nnnExamplenn>>> names = 'Hello World' 'US Election' 'Movie Night'n>>> df = pd.DataFrame(data = names columns='Names')n>>> dfn     Namesn0    Hello Worldn1    US Electionn2    Movie Nightnn>>> df'Names2' = df'Names'.apply(lambda x: ""#""+x.replace(' ' ''))n>>> dfn     Names         Names2n0    Hello World   #HelloWorldn1    US Election   #USElectionn2    Movie Night   #MovieNightnn' 'Try a list comprehesion:nndf = pandas.DataFrame({'columnOne': 'Hello World' 'US Election' 'Movie Night'})nndf'column2' = '#' + item.replace(' ' '') for item in df.columnOnennIn 2: dfnnnn' ""Your general approach is totally fine you just have a few problems. When you use apply on an entire dataframe it will pass either a row or a column to the function it is applying. In your case you don't want a row or a column - you want the string that is within each cell in the first column. So instead of running df.apply you want df'columnOne'.apply.nnHere's what I would do: nnimport pandas as pdnndf = pd.DataFrame('First test here' 'Second test' columns='A')nn# Note that this function expects a string and returns a stringndef new_string(s):n    # Get rid of the spacesn    s = s.replace(' ''')n    # Add the hashn    s = '#' + sn    return snn# The apply it to the first column and save it in the second new columnndf'B' = df'A'.apply(new_string)nnnOr if you really want it in a one-liner:nndf'B' = df'A'.apply(lambda x: '#' + x.replace(' '''))nn"" 'You can use str.replace as commented MaxU or Series.replace with parameter regex=True for replacing all whitespaces by empty strings:nndf'column2' = '#' + df.column1.str.replace('s+''')ndf'column3' = '#' + df.column1.replace('s+''' regex=True)nnprint (df)n       column1      column2      column3n0  Hello World  #HelloWorld  #HelloWorldn1  US Election  #USElection  #USElectionnn'",['pandas'],"['pandas', 'python-2.7']"
40113593,"'Dataframe - Sum Arrays in Cell - Memory Issue' ""I have a very large dataframe (close to 1 million rows) which has a couple of meta data columns and one single column that contains a long string of triples. One string could look like this:nn00123.63;103602736.11;3027098.08;...nnThat is three values separated by comma and then separated by semicolon. Let us refer to the three values as IN OUT MEASURE. Effectively i want to group my data by the original columns + the IN & OUT columns and then sum over the MEASURE column. Since each long string contains roughly 30 triples my dataframe would grow to be ~30 million rows if i simply unstacked the data. Obviously this is not feasible.nnSo given a set of columns (which may in- or exclude the IN & OUT columns) over which I want to group and then sum my MEASURE data how would I efficiently strip out the relevant data and sum everything up without blowing up my memory?nnMy current solution simply loops over each row and then over each triple and keeps a running total of each group I specified. This is very slow so I am looking for something faster perhaps vectorised. Any help would be appreciated.nnEdit: Sample data below (columns separated by pipe)nnDATE|REGION|PRIORITY|PARAMETERSn10-Oct-2016|UK|High|0077.82;30907373.70;n10-Oct-2016|US|Low|0307.82;3090733.70;n11-Oct-2016|UK|High|00383.82;4090713.75;n12-Oct-2016|NA|Low|4090937.11;3018098.23;nnnwhere PARAMETERS has the form 'INOUTMEASURE;INOUTMEASURE;...'nI basically want to (as an example) create a pivot table wherennvalues=MEASUREnindex=DATE INncolumns=PRIORITYnn"" nan",['pandas'],['pandas']
40113835,"'Django ImportError: No module named... but module is visible in Project Interpreter settings' 'I am developing a Django app and I am experiencing a strange problem. I've installed a few modules using pip and I can see them in ""project interpreter settings"":nnnnHowever when I try to import any of these modules I get errors like this:nnFile ""/Users/Franek/Documents/testy/testy/testysearch/views.py"" line 4 in <module>n    from sumy.summarizers.text_rank import TextRankSummarizernImportError: No module named sumy.summarizers.text_ranknnnI am using virtualenv but I don't think this can be an issue because when I try to run some of these modules from console (bypassing Django) they work properly. What am I doing wrong?n' 'Did u activate your virtualenv with the command:nnsource <virtualenv_name>/bin/ativatenn'","['django', 'python-2.7']",['django']
40113921,"'Issue adding request headers for Django Tests' 'I need to add a header to a request in a Django test. I have browsed a few pages on both Stack Overflow and elsewhere following various suggestions. I can add the headers to PUTs and GETs successfully but having an issue with POSTs. Any advice would be greatly appreciated.nnFor PUT and GET I have used the following passing successfully:nnresp = self.client.put(resource_url res_params **{'HTTP_SSL_CLIENT_CERT': self.client_cert})nnnFor POST I tried the same thing but am receiving the error: n""'str' object has no attribute 'items'""nnI have tried the following:nnresp = self.client.post(resource_url res_params **{'HTTP_SSL_CLIENT_CERT': self.client_cert})nnresp = self.client.post(resource_url res_params HTTP_SSL_CLIENT_CERT=self.client_cert)nnresp = self.client.post(resource_url res_params HTTP_SSL_CLIENT_CERT='1234567890')nn' ""For anybody that finds themselves looking at this page with a similar issue I was able to get this working with the following:nnresp = self.client.post(resource_url data=res_params content_type='application/json' HTTP_SSL_CLIENT_CERT=self.client_cert)nn""",['django'],['django']
40113977,"'How to select repeating items in a list of dictionaries?' 'This is my code so far:nnimport numpy as npnnimport csvnusers_dict = nwith open('vincent/users.csv') as csvfile:n    users = csv.DictReader(csvfile)n    for i in range(3900):n        user = users.next()n        users_dict.append(user) n        print(user)nnevents_dict = nwith open('vincent/events.csv') as csvfile:n    events = csv.DictReader(csvfile)n    for i in range(27727):n        event = events.next()n        events_dict.append(event) n        print(event)nnrevisit_list = {""repeat_id""} nndef find_revisit(events_dict):n    for ij in events_dict(): n        if j == events_dicti:n            print events_dictj n            revisit_list.append(j)nfind_revisitnnnBasically I have a printed dictionary: {'user_id':  'user_session_id': 'app': 'time_spent':}nnThe user_ids can occur more than once because the users use the app repeatedly. I want to print how many times a user_id is printed in the list. nnMy function isn't printing anything.n' nan",['dictionary'],"['dictionary', 'list']"
40113979,"'Sorting on multiple levels in pandas pivot table while preserving subtotals' 'I've done a table in pandas consisting in 3 levels.nnEach level has its own subtotal grouping each level child group with its parents.nnI would like to sort every level based on their total Sales just the way Excel does that when creating pivot tables i.e. displaying the total in the top then sorting from largest to smallest sales in the second level and each sub level sorted from larges to smalles.nnBelow is an image that shows how my table is currently.nnI've tried using ""lexsort"" when creating each sub level but I got the same result when concatenating all my levels.nnenter image description heren' nan",['pandas'],['pandas']
40114115,"'Precise Python 2.7 calculation including Pi' 'I am working on a small program that calculates different things related to orbital mechanics such as the semi-major axis of an orbit velocity etc. (No experience in this subject is required to answer this).nnEverything worked out well until I tried to calculate the orbital period (a formula where I had to use Pi):nnT = 2Ïx80 âx88x9a a3 / Âµ (Click for image)nnWhere T is time in seconds a is the semi-major axis and Âµ is the standard gravitational parameter.nnNow my problem is that my program does not calculate it very precise as the result of the formula is a bit off; for example: a circular orbit at an altitude of 160km should take approx 88 minutes but my program tells me an approx of 90 minutes and 37 seconds.nnMy code:nn#the standard gravitational parameter of the EarthngravPara = 3.986004418*10**14nn#the semi-major axis of the orbit (the radius of the Earth + the apoapsis and periapsis of your orbit / 2)nsemiMajor = (bodyDia + ap + pe) / 2nn#formula to calculate orbital periodntimeSeconds = (2 * math.pi) * math.sqrt(semiMajor**3 / gravPara)nn#making the result appear as minutes and seconds instead of just secondsntimeMinutes = 0nwhile (timeSeconds > 60):n   timeSeconds = timeSeconds - 60n   timeMinutes = timeMinutes + 1nn#round the variable to store secondsnround(timeSeconds 0)nn#print the resultnprint timeMinutesnprint timeSecondsnnnSo my question is: is it an error in my code or is math.pi not very precise when used together in such a formula? Should I store it as a float and use the float instead or should I split up the calculation into multiple pieces?nnI would be very thankful if you could help me out on this one as searching through the Python reference as well as other forums did not get me very far.nnPS: when using print math.pi it returns a precise value of Pi so the math.pi function seems to be working correctly.n' ""math.pi is a float with 15 decimals: 3.141592653589793nnAs per chepners comment to your original post that equates to about the size of an atom when calculating spheres the size of the earth. nnSo to answer your question: it's not math.pin"" 'Okay - seems like I have found the solution to my problem; while editing my question to include my calculation for the variable semiMajor I realized I forgot to include parentheses around bodyDia + ap + pe which caused faulty prioritizing leading to the not-very-precise calculation.nnSo it was just a silly mistake in my code and it was easily solved by adding two parentheses.nThank you for taking your time.n'",['python-2.7'],['python-2.7']
40114214,"'How to fix error saying plugin_env` should be an ``Environment`` instance that contains pkg_resources.DistributionNotFound: Django==1.8' 'when I run the command from the shell:n$ django-admin.py startproject myproject .ni get the below error:nnTraceback (most recent call last):n  File ""/usr/local/bin/django-admin.py"" line 4 in <module>n    __import__('pkg_resources').run_script('Django==1.8' 'django-admin.py')n  File ""build/bdist.macosx-10.9-intel/egg/pkg_resources.py"" line 2716 in <module>nn  File ""build/bdist.macosx-10.9-intel/egg/pkg_resources.py"" line 685 in requiren    def __getstate__(self):n  File ""build/bdist.macosx-10.9-intel/egg/pkg_resources.py"" line 588 in resolven    The `plugin_env` should be an ``Environment`` instance that containsnpkg_resources.DistributionNotFound: Django==1.8nnneven though django is installed.nn>>> import djangon>>> djangon<module 'django' from '/Library/Python/2.7/site-packages/Django-1.8-py2.7.egg/django/__init__.pyc'>nn' nan",['django'],['django']
40114225,"'Mapping csv file to nested json' 'I have data in a csv in the form of nn""category1"" 2010 ""deatil1""n""category1"" 2010 ""deatil2""n""category1"" 2011 ""deatil3""n""category2"" 2011 ""deatil4""nnnI need to map it to json in form of nn {n        ""name"": ""Data""n        ""children"": {n            ""name"": ""category1""n            ""children"": {n                ""name"": ""2010""n                ""children"": n                    {""name"": ""deatil1""} n                    {""name"": ""detail2""}n                 n                ""name"": ""2011""n                ""children"": n                    {""name"": ""detail3""}n                n            } {n            }n        } n            {n            ""name"": ""category2""n            ""children"": {n                    ""name"": ""2011""n                    ""children"": {n                        ""name"": ""detail4""n                    }n                }n            n        }n    n    }nnnBasically I need to collect up all the details for each unique category and year pair and put the listnnI have tried to use a nested dict structure but the output is not correct.nnI have created a custom dict class that handles the nesting of the nesting of the dictionaries. The following code collects the data in the right structure but I am unsure how to proceed with outputting it in the right format. Any help would be greatly appreciated.nnclass Vividict(dict):nn    def __missing__(self key):n        value = selfkey = type(self)()n        return valuenndict = Vividict()nnfor row in ws.iter_rows(row_offset=1):n    sector = row0.valuen    year =  row2.valuen    detail = row1.valuen    dictsectoryeardetailnnprint json.dumps(dict).encode('utf8')nn' 'Starting from your dict structure it's a matter of building up the new data structure. I am using here mostly list comprehensions where dict are created:nnimport jsonnnrows = n    (""category1"" 2010 ""deatil1"")n    (""category1"" 2010 ""deatil2"")n    (""category1"" 2011 ""deatil3"")n    (""category2"" 2011 ""deatil4"")nnclass Vividict(dict):n    def __missing__(self key):n        value = selfkey = type(self)()n        return valuenndict = Vividict()nnfor row in rows:n    sector = row0n    year = row1n    detail = row2n    dictsectoryeardetailnn# This is the new data structure derived from the existing 'dict'nd = {'name': 'Data'n     'children': n         {'name': k1  # sectorn          'children': n                       {'name': k2  # yearn                        'children': n                            {n                             'name': k3  # deatiln                             } for k3 in v2.keys()n                        } for k2 v2 in v1.iteritems()n          } for k1 v1 in dict.iteritems()n     }nnprint json.dumps(d).encode('utf8')nnnSee it in action here: https://eval.in/662805n'",['dictionary'],"['dictionary', 'python-2.7']"
40114305,"'parallel processing with dataframes python' 'I have a set of functions that I want to call for every row in pandas dataframe. Since apply is considered to be faster I use apply with pandas dataframe but two of these functions are quite slow one has a lot of I/o disk access and other acessess a web API and returns the result. I want to know is there a faster way to do it by using multiprocessing or multithreading in python. nnfrom collections import ChainMapnimport pandas as pd ndef applyfeatures(xdatacolumn1datacolumn2):n     rougescores=func1(xdatacolumn1xdatacolumn2)n     ngramscores=func2(xdatacolumn1xdatacolumn2)n     terpscores=func3(xdatacolumn1xdatacolumn2)n     z= dict(ChainMap(rougescoresngramscoresterpscores))n     return pd.Series(z)nnif __name__ == '__main__':n    df=pd.read_csv(input_file)n    start = timer()n    newdf=df.apply(applyfeaturesargs=(datacolumn1datacolumn2)axis=1)n    end = timer()n    print(""feature generation for {0}took"".format(str(features)))n    print(end - start)      n    newdf.to_csv(features_file)nn' nan",['pandas'],['pandas']
40114327,"'How can I insert a Series into a DataFrame row?' ""I have a DataFrame like this:nnimport pandas as pdnimport numpy as npndf = pd.DataFrame(columns='a''b''c''d' index='x''y''z')ndfn     a    b    c    dnx  NaN  NaN  NaN  NaNny  NaN  NaN  NaN  NaNnz  NaN  NaN  NaN  NaNnnnI also have a Series like thisnns = pd.Series(np.random.randn(3) index='b' 'c' 'd')nsnb   -0.738283nc   -0.649760nd   -0.777346 ndtype: float64nnnI want to insert the Series into a row of the DataFrame for example the 1th row resulting the final DataFrame:nn     a       b          c         dnx  NaN      NaN        NaN       NaNny  NaN  -0.738283  -0.649760  -0.777346nz  NaN      NaN        NaN       NaNnnnHow can I do it? thanks in advance ;)n"" 'You can use iloc if need select index of df by position:nn#select second row (python counts from 0)ndf.iloc1 = snprint (df)n     a        b         c       dnx  NaN      NaN       NaN     NaNny  NaN  1.71523  0.269975 -1.3663nz  NaN      NaN       NaN     NaNnnnOr ix (loc) if need select by label:nndf.ix'y' = sndf.loc'z' = snprint (df)nn     a         b         c         dnx  NaN       NaN       NaN       NaNny  NaN  0.619316  0.917374 -0.559769nz  NaN  0.619316  0.917374 -0.559769nn'","['pandas', 'numpy']",['pandas']
40114423,"'regex to match several string in Python' 'I have questions with regex in Python.nnPossible variations can be nn10 hours 12 weeks or 7 business days.nnI want to have my regex something like nnstring = ""I have an 7 business day trip and 12 weeks vacation.""nre.findall(r'd+s(business)?s(hours|weeks|days)' string)nnnso that I expect to find ""7 business day"" and ""12 weeks"" but it returns Nonen' 'You need to tweak your regex to this:nn>>> string = ""I have an 7 business day trip and 12 weeks vacation.""n>>> print re.findall(r'(d+)s*(?:business day|hour|week)s?' string)n'7' '12'nnnThis matches any number that is followed by business day or hour or week and an optional s in the end.n' 'string = ""I have an 7 business day trip and 12 weeks vacation.""nprint re.findall(r'd+s(?:businesss)?(?:hour|week|day)s?' string)n'7 business day' '12 weeks'nnd+s(?:businesss)?(?:hour|week|day)s?nnnDebuggex DemonnThe demo should explain how this works. The reason yours wasn't is because it was looking for 7 businessdays which doesn't match.nnAlthough if you don't want to accept business week/hour you'll need to modify it further:nnd+s(?:hour|week|(?:business )?day)s?nnnDebuggex Demon' 'Similar to @anubhava's answer but matches ""7 business day"" rather than just ""7"". Just move the closing parenthesis from after d+ to the end:nnre.findall(r'(d+s*(?:business day|hour|week)s?)' string)nn' 'I've matched "" trip and "" between ""7 business day"" and ""12 weeks""nnimport renstring = ""I have an 7 business days trip and 12 weeks vacation.""nprint(re.findall(r'(d+sbusinesssdays?)stripsands(d+s(?:hours?|weeks?|days?))svacation' string))nn' 'd+s+(businesss)?(hour|week|day)s?n'",['regex'],"['regex', 'python-2.7']"
40114534,"'Numpy 4d array slicing' ""Why does slicing a 4d array give me a 3d array? I expected a 4d array with extent 1 in one of the dimensions.nnExample:nnprint X.shapen(1783 1 96 96)nnnSlice array:nnprint X11:::.shapennnornnprint X11:.shapennngives me (1 96 96) but I expected (1 1 96 96)nnI can do it by print X11:12:.shape but I wonder why the first method doesn't work as I expect?n"" 'Per the docs:nnn  An integer i returns the same values as i:i+1 except the dimensionality of the returned object is reduced by 1. In particular a selection tuple with the p-th element an integer (and all other entries :) returns the corresponding sub-array with dimension N - 1. If N = 1 then the returned object is an array scalar. nnnnnThus when your index is an integer the value(s) at that index is(are) returned and the corresponding axis is removed. In one dimension the behavior is as you would expect:nnIn 6: a = np.arange(5); anOut6: array(0 1 2 3 4)nnIn 7: a2nOut7: 2nnIn 8: a2.shapenOut8: ()nnna is 1-dimensional a2 is 0-dimensional. nnIn higher dimensions if X is 4-dimensional and of shape (178319696) thennX11::: returns all the values where the first axis index equals 11 and then that axis is removed. So X11:::.shape is (19696).nnWhen the slice specifies a range such as a2:3 then all the values within that range are returned and the axis is not removed:nnIn 9: a2:3nOut9: array(2)nnIn 10: a2:3.shapenOut10: (1)nnnSimilarly X11:12 : : : has shape (119696).n'",['numpy'],['numpy']
40114605,"'Why is this piece of code not working?' 'I am currently doing a project for school in which I am supposed to make a dice game. Here is the code:nnRoll = input(""Do you want to Roll or Stick?"")nif Roll in (""Roll""  ""roll""):n    print(""Your new numbers are""  +number10  +number20  +number30  +number40  +number50)nnKeepDelete = input(""Would you like to keep or delete a number?"")nif KeepDelete in(""Keep"" ""keep""):n    print(""Your numbers are""  +number10  +number20  +number30  +number40  +number50)nprint(""Your final score is""  number10+number20+number30+number40+number50)nif KeepDelete in(""Delete"" ""delete""):n    Delete = int(input(""What number would you like to delete?""))nnif Delete == (number10):n    del(number10)nScore1 = int(""Your numbers are""  number100  number20  number30  number40  number50)nprint(""Your final score is""  +number100 + number20 + number30 +number40 + number50)nnif Delete == (number20):n   del(number20)nScore2 = int(""Your numbers are""  number10  number200  number30  number40  number50)nprint(""Your final score is""  +number10 + number200 + number30 + number40 + number50)nnif Delete == (number30):n    del(number30)nScore3 = int(""Your numbers are""  number10  number20  number300  number40  number50)nprint(""Your final score is""  +number10 + number20 +number300 + number40 + number50)nnif Delete == (number40):n    del(number40)nScore4 = int(""Your numbers are""  number10  number20  number30  number400  number50)nprint(""Your final score is"" +number10 + number20 + number30 + number400 + number50)nnif Delete == (number50):n    del(number50)nScore5 = int(""Your numbers are""  number10  number20  number30  number40  number500)nprint(""Your final score is"" +number10 + number20 + number30 + number40 + number500)nnnHere is the error code:nnScore1 = int(""Your numbers are""  number100  number20  number30  number40  number50)nTypeError: int() takes at most 2 arguments (6 given)nnnSorry for such a long piece but I have been confused on this for about six hours. Any help would be appreciated.n' 'Just taking a section of your code:   nnprint(""Your final score is""  number10+number20+number30+number40+number50)nif KeepDelete in(""Delete"" ""delete""):n    Delete = int(input(""What number would you like to delete?""))nnif Delete == (number10):n    del(number10)nScore1 = int(""Your numbers are""  number100  number20  number30  number40  number50)nprint(""Your final score is""  +number100 + number20 + number30 +number40 + number50)nnnint() casts the arguments to integer format.  The error message is telling you it takes two arguments: 1) the value to be converted and 2) the base.nnSo in:nnDelete = int(input(""What number would you like to delete?""))nnnYou're trying to cast the argument input(""What..."")) to an integer.nnIn the specific error message you're getting you're trying to cast ""your numbers are"" and all of the subsequent variables to int and pass that to the variable Score 1.  Python doesn't know where to start with that.nnYou can find more information at Python Docs.n'",['python-3.x'],"['python-3.x', 'python-2.7']"
40114807,"'pandas updating column value using isin and loc' 'I trying to update column in data frame one same as herehttp://stackoverflow.com/questions/24768657/replace-column-values-based-on-another-dataframe-python-pandas-better-way. However i am not able to do so - nndf = pd.read_csv('Analyzed_test.csv')ndf'rule_prediction' = "" "" # created a columnna1 = pd.read_csv('D:JunkMLfilesAnalyzed_rule1.csv')na2 = pd.read_csv('D:JunkMLfilesAnalyzed_rule2.csv')na3 = pd.read_csv('D:JunkMLfilesAnalyzed_rule3.csv')na4 = pd.read_csv('D:JunkMLfilesAnalyzed_rule4.csv')nndf.locdf.ID.isin(a1.ID) 'rule_prediction' = a1'rule_prediction'ndf.locdf.ID.isin(a2.ID) 'rule_prediction' = a2'rule_prediction'ndf.locdf.ID.isin(a3.ID) 'rule_prediction' = a3'rule_prediction'ndf.locdf.ID.isin(a4.ID) 'rule_prediction' = a4'rule_prediction'nn#print t.countn#print self.df.head()ndf.to_csv('D:JunkMLfilesoutput.csv')nnnWhen i open output.csv i see no values populated.nnColumns in Analyzed_rule1-4.csv ndataframe in Analyzed_rule1.csv nnThe one i want to update is - nAnalyzed_test.csv to output.csv based on ID columns matched.nnThanks in advance.n' nan",['pandas'],['pandas']
40114876,"""Validating a Django model field based on another field's value?"" ""I have a Django app with models accessible by both Django REST Framework and a regular form interface. The form interface has some validation checks before saving changes to the model but not using any special Django framework just a simple local change in the view.nnI'd like to apply the same validation to forms and REST calls so I want to move my validation into the model. I can see how to do that for simple cases using the validators field of the Field but in one case I have a name/type/value model where the acceptable values for 'value' change depending on which type is selected. The validator doesn't get sent any information about the model that the field is in so it doesn't have access to other fields.nnHow can I perform this validation without having essentially the same code in a serializer for DRF and my POST view for the form?n"" ""The validation per-field doesn't get sent any information about other fields when it is defined like this:nndef validate_myfield(self value):n    ...nnnHowever if you have a method defined like this:nndef validate(self data):n    ...nnnThen you get all the data in a dict and you can do cross-field validation.  n""",['django'],['django']
40115187,"'Python dataset update - TypeError: update() takes at most 2 positional arguments (3 given)' 'When trying to update database with data from a dict where uuident = uuident i'm receiving this errornnError:nnTypeError: update() takes at most 2 positional arguments (3 given)nnnThe error happens only in this update. If insert there is no errors at all.nnI'm a beginner can you please help me out?nndetailsnnTraceback (most recent call last):n  File ""/home/ubuntu/workspace/ex50/bin/teste.py"" line 59 in <module>n    main()n  File ""/home/ubuntu/workspace/ex50/bin/teste.py"" line 35 in mainn    prec.precifica(""7f559bb1-b6c6-44b7-ba4e-1e4592dcd009"")n  File ""/home/ubuntu/workspace/ex50/bin/precificator.py"" line 81 in precifican    produto_precificado.update(product'uuident')n  File ""/usr/lib/python2.7/_abcoll.py"" line 534 in updaten    ""arguments ({} given)"".format(len(args)))nTypeError: update() takes at most 2 positional arguments (3 given)nnnteste.pynnfrom alcateia.alcateia import *nfrom bling.bling import *nfrom tray.tray import *nimport alcateia.alcateianimport tray.traynimport tray.trayservicenfrom precificator import Precificatornimport loggingnnndef main():n    logging.basicConfig(filename='myapp.log' level=logging.INFO format='%(asctime)s %(message)s' datefmt='%m/%d/%Y %I:%M:%S %p')n    logging.info('Programa inicializado...')nn    prec = Precificator()n    prec.precifica(""7f559bb1-b6c6-44b7-ba4e-1e4592dcd009"")nnn    logging.info('Processo finalizado!')n    logging.info('--------------------')nnnnif __name__ == '__main__':n    main()nnnprecificator.pynn# coding: utf-8nimport sysnimport uuidnfrom sgcon import Produtonfrom db import produtosalca alca_uuid cem precificadonimport loggingnlogger = logging.getLogger(__name__)nnclass Precificator(object):n    """"""n    modulo precificadorn    """"""n    def __init__(self):n        passnn    def precifica(selfuuident):n         print 'uuident value is %s' % uuidentn         print 'uuident type is %s' % type(uuident)nn         product = {} ## cria dict productnn         product'uuident' = uuidentnn         produto_cem = cem.find_one(uuident=uuident) ## gets produto_cem from database cemnn         valorcem = produto_cem'valorcem' nn         margem = 0.04 ## definimos margem em 10%n         product'margem'=margem  ## atribuimos margemnn         valorMargem = valorcem * margem  ## valor + margemn         product'valormargem'=valorMargemnn         despadm = 15.00 ## desp adm 15 reaisn         product'despadm' = despadm nn         outrasdesp = 5.00 ## outras desp 5 reaisn         product'outrasdesp' = outrasdespnn         somatudo = valorMargem + despadm + outrasdespnn         comissaovenda = 0.00 ##comissao mktplace 16%n         product'comissaovenda' = comissaovendann         comissaorecebiveis = 0.05 ##comissao / desp financeiras 0%n         product'comissaorecebiveis'=comissaorecebiveis nn         cemcommargem = valorcem*(1+(margem)) ## cem com margem = cem*(1+margem)nn         aliqICMS = produto_cem'aliqICMS' n         product'aliqICMS' = aliqICMSnn         aliqPIS = produto_cem'aliqPIS'nn         aliqCofins = produto_cem'aliqCofins'nn         aliqTotalImposto = aliqICMS + aliqCofins + aliqPIS ## aliquota total (em %) dos impostosnn         base = cemcommargem + despadm + outrasdesp ## Soma as despesas em reais ao valorcem e obtem a base para o calculonn         outrasAliq = comissaovenda + comissaorecebiveis ## outras aliquotas nÃ£o tributÃ¡riasnn         indice = 1-(aliqTotalImposto + outrasAliq) ##  Ãxadndice para cÃ¡lculonn         precovenda = base / indice  ## aplica o Ãxadndicenn         product'precovenda'=precovenda ## atribui ao dict productnn         ## ALL MATH DONE AND DICT PRODUCT IS READY TO GO TO DATABASE TABLE PRECIFICAnn         produto_precificado = precificado.find_one(uuident=uuident) ## CHECKS IF ROW WITH THIS UUIDENT EXISTS IN TABLE PRECIFICAnn         """"""n         CHECKS AND ACTn         """"""nn         if produto_precificado: ## IF PRODUCT EXISTS IN DATABASE TABLEn            ## UPDATEn            print 'produto exists in db'n            print productn            print type(product)n            """"""n            THIS DO NOT WORKn            """"""n            produto_precificado.update(product'uuident') ## THIS DO NOT WORK!!!!n            ##produto_precificado.update(dict(precovenda=precovenda)'id')nn         else: ## IF product do not existsn            ## INSERTn            print 'produto nao existe no bd'n            """"""n            THIS WORKS!!!!n            """"""n            precificado.insert(product)  ### THIS WORKS!nnnUPDATEnnproduto_precificado type is <class 'collections.OrderedDict'>n' ""The builtin dict update method accepts other keywords=values and updates the dict with that or another dictionary and updates the dict with all keys from the second dict.nnWhat your probably want to do is:nnproduto_precificadoproduct'uuident' = productnnnto make a hash of products according to uuident (or whatever key).n"" ""I'm sorry for my terrible mistake here.nnWell just in case somebody goes through the same:nnproduto_precificado is a row from table precificado.nnSo that was the error.nnI changed:nnproduto_precificado.update(product'uuident')nnnfornnprecificado.update(product'uuident')nnnWorking like a charm. n""",['python-2.7'],"['python-2.7', 'dictionary']"
40115278,"'Generate a lot of random strings' 'I have a method that will generate 50000 random strings save them all to a file and then run through the file and delete all duplicates of the strings that occur. Out of those 50000 random strings after using set() to generate unique ones on average 63 of them are left. nnFunction to generate the strings:nndef random_strings(size=8 chars=string.ascii_uppercase + string.digits + string.ascii_lowercase):n    return ''.join(random.choice(chars) for _ in xrange(size))nnnDelete duplicates:nn    with open(""dicts/temp_dict.txt"" ""a+"") as data:n        created = 0n        while created != 50000:n            string = random_strings()n            data.write(string + ""n"")n            created += 1n            sys.stdout.write(""rCreating password: {} out of 50000"".format(created))n            sys.stdout.flush()nn        print ""nRemoving duplicates..""n        with open(""dictsrainbow-dict.txt"" ""a+"") as rewrite:n            rewrite.writelines(set(data))nnnExample of before and after:nhttps://gist.github.com/Ekultek/a760912b40cb32de5f5b3d2fc580b99fnnHow can I generate completely random unique strings without duplicates?n' 'You can use set from the startnncreated = set()nwhile len(created) < 50000:n    created.add(random_strings())nnnAnd save once outside the loopn' 'You could guarantee unique strings by generating unique numbers starting with a random number is a range that is 1/50000th of the total number of possibilities (628). Then generate more random numbers each time determining the window in which the next number can be selected. This is not perfectly random but I believe it's practically close enough.nnThen these numbers can each be converted to strings by considering a representation of a 62-base number. Here is the code and a test at the end to check that indeed all 50000 strings are unique:nnimport stringnimport randomnndef random_strings(count size=8 chars=string.ascii_uppercase + string.digits + string.ascii_lowercase):n    max = len(chars) ** size - 1n    start = 0n    choices = n    for i in range(0count):n        start = random.randint(start start + (max-start) // (count-i))n        digits = n        temp = startn        while len(digits) < size:n            temp i = divmod(temp len(chars))n            digits.append(charsi)n        choices.append(''.join(digits))n        start += 1n    return choicesnnchoices = random_strings(50000)n# optional shuffle since they are produced in order of `chars`nrandom.shuffle(choices)n# Test: output how many distinct values there are:nprint (len(set(choices)))nnnSee it run on repl.itnnThis produces your strings in linear time. With the above parameters you'll have the answer within a second on the average PC.n'",['python-2.7'],"['python-3.x', 'python-2.7']"
40115346,"'Contains function in Pandas' ""I am performing matching (kind of fuzzy matching) between the company names of two data frames. For doing so first I am performing full merge between all the company names where the starting alphabet matches. Which means all the companies starting with 'A' would be matched to all the companies starting with 'A' in other data frame. This is done as follows: nndf1'df1_Start' = df1'company1'.astype(str).str.slice(02) ndf2'df2_Start' = df2'company2'.astype(str).str.slice(02)nMerge = pd.merge(df1df2 left_on='df1_Start'right_on='df2_Start')nnnNow I want to have all the rows from FullMerge where company in df1 contains the company in df2. This is because companies in df1 have elongated names. nnMerge1=MergeMerge'company1'.str.contains(Merge'company2'.str)nnnThis isn't working for me. How do I perform this task? Also Please suggest what other ways can I use to match the company names. Because companies might be same in two data frames but are not written in the exactly same way.  n"" 'I think you need | with join for generating all values separated by | (or in regex) for str.contains:nnMerge1=MergeFullMerge'company1'.str.contains(""|"".join(Merge'company2'.tolist())nn'",['pandas'],['pandas']
40115404,"'How can I store a file path in Mysql database using django?' 'I need to store a file path in db using django via ajax form submission . nnHere is my view:nnrnrndef dashboard(request):rn    container=rn    DIR = os.path.realpath(""/home/user/Desktop/Demo"")rn    WAY = os.listdir(DIR)rn    for file in WAY:rn        if file.endswith('.mp4'):rn            file_name = filern            FDIR=os.path.join(DIR file)rn            container.append(FDIR)rn            rn    return render(request 'dashboard.html' {'container': container})rnrnrnnndef new_scheduler(request):n    if request.method =='POST':n        f_name = request.POST.get('file')n        dateAndTime = request.POST.get('dateAndTime')n    Scheduled_data = schedulesdb.objects.create(n            f_name = filen            dateAndTime = dateAndTime  n        )n    Scheduled_data.save()n    return HttpResponse ('done')nnnIt save in database like <type 'file'> .nnHere is my model.py:nnclass schedulesdb(models.Model):n    f_name = models.CharField(max_length=100)n    dateAndTime = models.DateTimeField('%Y-%m-%d %H:%M:%S'null=True)n    user = models.ForeignKey(settings.AUTH_USER_MODEL default=2)n    def __unicode__(self):              #  on Python 2n        return self.f_namennnThanks in advance :)n' 'From your code it's not 100% clear whether you're intending to handle file uploads from the client or simply store strings that happen to be a file path (potentially for locating a file on some remote filesystem).nn1. File uploadsnnConsider using the FileField model field type rather than the CharField.nnThe Django documentation has a solid explanation and examples of how to do simple file uploads.nn2. Obtaining the actual POST data value for the f_name fieldnnYour code sample is storing """" because you're assigning 'file' (which is a builtin type) rather than the f_name variable that you previously declared. Like this:nndef new_scheduler(request):nif request.method =='POST':n    f_name = request.POST.get('file')n    dateAndTime = request.POST.get('dateAndTime')nScheduled_data = schedulesdb.objects.create(n        f_name = f_name # Note the use of f_name instead of filen        dateAndTime = dateAndTime  n    )nScheduled_data.save()nreturn HttpResponse ('done')nn'",['django'],['django']
40115452,"'Error in getting the running median' 'I am trying to get a running median for a number of integers. For example: 6 elements will come one by one let say 1245387  for which running median at each input is 12854.565 respectively. I wrote a python code but it seems to give incorrect answer. Help is appreciated .nnn = int(raw_input().strip())ns=nfor i in xrange(n):n    a=int(raw_input())n    if len(s)==0: n        s.append(a)n        print ""%.1f"" % an    else:n        for j in xrange(len(s)):n            if a<sj:n                s.insert(ja)n        if a>=s-1:n            s.append(a)n        if len(s)%2==0:n            print ""%.1f"" % float((slen(s)/2 + slen(s)/2 -1)/2.0)n        else:n            print  ""%.1f"" % slen(s)/2nn' 'n = int(raw_input().strip())ns=nfor i in xrange(n):n    a=int(raw_input())n    if len(s)==0: n        s.append(a)n        print ""%.1f"" % an    else:n        for j in xrange(len(s)):n            if a<sj:n                s.insert(ja)n                break # inserted this breakn        if a>=s-1:n            s.append(a)n        if len(s)%2==0:n            print ""%.1f"" % float((slen(s)/2 + slen(s)/2 -1)/2.0)n        else:n            print  ""%.1f"" % slen(s)/2nnnThis was the output and input:nn 6n 12n12.0n 4n8.0n 5n5.0n 3n4.5n 8n5.0n 7n6.0nnnThe issue was in your for j in xrange(len(s)) you were inserting as long as a was less then the next value. You didn't just insert once that added more values than you wanted into the list. Adding a break will only insert once at the time it finds the first spot it belongs too. n' 'Read the comments embedded in the code below - nnn = int(raw_input().strip())ns=nfor i in xrange(n):n    a=int(raw_input())n    if len(s)==0:n        s.append(a)n        print ""%.1f"" % an    else:n        for j in xrange(len(s)):n            if a<sj:n                s.insert(ja)n                break  # break after insertion to avoid multiple insertionsn        else:  # Read https://docs.python.org/3/reference/compound_stmts.html#forn            s.append(a)nn        if len(s)%2==0:n            print ""%.1f"" % float((slen(s)/2 + slen(s)/2 -1)/2.0)n        else:n            print  ""%.1f"" % slen(s)/2nnnnnA more Pythonic (sic) way of doing the same - nnimport bisectnnn = int(raw_input().strip())ns=nfor i in xrange(n):n    a=int(raw_input())nn    bisect.insort_left(s a)nn    quotient remainder = divmod(len(s) 2)n    if remainder:n        print  ""%.1f"" % squotientn    else:n        print ""%.1f"" % ((squotient - 1 + squotient)/2.0)nn'",['python-2.7'],"['python-3.x', 'python-2.7', 'list']"
40115565,"'Concisely adding variables to Django context dictionary' ""The Django documentation suggests adding variables to the context dictionary in class based views as follows:nndef get_context_data(self **kwargs):n        # Call the base implementation first to get a contextn        context = super(PublisherDetail self).get_context_data(**kwargs)n        # Add in a QuerySet of all the booksn        context'book_list' = Book.objects.all()n        return contextnnnI often have a lot of variables in my gather context function so my code ends up looking like this:nndef get_context_data(self **kwargs):n        context = super(PublisherDetail self).get_context_data(**kwargs)n        a = 2n        b = 'hello'n        c = 75 # temp variable not wanted in context dictn        d = a * cnn        context'a' = an        context'b' = bn        context'd' = dn        return contextnnnTo avoid adding each variable to the context dictionary on its own line I've begun doing the following:nndef get_context_data(self **kwargs):n        context = super(PublisherDetail self).get_context_data(**kwargs)n        a = 2n        b = 'hello'n        c = 75 # temp variable not wanted in context dictn        d = a * cnn        del c # delete any variables you don't want to addn        context.update({k:v for kv in locals().copy().iteritems() if k:2 != '__' and k != 'context'})n        return contextnnnIt seems to be working but I'm not very familiar with locals(). Is there any reason why I shouldn't be doing it this way?n"" ""Use locals is such a bad idea. Just add to the context directlynndef get_context_data(self **kwargs):n    context = super(PublisherDetail self).get_context_data(**kwargs)n    c = 75 # temp variable not wanted in context dictnn    context'a' = 2n    context'b' = 'hello'n    context'd' = context'a' * cn    return contextnn""","['django', 'dictionary']",['django']
40115598,"'Multiple Pandas DataFrame Bar charts on the same chart' 'How to plot Multiple DataFrame Bar charts on the same chart? nnI want to plot top three scores (or top five). Since I know 1st >= 2nd >= 3rd I want to plot the top three (or five) in the chart on the same bar instead of spreading them out in three (or five) bars.nnThe visual effect will be exactly like the stacked bar but the bars are not stacking on top of each other but measured from the bottom instead. nnnnUPDATE: @DizietAsahi suggested to use stacked bar instead. I guess that's the simplest solution. Can someone provide dataframe manipulation code to get the difference of the scores below please? nnThe source data is in the form of TID and Score just like the following data in CSV format which has been already filtered out so as only top 3 are remaining. The raw data have much more scores for the same TID. The challenge of going this way is that I also need to plot the MEAN score as well as the top three. I.e. I personally think it is impossible to manipulation the MEAN score as well as the top three at the same time to get the differences from below. So either ways have challenges (to me). nnHere is a sample data in CSV format:nnTIDScoren06510n06472n06441n07630n07619n07574n08617n08589n08560n09610n09595n09553n10593n10550n10542n11442n11404n11381nnnIn DataFrame format (only for Multiple DataFrame Bar charts case. For using stacked bar generating a bunch of random numbers as Score for each TID would be fine):nnScores = n{""TID"":07""ScoreRank"":1""Score"":834""Average"":690}n{""TID"":07""ScoreRank"":2""Score"":820""Average"":690}n{""TID"":07""ScoreRank"":3""Score"":788""Average"":690}n{""TID"":08""ScoreRank"":1""Score"":617""Average"":571}n{""TID"":08""ScoreRank"":2""Score"":610""Average"":571}n{""TID"":08""ScoreRank"":3""Score"":600""Average"":571}n{""TID"":09""ScoreRank"":1""Score"":650""Average"":584}n{""TID"":09""ScoreRank"":2""Score"":644""Average"":584}n{""TID"":09""ScoreRank"":3""Score"":618""Average"":584}n{""TID"":10""ScoreRank"":1""Score"":632""Average"":547}n{""TID"":10""ScoreRank"":2""Score"":593""Average"":547}n{""TID"":10""ScoreRank"":3""Score"":577""Average"":547}n{""TID"":11""ScoreRank"":1""Score"":479""Average"":409}n{""TID"":11""ScoreRank"":2""Score"":445""Average"":409}n{""TID"":11""ScoreRank"":3""Score"":442""Average"":409}n{""TID"":12""ScoreRank"":1""Score"":370""Average"":299}n{""TID"":12""ScoreRank"":2""Score"":349""Average"":299}n{""TID"":12""ScoreRank"":3""Score"":341""Average"":299}n{""TID"":13""ScoreRank"":1""Score"":342""Average"":252}n{""TID"":13""ScoreRank"":2""Score"":318""Average"":252}n{""TID"":13""ScoreRank"":3""Score"":286""Average"":252}n{""TID"":14""ScoreRank"":1""Score"":303""Average"":257}n{""TID"":14""ScoreRank"":2""Score"":292""Average"":257}n{""TID"":14""ScoreRank"":3""Score"":288""Average"":257}n{""TID"":15""ScoreRank"":1""Score"":312""Average"":242}n{""TID"":15""ScoreRank"":2""Score"":276""Average"":242}n{""TID"":15""ScoreRank"":3""Score"":264""Average"":242}n{""TID"":16""ScoreRank"":1""Score"":421""Average"":369}n{""TID"":16""ScoreRank"":2""Score"":403""Average"":369}n{""TID"":16""ScoreRank"":3""Score"":398""Average"":369}n{""TID"":17""ScoreRank"":1""Score"":479""Average"":418}n{""TID"":17""ScoreRank"":2""Score"":466""Average"":418}n{""TID"":17""ScoreRank"":3""Score"":455""Average"":418}n{""TID"":18""ScoreRank"":1""Score"":554""Average"":463}n{""TID"":18""ScoreRank"":2""Score"":521""Average"":463}n{""TID"":18""ScoreRank"":3""Score"":520""Average"":463}ndf = pandas.DataFrame(Scores)nnnThanksn' 'Is this what you are looking for? nnimport pandasnimport matplotlib.pyplot as pltnimport numpy as npnScores = n{""TID"":7""ScoreRank"":1""Score"":834""Average"":690}n{""TID"":7""ScoreRank"":2""Score"":820""Average"":690}n{""TID"":7""ScoreRank"":3""Score"":788""Average"":690}n{""TID"":8""ScoreRank"":1""Score"":617""Average"":571}n{""TID"":8""ScoreRank"":2""Score"":610""Average"":571}n{""TID"":8""ScoreRank"":3""Score"":600""Average"":571}n{""TID"":9""ScoreRank"":1""Score"":650""Average"":584}n{""TID"":9""ScoreRank"":2""Score"":644""Average"":584}n{""TID"":9""ScoreRank"":3""Score"":618""Average"":584}n{""TID"":10""ScoreRank"":1""Score"":632""Average"":547}n{""TID"":10""ScoreRank"":2""Score"":593""Average"":547}n{""TID"":10""ScoreRank"":3""Score"":577""Average"":547}n{""TID"":11""ScoreRank"":1""Score"":479""Average"":409}n{""TID"":11""ScoreRank"":2""Score"":445""Average"":409}n{""TID"":11""ScoreRank"":3""Score"":442""Average"":409}n{""TID"":12""ScoreRank"":1""Score"":370""Average"":299}n{""TID"":12""ScoreRank"":2""Score"":349""Average"":299}n{""TID"":12""ScoreRank"":3""Score"":341""Average"":299}n{""TID"":13""ScoreRank"":1""Score"":342""Average"":252}n{""TID"":13""ScoreRank"":2""Score"":318""Average"":252}n{""TID"":13""ScoreRank"":3""Score"":286""Average"":252}n{""TID"":14""ScoreRank"":1""Score"":303""Average"":257}n{""TID"":14""ScoreRank"":2""Score"":292""Average"":257}n{""TID"":14""ScoreRank"":3""Score"":288""Average"":257}n{""TID"":15""ScoreRank"":1""Score"":312""Average"":242}n{""TID"":15""ScoreRank"":2""Score"":276""Average"":242}n{""TID"":15""ScoreRank"":3""Score"":264""Average"":242}n{""TID"":16""ScoreRank"":1""Score"":421""Average"":369}n{""TID"":16""ScoreRank"":2""Score"":403""Average"":369}n{""TID"":16""ScoreRank"":3""Score"":398""Average"":369}n{""TID"":17""ScoreRank"":1""Score"":479""Average"":418}n{""TID"":17""ScoreRank"":2""Score"":466""Average"":418}n{""TID"":17""ScoreRank"":3""Score"":455""Average"":418}n{""TID"":18""ScoreRank"":1""Score"":554""Average"":463}n{""TID"":18""ScoreRank"":2""Score"":521""Average"":463}n{""TID"":18""ScoreRank"":3""Score"":520""Average"":463}nndf = pandas.DataFrame(Scores)nf ax1 = plt.subplots(1 figsize=(105))nbar_width = 0.75nbar_l = i+1 for i in range(len(np.unique(df'TID')))ntick_pos = i+(bar_width/2) for i in bar_lnax1.bar(bar_ln        df'Score'df'ScoreRank' == 1n        width=bar_widthn        label='Rank1'n        alpha=0.5n        color='#eaff0a')nnax1.bar(bar_lnn        df'Score'df'ScoreRank' == 2n        width=bar_widthn        label='Rank2'n        alpha=0.5n        color='#939393')nnax1.bar(bar_ln        df'Score'df'ScoreRank' == 3n        width=bar_widthn        label='Rank3'n        alpha=0.5n        color='#e29024')nnax1.bar(bar_ln        df'Average'df'ScoreRank' == 3n        width=bar_widthn        label='Average'n        alpha=0.5n        color='#FF0000')nnplt.xticks(tick_pos np.unique(df'TID'))nax1.set_ylabel(""Score"")nax1.set_xlabel(""TID"")nplt.legend(loc='upper right')nplt.xlim(min(tick_pos)-bar_width max(tick_pos)+bar_width)nplt.show()nnnresult: nnn'",['matplotlib'],['pandas']
40115608,'How to turn a 1D radial profile into a 2D array in python' 'I have a list that models a phenomenon that is a function of radius. I want to convert this to a 2D array.  I wrote some code that does exactly what I want but since it uses nested for loops it is quite slow.nnl = len(profile1D)/2ncritDim = int((l**2 /2.)**(1/2.))nprofile2D = np.empty(critDim critDim)nfor x in xrange(0 critDim):n    for y in xrange(0critDim):n        r = ((x**2 + y**2)**(1/2.))n        profile2Dxy = profile1Dint(l+r)nnnIs there a more efficient way to do the same thing by avoiding these loops?n' 'Here's a vectorized approach using broadcasting -nna = np.arange(critDim)**2nr2D = np.sqrt(a:None + a)nout = profile1D(l+r2D).astype(int)nnnIf there are many repeated indices generated by l+r2D we can use np.take for some further performance boost like so -nnout = np.take(profile1D(l+r2D).astype(int))nnnRuntime testnnFunction definitions -nndef org_app(profile1DlcritDim):n    profile2D = np.empty(critDim critDim)n    for x in xrange(0 critDim):n        for y in xrange(0critDim):n            r = ((x**2 + y**2)**(1/2.))n            profile2Dxy = profile1Dint(l+r)n    return profile2Dnndef vect_app1(profile1DlcritDim):n    a = np.arange(critDim)**2n    r2D = np.sqrt(a:None + a)n    out = profile1D(l+r2D).astype(int)n    return outnndef vect_app2(profile1DlcritDim):n    a = np.arange(critDim)**2n    r2D = np.sqrt(a:None + a)n    out = np.take(profile1D(l+r2D).astype(int))n    return outnnnTimings and verification -nnIn 25: # Setup input array and paramsn    ...: profile1D = np.random.randint(09(1000))n    ...: l = len(profile1D)/2n    ...: critDim = int((l**2 /2.)**(1/2.))n    ...: nnIn 26: np.allclose(org_app(profile1DlcritDim)vect_app1(profile1DlcritDim))nOut26: TruennIn 27: np.allclose(org_app(profile1DlcritDim)vect_app2(profile1DlcritDim))nOut27: TruennIn 28: %timeit org_app(profile1DlcritDim)n10 loops best of 3: 154 ms per loopnnIn 29: %timeit vect_app1(profile1DlcritDim)n1000 loops best of 3: 1.69 ms per loopnnIn 30: %timeit vect_app2(profile1DlcritDim)n1000 loops best of 3: 1.68 ms per loopnnIn 31: # Setup input array and paramsn    ...: profile1D = np.random.randint(09(5000))n    ...: l = len(profile1D)/2n    ...: critDim = int((l**2 /2.)**(1/2.))n    ...: nnIn 32: %timeit org_app(profile1DlcritDim)n1 loops best of 3: 3.76 s per loopnnIn 33: %timeit vect_app1(profile1DlcritDim)n10 loops best of 3: 59.8 ms per loopnnIn 34: %timeit vect_app2(profile1DlcritDim)n10 loops best of 3: 59.5 ms per loopnn',['numpy'],['numpy']
40115644,'I am making a movie inventory using python in Django.' 'I am passing parameters in URL that parameter will be added in the database. In the parameter there is Name of movies and movie count. Using this list I need to perform rent and return functions. So if I rent that movie the movie count will de duducted from the original list and if i return the movie count will increment.nwhat should I add in rent and return functions and html files. n' nan,['django'],['django']
40115650,'How to add additional tick labels formatted differently in matplotlib' 'I'm having real problems plotting a 2nd line of tick labels on x-axis directly underneath the original ones. I'm using seaborn so I need to add these extra labels after the plot is rendered.nnBelow is what I'm trying to achieve but I'd like the gap between the 2 rows of tick labels to be a bit bigger and make the 2nd row bold and a different colour.nnnnMy attempts involve hacking the existing tick labels and appending the new strings underneath separated by newline:nn            # n_labels is list that has the new labels I wish to plot directlyn            # underneath the 1st rown            locs = ax.get_xticks().tolist()n            labels = x.get_text() for x in ax.get_xticklabels()n            nl = 'n'.join(l n_labelsi) for i l in enumerate(labels)n            ax.set_xticks(locs)n            ax.set_xticklabels(nl)nnnAny ideas? Thank you!n' 'One possibility would be to create a second x-axis on top of the first and adjust the position and xtickslabels of the second x-axis. Check this example in the documentation as a starting point.n',['matplotlib'],['matplotlib']
40115654,"'Sort a list of lists based on an if/else condition in Python 3.5' ""I need to sort a list containing nested lists based on a condition. The condition is: if first index is 0 sort on index nr 7. Then if second index is 0 sort on index nr 8. So the below list (unsorted):nn11 37620 'mat' 'xxx' 1 28.5 0 11 37620 'Arp' 'xxx' 1 28n 10 24210 'Skatt' 'xxx' 2 40 0 0 0 0 0 0 0n 10 37010 'test a' 'xxx' 5 36.75 0 10 37010 '' 'xxx' 7 50.75n 0 0 'mottagare' 'xxx' 3 20.25 0 10 21511 0 0 0 0     n 10 40000 'eld' 'xxx' 5 30.5 0 10 40000 'Oly' 'xxx' 5 30n 10 17060 'bok' 'xxx' 1 28.5 0 0 0 0 0 0 0nnnShould look like this:nn10 17060 'bok' 'xxx' 1 28.5 0 0 0 0 0 0 0n 0 0 'mottagare' 'xxx' 3 20.25 0 10 21511 0 0 0 0n 10 24210 'Skatt' 'xxx' 2 40 0 0 0 0 0 0 0n 10 40000 'eld' 'xxx' 5 30.5 0 10 40000 'Oly' 'xxx' 5 30     n 10 37010 'test a' 'xxx' 5 36.75 0 10 37010 '' 'xxx' 7 50.75n 11 37620 'mat' 'xxx' 1 28.5 0 11 37620 'Arp' 'xxx' 1 28nnnI have tried with a_list.sort(key = itemgetter(0)) and lambda but the zero's always end up first. I have solved this by bubble sort but it is awfully slow already with 6000 elements in the lists. I paste the bubblesort below for reference. The list zero values are originally None but for sorting in Python 3 I have converted them to int 0.nnthe_list_pos = 0nfor key value in kund_dict2.items():n    # Start sorting from the whole list since the_list_pos is zeron    for passnum in range(len(komplett_lista)-1the_list_pos-1):n        # Loop the list one by onen        for i in range(passnum):n            # If these helper variables are None at the end nothing happensn            comp1 = Nonen            comp2 = Nonen            # Check that the variables to compare are not None and set them to appropiate valuesn            if komplett_listai0 is not None and komplett_listai0 == key:n                comp1 = komplett_listai1n            elif komplett_listai7 is not None and komplett_listai7 == key:n                comp1 = komplett_listai8   n            if komplett_listai+10 is not None and komplett_listai+10 == key:n                comp2 = komplett_listai+11n            elif komplett_listai+17 is not None and komplett_listai+17 == key:n                comp2 = komplett_listai+18n            # Do the actual sortingn            if comp1 is not None and comp2 is not None:    n                if comp1 > comp2:n                    temp = komplett_listain                    komplett_listai = komplett_listai+1n                    komplett_listai+1 = tempn    # update the position so that we do not sort over the already sorted datan    the_list_pos += (value)nnnAny advices to solve this is greatly appreciated!n"" 'Write a function to contain your logic for finding which column to sort on:nndef sort_col_value(row):n    # if first index is 0 sort on index nr 7. n    if row0 == 0:n        return row7n    # Then if second index is 0 sort on index nr 8n    if row1 == 0:n        return row8n    return row0nnnthen use this function as the key parameter:nnmylist.sort(key=sort_col_value)nn'",['list'],['list']
40115710,"""How to block specific django app's url"" ""I'm using the AllAuth plugin. nnIs there a proper way to block only a part of it's urls?n"" nan",['django'],['django']
40115725,"'MatPlotLib is very slow in python' 'import matplotlibnmatplotlib.use('TkAgg')ndef generate_graph(selfsubjecttargetfilename):n    x_data = range(0 len(self.smooth_hydro))n    mslen = len(i1 for i in self.master_seq.items()0)n    diff=(mslen-len(self.smooth_hydro))/2n    x1_data = range(0len(self.smooth_groups.items()0-1))n    x2_data = range(0mslen)n    plt.figure()n    plt.axhline(y=0 color='black')n    plt.ylim(-3 3)n    plt.xlim(right=mslen)n    plt.plot(x_data self.smooth_hydro linewidth=1.0 label=""hydrophobicity"" color='r')n    plt.plot(x_data self.smooth_amphi linewidth=1.0 label=""amphipathicity"" color='g')n    for pos in self.hmmtop:n        plt.axvline(x=pos-1-diff ymin=-2 ymax = 0.1 linewidth=1 color='black'alpha=0.2)nn    plt.axvspan(subject0-diffsubject1-diff facecolor=""orange"" alpha=0.2)n    plt.axvspan(target0-difftarget1-diff facecolor=""orange"" alpha=0.2)nn    plt.legend(loc='upper center' bbox_to_anchor=(0.5 1.05)n              ncol=3 fancybox=True shadow=True)n    plt.xlabel(""Residue Number"")n    plt.ylabel(""Value"")n    width = (0.0265)*len(self.master_seq0) if mslen > 600 else 15n    plt.grid('on')n    plt.savefig(self.out+'/graphs/'+filename+'.png')n    plt.clf()n    plt.cla()n    plt.close()nnnI am calling this function repeatedly but the images generated are extremely slow. Can someone please help me optimize this code so that it can run faster?nnThank you!n' 'I found this answer in another post. All credit to Luke.nnn  Matplotlib makes great publication-quality graphics but is not veryn  well optimized for speed. There are a variety of python plottingn  packages that are designed with speed in mind:n  n  n  http://pyqwt.sourceforge.net/  edit: pyqwt is no longern  maintained;the previous maintainer is recommending pyqtgraph n  http://code.google.com/p/guiqwt/n  http://code.enthought.com/projects/chaco/ n  http://www.pyqtgraph.org/n  nn'",['matplotlib'],['matplotlib']
40115727,"'Deleting cookies and changing user agent in Python 3+ without Mechanize' ""How do I delete cookies from a web browser and change the user agent in Python 3+ without using mechanize? I'm not going to be accessing the web through Python I would just like my browser (Firefox or Chrome) to delete cookies and change my user agent for example at every startup (I can do the startup bit just not the rest!)n"" 'set the Expires attribute to a date in the past (like Epoch):nnSet-Cookie: name=val; expires=Thu 01 Jan 1970 00:00:00 GMTnnnRead more here:nCorrect way to delete cookies server-siden'",['python-3.x'],"['python-3.x', 'python-2.7']"
40115743,"'Importing QtGui from pyqtgraph.Qt as *' ""I am trying to insert a graph in my PySide GUI using pyqtgraph.nnObjective: keep using wildcard imports for PySide while obeying pyqtgraphs import rules.nnApparently PySide.QtCore and PySide.QtGui needs to be imported through pyqtgraph for the package to work properly. In the example its written like this:nnfrom pyqtgraph.Qt import QtCore QtGuinnnTypically I import the PySide components as:nnfrom PySide.QtCore import *nfrom PySide.QtGui  import *nnnNotice the wildcard import statement. The problem is that the following throws an exception on import (ImportError: No module named QtGui):nnfrom pyqtgraph.Qt.QtCore import *nfrom pyqtgraph.Qt.QtGui  import *nnnIs there a way around this? I would prefer not to have to go back into my code and replaces all the self.clock_timer = QTimer() with self.clock_timer = QtCore.Timer() statements.nnShort Cut: If I could avoid going through pyqtgraph to import QtCore and QtGui that would be even better. When I try to use do it (using the first import style) certain features (e.g. AutoPan) don't work.n"" nan",['python-2.7'],['python-2.7']
40115781,"'if i run this script for finding GTIN-8 number it does not accept my answer even when it is 7 numbers - it used to work before' 'try:n    product_code =( input(""enter your product code( 7 numbers )""))n    if len(product_code) == 7:n        digit (product_code)n        creator (product_code)n        product_code = Truen    else:n        print (""your product code is either too long or short"")n        product_code = Falsenexcept ValueError:n        print (""please enter a valid product code number"")n        product_code = Falsenn' nan",['python-3.x'],['python-2.7']
40116025,"'Append each line in file' 'I want to append each line in file in python For example:nnFile.txtnnIs it funny?nIs it dog?nnnExpected ResultnnIs it funny? YesnIs it dog? NonnnAssume that YES No is given. I am doing in this way:nnwith open('File.txt' 'a') as w:n            w.write(""Yes"")nnnBut it appends at the end of file. Not on every line.nnEdit 1nnwith open('File.txt' 'r+') as w:n            for line in w:n                w.write(line + "" Yes "")nnnThis is giving the resultnnIs it funny?nIs it dog?Is it funny?n Yes Is it dog? Yes nnnI do not need this.It is adding new line with appended string.nI need nnIs it funny? YesnIs it dog? Nonn' 'Here is a solution that copies existing file content to a temp file. Modifies it as per needs. Then writes back to original file.nInspiration from herennimport tempfile    nnfilename = ""c:tempFile.txt""nn#Create temporary filent = tempfile.NamedTemporaryFile(mode=""r+"")nn#Open input file in read-only modeni = open(filename 'r')nn#Copy input file to temporary filenfor line in i:n  #For ""funny"" add ""Yes""n  if ""funny"" in line:n      t.write(line.rstrip() + ""Yes"" +""n"")n  #For ""dog"" add ""No""n  elif ""dog"" in line:n      t.write(line.rstrip() + ""No"" +""n"")nnni.close() #Close input filennt.seek(0) #Rewind temporary filenno = open(filename ""w"")  #Reopen input file writablenn#Overwriting original file with temp file contents          nfor line in t:n   o.write(line)  nnt.close() #Close temporary filenn' 'You can write to a tempfile then replace the original:nnfrom tempfile import NamedTemporaryFilenfrom shutil import movendata = ""Yes"" ""No""nwith open(""in.txt"") as f NamedTemporaryFile(""w""dir=""."" delete=False) as temp:n    # pair up lines and each stringn    for arg line in zip(data f):n        # remove the newline and concat new datan        temp.write(line.rstrip()+"" {}n"".format(arg))nn# replace original filenmove(temp.name""in.txt"")nnnYou could also use fileinput with inplace=True:nnimport fileinputnimport sysnfor arg line in zip(data fileinput.input(""in.txt""inplace=True)):n    sys.stdout.write(line.rstrip()+"" {}n"".format(arg))nnnOutput:nnIs it funny? YesnIs it dog? Nonn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40116054,"'Combining two dicts' 'I have 2 collections from mongodb that I want represented on a single table. I'm having trouble doing this and was able to generate both collections in two separate tables by creating two dictionaries and outputting them to two separate html tables. My code basically works like this:nnIn Python (WSGI):nnhtml_dict = {}nhtml_dict'tableData' = getTableData(....) # Gets all the data I need and returns it as table_dict for the first collectionnhtml_dict'tableData' = getTableData2(..) # Same thing but for the second collectionnnnSomething to note is that both collections don't really share all the same key words except for a few. The main one is 'id' which is used to sort it numerically (highest to lowest)(also the id is unique). The html table is built like this: nn<table class=""table table-bordered"" id=""enhanced"">n  <thead>n    <!-- First Header -->n    <tr>n    {% for item colspan in html_dict'tableData''header''firstRow' %}n      <td colspan=""{{ colspan }}"">{{ item }}</td>n    {% endfor %}n    </tr>n    <!-- Second Header -->n    <tr>n      {% for item in html_dict'tableData''header''secondRow' %}n        <td>{{ item }}</td>n      {% endfor %}n    </tr>n  </thead>n  <tbody>n    {% for row in html_dict'tableData''body' %}n        <tr>n            {% if row.action == 'dash' %}n                <td>-</td>n                {{ fillIdCell(row.baseColorrow.baseNumberrow.baseIdrow.baseDate) }} n                {{ fillSourceControl(row.baseHash row.baseAuthor row.baseIssues row.baseComment) }}n            {% elif row.action == 'skipOuterColumn' %}n                <!-- Don't add td-->n                {{ fillIdCell(row.baseColorrow.baseNumberrow.baseIdrow.baseDate) }} n                {{ fillSourceControl(row.baseHash row.baseAuthor row.baseIssues row.baseComment) }}n            {% elif row.action == 'rowSpan' %}n                {{ fillIdCell(row.outerColorrow.outerNumberrow.outerIdrow.outerDaterowSpan=row.outerRowSpan) }} n                {{ fillIdCell(row.baseColor row.baseNumber row.baseId row.baseDate) }}n                {{ fillSourceControl(row.baseHash row.baseAuthor row.baseIssues row.baseComment) }}n            {% else %}n            {% endif %}n        </tr>n    {% endfor %}n  </tbody>nnnnnIs there any way to combine these two dictionaries and sort them such that only one table could be generated (rather than two)?nnJust so you know how the two collections differ. Collection 1 may look like this:nn{n""_id"" : ObjectId(""5642c2f04e79869012edaa5b"")n""__v"" : 0n""defaultBranch"" : truen""id"" : 754318n""number"" : 933n""state"" : ""finished""n""status"" : ""SUCCESS""nnn}nnand collection 2: nn{n""_id"" : ObjectId(""57fd3d132cf4dd220c8c154f"")n""status"" : ""pending""n""branchName"" : ""develop""n""number"" : ""918""n""id"" : ""1249604""nnn}nnWhere I want it to be sorted by their ""number"" values.nnThe sample output of the two dicts merged would be nn{'baseColor': 'success' 'baseHash': u'de7abdf' 'baseId': 1256123 'baseNumber': u'938''baseDate': '2016-10-19 20:22:12'}n{'baseColor': 'success' 'baseHash': u'e8eff08' 'baseId': 1256080 'baseNumber': u'908' 'baseDate': '2016-10-19 20:22:12'}n{'baseColor': 'warning' 'baseId': u'1249990' 'action': 'skipOuterColumn' 'baseNumber': u'922' 'BranchName': u'develop' 'baseStatus': u'pending'}n{'baseColor': 'warning' 'baseId': u'1249604' 'action': 'skipOuterColumn' 'baseNumber': u'918' 'BranchName': u'develop' 'baseStatus': u'pending'}nnnIf you notice the two top ones are from collection 1 and the lower ones are of collection 2. I want them to be order based off 'baseNumber' but that should technically be how the output is of the combined dict.n' nan",['dictionary'],"['dictionary', 'python-2.7']"
40116065,"'python pandas - how can I map values in 1 dataframe to indices in another without looping?' 'I have 2 dataframes - ""df_rollmax"" is a derivative of ""df_data"" with the same shape. I am attempting to map the values of df_rollmax back to df_data and create a third df (df_maxdates) which contains the dates at which each value in df_rollmax originally showed up in df_data.nnlist1 = 21101221102511324112211092810830102261062511124110ndf_data = pd.DataFrame(list1index=pd.date_range('2000-1-1'periods=10 freq='D') columns=list('AB'))ndf_rollmax = pd.DataFrame(df_data.rolling(center=Falsewindow=5).max())nmapA = pd.Series(df_data.index index=df_data'A')nnnFrom a previous question I see that a single date can be found with:nnmapArollmax.ix'j''A' returns Timestamp('2000-01-07 00:00:00')nnBut my real dataset is much larger and I would like to fill the third dataframe with dates without looping over every row and column.nnMapping back to the indices is a problem due to: ValueError: cannot reindex from a duplicate axis so this isn't working...nndf_maxdates = pd.DataFrame(index=df_data.index columns=df_data.columns)nfor s in df_data.columns:n    df_maxdatess = mapA.locdf_rollmaxsnnnUsing the last instance of the duplicate value would be fine but df.duplicated(keep='last') isn't cooperating. nnGreatly appreciate any and all wisdom.nnLink to original questionnnUpdate - this is what df_maxdates would look like:nnn' 'You can use this BrenBarn's solution:nnW = 5  # window sizenndf = pd.DataFrame(columns=df_data.columns index=df_data.indexW-1:)nnfor col in df.columns.tolist():n    dfcol = df_data.indexdf_datacol.rolling(W)n                                    .apply(np.argmax)(W-1):n                                    .astype(int)n                             +n                             np.arange(len(df_data)-(W-1))nndf = pd.DataFrame(columns=df_data.columns index=df_data.index:W-1).append(df)nnIn 226: dfnOut226:n                    A          Bn2000-01-01        NaT        NaTn2000-01-02        NaT        NaTn2000-01-03        NaT        NaTn2000-01-04        NaT        NaTn2000-01-05 2000-01-03 2000-01-03n2000-01-06 2000-01-06 2000-01-03n2000-01-07 2000-01-07 2000-01-03n2000-01-08 2000-01-07 2000-01-04n2000-01-09 2000-01-07 2000-01-09n2000-01-10 2000-01-07 2000-01-09nnnor this piRSquared's solution:nndef idxmax(s w):n    i = 0n    while i + w <= len(s):n        yield(s.iloci:i+w.idxmax())n        i += 1nnx = pd.DataFrame({'A':np.nan*4 + list(idxmax(df_data.A 5))n                  'B':np.nan*4 + list(idxmax(df_data.B 5))}n                 index=df_data.index)nnnDemo:nnIn 89: x = pd.DataFrame({'A':pd.to_datetime(np.nan*4 + list(idxmax(df_data.A 5)))n    ...:                   'B':pd.to_datetime(np.nan*4 + list(idxmax(df_data.B 5)))}n    ...:                  index=df_data.index)n    ...:nnIn 90: xnOut90:n                    A          Bn2000-01-01        NaT        NaTn2000-01-02        NaT        NaTn2000-01-03        NaT        NaTn2000-01-04        NaT        NaTn2000-01-05 2000-01-03 2000-01-03n2000-01-06 2000-01-06 2000-01-03n2000-01-07 2000-01-07 2000-01-03n2000-01-08 2000-01-07 2000-01-04n2000-01-09 2000-01-07 2000-01-09n2000-01-10 2000-01-07 2000-01-09nn'",['pandas'],['pandas']
40116099,"'Sum values in dictionary' ""I'm working with an Excel file and openpyxl.nnBelow is sample data:nnName    ValuenAmy1    4nBob1    5nBob1    5nBob2    8nChris1  7nChris2  3nChris3  6nChris3  6nChris3  6nnnUsing the for loop below I grab the value associated with each unique name.nnfor rowNum in range(2 11):n    person = sheet.cell(row = rowNum column = 13).valuen    people.append(person)n    personValue.update({person: sheet.cell(row = rowNum column = 26).value})nnnThat yields a dictionary with a single entry for each name (Amy1 Bob1 Bob2 etc.).nnI want to merge and sum the value for each matching name to return the following result:nnName  ValuenAmy   4nBob   13nChris 16nn"" ""You can use the get() method to set a default value for a key and then add to it that way.nnSince all of your keys are in the format name# you can get the end result you want like this:nnmergedResult = dict()nnfor name in startingDict:n    mergedResultname:-1 = mergedResult.get(name:-1 0) + startingDictnamennnHere the get() method checks for a key name:-1 (the name from your starting dictionary without the final character) in your result dictionary. If that key isn't present it adds it with a default value of 0 and returns that value. If that key is already present it simply returns the corresponding value. Then the value from your starting dictionary is added to the value in your result dictionary.n"" ""If name = sheet.cell(row = rowNum column = 13).valuennAnd value =  sheet.cell(row = rowNum column = 26).valuennEdited according to your comments:nnfrom collections import defaultdictnnpeople = defaultdict(int)ncategory = defaultdict(int)nnfor rowNum in range(2 11):n    # Name with numbern    person = sheet.cell(row = rowNum column = 13).valuen    # Name without numbern    category_name = ''.join(c for c in person if not c.isdigit())n    peopleperson += sheet.cell(row = rowNum column = 26).valuen    categorycategory_name += sheet.cell(row = rowNum column = 26).valuennnResult - people:nnName    ValuenAmy1    4nBob1    10nBob2    8nChris1  7nChris2  3nChris3  18nnnResult - category:nnName    ValuenAmy     4nBob     18nChris   28nnnThis will work.nnThanks Padraic Cunningham.nI just realized what i misunderstood.n""","['list', 'dictionary']","['dictionary', 'python-2.7']"
40116126,"'How to apply a short FIR low-pass filter in Python' 'I am trying to implement something similar to what is detailed in this comment (https://github.com/scipy/scipy/issues/4940#issuecomment-109952602) (reposted here):nnn  Anyway a spike-train coded as a sum of delta functions is an analog signal. So when you bin the signal into rate or count histograms you will introduce aliasing and your binning noise is the aliasing. The theory is explained in the classical French and Holden (1971) paper though it is uncommon to use their ""exact"" anti-alias filter for reasons of efficiency. The easiest solution is to convolve each delta-function spike with a short FIR low-pass filter before you sample the spike train. http://link.springer.com/article/10.1007/BF00291117nnnI haven't figured out how to accomplish this. I looked into various NumPy and SciPy functions but they all assume you know what you're doing :)n' nan",['numpy'],['numpy']
40116219,"'Sum of several columns from a pandas dataframe' ""So say I have the following table:nnIn 2: df = pd.DataFrame({'a': 123 'b':246 'c':111})nnIn 3: dfnOut3: n   a  b  cn0  1  2  1n1  2  4  1n2  3  6  1nnnI can sum a and b that way:nnIn 4: sum(df'a') + sum(df'b')nOut4: 18nnnHowever this is not very convenient for larger dataframe where you have to sum multiple columns together.nnIs there a neater way to sum columns (similar to the below)? What if I want to sum the entire DataFrame without specifying the columns?nnIn 4: sum(df'a' 'b') #that will not work!nOut4: 18nIn 4: sum(df) #that will not work!nOut4: 21nn"" 'I think you can use double sum - first DataFrame.sum create Series of sums and second Series.sum get sum of Series:nnprint (df'a''b'.sum())na     6nb    12ndtype: int64nnprint (df'a''b'.sum().sum())n18nnnYou can also use:nnprint (df'a''b'.sum(axis=1))n0    3n1    6n2    9ndtype: int64nnprint (df'a''b'.sum(axis=1).sum())n18nnnThank you pirSquared for another solution - convert df to numpy array by values and then sum:nnprint (df'a''b'.values.sum())n18nnnnnprint (df.sum().sum())n21nn'",['pandas'],['pandas']
40116421,"'Django ""module 'portal.views' has no attribute 'MyAccount'""' ""I just made another class based view in Django and it apparently isn't being imported in urls.py which is confusing. I even simplified it by making the view just a def.nnviews.py:nnfrom django.shortcuts import rendernfrom django.views import genericnfrom django.contrib.auth.decorators import login_requirednfrom django.utils.decorators import method_decoratornnfrom django.contrib.auth.models import Usernfrom .models import RxgAssetnn# Create your views here.nndef index(request):n    return render(request 'index.html')nn@method_decorator(login_required name='dispatch')nclass GregAssets(generic.ListView):n    template_name = 'greg_assets.html'n    context_object_name = 'greg_assets'nn    def get_queryset(self):n        if self.request.user.is_superuser:n            return GregAsset.objects.order_by('id')n        else:n            return GregAsset.objects n                .filter(organization=self.request.user.employee.organization) n                .order_by('id')nnclass GregShowAsset(generic.DetailView):n    model = GregAssetn    template_name = 'greg_show_asset.html'n    context_object_name = 'greg_asset'nn    def get_object(self queryset=None):n        asset = GregAsset.objects.get(id=self.kwargs'pk')n        if self.request.user.is_superuser:n            return assetn        else:n            if self.request.user.employee.organization == asset.organization:n                return assetn            else:n                return Nonenndef MyProfile(request):n    return render(request 'index.html')nnnurls.py:nfrom django.conf.urls import urlnfrom portal import viewsnnurlpatterns = nnurl(r'^$' views.index name='index')nurl(r'^rxg_assets/$' views.RxgAssets.as_view() name='rxg_assets')nurl(r'^rxg_assets/(?P<pk>0-9+)/$' views.RxgShowAsset.as_view() name='rxg_show_asset')nurl(r'^my_account/$' views.MyAccount.as_view() name='my_account')nnnnOutput:nnAttributeError at /portal/my_account/nmodule 'portal.views' has no attribute 'MyAccount'nRequest Method: GETnRequest URL:    https://www.website.com/portal/my_account/nDjango Version: 1.10.2nException Type: AttributeErrornException Value:    nmodule 'portal.views' has no attribute 'MyAccount'nException Location: /server/apache/partner/portal/urls.py in <module> line 8nPython Executable:  nPython Version: 3.5.2nPython Path:    n'/server/apache/partner'n '/server/apache/partner-env/lib/python3.5/site-packages'n '/usr/local/lib/python35.zip'n '/usr/local/lib/python3.5'n '/usr/local/lib/python3.5/plat-freebsd11'n '/usr/local/lib/python3.5/lib-dynload'n '/usr/local/lib/python3.5/site-packages'nServer time:    Tue 18 Oct 2016 19:17:27 +0000nn"" ""MyProfile != MyAccount. Thanks Daniel I don't know why I didn't see that.nn-gnsn""",['django'],['django']
40116432,"'pyinstaller: matplotlib font cache changes to /var/folders in generated app' ""I'm running pyinstaller 3.3.dev0+gb78bfe5 (which is current as of this writing) and seeing something strange: when I run the one-directory version of my app I get a warning that matplotlib is rebuilding the font cache but not when I run the app directly in python.nnBy printing mpl.get_cachedir() I see that the pyinstaller-built version sees the cache dir in /var/folders/.... (the basename of which changes each run) rather than in ~/.matplotlib. Obviously a cache whose path changes on each isn't a very helpful optimization... nnWhen I run the app directly in python the cache dir is ~/.matplotlib. If I remove the cache the first time I run the app (directly via python) I get the message and then no more on subsequent runs as expected.nnI see that TMPDIR is (automatically apparently) set to /var/folders/9t/31_qw25565vdmzbtdsdlnh340000gn/T/ which indeed is the parent of the (ever changing) cache dir. What's puzzling is why matplotlib in one case uses this and in the other case uses the standard cache dir. Could the pyinstaller build be picking up a different version of matplotlib or is this an env var issue? Or something else peculiar to pyinstaller?nnFWIW I'm running on Mac OS 10.10.5 (Yosemite) and python 2.7.11 via Anaconda.n"" nan",['matplotlib'],['matplotlib']
40116437,"'Having trouble rewriting code to list comprehension for image rotation in python' ""So after not finding my problem here on stackoverflow which is how to rewrite a for-loop to a list comprehension where values are inserted I have to ask now if it possible to rewrite this code:nnrotate = np.zeros((whc) np.uint8) # create an empty image filled with zeros turned 90Â°nnfor y in xrange(h):n    for x in xrange(w):n        rotatexy = imgyxnnninto list comprehension? I thought something like this would work but it didn't:nnrotatexy = imgyx for y in range(h) for x in range(w) nnnafter that I just played around with various combinations of adding indexes and brackets and I always got some syntax errors. Just for the record I know that there are functions for rotation of images in opencv and in numpy I'm just interested in rewriting the  for-loop to list-comprehension.n"" 'rotate = np.array(imgyx for y in xrange(h) for x in xrange(w))nn'",['numpy'],"['list', 'python-2.7']"
40116461,"'Django -- Form Field on change' 'I'm using Django forms to display data.nnThere is a HTML select field - which has 2 options a) teachers and b) Students.nnDjango forms:- nnself.fields'account_type'.choices = ('student''Student')('teacher' 'Teacher')nnself.helper.layout = Layout(n                    HTML('''<h5>Sign Up Information</h5>''')n                    Div(n                        Field('account_type' placeholder=""Account Type"" css_class='form-control')n                        css_class = 'form-group'n                    )            nnnBased on whether you select ""Student"" or ""Teacher"" you need auto populate another field - topics. How can I fire the 'onchange' event in Django forms.n' 'It looks like you are using Django Crispy forms and not plain Django forms.nnIf you want to set the onchange attribute you should be able to just pass that as a keyword argument as described in the docs.nnField('account_type'n      placeholder=""Account Type""n      css_class='form-control'n      onchange=""myChangeHander()""n)nnnA better way would be to give that element an id and to attach an event in JavaScript.nnField('account_type'n      placeholder=""Account Type""n      css_class='form-control'n      css_id=""account_type_id""n)nnnAssuming you use jQuery you would put something like this somewhere in a <script> tag or JavaScript file:nn$(""#account_type_id"").on(""change"" function() {...});      nn'",['django'],['django']
40116573,"'rq error on heroku rq.exceptions.UnpickleError: ('Could not unpickle' AppRegistryNotReady(""Models aren't loaded yet.""))' 'I'm trying to pass a function to the worker on heroku but got an error message below. Can anyone help me resolve this error? Thanks in advance! I'm using django 1.10.2 and python 3.5.2nnrq.exceptions.UnpickleError: ('Could not unpickle' AppRegistryNotReady(""Models aren't loaded yet.""))nnnMy worker.py is in the same folder as manage.py.nnimport osnos.environ.setdefault(""DJANGO_SETTINGS_MODULE"" ""myapp.settings"")nnimport redisnfrom rq import Worker Queue Connectionnnlisten = 'high' 'default' 'low'nnredis_url = os.getenv('REDISTOGO_URL' 'redis://localhost:6379')nnconn = redis.from_url(redis_url)nnif __name__ == '__main__':n    with Connection(conn):n        worker = Worker(map(Queue listen))n        worker.work()nnnHere is the main.py function related to the worker:nnfrom myapp.models import Mymodeln...... nmyobject = Mymodel()nqueue = Queue(connection = conn)  # heroku workernresult = queue.enqueue(myfunction myobject)n......nnnMyfunction is defined in utility.py:nnfrom myapp.models import Mymodelnndef myfunction(myobject):n......nnnThe model_object is the model object. nnMy wsgi.py file.nnimport osnfrom django.core.wsgi import get_wsgi_applicationnnos.environ.setdefault(""DJANGO_SETTINGS_MODULE"" ""cnpsop.settings"")nnapplication = get_wsgi_application()nn' nan",['django'],['django']
40116648,"'How to use a variable to find another variable in a list - python' '(Python 3.x)nnz=nx=0nwhile 1==1:n    x=x+1n    y=1n    z.append(x)n    while y==1:n        a = 0n        b = 0n        if z(a)==x:n            print(x)n            y = 2n        elif x%z(a)!= 0:n            a = a+1n        elif b == 2:n            y = 2n        else:n            b = b+1nnnSo I made a code to find all the prime numbers until python crashes. However it relies on z(a) for it to work. The idea is that as ""a"" changes it moves on in the list. nn""z(a)"" is where the error lies so does anyone know a way to fix this?n' ""z is a list. You can approach values inside it by indexes using the za operator (and not z(a) which assumes a function call with a as parameter).nnnnI've took the liberty of using boolean variables += operators and unpacking values:nnz = nx = 0nwhile True:n    x += 1n    y = Truen    z.append(x)n    while y:n        a b = 0 0n        if za == x:n            print(x)n            y = Falsen        elif x % za: a += 1n        elif b == 2: y = Falsen        else: b += 1nnnnnI believe that's what you want to achieve (infinitely incrementing prime generator):nndef prime (n): return not any(n % i == 0 for i in range(2 n))nx = 0nwhile True:n    if prime(x): print(x)n    x += 1nn""",['python-3.x'],"['list', 'python-3.x', 'python-2.7']"
40116923,"'How to search the entire HDD for all pdf files?' ""As the title suggests I would like to get python 3.5 to search my root ('C:')nfor pdf files and then move those files to a specific folder.nThis task can easily split into 2: n1. Search my root for files with the pdf extension.n2. Move those to a specific folder.nnNow. I know how to search for a specific file name but not plural files that has a specific extension. nnimport osnnprint('Welcome to the Walker Module.')nprint('find(name path) or find_all(name path)')nndef find(name path):nfor root dirs files in os.walk(path):n    print('Searching for files...')n    if name in files:n        return os.path.join(root name)nndef find_all(name path):nresult = nfor root dirs files in os.walk(path):n    print('Searching for files...')n    if name in files:n        result.append(os.path.join(root name))nreturn resultnnnThis little program will find me either the 1st or all locations of a specific file. nI however can not modify this to be able to search for pdf files due to the lack of knowledge with python and programming in general.nnWould love to have some kind of insight on where to go from here. nnTo sum it up nnnSearch the root for all pdf files. nMove those files into a specific location. Lets say 'G:Books'nnnThanks in advance. n"" 'Your find_all function is very close to the final result.nWhen you loop through the files you can check their extension with os.path.splitext and if they are .pdf files you can move them with shutil.movennHere's an example that walks the tree of a source directory checks the extension of every file and in case of match moves the files to a destination directory:nnimport osnimport shutilnnndef move_all_ext(extension source_root dest_dir):n    # Recursively walk source_rootn    for (dirpath dirnames filenames) in os.walk(source_root):n        # Loop through the files in current dirpathn        for filename in filenames:n            # Check file extensionn            if os.path.splitext(filename)-1 == extension:n                # Move filen                shutil.move(os.path.join(dirpath filename) os.path.join(dest_dir filename))nnn# Move all pdf files from C: to G:Booksnmove_all_ext("".pdf"" ""C:"" ""G:Books"")nn' 'You can use glob from python 3.5 onwards. It supports a recursive search.nnn  If recursive is true the pattern âx80x9c**âx80x9d will match any files and zero or more directories and subdirectories. If the pattern is followed by an os.sep only directories and subdirectories match.nnnTherefore you can use it likennimport globnfrom os import pathnimport shutilnndef searchandmove(wild srcpath destpath):nn    search = path.join(srcpath'**' wild)nn    for fpath in glob.iglob(search recursive=True):n        print(fpath)n        dest = path.join(destpath path.basename(fpath))n        shutil.move(fpath dest)nnsearchandmove('*.pdf' 'C:' 'G:Books')nnnWith a minimum of string wrangling. For large searches however such as from the root of a filesystem it can take a while but I'm sure any approach would have this issue. nnTested only on linux but should work fine on windows. Whatever you pass as destpath must already exist.n'",['python-3.x'],['python-3.x']
40116937,"'How can I extract the information I want using this RegEx or better?' 'So here's the Regular Expression I have so far.nnr""(?s)(?<=(A-G1-3)).*?(?=A-G1-3|$)""nnIt looks behind for a letter followed by a number between A-G and 1-3 as well as doing the same when looking ahead. I've tested it using Regex101.nHere's what it returns for each matchnnThis is the string I'm testing it againstnn""A1 **ACBFEKJRQ0Z+-** F2 **.12STLMGHD** F1 **9)(** D2 **!?56WXP** C1 **IONVU43""'** E1 **Y87><** A3 **-=.'""!?><()@**""nnn(the string shouldn't have any spaces but I needed to embolden the values between each Letter followed by a number so it is easier to see what I want)nnWhat I want it to do is store the values between each of the matches for the group (The ""Full Matches"") and the matches for the group they coincide with to use later.nnIn the end I would like to end up with either a list of tuples or a dictionary for example:nndict = {""A1"":""ACBFEKJRQ0Z+-"" ""F2"":""12STLMGHD"" ""F1"":""9)("" ""next group match"":""characters that follow""}nnnornnlist_of_tuples = (""A1""""ACBFEKJRQ0Z+-"" ""F2""""12STLMGHD"" ""F1""""9)("" ""next group match""""characters that follow"")nnnThe string being compared to the RegEx won't ever have something like ""C1F2"" btwnnP.S. Excuse the terrible explanation any help is greatly appreciatedn' 'I suggestnn(?s)(A-G1-3)((?:(?!A-G1-3).)*)nnnSee the regex demonnThe (?s) will enable . to match linebreaks (A-G1-3)  will capture the uppercase letter+digit into Group 1 and ((?:(?!A-G1-3).)*) will match all text that is not starting the uppercase letter+digit sequence.nnThe same regex can be unrolled as (A-G1-3)(^A-G*(?:A-G(?!1-3)^A-G*)*) for better performance (no re.DOTALL modifier or (?s) is necessary with it). See this demo.nnPython demo:nnimport renregex = r""(?s)(A-G1-3)((?:(?!A-G1-3).)*)""ntest_str = """"""A1 ACBFEKJRQ0Z+-F2.12STLMGHDF19)(D2!?56WXPC1IONVU43""'E1Y87><A3-=.'""!?><()@""""""ndct = dict(re.findall(regex test_str))nprint(dct)nn'",['regex'],['regex']
40116968,"'Colorbar/plotting issue? ""posx and posy should be finite values""' 'The problemnnSo I have a lat-lon array with 6 layers (array.size = (1922886)) containing a bunch of data ranging in values from nearly 0 to about 0.65. When I plot data from every one of the 6 layers (::0 ::1 etc.) I have no problems and get a nice map except for ::4. For some reason when I try to plot this 2D array I get an error message I don't understand and it only comes up when I try to include a colorbar. If I nix the colorbar there's no error but I need that colorbar...nnThe codennHere's the code I use for a different part of the array along with the resulting plot. Let's go with ::5.nn#Set labelsnlonlabels = '0''45E''90E''135E''180''135W''90W''45W''0'nlatlabels = '90S''60S''30S''Eq.''30N''60N''90N'nn#Set cmap propertiesnbounds = np.array(00.0010.010.050.10.20.30.40.50.6)nboundlabels = '0''0.001''0.01''0.05''0.1''0.2''0.3''0.4''0.5''0.6'ncmap = plt.get_cmap('jet')nnorm = colors.PowerNorm(0.35vmax=0.65) #creates logarithmic scalenn#Create basemapnfigax = plt.subplots(figsize=(15.10.))nm = Basemap(projection='cyl'llcrnrlat=-90urcrnrlat=90llcrnrlon=0urcrnrlon=360.lon_0=180.resolution='c')nm.drawcoastlines(linewidth=2color='w')nm.drawcountries(linewidth=2color='w')nm.drawparallels(np.arange(-909030.)linewidth=0.3)nm.drawmeridians(np.arange(-180.180.45.)linewidth=0.3)   nmeshlonmeshlat = np.meshgrid(lonlat)nxy = m(meshlonmeshlat)nn#Plot variablesntrend = m.pcolormesh(xyarray::5cmap='jet'norm=normshading='gouraud')nn#Set plot propertiesn#Colorbarncbar=m.colorbar(trend size='5%'ticks=boundslocation='bottom'pad=0.8)ncbar.set_label(label='Here is a label'size=25)ncbar.set_ticklabels(boundlabels)nfor t in cbar.ax.get_xticklabels():n    t.set_fontsize(25)n#Titles & labelsnax.set_title('Here is a title for ::5'fontsize=35)nax.set_xlabel('Longitude'fontsize=25)nax.set_xticks(np.arange(040545))nax.set_xticklabels(lonlabelsfontsize=20)nax.set_yticks(np.arange(-9012030))nax.set_yticklabels(latlabelsfontsize=20)nnnnnNow when I use the EXACT same code but plot for array::4 instead of array::5 I get this error.nnValueError                                Traceback (most recent call last)n/linuxapps/anaconda/lib/python2.7/site-packages/IPython/core/formatters.pyc in __call__(self obj)n    305                 passn    306             else:n--> 307                 return printer(obj)n    308             # Finally look for special method namesn    309             method = get_real_method(obj self.print_method)nnlots of further tracebacknn/linuxapps/anaconda/lib/python2.7/site-packages/matplotlib/text.pyc in draw(self renderer)n    755             posy = float(textobj.convert_yunits(textobj._y))n    756             if not np.isfinite(posx) or not np.isfinite(posy):n--> 757                 raise ValueError(""posx and posy should be finite values"")n    758             posx posy = trans.transform_point((posx posy))n    759             canvasw canvash = renderer.get_canvas_width_height()nnValueError: posx and posy should be finite valuesnnnI have no idea why it's doing this as my code for every other part of the array plots just fine and they all use the same meshgrid. There are no NaN's in the array. Also here's the result if I comment out all the code between #Colorbar and #Titles & labelsnnnnUPDATE: The problem also disappears when I include the colorbar code but changed the PowerNorm to 1.0 (norm = colors.PowerNorm(1.0vmax=0.65)). Anything other than 1.0 generates the error when the colorbar is included.nnThe questionnnWhat could be causing the posx & posy error message and how can I get rid of it so I can make this plot with the colorbar included?nnUPDATEnnWhen I run the kernel from scratch again with the same code (except that I changed the 0.6 bound to 0.65) I get the following warnings in the array::4 block. I'm not sure if they're related but I'll include them just in case.nn/linuxapps/anaconda/lib/python2.7/site-packages/matplotlib/colors.py:1202: RuntimeWarning: invalid value encountered in powern  np.power(resdat gamma resdat)nn<matplotlib.text.Text at 0x2af62c8e6710>n <matplotlib.text.Text at 0x2af62c8ffed0>n <matplotlib.text.Text at 0x2af62cad8e90>n <matplotlib.text.Text at 0x2af62cadd3d0>n <matplotlib.text.Text at 0x2af62caddad0>n <matplotlib.text.Text at 0x2af62cae7250>n <matplotlib.text.Text at 0x2af62cacd050>nn/linuxapps/anaconda/lib/python2.7/site-packages/matplotlib/axis.py:1015:     UserWarning: Unable to find pixel distance along axis for interval padding of ticks; assuming no interval padding needed.n  warnings.warn(""Unable to find pixel distance along axis ""n/linuxapps/anaconda/lib/python2.7/site-packages/matplotlib/axis.py:1025:     UserWarning: Unable to find pixel distance along axis for interval padding of ticks; assuming no interval padding needed.n  warnings.warn(""Unable to find pixel distance along axis ""nn' 'So I found out that specifying vmax & vmin solves the problem. I have no idea why but once I did my plot turned out correctly with the colorbar.nntrend = m.pcolormesh(xyarray::5cmap='jet'norm=normshading='gouraud'vmin=0.vmax=0.6)nnnn'",['matplotlib'],['matplotlib']
40117162,"'How can I create a download handler to process api GET requests?' ""I'm writing a website in Django with python 3.4 with Django-restframework for an API.nnMy API works great and I can download a stored file using the GET request.  I need to shift my processing from end computer to server now and I'm not sure how to do it. nnSo basically When I send my api a GET requeset I would like to have the file processed based on information passed in. For example I would like to pass two variables (Printer Plastic) and based on that process with specific files on my server and output a more specific file.nnAm I correct in thinking I can call some sort of custom GET functions (like an upload handler) if I pass in variables or is there a better way to solve this?n"" nan",['django'],['django']
40117201,'Barcode Input with Django Application' 'Any resources out there with code examples that explain how to configure and use a Django 1.9 web application to accept barcode input?n' nan,['django'],['django']
40117542,"'Crispy Layout: Submit button loops back to same page' 'I started using crispy layouts so I could add a checkbox so it can hide/show password field. The issue that I am having is that every time the form is submitted it takes me back to the same page instead to accounts. It used to work fine before implementing crispy layout but now I doesn't.nnThis is what I have in its form.py:nnfrom crispy_forms.bootstrap import StrictButton FormActionsnfrom crispy_forms.helper import FormHelpernfrom crispy_forms.layout import Layout Div HTML Fieldnfrom django import formsnfrom producer.models import LibsynConfignnclass LibsynAccountForm(forms.ModelForm):nn    # user can not change podcast name here is just provided as referencen    podcast_name = forms.CharField(label='Podcast Name' required=False max_length=100 disabled=True)n    podcast_id = forms.IntegerField(widget=forms.Field.hidden_widget)nn    # Libsyn Config datan    libsyn_config_id = forms.IntegerField(widget=forms.Field.hidden_widget required=False)n    show_slug = forms.CharField(label='Show Slug in Libsyn' max_length=100 required=True)n    server_directory = forms.ChoiceField(choices=LibsynConfig.SERVER_DIRECTORY_TYPES)nn    # credetials datan    user_name = forms.CharField(label='Username' required=True)n    password = forms.CharField(label='Password' required=True)n    check_box = forms.BooleanField(label='Show/Hide Password')nn    def __init__(self *args **kwargs):nn        super(LibsynAccountForm self).__init__(*args **kwargs)n        self.helper = FormHelper(self)n        self.helper.layout = Layout(n            Div(n                Div(n                    Div(n                        Div(n                            HTML('<h2>Libsyn</h2><p><h3>Choose an Account</h3><hr>')n                            'podcast_name'n                            'show_slug'n                            'server_directory'n                            'user_name'n                            Field('password' id='pw' type='password')n                            Field('check_box' id='box' onclick ='reveal()')n                            HTML('<hr>')n                            FormActions(n                                StrictButton('<i class=""fa fa-check pull-right"" aria-hidden=""true""></i> Finish'n                                             name=""save""n                                             value=""save""n                                             type='submit'n                                             css_class=""btn btn-primary box-shadow--6dp"")n                            )nn                            css_class='col-sm-12'n                        )n                        css_class='row'n                    )n                    css_class='panel-body'n                )n                css_class='panel panel-default box-shadow--16dp col-sm-6 col-sm-offset-3'n            )n        )nn    class Meta:n        model = LibsynConfign        fields = 'podcast_name' 'show_slug' 'server_directory' 'user_name'n                 'user_name'nnnHere is what I have in views.py:nnclass LibsynAccountView(PodcastRequiredMixin View):n    form_class = LibsynAccountFormn    template_name = 'pf/forms_libsyn_account.html'nn    def get(self request *args **kwargs):n        # We need to get the libsyn config for the podcast for the usern        # If Podcast but no libysn config provide empty form.n        initial_values = {n            'podcast_name': self.podcast.namen            'podcast_id': self.podcast.idn        }n        libsyn_config_id = self.podcast.libsyn_config_idnn        if libsyn_config_id is not None:n            libsyn_config = self.podcast.libsyn_confign            initial_values'libsyn_config_id' = libsyn_config_idn            initial_values'show_slug' = libsyn_config.show_slugn            initial_values'server_directory' = libsyn_config.server_directoryn            credentials_id = libsyn_config.credentials_idnn            if credentials_id is not None:n                credentials = libsyn_config.credentialsn                initial_values'user_name' = credentials.user_namen                initial_values'password' = credentials.passwordnn        else:n            initial_values'server_directory' = LibsynConfig.DROPBOX # Default valuenn        form = self.form_class(initial=initial_values)n        return render(request self.template_name {'form': form})nn    def post(self request *args **kwargs):n        form = self.form_class(request.POST)nn        if form.is_valid():n            # lets get the datan            podcast_id = form.cleaned_data.get('podcast_id')n            libsyn_config_id = form.cleaned_data.get('libsyn_config_id')n            show_slug = form.cleaned_data.get('show_slug')n            server_directory = form.cleaned_data.get('server_directory')n            user_name = form.cleaned_data.get('user_name')n            password = form.cleaned_data.get('password')nn            # Get the podcastn            podcast = get_object_or_404(Podcast id=podcast_id)nn            # If we have a libsyn_config_id get it otherwise create a new one.n            if libsyn_config_id is not None:n                libsyn_config = LibsynConfig.objects.get(id=libsyn_config_id)n            else:n                libsyn_config = LibsynConfig()nn            # Update base datan            libsyn_config.show_slug = show_slugn            libsyn_config.server_directory = server_directorynn            # update creadentials if no current credentails create newn            credentials_id = libsyn_config.credentials_idnn            if credentials_id is None:n                credentials = Credentials()n            else:n                credentials = libsyn_config.credentialsnn            credentials.user_name = user_namen            credentials.password = passwordn            credentials.save()nn            libsyn_config.credentials = credentialsn            libsyn_config.client = podcast.clientn            libsyn_config.save()nn            # update podcastn            podcast.libsyn_config = libsyn_confign            podcast.save()nn            return HttpResponseRedirect(reverse('pf:accounts'))nn        return render(request self.template_name {'form': form})nn' nan",['django'],['django']
40117632,"'Django TemporaryUploadedFile does not exist but nevertheless it is read successfully' ""I have the following situation here. My OS shows that django TemporaryUploadedFile which I got via the POST request does not exist anymore but somehow this uploaded file can be read.nHere is the codenntext_file = request.FILES'text_file'nnprint(text_file.temporary_file_path())nos.system('ls -l ' + text_file.temporary_file_path())nnfs = FileSystemStorage()nfile_new =fs.save(text_file.name text_file)nnprint(text_file.temporary_file_path())nos.system('ls -l ' + text_file.temporary_file_path())nnfs.delete(file_new)nnfor chunk in text_file.chunks():n    text += chunk.decode(encoding)nnprint('Got text OK.')nnnThis gives the following output:nn/tmp/tmp0tngal9t.upload foo.txtn-rw------- 1 mine machine 3072889 oct 18 19:29 /tmp/tmp0tngal9t.uploadnn/tmp/tmp0tngal9t.upload foo.txtnls: cannot access '/tmp/tmp0tngal9t.upload': No such file or directorynnGot text OK.nnnSo TemporaryUploadedFile is disappeared after it was saved to file_new which later is also deleted. Anyway text_file is successfully read by chunks and I get all the text from uploaded foo.txt file. How it is possible? From where text_file.chunks() gets the data if text_file does not exist anymore?nnI use:nnnpython 3.5.2ndjango 1.10.2nubuntu 16.04.1nn"" nan",['django'],['django']
40117685,"'String Containment in Pandas' 'I am trying to produce all the rows where company1 in df is contained in company2. I am doing it as follows:nndf1=df'company1''company2'(df.apply(lambda x: x'company1' in x'company2' axis=1) == True)nnnWhen I run the above line of code it also shows ""South"" matched with ""Southern"". Also ""South"" matched with ""Route South"". I want to get rid of all such cases. Company1 should only be contained in beginning of Company2. And company1 should not be a part of some word in company2 like ""South"" (company1) matched with ""Southern"" (company2). How should I modify my code to accomplish above two requirements?n' 'I think you need:nndf = pd.DataFrame({'company1': {0: 'South' 1: 'South' 2:'South'} n                   'company2': {0: 'Southern' 1: 'Route South' 2: 'South Route'}})nnprint (df)n  company1     company2n0    South     Southernn1    South  Route Southn2    South  South Routenndf1=dfdf'company2'.str.contains(""|"".join('^' + df'company1' + ' '))nprint (df1)n  company1     company2n2    South  South Routenn'",['pandas'],['pandas']
40117702,"'Python: Filter DataFrame in Pandas by hour day and month grouped by year' 'Being new to Pandas I had to dig a lot in order to find a solution to this problem. I would like to know a better way to get this resolved taking into account I still need to resolve the border problems.nnI have a set of 10 minutal measures of ""Power"" from 2009 till 2012 and want to get a window of hours and day/month for all the years (i.e. Filter by hour day and month grouped by year).nnWhat I have come to is as follows:nnimport pandas as pdnimport numpy as npnimport datetimenndates = pd.date_range(start=""08/01/2009""end=""08/01/2012""freq=""10min"")ndf = pd.DataFrame(np.random.rand(len(dates) 1)*1500 index=dates columns='Power')nndef filter(df day month hour daysWindow hoursWindow):n    """"""n    Filter a Dataframe by a date window and hour window grouped by yearsnn    @type df: DataFramen    @param df: DataFrame with dates and valuesnn    @type day: intn    @param day: Day to focus onnn    @type month: intn    @param month: Month to focus onnn    @type hour: intn    @param hour: Hour to focus onnn    @type daysWindow: intn    @param daysWindow: Number of days to perform the days window selectionnn    @type hourWindow: intn    @param hourWindow: Number of hours to perform the hours window selectionnn    @rtype: DataFramen    @return: Returns a DataFrame with then    """"""n    df_filtered = Nonen    grouped = df.groupby(lambda x : x.year)n    for year groupYear in grouped:n        groupedMonthDay = groupYear.groupby(lambda x : (x.month x.day))n        for monthDay groupMonthDay in groupedMonthDay:n            if monthDay >= (monthday - daysWindow) and monthDay <= (monthday + daysWindow):n                new_df = groupMonthDay.ixgroupMonthDay.index.indexer_between_time(datetime.time(hour - hoursWindow) datetime.time(hour + hoursWindow))n                if df_filtered is None:n                    df_filtered = new_dfn                else:n                    df_filtered = df_filtered.append(new_df)n    return df_filterednndf_filtered = filter(dfday=8 month=10 hour=8 daysWindow=1 hoursWindow=1)nprint len(df)nprint len(df_filtered)nnnWhich returns as output:nn>>> n157825n117nnnOf course there would be an improvement this code needs regarding border issues when selecting an hour like 1 and hoursWindow 2. i.e.:nn>>> filter(dfday=8 month=10 hour=1 daysWindow=1 hoursWindow=2)nTraceback (most recent call last):n  File ""<interactive input>"" line 1 in <module>n  File ""D:tmptest_filtro.py"" line 40 in filtern    new_df = groupMonthDay.ixgroupMonthDay.index.indexer_between_time(datetime.time(hour - hoursWindow) datetime.time(hour + hoursWindow))nValueError: hour must be in 0..23nnnSimilar issue would happen when selecting a day like 1 or 30. nnHow could this code be improved?n' nan",['pandas'],['pandas']
40117799,"'Python: Pandas Text File to DataFrame' 'I have a text file which is of the form: nnI want to create a dataframe from this using separated by the whitespace as columns and use the letters at the top as column names then export the dataframe to excel. This is the code I have constructed so far:nnimport pandas as pdnndata = pd.read_csv('testrun.txt' delim_whitespace=True header = None names = ""n"" ""p"" ""d"" ""f"" ""g"")nndf = pd.DataFrame(data)nndf.to_excel(r'C:Users""my_name""Desktopspdsht.xlsx')nnnSo far this code sucks the n p d f g into the data frame as just another row. Is there anyway I can omit this first row and have pandas append it as the column names? As you can see I already put the column names in manually but that doesn't get rid of the n p d f g within the first row. n' nan","['python-3.x', 'pandas']",['pandas']
40117842,"'Django AWS Elastic-Beanstalk WSGI.py configuration' 'I am currently setting up a django application with python3 on AWS Elastic-Beanstalk but I am having issues with configuring the wsgi.py file for the application. Why am I having the error: ERROR: Your WSGIPath refers to a file that does not exist.?   nnWhen running eb config I set the wsgi path to WSGIPath: pronet/pronet/src/pronet/wsgi.pynnIs the issue with my wsgi.py script eb config wsgi settings or not having the django module installed?nnWSGI.py Scriptnn""""""nWSGI config for pronet project.nIt exposes the WSGI callable as a module-level variable named ``application``.nFor more information on this file seenhttps://docs.djangoproject.com/en/dev/howto/deployment/wsgi/n""""""nimport osnos.environ.setdefault(""DJANGO_SETTINGS_MODULE"" ""pronet.settings.production"")nnfrom django.core.wsgi import get_wsgi_applicationnapplication = get_wsgi_application()nn# Wrap werkzeug debugger if DEBUG is onnfrom django.conf import settingsnif settings.DEBUG:n    try:n        import django.views.debugn        import sixn        from werkzeug.debug import DebuggedApplicationnn        def null_technical_500_response(request exc_type exc_value tb):n            six.reraise(exc_type exc_value tb)nn        django.views.debug.technical_500_response = null_technical_500_responsen        application = DebuggedApplication(application evalex=Truen                                          # Turning off pin security as DEBUG is Truen                                          pin_security=False)n    except ImportError:n        passnnnElasticbeanStalk eb logs output filennTue Oct 18 18:59:52.882790 2016 :error pid 25763 nremote 172.31.5.99:148 mod_wsgi (pid=25763): n    Exception occurred processing WSGI script n'/opt/python/current/app/pronet/src/pronet/wsgi.py'.nnnTue Oct 18 20:01:21.096064 2016 :error pid 25763 n    remote 172.31.46.245:148 ImportError: No module named 'django'nTue Oct 18 20:01:21.478180 2016 :error pid 25763 n    remote 172.31.46.245:60132 mod_wsgi (pid=25763): n    Target WSGI script '/opt/python/current/app/pronet/src/pronet/wsgi.py' n    cannot be loaded as PytExamine: sing WSGI script  '/opt/python/current/app/pronet/src/pronet/wsgi.py'.nnnProject Directory ""Pronet/pronet/src/pronet/wsgi.py""nnnnI changed the wsgi path to  WSGIPath: pronet/src/pronet/wsgi.py and now I received this message in the eb logs. Does this mean the wsgi.py is found?nnTue Oct 18 20:53:09.711239 2016 so:warn pid 31697 AH01574: module wsgi_module is already loaded skippingnn' nan",['django'],['django']
40117865,"'POST request failing after migrating from requests to urllib2' 'I have moved away from using the python requests library as it was a bit fiddly to get working on Google App Engine. Instead I'm using urllib2 which has better support. Unfortunately the POST request that previously worked with the requests library no longer works with urllib2.nnWith requests the code was as followsnnvalues = { 'somekey' : 'somevalue'}nr = requests.post(some_url data=values)nnnWith urllib2 the code is as followsnnvalues = { 'somekey' : 'somevalue'}ndata = urllib.urlencode(values)nreq = urllib2.Request(some_url data)nresponse = urllib2.urlopen(req)nnnUnfortunately the latter raises the following errornnHTTP Error 405: Method Not AllowednnnThe url I'm posting to has the following form:nnsome_url = 'http://ec2-11-111-111-1.compute-1.amazonaws.com'nnnI have read that there is an issue with trailing slashes with urllib2 however when I add the slash as follows nnsome_url = 'http://ec2-11-111-111-1.compute-1.amazonaws.com/'nnnI still get the same error.nnThere is no redirection at the destination - so the request shouldn't be transformed to a GET. Even if it were the url actually accepts GET and POST requests. The EC2 linux instance is running django and I can see that it successfully receives the request and makes use of it - so doesn't return a 405. For some reason urllib2 is picking up a 405 and throwing the exception.nnAny ideas as to what may be going wrong?nnEdit 1:nnAs per @philip-tzou 's good call the following information might helpnnprint req.get_method()nnnyields POSTnnprint req.header_items()nnnyields nnEdit 2nnAdding a user agent header (as @padraic-cunningham suggests) didn't solve it unfortunately. I added the same header shown in the urllib2 examplenn    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'n    headers = {'User-Agent': user_agent}n    data = urllib.urlencode(values)n    req = urllib2.Request(some_url data headers)nnnEdit 3nnAs @furas suggested I've sent the request I'm making to requestb.in to double check what's being sent. It is indeed a POST request being made with the following headers:nnConnection: closenTotal-Route-Time: 0nX-Cloud-Trace-Context: ed073df03ccd05657<removed>2a203/<removed>129639701404;o=5nConnect-Time: 1nCf-Ipcountry: USnCf-Ray: <removed>1d155ac-ORDnCf-Visitor: {""scheme"":""http""}nContent-Length: 852nContent-Type: application/x-www-form-urlencodednVia: 1.1 vegurnX-Request-Id: 20092050-5df4-42f8-8fe0-<removed>nAccept-Encoding: gzipnCf-Connecting-Ip: <removed>nHost: requestb.innUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppEngine-Google; (+http://code.google.com/appengine; appid: s~<removed>)nnnand now req.header_items() yields ('User-agent' 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)')nnby way of comparison the headers from the requests POST arennCf-Connecting-Ip: <removed>nAccept-Encoding: gzipnHost: requestb.innCf-Ipcountry: USnTotal-Route-Time: 0nCf-Ray: 2f42a45185<removed>-ORDnConnect-Time: 1nConnection: closenCf-Visitor: {""scheme"":""http""}nContent-Type: application/x-www-form-urlencodednContent-Length: 852nX-Cloud-Trace-Context: 8932f0f9b165d9a0f698<removed>/1740038835186<removed>;o=5nAccept: */*nX-Request-Id: c88a29e1-660e-4961-8112-<removed>nVia: 1.1 vegurnUser-Agent: python-requests/2.11.1 AppEngine-Google; (+http://code.google.com/appengine; appid: s~<removed>)nn' nan",['python-2.7'],"['django', 'python-2.7']"
40117874,"'accelerating the data generation process' 'I am actually trying to generate some data using raw data from pandas data frame but it seems the current procedure is too slow.... generating 1000 data takes too much timenn    for i in range(0 self._price_handler.pair_framesself._pairs0.shape0 - self._duration_of_input - self._prediction_gap * 2 - 1n                   self._gaps_for_training):n        x_list_tmp = n        y_list_tmp = n        for pair_now in self._pairs:n            reference_value = self._price_handler.pair_framespair_now""Close"".iloci + self._duration_of_input - 1n            projected_list_tmp = nn            for k in range(i + self._duration_of_input + int(self._prediction_gap / 2.0)n                           i + self._duration_of_input + int(self._prediction_gap / 2.0 * 3)):n                projected_list_tmp.append(self._price_handler.pair_framespair_now""Close"".ilock)n                projected_list_tmp.append(self._price_handler.pair_framespair_now""Open"".ilock)n                projected_list_tmp.append(self._price_handler.pair_framespair_now""Low"".ilock)nn            projection = np.mean(projected_list_tmp)n            y_list_tmp.append(100 * percent_difference(projection reference_value))nn            for j in range(i i + self._duration_of_input):n                x_list_tmp.append(percent_difference(self._price_handler.pair_framespair_now""Open"".ilocjn                                                     reference_value))n                x_list_tmp.append(percent_difference(self._price_handler.pair_framespair_now""High"".ilocjn                                                     reference_value))n                x_list_tmp.append(percent_difference(self._price_handler.pair_framespair_now""Low"".ilocjn                                                     reference_value))n                x_list_tmp.append(percent_difference(self._price_handler.pair_framespair_now""Close"".ilocjn                                                     reference_value))n                x_list_tmp.append(self._price_handler.pair_framespair_now""Volume"".ilocj)nn        X_list_total.append(x_list_tmp)n        Y_list_total.append(y_list_tmp)nn        if (i%1000==0):n            print(""incorpoated ""+str(i)+"" data points into X_list_total and Y_list_total"")nnnAnyone has some suggestions on how could we accelerate this? The second possibility maybe that we could generate the data once and for all. Any suggestions on what should we used to store such x_lis and y_list? Thank you.n' nan",['pandas'],['python-2.7']
40118037,"'How Can I Detect Gaps and Consecutive Periods In A Time Series In Pandas' 'I have a pandas Dataframe that is indexed by Date.  I would like to select all consecutive gaps by period and all consecutive days by Period.    How can I do this?nnExample of Dataframe with No Columns but a Date Index:nnIn 29: import pandas as pdnnIn 30: dates = pd.to_datetime('2016-09-19 10:23:03' '2016-08-03 10:53:39''2016-09-05 11:11:30' '2016-09-05 11:10:46''2016-09-05 10:53:39')nnIn 31: ts = pd.DataFrame(index=dates)nnnAs you can see there is a gap from 2016-08-03 and 2016-09-19.  How do I detect these so I can create descriptive statistics i.e.  40 gaps with median gap duration of ""x"" etc.  Also I can see that 2016-09-05 and 2016-09-06 is a two day range.  How I can detect these and also print descriptive stats?nnIdeally the result would be returned as another Dataframe in each case since I want use other columns in the Dataframe to groupby. n' ""here's something to get started:nndf = pd.DataFrame(np.ones(5)columns = 'ones')ndf.index = pd.DatetimeIndex('2016-09-19 10:23:03' '2016-08-03 10:53:39' '2016-09-05 11:11:30' '2016-09-05 11:10:46' '2016-09-06 10:53:39')ndaily_rng = pd.date_range('2016-08-03 00:00:00' periods=48 freq='D')ndaily_rng = daily_rng.append(df.index)ndaily_rng = sorted(daily_rng)ndf =  df.reindex(daily_rng).fillna(0)ndf = df.astype(int)ndf'ones' = df.cumsum()nnnThe cumsum() creates a grouping variable on 'ones' partitioning your data at the points your provided. If you print df to say a spreadsheet it will make sense:nnprint df.head()nn                     onesn2016-08-03 00:00:00     0n2016-08-03 10:53:39     1n2016-08-04 00:00:00     1n2016-08-05 00:00:00     1n2016-08-06 00:00:00     1nnprint df.tail()n                     onesn2016-09-16 00:00:00     4n2016-09-17 00:00:00     4n2016-09-18 00:00:00     4n2016-09-19 00:00:00     4n2016-09-19 10:23:03     5nnnnow to complete:nndf = df.reset_index()ndf = df.groupby('ones').aggregate({'ones':{'gaps':'count'}'index':{'first_spotted':'min'}})ndf.columns = df.columns.droplevel()nnnwhich gives:nn              first_time  gapsnones                          n0    2016-08-03 00:00:00     1n1    2016-08-03 10:53:39    34n2    2016-09-05 11:10:46     1n3    2016-09-05 11:11:30     2n4    2016-09-06 10:53:39    14n5    2016-09-19 10:23:03     1nn""",['pandas'],['pandas']
40118040,'Using AST how to retrieve fully qualified name of a name in Python?' 'I did lot of search and lot of sample coding. But Not able to get-nHow to retrieve fully qualified name of a name in Python?nne.g.nnfrom Module import Anndef MyFunc():n    AObject = A()nnnUsing AST - NodeVisitor how to get the fully qualified name of the name A...that is Module.A from the statement AObject = A()?n' nan,"['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40118055,"'Numpy CAPI PyArray_New Visual Studio Warning C4055' 'I am converting a computational C program to Python with using PyArray_SimpleNew() to create a numpy array in C. However i get warning nnC4055:: from data pointer 'void *' to function pointer 'PyObject *(__cdecl *)nnnHere is an extraction of the relevant code:nnPyObject* myArray=NULL;nnpy_int nd=1;nnpy_int dims1={10};nmyArray=PyArray_SimpleNew(nddimsNPY_UINT64)nnnthe warning happens at the last line. After some google searches it suggests that it's due to an improper implementation in Numpy library that violates C standards.nnSo my questions arenn1.Could anyone explain what's happening here? Especially where that ""void*"" comes from?n2.Does this warning really matters in this use case? Would it be safe to suppress it?nnsome reference:nnhttp://docs.scipy.org/doc/numpy/reference/c-api.array.htmlnPointer-type mismatch with PyArray_SimpleNewn' nan",['numpy'],['numpy']
40118058,'pyplot contour plot function with coordinate vector' 'I have a function f(x) that takes a 2D numpy array as x and calculates the value for the function at that position. nnHowever x has to be a 2D array (no matrix). How can I plot a contour plot of this function? I tried np.meshgrid but with limited success..n' nan,['matplotlib'],"['numpy', 'matplotlib']"
40118217,'Create Map by Opening .dat File' 'I'm using python for the first time and I'm trying to create a map with a .dat file. The file looks like this:nnnnAfter plotting the points the graph should look like this: nnnnCode:nnimport numpy as npnimport matplotlib.pyplot as pltnnndata= open('mat.dat')n#pl.xlabel(âx80x99xâx80x99)n#pl.ylabel(âx80x99yâx80x99)n#pl.xlim(0.0 90.0)n#pl.ylim(10.0 80.0)n#pl.show()nnnBut I can't read the file(directory error on pycharm). If I'm trying to plot only rows how would I do that? I know I'm supposed to use arrays. Do I create two array like this?nnx=np.aaray  #<---insert x values here?ny=np.array  #<---insert y values here?nn' nan,"['python-3.x', 'numpy', 'matplotlib']",['matplotlib']
40118240,"'get access and modify element values for an numpy array' 'I once saw the following code segmentnnimport numpy as npnnx=3nny=3nlabel = np.ones((nx ny))nmask=np.zeros((nxny)dtype=np.bool)nlabelmask=0nnnThe mask generated is a bool arraynnFalse False Falsen False False Falsen False False FalsennnIf I would like to assign some elements in mask to other values for instance I have been trying to use mask21=""True"" but it did not work without changing the corrsponding entry as I expected.  What's the correct way to get access and change the value for an numpy array. In addition what does labelmask=0 do? It seems to me that it tries to use each mask entry value to assign the corrsponding label entry value.n' 'Here is a code snippet with some comments that might help you make sense of this. I would suggest you look into the link that @Divakar provided and look into boolean-indexing.  nn# a two dimensional array with random valuesnarr = np.random.random((5 5))nn# assign mask to a two dimensional array (same shape as arr)n# that has True for every element where the correspondingn# element in arr is greater than 0.5nmask = arr > 0.5nn# assign all the elements in arr that are greater than 0.5 to 0narrmask = 0nn# the above can be more concisely written as:narrarr>0.5 = 0nn# you can change the mask any way you wantnn# here I invert the maskninv_mask = np.invert(mask)nn# assign all the values in arr less than 0.5 to 1narrinv_mask = 1nn'",['numpy'],['numpy']
40118259,"'Unable to create a second dataframe python pandas' 'My second data frame is not loading values when i create it. Any help with why it is not working? When i make my cursor a list it has a bunch of values in it but for whatever reason when i try to do a normal data frame load with pandas a second time it does not work.nnMy code:nn    conn = pyodbc.connect(constr autocommit=True)n    cursor = conn.cursor()n    secondCheckList = n    checkCount = 0n    maxValue = 0n    strsql = ""SELECT * FROM CRMCSVFILE""n    cursor = cursor.execute(strsql)n    cols = n    SQLupdateNewIdField = ""UPDATE CRMCSVFILE SET NEW_ID = ? WHERE Email_Address_Txt = ? OR TELEPHONE_NUM = ? OR DRIVER_LICENSE_NUM = ?""n    for row in cursor.description:n        cols.append(row0)n    df = pd.DataFrame.from_records(cursor)n    df.columns = colsn    newIdInt = 1n    for row in range(len(df'Email_Address_Txt')):n        #run initial search to figure out the max number of records. Look for email phone and drivers license names have a chance not to be uniquen        SQLrecordCheck = ""SELECT * FROM CRMCSVFILE WHERE Email_Address_Txt = '"" + str(df'Email_Address_Txt'row) + ""' OR TELEPHONE_NUM = '"" + str(df'Telephone_Num'row) + ""' OR DRIVER_LICENSE_NUM = '"" + str(df'Driver_License_Num'row) + ""'""n##        print(SQLrecordCheck)n        cursor = cursor.execute(SQLrecordCheck)n## maxValue is indeed a list filled with recordsn            maxValue =(list(cursor))n## THIS IS WHERE PROBLEM OCCURSn        tempdf = pd.DataFrame.from_records(cursor)nn' 'Why not just use pd.read_sql_query(""your_query"" conn) this will return the result of the query as a dataframe and requires less code. Also you set cursor to cursor.execute(strsql) at the top and then you are trying to call execute on cursor again in your for loop but you can no longer call execute on cursor you will have to set cursor = conn.cursor() again. n'",['pandas'],"['pandas', 'python-2.7']"
40118471,"'How to create a backward moving input class in Python' 'How to create a backward moving input class in Python? I have a class called input which reads a file forward returning one character at a time now I would like to change it to read backwards.nn# Buffered input file.  Returns one character at a time.nnnclass Input:nn        def __init__( self file ):n                self.file = file        # must open( <filename> 'rb' )n                self.length = 0n                self.used = 0n                self.buffer = """"nn        def read( self ):n                if self.used < self.length:     # if something in buffern                        c = self.bufferself.usedn                        self.used += 1n                        return cnn                else:n                        self.buffer = self.file.read( 2048 )  # or 2048n                        self.length = len( self.buffer )n                        if self.length == 0:n                                return -1n                        else:n                                c = self.buffer0n                                self.used = 1n                                return cnn' 'I think the only way this can work with text files in Python 3 is to read the whole text of the file in at once and then yield characters from the end of the string you've loaded. You can't read the file in chunks starting from the end because there's no way to safely seek to an arbitrary position in the text. If you picked an arbitrary spot (e.g. 2048 bytes before the end of the file) you might land in the middle of a multi-byte character. For this reason Python doesn't support doing a seek to anywhere other than the start and end of the file or to a place you've been before (and saved the position of with tell).nnIf your file is small enough I'd suggest something like this:nnclass ReverseInput():n    def __init__(self file):n        buffer = file.read() # read all textn        self.rev_iter = reversed(buffer) # save a reverse iterator into the textnn    def read(self):n        try:n            return next(self.rev_iter)n        except StopIteration:n            return -1  # raising an exception or returning """" might be a better APInnnIf the file is too large to store in memory at once I suppose you could work around the limitation on seeking by reading and discarding blocks of a limited size going forwards through the file and using self.file.tell() to save locations you can seek back to later. It would probably be slow awkward and easy to mess up.n'",['python-3.x'],['python-3.x']
40118500,"'output truncated when writing to a file in python' 'i have unusual problem i'm using Anaconda and my python code runs really good the output on the screen is perfect however after each print i put file.write to write my result in my file as well but not all output is written there every time it truncates the output in different positions which doesn't make sense. the file was opened in 'w' mode. my code is really long like 400 line of code so its not possible to paste it here. ni tried to close the console after each run and restart it but it doesn't always work i had a correct file output like just twice in 10 run tries. ncan any one tell me why is this happening ...your time is highly appreciated nnfile.write(""n n"")ncurrent=EventQueue.headnfor i in range(0EventQueue.size()):  n    print ""*"" *70n    file.write(""n In Time %s  "" %str(current.index))n    file.write(str(current.data))n    print ""In Time ""current.index  ""  ""current.datan    current=current.nextn    print ""*"" *70nnfile.closennnwhen the size is equal to 25 there would be like only 16 or 19 output written in the filen' 'i just added the parenthesses to the file.close it fixed the problem ... thanks and sorry for the n'",['python-2.7'],['python-2.7']
40118544,'python 3 smtplib: binary attachment encodes incorrectly in flask' 'Update: This problem only exists when I am running Flask and does not occur outside of Flask. I am in the process of attempting to isolate the problem inside my Flask environment. I thought it might be flask_mail but removing that did not solve the issue. The below code fails when run from Flask on my system but not if I run it from a shell script from within the same virtual environment and same python binary. I don't expect any answers at this point due to complexity but will leave this open for posterity.nnnnI am trying to send a binary attachment using the python 3.5.2 smtplib over TLS. My platform is OSX and I am using python installed from homebrew.nnWhen I receive the attachment the encoding appears to be munged. Instead of the original file that starts with this hex:nnffd8 ffe0 0010 4a46 4946 0001 0100 0001nni.e. <FF><D8><FF><E0>^@^PJFIF^@^A^Annnthe starting hex of my attachment as received has some weird base64 leftovers:nn5c75 6463 6666 5c75 6463 6438 5c75 6463 6666 5c75 6463 6530 0010 4a46 4946 0001nni.e. udcffudcd8udcffudce0^@^PJFIFnnnThis is a minimal case that fails which is pretty much exactly what is in the official documentation with the exception of the addition of the TLS logic:nnimport smtplibnfrom email.mime.multipart import MIMEMultipartnfrom email.mime.image import MIMEImagenndef send_my_email():n    msg = MIMEMultipart()n    msg'Subject' = 'subject'n    msg'From' = 'XXXX@gmail.com'n    msg'To' = 'YYYY@gmail.com'n    with open('/tmp/image.jpg' mode='rb') as image_file:n        image = MIMEImage(image_file.read())n    msg.attach(image)n    s = smtplib.SMTP('smtp.gmail.com' 587)n    s.starttls()n    s.login('XXXX@gmail.com' 'password')n    s.send_message(msg)n    s.quit()nnnBased on another question on here I tried this instead of send_message() and it also failed:nn    s.sendmail('XXXX@gmail.com' 'YYYY@gmail.com' msg.as_string())nnnI have also tried explicitly adding _subtype='jpg' when I init MIMEImage adding a Content-Transfer-Encoding header and adding a Content-Disposition header and none of those seemed to make a difference.nnI have verified that I do not have a problem with my email client when it receives base64 encoded attachments from other clients.nnI looked at the smtplib source and noticed that the way smtplib handles line separators looks a little odd and wonder if this is possibly related. (also see ref: https://bugs.python.org/issue14645)nnDo I need to encode something differently set something special for my platform or is this a glitch? Thanks!n' nan,['python-3.x'],"['python-3.x', 'python-2.7']"
40118548,"'Plotting secondary Y-axis using Panda?' 'My current code takes a list from a csv file and lists the header for the user to pick from so it can plot.nnimport pandas as pdnndf = pd.DataFrame.from_csv('log40a.csv'index_col=False)nnfrom collections import OrderedDictnheadings = OrderedDict(enumerate(df1))nfor num heading in headings.items():n    print(""{}) {}"".format(num heading))nnprint ('Select X-Axis')nxaxis = int(input())nnprint ('Select Y-Axis')nyaxis = int(input())nndf.plot(x= headingsxaxis y= headingsyaxis)nnnMy first question. How do I add a secondary Y axis. I know with matplotlib I first create a figure and then plot the first yaxis with the xaxis and then do the same thing to the 2nd yaxis. However I am not sure how it is done in pandas. Is it similar?nnI tried using matplotlib to do it but it gave me an error:nnfig1 = plt.figure(figsize= (1010))nax = fig1.add_subplot(211)nax.plot(headingsxaxis headingsyaxis label='Alt(m)' color = 'r')nax.plot(headingsxaxis headingsyaxis1 label='AS_Cmd' color = 'blue')nnnError:nnValueError: Unrecognized character a in format stringnn' 'You need to create an array with the column names that you want plotted on the y axis. nnAn example if you delimite the y columns with a ''nndf.plot(x= headingsxaxis y=headingsyaxis.split("""") figsize=(15 10))nnnTo run it you will need to change your input method so that it is an array rather then a string. n'",['pandas'],"['matplotlib', 'pandas']"
40118638,"'Pandas merging 2 DataFrames into one graph' ""I am trying to plot two pandas dataframes. One dataframe needs to be displayed as a line graph and another as a scatter plot on the same graph.nnThis plots the first dataframe:nnline = pd.read_csv('nugt_daily.csv'parse_dates='Date')nline = line.sort_values(by='Date')nline.set_index('Date'inplace=True)nline'Close'.plot(figsize=(16 12))nnnI want to plot the following dataframe on top of the previous graph - but as a scatter plot (rather than a line graph):nnpoints = pandas.read_csv('test_doc.csv')npoints = points.sort_values(by='Date')npoints.set_index('Date'inplace=True)npoints.plot(figsize=(16 12))nnnHow can I achieve this? When I run the two codes one after the other I see two separate graphs for each dataframe.n"" ""Use return_type='axes' to get df1.scatterplot to return a matplotlib Axes object. Then pass that axes to the second call to linegraph using ax=ax. This will cause both plots to be drawn on the same axes.nnTry:nnax = df1.plot()ndf2.plot(ax=ax)nn""","['pandas', 'numpy', 'matplotlib']","['pandas', 'matplotlib']"
40118704,"'django contact page send_email' 'I am trying to create a contact page which will take 17 inputs from a visitor and then email that information to me. I found many basic tutorials but none specific to what I am trying to achieve. So far this is what I have:nnI created a new Django project ""contactform"" then a new app ""send_email""nnThis is my forms.py file located- send_email/forms.pynnfrom django import formsnnclass ContactForm(forms.Form):n    title = forms.CharField(max_length=3 required=True)n    first_name = forms.CharField(required=True)n    last_name = forms.CharField(required=True)n    identity_type = forms.CharField(required=True)n    identity_number = forms.IntegerField(required=True)n    current_job = forms.CharField(required=True)n    career_prospects = forms.CharField(required=True)n    age = forms.IntegerField(required=True)n    nationality = forms.CharField(required=True)n    address = forms.CharField(required=True)n    city = forms.CharField(required=True)n    province = forms.CharField(required=True)n    postal_code = forms.IntegerField(required=True)n    contact_number = forms.IntegerField(required=True)n    daytime_contact_number = forms.IntegerField(required=True)n    evening_contact_number = forms.IntegerField(required=True)n    email_address = forms.EmailField(required=True)nnnMy views.py file located- send_email/views.pynnfrom django.core.mail import send_mail BadHeaderErrornfrom django.http import HttpResponse HttpResponseRedirectnfrom django.shortcuts import render redirectnfrom .forms import ContactFormnndef email(request):nif request.method == 'GET':n    form = ContactForm()nelse:n    form = ContactForm(request.POST)n    if form.is_valid():n        title = form.cleaned_data'title'n        first_name = form.cleaned_data'first_name'n        last_name = form.cleaned_data'last_name'n        identity_type = form.cleaned_data'identity_type'n        identity_number = form.cleaned_data'identity_number'n        current_job = form.cleaned_data'current_job'n        career_prospects = form.cleaned_data'career_prospects'n        age = form.cleaned_data'age'n        nationality = form.cleaned_data'nationality'n        address = form.cleaned_data'address'n        city = form.cleaned_data'city'n        province = form.cleaned_data'province'n        postal_code = form.cleaned_data'postal_code'n        contact_number = form.cleaned_data'contact_number'n        daytime_contact_number = form.cleaned_data'daytime_contact_number'n        evening_contact_number = form.cleaned_data'evening_contact_number'n        email_address = form.cleaned_data'email_address'n        try:n            send_mail(first_name message email_address 'admin@example.com')n        except BadHeaderError:n            return HttpResponse('Invalid header found.')n        return redirect('success')nreturn render(request ""email.html"" {'form': form})nndef success(request):nreturn HttpResponse('Success! Thank you for your message.')nnnemail.html as follows:nn<h1>Contact Us</h1>n<form method=""post"">    n{% csrf_token %}n{{ form.as_ul }}n<div class=""form-actions"">n    <button type=""submit"">Send</button>n</div>  nnnnnNow I am well aware that Django send_mail take these arguments: (subject message sender recipients) I just want to know if there is a way to pass the data I am asking for into the ""message"" parameter and email it as a list?n' ""Here you go:nnnnemail.template.htmlnnHello someone filled out a contact form with the following information:nnFirst name: {{ first_name }}nLast name : {{ last_name }}n. . . and so onnnn-- or if youâx80x99re lazy like me --nnHello someone filled out a contact form with the following information:n{% for key value in form.cleaned_data.items %}n{{ key }}: {{ value }}n{% endfor %}nnnnnfrom django.template.loader import get_templatenfrom django.template import Contextnndef email(request):n    . . .n    context = Context(locals())n    template = get_template('email.template.html')n    message = template.render(context)nn""",['django'],['django']
40118721,"'How to use REGEX with multiline' 'The following expression works well extracting the portion of data string that starts with the word Block followed by open bracket { and ending with the closing bracket '}':nndata =""""""nSomewhere over the rainbownWay up high nBlock {n line 1n line 2n line 3n}nAnd the dreams that you dreamed ofnOnce in a lullabyn""""""nregex = re.compile(""""""(Block {n ^{}*n}n)"""""" re.MULTILINE)nresult = regex.findall(data)nprint result nnnwhich returns:nn'Block {n line 1n line 2n line 3n}n'nnnBut if there is another curly bracket inside of the Block portion of the string the expression breaks returning an empty list:nndata =""""""nSomewhere over the rainbownWay up high nBlock {n line 1n line 2n {{}n line 3n}nAnd the dreams that you dreamed ofnOnce in a lullabynBlock {n line 4n line 5n {{n }n line 6n}nSomewhere over the rainbownBlue birds flynAnd the dreams that you dreamed ofnDreams really do come true ooh ohn""""""nnnHow to modify this regex expression to make it ignore the brackets that are inside of the Blocks and yet each block is returned as the separate entity in result list (so each Block could be accessed separately)?n' 'Wouldn't this work?nnregex = re.compile(""""""(Block {n ^}*n}n)"""""" re.MULTILINE)nnIn the version you've posted it is exiting the match whenever it comes across a second opening brace even though you want it to exit upon the first closing brace.  If you want nested opening / closing braces that's another story.n' 'I would suggest you to use:nn(Block ?{n ?^$+?n}n)nnnSince python matches greedy we use ? to be non-greedy.nnWorked well for me. nIn addition I would recommend you the use of https://regex101.com/nnBest Regardsn'",['regex'],['regex']
40118976,"'How argument with return statement calling function?' 'I am trying to understand a program how this return is calling function and how we are passing argument in function with return ?nnprogram is :nndef hello(xb):n    z=x+bn    print(z)n    return ""hi""nnndef hi(n):n    return hello(44)nfor i in range(3):n    print(hi(3))nnni am confuse how return hello(44) calling main function? can we pass argument in function with return ??nnif we pass argument in function with return then i tried something like this but its giving error :nndef hello(xb):n    z=x+bn    print(z)nnn    return hello(4 4)nnnbut its not working  I know i am not calling function but i did with return hello(44) why its not working when same working in previous program? Please explain n' 'def hello(xb):n    z=x+bn    print(z)nnn    return hello(4 4)nnndoes not work because of infinite recursion. Essentially this function is making an infinite loop.nnTo see how this works look at how you would write it out in code:nnx = 4nb = 4nz = x+bnprint(z)n#And then we are running the function again.nx = 4nb = 4nz=x+bnprint(z)n#And again.nx = 4nb = 4nz=x+bnprint(z)n#And again.nx = 4nb = 4nz=x+bnprint(z)nnnYou get the idea. But when we call it with a different function the code looks like this:nnfor i in range(3):n    x = 4n    b = 4n    z=x+bn    print(z)nnnAnd then the function does not run again because there are no more calls to it.nnSee http://www.python-course.eu/course.php and http://openbookproject.net/thinkcs/python/english3e/recursion.html for more information.n'","['python-2.7', 'python-3.x']","['python-3.x', 'python-2.7']"
40119025,'Getting html of Facebook page using urllib2' 'I am writing a Python script that can take a Facebook URL and locally save an html file of that Facebook page. Based on the answer to this question: Inherent Python way to save web page sourcennI tried using urllib2 but the resulting html file is different (missing some parts) compared to the html file that get from manually right clicking on the Facebook page and saving the entire webpage. Do you know why they would be different and what other Python libraries I could use instead of urllib2?n' nan,['python-2.7'],['python-2.7']
40119050,"'Python: Pandas dealing with spaced column names' 'If I have multiple text files that I need to parse that look like so but can vary in terms of column names and the length of the hashtags above: nnHow would I go about turning this into a pandas dataframe? I've tried using     pd.read_table('file.txt' delim_whitespace = True skiprows = 14) but it has all sorts of problems. My issues are... nnAll the text asterisks and pounds at the top needs to be ignored but I can't just use skip rows because the size of all the junk up top can vary in length in another file. nnThe columns ""stat (+/-)"" and ""syst (+/-)"" are seen as 4 columns because of the whitespace.nnThe one pound sign is included in the column names and I don't want that. I can't just assign the column names manually because they vary from text file to text file.nnAny help is much obliged I'm just not really sure where to go from after I read the file using pandas.n' 'Consider reading in raw file cleaning it line by line while writing to a new file using csv module. Regex is used to identify column headers using the i as match criteria. Below assumes more than one space separates columns:nnimport osnimport csv renimport pandas as pdnnrawfile = ""path/To/RawText.txt""ntempfile = ""path/To/TempText.txt""nnwith open(tempfile 'w' newline='') as output_file:n    writer = csv.writer(output_file)    nn    with open(rawfile 'r') as data_file:n        for line in data_file:            n            if re.match('^.*i' line):                     # KEEP COLUMN HEADER ROWn                line = line.replace('n' '')                n                row = line.split(""  "")                n                writer.writerow(row)nn            elif line.startswith('#') == False:            # REMOVE HASHTAG LINESn                line = line.replace('n' '')n                row = line.split(""  "")            n                writer.writerow(row)nndf = pd.read_csv(tempfile)                                 # IMPORT TEMP  FILEndf.columns = c.replace('# ' '') for c in df.columns     # REMOVE '#' IN COL NAMES     nnos.remove(tempfile)                                        # DELETE TEMP FILEnn' ""This is the way I'm mentioning in the comment: it uses a file object to skip the custom dirty data you need to skip at the beginning. You land the file offset at the appropriate location in the file where read_fwf simply does the job:nnwith open(rawfile 'r') as data_file:n    while(data_file.read(1)=='#'):n        last_pound_pos = data_file.tell()n        data_file.readline()n    data_file.seek(last_pound_pos)n    df = pd.read_fwf(data_file)nndfnOut88: n   i      mult  stat (+/-)  syst (+/-)        Q2         x       x.1       Phpn0  0  0.322541    0.018731    0.026681  1.250269  0.037525  0.148981  0.104192n1  1  0.667686    0.023593    0.033163  1.250269  0.037525  0.150414  0.211203n2  2  0.766044    0.022712    0.037836  1.250269  0.037525  0.149641  0.316589n3  3  0.668402    0.024219    0.031938  1.250269  0.037525  0.148027  0.415451n4  4  0.423496    0.020548    0.018001  1.250269  0.037525  0.154227  0.557743n5  5  0.237175    0.023561    0.007481  1.250269  0.037525  0.159904  0.750544nn""","['python-3.x', 'pandas']",['pandas']
40119192,"'Python - Quadratic Equation PLS respond' 'We have to make a program that solves a quadratic equation I did that part but we also have to include a section where the user inputs what they think the correct answer is and if they are right the program should output something like ""You are correct"". If they are wrong however it should output something like ""You are wrong"" and then underneath it should output the correct answers. This is what i have so far can someone please incorporate this part for me My code is below. nnprint ""This program can be used to solve quadratic equations""nnprint ""Below please input values for a b and c"" nnprint ""n----------------------------n""nnimport mathnnnfor i in range(39479):nn    a = float(raw_input(""Enter a value for a: ""))n    b = float(raw_input(""Enter a value for b: ""))n    c = float(raw_input(""Enter a value for c: ""))nn    if a==0:n        print ""Please input a value greater than or less than 0 for a""n    else:n        breaknnprint ""n----------------------------n""nnndiscriminant = (b**2)-(4*(a*c)) nnif discriminant < 0:nn    print (""This equation has no real solution"")nnelif discriminant == 0:nn    repeated_solution = (-b-math.sqrt(b**2-4*a*c))/2*an    print (""This equation has one repeated solution: "") repeated_solutionnnelse:nn    root_1 = (-b+math.sqrt(discriminant))/(2*a)n    root_2 = (-b-math.sqrt(discriminant))/(2*a)n    print ""This equation has two solutions:"" root_1 "" and/or"" root_2nn' 'I understood that you are having an issue dealing with comparison part.  So you can add a realy basic validation something look like that:nd = float(raw_input(""what is your answer: "")) nif d*d=root_1*root_1 |   d*d=repeated_solution*repeated_solution:n    print('correct') nelse:n    print('false')nMathematically you compare the square of the answer with results the both cases lead to the same mechanic. to avoid issues of negative format. nAnd delete the part when you print the results...n' 'print ""This program can be used to solve quadratic equations""nnprint ""Below please input values for a b and c"" nnprint ""n----------------------------n""nnimport mathnnnfor i in range(39479):nn    a = float(raw_input(""Enter a value for a: ""))n    b = float(raw_input(""Enter a value for b: ""))n    c = float(raw_input(""Enter a value for c: ""))nn    if a==0:n        print ""Please input a value greater than or less than 0 for a""n    else:n        breaknnprint ""n----------------------------n""nnndiscriminant = (b**2)-(4*(a*c)) nnif discriminant < 0:nn    print (""This equation has no real solution"")nnelif discriminant == 0:nn    repeated_solution = format((-b-math.sqrt(b**2-4*a*c))/2*a'.3f')n    guess=format(float(raw_input(""This equation has one repeated solution Make a guess:""))'.3f')n    if guess==repeated_solution:n        print ""You are correct.WOW!""n        print (""This equation has one repeated solution: "") repeated_solution        n    else:n        print ""Wrong Answer""nelse:n    root_1 = format((-b+math.sqrt(discriminant))/(2*a)'.3f')n    root_2 = format((-b-math.sqrt(discriminant))/(2*a)'.3f')n    guess1=format(float(raw_input(""This equation has two solutions Make a guess for solution1:""))'.3f')n    guess2=format(float(raw_input(""This equation has two solutions Make a guess for solution2:""))'.3f')n    if set(root_1root_2).issubset( guess1guess2):n        print ""You are correct.WOW!""n        print ""This equation has two solutions:"" root_1 "" and/or"" root_2n    else:n        print ""Wrong Answer""nn'","['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40119370,"""Python regex issue. Validation works but in two parts I to extract each valid 'part' separately"" ""My code is:nntest1 = flightn###Referencelink: http://academe.co.uk/2014/01/validating-flight-codes/n#Do not mess up trailing stringsnp = re.compile(r'^(a-za-z|a-z0-9|0-9a-z)a-z?0-9{14}a-z?$')nm = p.search(test1)  # p.match() to find from start of string onlynif m:n print '200good date and time'  # group(1...n) for capture groupsnelse:n print('errorbad flight number')quit()nnnI need to get the carrier code (the first bit) and the flight number(second bit) separately. nnCan I extract the regex as in: a = 'first valid part' of regex b = 'second valid part'n"" ""Try this maybe.nnp = re.compile(r'^(a-za-z|a-z0-9|0-9a-z)(a-z?0-9{14}a-z?)$')nm = p.findall(test1)nn""",['regex'],['regex']
40119416,"'Pandas - Loc w/categories' ""I'm trying to call a value by a set of index values in Pandas. When I create the bins using this method I'm able to call the index values without issue:nnimport numpy as npnimport pandas as pdndf=pd.DataFrame(100*np.random.uniform(0 1 size=100)columns='randoms')ndf'the'='the'ndf'another'=100*np.random.uniform(0 1 size=100)nbins=050100nlabels='0-50''51-100'ndf'cat'=df.randoms.apply(lambda x: '0-50' if x<=50 else '51-100')nx=df.groupby('the''cat').quantile(np.arange(01.1.1))nx.loc'the''0-50'nnnHowever I realized as my binning got more complex I should use the pd.cut method. But when I do so I get the following error:nnimport numpy as npnimport pandas as pdndf=pd.DataFrame(100*np.random.uniform(0 1 size=100)columns='randoms')ndf'the'='the'ndf'another'=100*np.random.uniform(0 1 size=100)nbins=050100nlabels='0-50''51-100'ndf'cat'=pd.cut(df.randomsbinslabels=labels)nx=df.groupby('the''cat').quantile(np.arange(01.1.1))nx.loc'the''0-50'nnKeyError: 'the label 0-50 is not in the columns'nnnHowever these work fine in the second method:nnx.loc'the'nx.loc'the''0-50'0nnnWhat's going on here?n"" nan",['pandas'],"['pandas', 'numpy']"
40119486,"'Find cells with data and use as index in dataframe' ""I'm reading an excel file but for this question purposes I will provide an example of what my dataframe looks like.nI have a dataframe like so:nndf = pd.DataFrame(n        'Texas 1' '111' '222' '333'n        'Texas 1' '444' '555' '666'n        'Texas 2' '777''888''999'n    )ndf2 = df2.replace('222' '')nnn          0    1    2    3na   Texas 1  111       333nb   Texas 1  444  555  666nc   Texas 2  777  888  999nnnAnd I want to be able to define a multiindex based on the values of the first row that are not blank.nSo something like this:nn      0     1    3nTexas 1   111  333 444  555  666nTexas 2   111  333 777  888  999nnnThe problem is that the values in row a will not always be in the same column so I need a way to find which columns have a value in the first row and use that column number as an index. So far I read my excel file like so:nndf1 = pd.read_excel('excel.XLS' index_col=1112437)nnnAnd I've been looking for a way to read the cells that are not NaN and are in row a and find their column number to store in a list and use that as for my index_col=(). But I can't figure out how. Any pointers in the right direction would be awesome!  n"" 'first of all you say ""where is not NaN"" but you replace with ''.nI'll replace '' with np.nan then dropnanndf.iloc0.replace('' np.nan).dropna().indexnnInt64Index(0 1 3 dtype='int64')nnnnndfdf.iloc0.replace('' np.nan).dropna().indexnnnn'",['pandas'],['pandas']
40119661,"'How to loop through a list and then swap digits for other instances of the loop to see?' 'I have an XML Document with a structure like this:nn<?xml version=""1.0"" encoding=""UTF-8""?>n<urlset xmlns=""http://www.sitemaps.org/schemas/sitemap/0.9"" xmlns:image=""http://www.google.com/schemas/sitemap-image/1.1"">n  <url>n    <loc>https://www.website.com/</loc>n    <changefreq>daily</changefreq>n  </url>n  <url>n    <loc>https://www.website.com/location/</loc>n    <lastmod>2016-10-13T06:03:41Z</lastmod>n    <changefreq>daily</changefreq>n    <image:image>n      <image:loc>https://website.com/image/</image:loc>n      <image:title>Title of Item</image:title>n    </image:image>n  </url>n  <url>n    <loc>https://www.website.com/location/</loc>n    <lastmod>2016-09-15T07:11:22Z</lastmod>n    <changefreq>daily</changefreq>n    <image:image>n      <image:loc>https://website.com/image/</image:loc>n      <image:title>Title of Item</image:title>n    </image:image>n  </url>n</urlset>nnnI want to see which  tag is the youngest using the  tab. I have used this to get the date broken down to see if one year is newer than the next year... etc. But it doesn't work because every time I iterate to a different  node the for loop ""forgets"" and doesn't save which date is the newest which makes it return the date from the last loop iterated not the newest date.nnI have tried everything based on variables even thinking that getter and setter methods would work but the values aren't updated.nntree = get_xml_data(line)n        to_log(tree)n        for child in tree:n            if child.tag.endswith(""url""):n                for c in child:n                    if c.tag.endswith(""lastmod""):n                        xml_date = c.textn                        year = """"n                        month = """"n                        day = """"n                        hour = """"n                        minute = """"n                        second = """"n                        for i in range(4):n                            year += str(xml_datei)n                        for i in range(5 7):n                            month += str(xml_datei)n                        for i in range(8 10):n                            day += str(xml_datei)n                        for i in range(11 13):n                            hour += str(xml_datei)n                        for i in range(14 16):n                            minute += str(xml_datei)n                        for i in range(17 19):n                            second += str(xml_datei)n                        if year > nt.get_year():n                            nt.set_year(int(year))n                            if month > nt.get_month():n                                nt.set_month(int(month))n                                if day > nt.get_day():n                                    nt.set_day(int(day))n                                    if hour > nt.get_hour():n                                        nt.set_hour(int(hour))n                                        if minute > nt.get_minute():n                                            nt.set_minute(int(minute))n                                            if second > nt.get_second():n                                                nt.set_second(int(second))nn                        to_log(""Addition:"" year month day hour minute second)n        to_log(""Newest addition:"" nt.get_year() nt.get_month() nt.get_day())n        to_log(""Newest addition (cont.):"" nt.get_hour() nt.get_minute() nt.get_second())nnnOutputs (for example the first addition should be the newest date):nn2016-10-18 19:25:20.332031 Addition: 2016 10 05 06 21 05n2016-10-18 19:25:20.332083 Addition: 2016 07 30 01 27 21n2016-10-18 19:25:20.332134 Addition: 2016 09 19 17 48 45n2016-10-18 19:25:20.332186 Addition: 2016 09 19 17 48 52n2016-10-18 19:25:20.332235 Newest addition: 2016 9 19n2016-10-18 19:25:20.332268 Newest addition (cont.): 17 48 52nn' 'This version remembers the newest addition date (and time):nnimport jdcalnndef julian(y m d h mi s):n    return sum(jdcal.gcal2jd(y m d)) + (h-12.0)/24 + mi/1440.0 + s/86400.0nnntree = get_xml_data(line)n    to_log(tree)n    julNewest = 0.0                                                         # establish a comparison value for the newest additionn    for child in tree:n        if child.tag.endswith(""url""):n            for c in child:n                    if c.tag.endswith(""lastmod""):n                        xml_date = c.textn                        year = float(xml_date0:4)n                        month = float(xml_date5:7)n                        day = float(xml_date8:10)n                        hour = float(xml_date11:13)n                        minute = float(xml_date14:16)n                        second = float(xml_date17:19)n                        julDay = julian(year month day hour minute second) # calculate Julian day number of recent additionn                        if julDay > julNewest:n                            nt.set_year(int(year))n                            nt.set_month(int(month))n                            nt.set_day(int(day))n                            nt.set_hour(int(hour))n                            nt.set_minute(int(minute))n                            nt.set_second(int(second))n                            julNewest = julDaynn                        to_log(""Addition:"" year month day hour minute second)n        to_log(""Newest addition:"" nt.get_year() nt.get_month() nt.get_day())n        to_log(""Newest addition (cont.):"" nt.get_hour() nt.get_minute() nt.get_second())`nnnYou first have to import the module jdcal (if not installed install it with ""pip install jdcal""). The function that is defined then allows you to represent any date as a unique (float) number. It is much easier to compare these single numbers to other date-converted numbers to see which one is higher (more recent newer).nnNote that I also simplified and sped up your code that constructs year month day information.nnHope this helps.nnRegardsn'",['list'],[]
40119792,"'Django model formset factory and forms' 'I'm trying to user Django model formset factory to render a template where a user can add images and change the images they have uploaded(very similar to what can be done in the admin). I currently can render the template and its correct fields to the template. What I cannot do is have the user preselected(want currently logged in) and when I refresh the page the image will be posted again(not sure if this is preventable). Below is my code. Thanks!nnModel:nnclass Image(models.Model):n    user = models.ForeignKey(User)n    image = models.ImageField(upload_to=content_file_name null=True blank=True)n    link = models.CharField(max_length=256 blank=True)nnnForm:nnclass ImageForm(forms.ModelForm):n    image = forms.ImageField(label='Image')nn    class Meta:n        model = Imagen        fields = ('image'n                  'link'n                  )nnnView:nn@login_requiredndef register(request):nnuser_data = User.objects.get(id=request.user.id)nImageFormSet = modelformset_factory(Imagen                                    fields=('user' 'image' 'link') extra=3)nnif request.method == 'POST':n    print '1'n    formset = ImageFormSet(request.POST request.FILES queryset=Image.objects.all())nn    if formset.is_valid():n        formset.user = request.usern        formset.save()nn    return render(request 'portal/register.html' {'formset': formset 'user_data': user_data})nnelse:n    print '2'n    formset = ImageFormSet(queryset=Image.objects.all())n    return render(request 'portal/register.html' {'formset': formset 'user_data': user_data})nnnTemplate:nn<form id="""" method=""post"" action=""""n      enctype=""multipart/form-data"">nn    {% csrf_token %}nn    {{ formset.management_form }}n    {% for form in formset %}n        {{ form }}n    {% endfor %}nnn<input type=""submit"" name=""submit"" value=""Submit"" />nnnn' 'let me explain the way you can do it.nnMODELSnnfrom django.utils.text import slugifynfrom django.db import modelsnfrom custom_user.models import AbstractEmailUsernn# User modelnclass UserModel(AbstractEmailUser):n    full_name = models.CharField(max_length=255)nn    def __str__(self):n        return str(self.id)nn# Function for getting images from instance of userndef get_image_filename(instance filename):n    title = instance.idn    slug = slugify(title)n    return ""user_images/%s-%s"" % (slug filename)nn# Save images with user instancenclass UserImages(models.Model):n    user = models.ForeignKey('UserModel' db_index=True default=None)n    image = models.ImageField(upload_to=get_image_filename verbose_name='Image' db_index=True blank=True null=True)nnnIn forms it's a just a two form one for model User other for UserImages model.nn# Images formsnclass ImageForm(forms.ModelForm):n    image = forms.ImageField(label='Image' required=False)nn    class Meta:n        model = UserImagesn        fields = ('image')nn# User formnclass UserForm(forms.ModelForm):n    full_name = forms.CharField(required=True)nn    class Meta:n        model = UserModeln        fields = ('full_name''email''password')nnnAnd in Views for post you can do something like thisnn# Viewnfrom models import *nfrom forms import *nn@csrf_protectndef post_view(request):n    template = 'some_template.html'n    ImageFormSet = modelformset_factory(UserImages form=ImageForm extra=15)n    if request.method == 'POST':n        user_form = UserForm(request.POST prefix='form1')n        formset = ImageFormSet(request.POST request.FILES queryset=UserImages.objects.none() prefix='form2')nn        if user_form.is_valid() and formset.is_valid():n            # Save User form and get user IDn            a = user_form.save(commit=False)n            a.save()nn            images = formset.save(commit=False)n            for image in images:n                image.user = an                image.save()nn            return HttpResponseRedirect('/success/')n        else:n            user_form = UserForm(prefix='form1')n            formset = ImageFormSet(queryset=UserImages.objects.none() prefix='form2')n    return render(request template {'form_user':user_form'formset':formset})nnnIn template you are doing the right thing.n'",['django'],['django']
40119855,"""Python 3.x : using a list if a letter isn't in that list add it. otherwise increment the value by 1"" 'so this is what I'm doing: I'm pulling up a file and having the program read it. Every time it encounters a letter it'll add the letter to list1 and add '1' to list2. Every time it encounters a letter in list1 it'll increment list2 by 1. nntxt = open(""Nameoffile.txt"")nwordcount = 0nCharcount = 0nletterlist =  #list 1nlettercount =  #list 2nnfor words in txt:n    print(words)n    for letters in words:n        if letters not in letterlist:n           letterlist.append(letters)n           lettercountletters = 1n        else:n           lettercountletters += 1nn        Charcount += 1n        print(letters)n        if letters == ' ':n           wordcount += 1n        if letters == '.':n           wordcount += 1n        if letters == 'n':n           Charcount -= 1n           wordcount += 1nn#down here it would print the resultsnnnthe problem I'm running into is that when running this I get the following error:nline 14 lettercountletters = 1nTypeError: list indices must be integers or slices not strnnI assumed I could get away with stating that at listletter set that value to a number but it isn't liking it. any possible hints on what to do?n' 'Lists work with integer indexes you can use a dictionary instead:nnlettercount = {} #list 2nnnDictionaries have the capacity to store key values objects so you can use not numeric keys to acees values. Their use is similar to the lists so you can still use:nnlettercountletters = 1nnnto add or update a key in the dictionary however they are not iterable as lists you have to iterate them using keys or iteritems methods.nTo print the results you can iterate over the keys and display the count:nnfor e in lettercount.keys():n    print (e str(lettercounte))nn' 'lettercount should be type dict not list. nType dict maps a unique key to a value while list just contains values.nThe value within brackets for a list should be an integer referring to a position in the list while a dictionary will reference the key in brackets. n' 'That line of your function essentially tries to do something like this:nnlettercount'a' += 1nnnwhich doesn't really make any sense. Lists are ordered collections and are only accessible via numerical index which is why you get an error telling you that an integer is required (not a string). As the other answers mentioned you really want to store the count for each letter in a dict. The Python standard library provides a Counter dict subclass which is actually perfect for your needs - it'll count the characters for you and make it easy to remove duplicates:nnimport collectionsnnlettercount = collections.Counter(yourtext)nnletterlist = set(lettercount)ncharcount = len(list(c for c in lettercount.elements() if c != 'n'))nwordcount = lettercount' ' + lettercount'.' + lettercount'n'nn'","['list', 'python-3.x']","['list', 'dictionary']"
40119867,"'Pythonic way to create list of address letter/numbers from an input address range like 1-12A' 'Simple case: For a given string input like '1-12A' I'd like to output a list likenn'1A' '2A' '3A' ...  '12A'nnnThat's easy enough I could use something like the following code:nnimport renninput = '1-12A'nnbegin = input.split('-')0                   #the first numbernend = input.split('-')-1                    #the last numbernletter = re.findall(r""(A-Z)"" input)0     #the letternnstr(x)+letter for x in range(begin end+1)  #works only if letter is behind numbernnnBut sometimes I'll have cases where the input is like 'B01-B12' and I'd like the output to be like this:nn'B01' 'B02' 'B03' ...  'B12'nnnNow the challenge is what's the most pythonic way to create a function to can build up such lists from either of the above two inputs? It might be a function that accepts the begin end and letter inputs but it has to account for leading zeros and the fact that the letter could be in front or behind the number.n' 'I'm not sure if there's a more pythonic way of doing it but using some regexes and python's format syntax we can fairly easily deal with your inputs. Here is a solution :nnimport renndef address_list(address_range):n    beginend = address_range.split('-')     n    NbNe=re.findall(r""d+"" address_range)nn    #we deduce the paading from the digits of beginn    padding=len(re.findall(r""d+"" begin)0) nn    #first we decide whether we should use begin or end as a template for the ouputn    #here we keep the first that is matching something like ab01 or 01abn    template_base = re.findall(r""a-zA-Z+d+|d+a-zA-Z+"" address_range)0nn    #we make a template by replacing the digits of end by some format syntaxn    template=template_base.replace(re.findall(r""d+"" template_base)0""{{:0{:}}}"".format(padding))nn    #print(""template : {}  example : {}"".format(templatetemplate.format(1)))nn    return template.format(x) for x in range(int(Nb) int(Ne)+1)  nnprint(address_list('1-12A'))nprint(address_list('B01-B12'))nprint(address_list('C01-9'))nnnOutput:nn'1A' '2A' '3A' '4A' '5A' '6A' '7A' '8A' '9A' '10A' '11A' '12A'n'B01' 'B02' 'B03' 'B04' 'B05' 'B06' 'B07' 'B08' 'B09' 'B10' 'B11' 'B12'n'C01' 'C02' 'C03' 'C04' 'C05' 'C06' 'C07' 'C08' 'C09'nn'",['list'],"['list', 'python-2.7']"
40119979,'How to format django generated sitemap lastmod date?' 'My sitemap generated this way:nnfrom django.contrib.sitemaps import Sitemapnfrom django.utils import timezonennclass StaticViewSitemap(Sitemap):n    priority = 0.5n    changefreq = 'daily'nn        def items(self):n            return 'index' 'contacts'nn        def lastmod(self item):n            return timezone.now()nnnAs django docs says lastmod returns datetime. It renders sitemap.xml lastmod to 'yyyy-mm-dd' format and looks so:nn<urlset>n    <url>n        <loc>http://127.0.0.1/index</loc>n       <lastmod>2016-10-19</lastmod>n       <changefreq>daily</changefreq>n    </url>n    <url>n       <loc>http://127.0.0.1/contacts</loc>n       <lastmod>2016-10-19</lastmod>n       <changefreq>daily</changefreq>n    </url>n</urlset>nnnBut how could I change lastmod format to ISO8601 (I need this: 2008-01-02T10:30:00+02:00) to get this:nn<urlset>n    <url>n        <loc>http://127.0.0.1/index</loc>n       <lastmod>2016-10-19T00:25:00+03:00</lastmod>n       <changefreq>daily</changefreq>n    </url>n    <url>n       <loc>http://127.0.0.1/contacts</loc>n       <lastmod>2016-10-19T00:25:00+03:00</lastmod>n       <changefreq>daily</changefreq>n    </url>n</urlset>nnnI've played around making custom 'formats' path as said here (Django format localization) but did not found which setting should I change to get appropriate date format.nThanks.nnMy urls.py:nn...nnsitemaps = {n    'static': StaticViewSitemapn}nnurlpatterns = n    ...n    url(r'^sitemap.xml$' sitemap {'sitemaps': sitemaps} name='django.contrib.sitemaps.views.sitemap')n    ...nnn' nan,['django'],['django']
40120031,"'Command function for button ""resets""' 'So in my tkinter python program I am calling on a command when a button is clicked. When that happens it runs a function but in the function I have it set a label to something on the first time the button is clicked and after that it should only update the said label. Basically after the attempt it changes the attempt to 1 ensuring the if statement will see that and not allow it to pass. However it keeps resetting and I don't know how to stop it. When you click the button no matter first or third the button resets and proof of that occurs because the h gets printed. It's as if the function restarts but it shouldn't since it's a loop for the GUI.nndef fight(): #Sees which one is stronger if user is stronger he gets win if no he gets loss also displays enemy stats and removes used characters after round is finishednntry:n    attempt=0n    namel = """"n    namer=""""n    left = lbox.curselection()0n    right = rbox.curselection()0nn    totalleft = 0n    totalright = 0n    if left == 0:n        namel = ""Rash""n        totalleft = Rash.totaln    elif left==1:n        namel = ""Untss""n        totalleft = Untss.totaln    elif left==2:n        namel = ""Illora""n        totalleft = 60+35+80nn    if right == 0:n        namer = ""Zys""n        totalright = Zys.totaln    elif right==1:n        namer = ""Eentha""n        totalright = Eentha.totaln    elif right==2:n        namer = ""Dant""n        totalright = Dant.totalnn    lbox.delete(lbox.curselection()0)n    rbox.delete(rbox.curselection()0)n    print(namel)n    print(namer)n    if attempt == 0:n        wins.set(""Wins"")n        loss.set(""Loss"")n        print(""h"")n        attempt=1n    if (totalleft>totalright):n        wins.set(wins.get()+""n""+namel)n        loss.set(loss.get()+""n""+namer)n    else:n        wins.set(wins.get()+""n""+namer)n        loss.set(loss.get()+""n""+namel)nexcept IndexError:n        passnnnAlso for those of you who saw my previous question I still need help with that I just also want to fix this bug too. n' 'At beginning of function fight you set attempt = 0 so you reset it. nnBesides attempt is local variable. It is created when you execute function fight and it is deleted when you leave function fight. You have to use global variable (or global IntVar)nnattempt = 0nndef fight():n    global attemptnnnBTW: of you use only values 0/1 in attempt then you can use True/False.      nnattempt = Falsenndef fight():n    global attemptnn    ...nn    if not attempt:nn       attempt = Truenn'",['tkinter'],['tkinter']
40120085,"'Python How can i read text file like dictionary' 'I hava a text file like this :nn""imei"": ""123456789""n""sim_no"": ""+90 xxx xxx xx xx""n""device_type"": ""standart""n""hw_version"": ""1.01""n""sw_version"": ""1.02""nnnand i want read this file like dictionary. I mean when i write imei it should give me 123456789. I'm creating free dictionary and i'm reading this file but its reading like string.nnfile=open(""test.txt""""r"")nnbuffer={}nprint(type(buffer))nbuffer=file.read()nprint(type(buffer))nn<class 'dict'>n<class 'str'> nnnEDIT : Problem is solved.nnimport jsonnnwith open(""test.txt"") as f:n    mydict = json.loads('{{ {} }}'.format(f.read()))nn' 'I think you can check this post and you can change the splitting word to "":"" n.nnHopefully it helps!n' 'I tried to come up with a more elegant solution that doesn't use regular expressions but everything I came up with is far more verbose so try this:nnimport rennd = {}nwith open('test.txt') as f:n    for line in f:n        k v = re.findall(r'""(.+?)""' line)n        dk = vnnprint(d)nnnre.findall(r'""(.+?)""' line) will return all the matches where text is within quotes on each line and assign the first match to k and the second to v. These are then used as keys and values in a dictionary d. Assuming that the format of your text file is constant this should give you the result you are looking for.nnNote that the order of the dictionary will likely be different than your text file but that shouldn't matter since it is a dictionary.n' 'Use the json module; you've already got legal JSON aside from missing the outer curly braces:nnimport jsonnnwith open(""test.txt"") as f:n    mydict = json.loads('{{ {} }}'.format(f.read()))nn'",['python-3.x'],['dictionary']
40120151,"'Find function in Python 3.x' ""When we have the following: nntweet2 = 'Want cheap snacks? Visit @cssu office in BA2283'nnnprint(tweet2tweet2.find('cheap')) results in the output 'c' and I cant wrap my head around how it does this. I tried the visualizer and it didn't show anything. Could anyone please explain?n"" 'tweet2.find('cheap') returns the index at which the beginning of ""cheap"" is found and when that index is used in tweet2index it returns the character at that index which is ""c""n' ""You should consider reading python documentation on string methods and lists  nn# define string variable tweet2ntweet2 = 'Want cheap snacks? Visit @cssu office in BA2283'n# find position of substring 'cheap' which is 5 (strings has 0-based indices in pythonnn = tweet2.find('cheap')n# print 5th element of string which is 'c'nprint(tweet2n)nn"" ""find returns an index not a slice.nnIf you want the full string you can get it like so:nnto_find = 'cheap'nind = tweet2.find(to_find)nprint(tweet2ind:ind+len(to_find))nn"" ""It's because the find(str string) method determines if str occurs in string or in a substring of string and returns the position of first occurrence. So when you call tweet2.find('cheap') it will return the position that is the first occurs of cheap.n""",['python-3.x'],"['python-3.x', 'python-2.7']"
40120210,"'Python runs the commented-out code' 'I have a problem that sometimes docker-py returns an error:nnPermission denied.nnnI'm trying to fix it. I commented out the piece of code and received the following picture.nnFile ""/opt/dst/src/utils/runner.py"" line 48 in run_codenn#if len(cli.containers(filters={'status': 'running' 'created'})) >= settings.DOCKER_CONTAINER_COUNT:nnnTraceback (most recent call last):n  File ""/opt/dst/env/lib/python2.7/site-packages/celery/app/trace.py"" line 240 in trace_taskn    R = retval = fun(*args **kwargs)n  File ""/opt/dst/env/lib/python2.7/site-packages/celery/app/trace.py"" line 438 in __protected_call__n    return self.run(*args **kwargs)n  File ""/opt/dst/src/core/tasks.py"" line 12 in runn    return 'Solution not found'n  File ""/opt/dst/src/utils/runner.py"" line 48 in run_coden    #if len(cli.containers(filters={'status': 'running' 'created'})) >= settings.DOCKER_CONTAINER_COUNT:n  File ""/opt/dst/env/lib/python2.7/site-packages/docker/api/container.py"" line 85 in containersn    res = self._result(self._get(u params=params) True)n  File ""/opt/dst/env/lib/python2.7/site-packages/docker/utils/decorators.py"" line 47 in innern    return f(self *args **kwargs)n  File ""/opt/dst/env/lib/python2.7/site-packages/docker/client.py"" line 132 in _getn    return self.get(url **self._set_request_timeout(kwargs))n  File ""/opt/dst/env/lib/python2.7/site-packages/requests/sessions.py"" line 487 in getn    return self.request('GET' url **kwargs)n  File ""/opt/dst/env/lib/python2.7/site-packages/requests/sessions.py"" line 475 in requestn    resp = self.send(prep **send_kwargs)n  File ""/opt/dst/env/lib/python2.7/site-packages/requests/sessions.py"" line 585 in sendn    r = adapter.send(request **kwargs)n  File ""/opt/dst/env/lib/python2.7/site-packages/requests/adapters.py"" line 453 in sendn    raise ConnectionError(err request=request)nConnectionError: ('Connection aborted.' error(13 'Permission denied'))nnnnnThe runner.pyc file is updated.nWhat could be the problem?nThank you for your help and sorry for my bad englishnnUPDATE:nncli = Client('unix://var/run/docker.sock' version='1.19')nkill_client = Client('unix://var/run/docker.sock' version='1.19' timeout=0.5)nconfig = cli.create_host_config(**get_host_config(file_path))n#if len(cli.containers(filters={'status': 'running' 'created'})) >= settings.DOCKER_CONTAINER_COUNT:n#    return 'must retry' Nonenrun_string = 'timeout {} python /tmp/script.py'.format(settings.DOCKER_EXECUTE_TIME)ncontainer = cli.create_container('python:2' run_string user=uid host_config=config)nn' 'Due to an error in the script worked two instance celery and this error occurred during the operation instance who has worked with the old code.n'",['django'],"['django', 'python-2.7']"
40120245,'Matplotlib.cbook: Can not import matplotlib.cookbook example csv files' 'I am running matplotlib version 1.5.1 on python 2.7.1 on ubuntu 16.04.nWhen I try to get some sample data from matplotlib cbook module it gives following error:  nnIOError: Errno 2 No such file or directory: u'/usr/lib/python2.7/dist-packages/matplotlib/mpl-data/sample_data/msft.csv'nnnThe MWE is given below:nnimport matplotlibnimport matplotlib.cbook as cbooknprint(matplotlib.__version__)  # 1.5.1nfname = cbook.get_sample_data('msft.csv' asfileobj=False)nnwith open(fname'r') as f:n    read_data = f.read()nnnThe example was taken from:nhttp://nullege.com/codes/search/matplotlib.cbook.get_sample_data nnNote: I also looked for bug report.nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=691960 nnHowever I could not figure the solution.nSo the question remains is how can we import some sample csv file (or may be some other png files) from matplotlib.cbook module?  nnSome links:nhttp://matplotlib.org/1.3.1/api/cbook_api.htmlnHow to center a plotted image? n' nan,['matplotlib'],['matplotlib']
40120299,"'Efficient way to select most recent index with finite value in column from Pandas DataFrame?' ""I'm trying to find the most recent index with a value that is not 'NaN' relative to the current index. So say I have a DataFrame with 'NaN' values like this:nn       A       B       Cn0    2.1     5.3     4.7n1    5.1     4.6     NaNn2    5.0     NaN     NaNn3    7.4     NaN     NaNn4    3.5     NaN     NaNn5    5.2     1.0     NaNn6    5.0     6.9     5.4n7    7.4     NaN     NaNn8    3.5     NaN     5.8nnnIf I am currently at index 4 I have the values:nn       A       B       Cn4    3.5     NaN     NaNnnnI want to know the last known value of 'B' relative to index 4 which is at index 1:nn       A       B       Cn1    5.1   -> 4.6    NaNnnnI know I can get a list of all indexes with NaN values using something like:nnindexes = df.indexdf'B'.apply(np.isnan)nnnBut this seems inefficient in a large database. Is there a way to tail just the last one relative to the current index?n"" 'You may try something like this convert the index to a series that have the same NaN values as column B and then use ffill() which carries the last non missing index forward for all subsequent NaNs:nnimport pandas as pdnimport numpy as npndf'Last_index_notnull' = df.index.to_series().where(df.B.notnull() np.nan).ffill()ndf'Last_value_notnull' = df.B.ffill()ndfnnnnnNow at index 4 you know the last non missing value is 4.6 and index is 1.n' 'some useful methods to knownnlast_valid_indexnfirst_valid_indexnfor columns B as of index 4nndf.B.ix:4.last_valid_index()nn1nnnyou can use this for all columns in this waynnpd.concat(df.ix:i.apply(pd.Series.last_valid_index) for i in df.indexn          axis=1).Tnnnn'","['pandas', 'numpy']",['pandas']
40120312,"'Multiple instances of celerybeat for autoscaled django app on elasticbeanstalk' ""I am trying to figure out the best way to structure a Django app that uses Celery to handle async and scheduled tasks in an autoscaling AWS ElasticBeanstalk environment.nnSo far I have used only a single instance Elastic Beanstalk environment with Celery + Celerybeat and this worked perfectly fine. However I want to have multiple instances running in my environment because every now and then an instance crashes and it takes a lot of time until the instance is back up but I can't scale my current architecture to more than one instance because Celerybeat is supposed to be running only once across all instances as otherwise every task scheduled by Celerybeat will be submitted multiple times (once for every EC2 instance in the environment).nnI have read about multiple solutions but all of them seem to have issues that don't make it work for me:nnnUsing django cache + locking: This approach is more like a quick fix than a real solution. This can't be the solution if you have a lot of scheduled tasks and you need to add code to check the cache for every task. Also tasks are still submitted multiple times this approach only makes sure that execution of the duplicates stops.nUsing leader_only option with ebextensions: Works fine initially but if an EC2 instance in the enviroment crashes or is replaced this would lead to a situation where no Celerybeat is running at all because the leader is only defined once at the creation of the environment.nCreating a new Django app just for async tasks in the Elastic Beanstalk worker tier: Nice because web servers and workers can be scaled independently and the web server performance is not affected by huge async work loads performed by the workers. However this approach does not work with Celery because the worker tier SQS daemon removes messages and posts the message bodies to a predefined urls. Additionally I don't like the idea of having a complete additional Django app that needs to import the models from the main app and needs to be separately updated and deployed if the tasks are modified in the main app.nnnHow to I use Celery with scheduled tasks in a distributed Elastic Beanstalk environment without task duplication? E.g. how can I make sure that exactly one instance is running across all instances all the time in the Elastic Beanstalk environment (even if the current instance with Celerybeat crashes)?nnAre there any other ways to achieve this? What's the best way to use Elastic Beanstalk's Worker Tier Environment with Django?n"" nan",['django'],['django']
40120335,"'Grabbing selected choice from Django template form' 'i have been googling for 2 days now without success. Im new to python and especially Django and just cant figure out how to grab a selection from a dropdown list from my html template. I would like to avoid using any javascript/ajax/ and even the use of Models (db stuffs) as this would complicate my existing code and Im already lost. ^__^nnFirstly my environment:nnPython2.7nDjango1.5nCentOS 6nnviews.pynndef get_cas_options():n    ...n    ... # this function works and lets say returns: abcdn    ...n    return casnndef get_cas_page(request):n    form = {}n    if form.is_valid():n        ....n        ....n        form""cas_selected"" = get_cas_options()n        ....n    return render(request 'templates/client_cas.html' form)nnnclient_cas.htmlnn<form method=""post"">n{% csrf_token %}nn<b>CAS:</b>n<select name=""cas_selected"">n    {% for option in cas_selected %}n        <option value=""{{option.id}}"" selected=""selected"">{{option}}</option>n    {% endfor %}n    <option value=""all"">all</option>n</select>nn</form>nnnThe code provided works. As in I do get a drop down on my html page with options: abcd.nnWhat i have attempted was to add:nnclient_cas.htmlnn<input type='submit' name='search!'/>nnnand nnviews.pynnuser_cas_selected = form'cas_selected'nnnproblem is no matter what i select from the drop down I always get the entire list returned to user_cas_selected var so i end up with this: abcd and have no idea what the user selected.nnI am not good at modifying models or using advanced Django techniques is there any simple way of me adding few extra lines of code for me to be able to grab which item i selected and feed it back to a variable in the views.py? nnNot to complicate this question but i have also added this which is never called as its abandoned in my code currently (as i cant figure it out) to the:nnforms.pynnclass CasSelectForm(forms.Form):n    cas_selected = forms.ChoiceField(widget=forms.Select(attrs={""onChange"": 'this.form.submit();'}) required=False)nnnbut a) choices needs to come from the views.get_cas_options method. Not sure i even want to go down this route as Ill probably get confused.nnHelp would be greatly appreciated. n' nan",['django'],['django']
40120379,"'Python Argparse: how to make an argument required if and only if one flag is given?' 'I am wondering how can I make one argument required when one flag is given and optional when that flag is not given?nnimport argparsennnparser = argparse.ArgumentParser()nnparser.add_argument('-c' '--convert' action = 'store_true')nparser.add_argument('-l' '--lookup' action = 'store_true')nparser.add_argument('name' type = str) nnargs = parser.parse_args()nnif args.name:n    print(args.name)nif args.convert:n    print (""convert now!"")nnnFor example in the codes above I want name to be required only when -c is given. When I run the program only with -l then there is an error:nn$ python3 test.py -lnusage: test.py -h -c -l namentest.py: error: the following arguments are required: namennnI have tried to use argument group to divide the arguments into two groups 1. -c and name; 2. -l but it didn't really work.nnAny suggestions are appreciated!n' 'This isn't something argparse can enforce on its own. What you can do is define name to be optional then check after parsing if your constraint is met.nnimport argparsennnparser = argparse.ArgumentParser()nnparser.add_argument('-c' '--convert' action='store_true')nparser.add_argument('-l' '--lookup' action='store_true')nparser.add_argument('name' nargs='?') nnargs = parser.parse_args()nn# If args.name must be a non-empty string when givenn# you can use 'not args.name' in place of 'args.name is None'nif args.convert and args.name is None:n    parser.error(""<name> required with --convert"")nnif args.name:n    print(args.name)nif args.convert:n    print (""convert now!"")nn' ""There isn't anything in argparse to do this directly; but it can be approximated in various waysnnparser.add_argument('-c' '--convert' action = 'store_true')nparser.add_argument('-l' '--lookup' action = 'store_true')nparser.add_argument('name' nargs='?' default='good default') nnnIt's not required in either case but in the case of -c you could either use the good default or you can complain after parsing.nnparser.add_argument('-c' '--convert')nparser.add_argument('-l' '--lookup' nargs='?' default='adefault' const='aconst')nnnIn this case -c expects an argument your required name.  An argument is optional for -l.  If no -l the value is the default; if  -l without the argument the value is the const.  You could even put -c and -l in a mutually exclusive group.nnThere isn't a mechanism for requiring several arguments to go together (i.e. no 'mutually-required-group`).  However subparsers work along that line.  Do I need to illustrate how subparsers could be use here?nnCustom Actions classes can be used to force some sort of interaction between arguments but usually it's easier to implement that sort of thing after parsing.  Remember argparse allows you give arguments in any order.  Thus the name  positional could occur before -c or after or between -l and -c etc.n""",['python-3.x'],"['python-3.x', 'python-2.7']"
40120596,"'Is there a built-in way to use CPython built-ins to make an arbitrary callable behave as an unbound class method?' 'In Python 2 it was possible to convert arbitrary callables to methods of a class. Importantly if the callable was a CPython built-in implemented in C you could use this to make methods of user-defined classes that were C layer themselves invoking no byte code when called.nnThis is occasionally useful if you're relying on the GIL to provide ""lock-free"" synchronization; since the GIL can only be swapped out between op codes if all the steps in a particular part of your code can be pushed to C you can make it behave atomically.nnIn Python 2 you could do something like this:nnimport typesnfrom operator import attrgetternclass Foo(object):n    ... This class maintains a member named length storing the length...nn    def __len__(self):n        return self.length  # We don't want this because we're trying to push all work to Cnn# Instead we explicitly make an unbound method that uses attrgetter to achieven# the same result as above __len__ but without no byte code invoked to satisfy itnFoo.__len__ = types.MethodType(attrgetter('length') None Foo)nnnIn Python 3 there is no longer an unbound method type and types.MethodType only takes two arguments and creates only bound methods (which is not useful for Python special methods like __len__ __hash__ etc. since special methods are often looked up directly on the type not the instance).nnIs there some way of accomplishing this in Py3 that I'm missing?nnThings I've looked at:nnnfunctools.partialmethod (appears to not have a C implementation so it fails the requirements and between the Python implementation and being much more general purpose than I need it's slow taking about 5 us in my tests vs. ~200-300 ns for direct Python definitions or attrgetter in Py2 a roughly 20x increase in overhead)nTrying to make attrgetter or the like follow the non-data descriptor protocol (not possible AFAICT can't monkey-patch in a __get__ or the like)nTrying to find a way to subclass attrgetter to give it a __get__ but of course the __get__ needs to be delegated to C layer somehow and now we're back where we startedn(Specific to attrgetter use case) Using __slots__ to make the member a descriptor in the first place then trying to somehow convert from the resulting descriptor for the data into something that skips the final step of binding and acquiring the real value to something that makes it callable so the real value retrieval is deferrednnnI can't swear I didn't miss something for any of those options though. Anyone have any solutions? Total hackery is allowed; I recognize I'm doing pathological things here. Ideally it would be flexible (to let you make something that behaves like an unbound method out of a class a Python built-in function like hex len etc. or any other callable object not defined at the Python layer). Importantly it needs to attach to the class not each instance (both to reduce per-instance overhead and to work correctly for dunder special methods which bypass instance lookup in most cases).n' nan",['python-3.x'],"['python-3.x', 'python-2.7']"
40120605,'Error on importing matplotlib on mac os x' '>>> import matplotlib.pyplot as pltnobjc19151: Class TKApplication is implemented in both /System/Library/Frameworks/Tk.framework/Versions/8.5/Tk (0x107aab188) and /Users/rit/anaconda2/envs/mac_gdal/lib/libtk8.5.dylib (0x1117e0e40). One of the two will be used. Which one is undefined.nobjc19151: Class TKMenu is implemented in both /System/Library/Frameworks/Tk.framework/Versions/8.5/Tk (0x107aab1d8) and /Users/rit/anaconda2/envs/mac_gdal/lib/libtk8.5.dylib (0x1117e2020). One of the two will be used. Which one is undefined.nobjc19151: Class TKContentView is implemented in both /System/Library/Frameworks/Tk.framework/Versions/8.5/Tk (0x107aab228) and /Users/rit/anaconda2/envs/mac_gdal/lib/libtk8.5.dylib (0x1117e28a0). One of the two will be used. Which one is undefined.nobjc19151: Class TKWindow is implemented in both /System/Library/Frameworks/Tk.framework/Versions/8.5/Tk (0x107aab278) and /Users/rit/anaconda2/envs/mac_gdal/lib/libtk8.5.dylib (0x1117e2da0). One of the two will be used. Which one is undefined.nnnHow do I fix this error when I import matplotlib. I am using python 2.7.12 on Mac Os X (Sierra)n' nan,['matplotlib'],"['matplotlib', 'tkinter']"
40120770,"'How to write unittest for variable assignment in python?' ""This is in Python 2.7.  I have a class called class A and there are some attributes that I want to throw an exception when being set by the user:nnmyA = A()nmyA.myattribute = 9   # this should throw an errornnnI want to write a unittest that ensures that this throws an error.  nnAfter creating a test class and inheriting unittest.TestCase I tried to write a test like this:nnmyA = A()nself.assertRaises(AttributeError eval('myA.myattribute = 9'))nnnBut this throws a syntax error.  However if I try eval('myA.myattribute = 9') it throws the attribute error as it should.nnHow do I write a unittest to test this correctly?  nnThanks.n"" ""self.assertRaises takes a callable (and optionally one or more arguments for that callable) as its argument; you are providing the value that results from calling the callable with its arguments. The correct test would be self.assertRaises(AttributeError eval 'myA.myattribute = 9')nn# Thanks to @mgilson for something that actually works whilen# resembling the original attempt.nself.assertRaises(AttributeError eval 'myA.myattribute = 9' locals())nnnHowever you should use assertRaises as a context manager which allows you to write the much more naturalnnwith self.assertRaises(AttributeError):n    myA.myattribute = 9nn"" 'You can also use assertRaises as a context manager:nnwith self.assertRaises(AttributeError):n    myA.myattribute = 9nnnThe documentation shows more examples for this if you are interested. The documentation for assertRaises has a lot more detail on this subject as well.nnFrom that documentation:nnn  If only the exception and possibly the msg arguments are given return a context manager so that the code under test can be writtenn  inline rather than as a function:nnwith self.assertRaises(SomeException):n     do_something()nnnnwhich is exactly what you are trying to do.n'",['python-2.7'],['python-2.7']
40120818,'how to hide axes in matplotlib.pyplot' 'I put the image in a numpy array and draw it with the following code. How can I tell the program not to draw the axes like (0 100 200...) nnimport matplotlib.pyplot as pltnplt.figure()nplt.imshow(output_ndarray)nplt.savefig(output_png)nnnn' 'plt.xticks()nplt.yticks()nnnhttp://matplotlib.org/api/pyplot_api.htmln' 'You can also use...nnplt.axis('off')nnnn',"['numpy', 'matplotlib']",['matplotlib']
40120931,"'pandas list cursor error' 'Making a follow up question to a separate question i posted earlier. Unable to create a second dataframe python pandasnnThe error i figured out was when i try to make a list out of my cursor object i could no longer call that cursor to say make another dataframe with it. See below:nnstrsql1 = ""SELECT * FROM CRMCSVFILE""ncursor = cursor.execute(strsql1)ndf = pd.DataFrame.from_records(cursor)nnnstrsql2 = ""SELECT * FROM CRMSVFILE WHERE EMAIL = 'some email'""ncursor = cursor.execute(strsql1)nmaxList = list(cursor)n#when i set maxList to list(cursor) i get an error on the next linenanother_df = pd.DataFrame.from_records(cursor)nnnThe error says that cursor is empty and i want to know why when i take out the maxList = list(cursor) statement that the code works fine and i can make as many dataframes as i want.n' nan",['pandas'],['pandas']
40121126,"'Error importing storage module.whitenoise.django' 'I'm trying to deploy a basic Django app to Heroku but am getting an error when I try to deploy.nnIt looks like the error is with whitenoise. I have six installed as part of my requirements so it should handle urllib.parse.nnHere is the error:nnremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/files/storage.py"" line 290 in get_storage_classnremote:            raise ImproperlyConfigured('Error importing storage module %s: ""%s""' % (module e))nremote:        django.core.exceptions.ImproperlyConfigured: Error importing storage module whitenoise.django: ""No module named urllib.parse""nremote: nremote:  !     Error while running '$ python manage.py collectstatic --noinput'.nnnHere is the full stack:nnremote: nremote: -----> Python app detectednremote: -----> Uninstalling stale dependenciesnremote:        Uninstalling DateTime-4.1.1:nremote:          Successfully uninstalled DateTime-4.1.1nremote:        Uninstalling simplejson-3.8.2:nremote:          Successfully uninstalled simplejson-3.8.2nremote: -----> Noticed cffi. Bootstrapping libffi.nremote:      $ pip install -r requirements.txtnremote:        Collecting altgraph==0.10.2 (from -r requirements.txt (line 1))nremote:          Downloading altgraph-0.10.2.tar.gz (481kB)nremote:        Collecting bdist-mpkg==0.5.0 (from -r requirements.txt (line 2))nremote:          Downloading bdist_mpkg-0.5.0.tar.gznremote:        Collecting bpython==0.12 (from -r requirements.txt (line 3))nremote:          Downloading bpython-0.12.tar.gz (130kB)nremote:        Collecting csvkit==0.7.3 (from -r requirements.txt (line 4))nremote:          Downloading csvkit-0.7.3.tar.gznremote:        Collecting Cython==0.19.2 (from -r requirements.txt (line 5))nremote:          Downloading Cython-0.19.2-cp27-cp27m-manylinux1_x86_64.whl (4.0MB)nremote:        Collecting dbf==0.94.3 (from -r requirements.txt (line 6))nremote:          Downloading dbf-0.94.003.tar.gz (79kB)nremote:        Collecting dj-database-url==0.4.1 (from -r requirements.txt (line 7))nremote:          Downloading dj-database-url-0.4.1.tar.gznremote:        Collecting Django==1.5.4 (from -r requirements.txt (line 8))nremote:          Downloading Django-1.5.4.tar.gz (8.1MB)nremote:        Collecting future==0.11.2 (from -r requirements.txt (line 9))nremote:          Downloading future-0.11.2.tar.gz (321kB)nremote:        Collecting futures==3.0.5 (from -r requirements.txt (line 10))nremote:          Downloading futures-3.0.5-py2-none-any.whlnremote:        Collecting greenlet==0.4.1 (from -r requirements.txt (line 11))nremote:          Downloading greenlet-0.4.1.zip (75kB)nremote:        Collecting grequests==0.2.0 (from -r requirements.txt (line 12))nremote:          Downloading grequests-0.2.0.tar.gznremote:        Collecting gunicorn==19.6.0 (from -r requirements.txt (line 13))nremote:          Downloading gunicorn-19.6.0-py2.py3-none-any.whl (114kB)nremote:        Collecting humanize==0.5 (from -r requirements.txt (line 14))nremote:          Downloading humanize-0.5.tar.gznremote:        Collecting iso8601==0.1.8 (from -r requirements.txt (line 15))nremote:          Downloading iso8601-0.1.8.tar.gznremote:        Collecting livestreamer==1.12.2 (from -r requirements.txt (line 16))nremote:          Downloading livestreamer-1.12.2.tar.gz (430kB)nremote:        Collecting macholib==1.5.1 (from -r requirements.txt (line 17))nremote:          Downloading macholib-1.5.1.tar.gz (454kB)nremote:        Collecting modulegraph==0.10.4 (from -r requirements.txt (line 18))nremote:          Downloading modulegraph-0.10.4.tar.gz (532kB)nremote:        Collecting MySQL-python==1.2.4 (from -r requirements.txt (line 19))nremote:          Downloading MySQL-python-1.2.4.zip (113kB)nremote:        Collecting openpyxl==2.0.3 (from -r requirements.txt (line 20))nremote:          Downloading openpyxl-2.0.3.tar.gz (113kB)nremote:        Collecting py2app==0.7.3 (from -r requirements.txt (line 21))nremote:          Downloading py2app-0.7.3.tar.gz (1.2MB)nremote:        Collecting pycrypto==2.6.1 (from -r requirements.txt (line 22))nremote:          Downloading pycrypto-2.6.1.tar.gz (446kB)nremote:        Collecting pycurl==7.19.0.2 (from -r requirements.txt (line 23))nremote:          Downloading pycurl-7.19.0.2.tar.gz (89kB)nremote:        Collecting Pygments==1.6 (from -r requirements.txt (line 24))nremote:          Downloading Pygments-1.6.tar.gz (1.4MB)nremote:        Collecting pyOpenSSL==0.13.1 (from -r requirements.txt (line 25))nremote:          Downloading pyOpenSSL-0.13.1.tar.gz (254kB)nremote:        Collecting pyparsing==2.0.1 (from -r requirements.txt (line 26))nremote:          Downloading pyparsing-2.0.1.tar.gz (1.1MB)nremote:        Collecting python-dateutil==1.5 (from -r requirements.txt (line 27))nremote:          Downloading python-dateutil-1.5.tar.gz (233kB)nremote:        Collecting pytz==2013.7 (from -r requirements.txt (line 28))nremote:          Downloading pytz-2013.7.tar.bz2 (177kB)nremote:        Collecting requests==2.0.1 (from -r requirements.txt (line 29))nremote:          Downloading requests-2.0.1-py2.py3-none-any.whl (439kB)nremote:        Collecting singledispatch==3.4.0.3 (from -r requirements.txt (line 30))nremote:          Downloading singledispatch-3.4.0.3-py2.py3-none-any.whlnremote:        Collecting six==1.4.1 (from -r requirements.txt (line 31))nremote:          Downloading six-1.4.1.tar.gznremote:        Collecting SQLAlchemy==0.9.4 (from -r requirements.txt (line 32))nremote:          Downloading SQLAlchemy-0.9.4.tar.gz (4.5MB)nremote:        Collecting virtualenv==15.0.3 (from -r requirements.txt (line 33))nremote:          Downloading virtualenv-15.0.3-py2.py3-none-any.whl (3.5MB)nremote:        Collecting whitenoise==3.2.2 (from -r requirements.txt (line 34))nremote:          Downloading whitenoise-3.2.2-py2.py3-none-any.whlnremote:        Collecting xattr==0.6.4 (from -r requirements.txt (line 35))nremote:          Downloading xattr-0.6.4.tar.gznremote:        Collecting xlrd==0.9.3 (from -r requirements.txt (line 36))nremote:          Downloading xlrd-0.9.3.tar.gz (178kB)nremote:        Collecting zope.interface==4.1.1 (from -r requirements.txt (line 37))nremote:          Downloading zope.interface-4.1.1.tar.gz (864kB)nremote:        Collecting gevent (from grequests==0.2.0->-r requirements.txt (line 12))nremote:          Downloading gevent-1.1.2-cp27-cp27m-manylinux1_x86_64.whl (1.3MB)nremote:        Collecting jdcal (from openpyxl==2.0.3->-r requirements.txt (line 20))nremote:          Downloading jdcal-1.3.tar.gznremote:        Installing collected packages: altgraph bdist-mpkg Pygments bpython xlrd python-dateutil SQLAlchemy jdcal openpyxl dbf csvkit Cython dj-database-url Django future futures greenlet gevent requests grequests gunicorn humanize iso8601 six singledispatch livestreamer macholib modulegraph MySQL-python py2app pycrypto pycurl pyOpenSSL pyparsing pytz virtualenv whitenoise xattr zope.interfacenremote:          Running setup.py install for altgraph: startednremote:            Running setup.py install for altgraph: finished with status 'done'nremote:          Running setup.py install for bdist-mpkg: startednremote:            Running setup.py install for bdist-mpkg: finished with status 'done'nremote:          Running setup.py install for Pygments: startednremote:            Running setup.py install for Pygments: finished with status 'done'nremote:          Running setup.py install for bpython: startednremote:            Running setup.py install for bpython: finished with status 'done'nremote:          Running setup.py install for xlrd: startednremote:            Running setup.py install for xlrd: finished with status 'done'nremote:          Running setup.py install for python-dateutil: startednremote:            Running setup.py install for python-dateutil: finished with status 'done'nremote:          Running setup.py install for SQLAlchemy: startednremote:            Running setup.py install for SQLAlchemy: finished with status 'done'nremote:          Running setup.py install for jdcal: startednremote:            Running setup.py install for jdcal: finished with status 'done'nremote:          Running setup.py install for openpyxl: startednremote:            Running setup.py install for openpyxl: finished with status 'done'nremote:          Running setup.py install for dbf: startednremote:            Running setup.py install for dbf: finished with status 'done'nremote:          Running setup.py install for csvkit: startednremote:            Running setup.py install for csvkit: finished with status 'done'nremote:          Running setup.py install for dj-database-url: startednremote:            Running setup.py install for dj-database-url: finished with status 'done'nremote:          Running setup.py install for Django: startednremote:            Running setup.py install for Django: finished with status 'done'nremote:          Running setup.py install for future: startednremote:            Running setup.py install for future: finished with status 'done'nremote:          Running setup.py install for greenlet: startednremote:            Running setup.py install for greenlet: finished with status 'done'nremote:          Found existing installation: requests 2.11.1nremote:            Uninstalling requests-2.11.1:nremote:              Successfully uninstalled requests-2.11.1nremote:          Running setup.py install for grequests: startednremote:            Running setup.py install for grequests: finished with status 'done'nremote:          Running setup.py install for humanize: startednremote:            Running setup.py install for humanize: finished with status 'done'nremote:          Running setup.py install for iso8601: startednremote:            Running setup.py install for iso8601: finished with status 'done'nremote:          Running setup.py install for six: startednremote:            Running setup.py install for six: finished with status 'done'nremote:          Running setup.py install for livestreamer: startednremote:            Running setup.py install for livestreamer: finished with status 'done'nremote:          Running setup.py install for macholib: startednremote:            Running setup.py install for macholib: finished with status 'done'nremote:          Running setup.py install for modulegraph: startednremote:            Running setup.py install for modulegraph: finished with status 'done'nremote:          Running setup.py install for MySQL-python: startednremote:            Running setup.py install for MySQL-python: finished with status 'done'nremote:          Running setup.py install for py2app: startednremote:            Running setup.py install for py2app: finished with status 'done'nremote:          Running setup.py install for pycrypto: startednremote:            Running setup.py install for pycrypto: finished with status 'done'nremote:          Running setup.py install for pycurl: startednremote:            Running setup.py install for pycurl: finished with status 'done'nremote:          Running setup.py install for pyOpenSSL: startednremote:            Running setup.py install for pyOpenSSL: finished with status 'done'nremote:          Running setup.py install for pyparsing: startednremote:            Running setup.py install for pyparsing: finished with status 'done'nremote:          Found existing installation: pytz 2016.7nremote:            Uninstalling pytz-2016.7:nremote:              Successfully uninstalled pytz-2016.7nremote:          Running setup.py install for pytz: startednremote:            Running setup.py install for pytz: finished with status 'done'nremote:          Running setup.py install for xattr: startednremote:            Running setup.py install for xattr: finished with status 'done'nremote:          Found existing installation: zope.interface 4.3.2nremote:            Uninstalling zope.interface-4.3.2:nremote:              Successfully uninstalled zope.interface-4.3.2nremote:          Running setup.py install for zope.interface: startednremote:            Running setup.py install for zope.interface: finished with status 'done'nremote:        Successfully installed Cython-0.19.2 Django-1.5.4 MySQL-python-1.2.4 Pygments-1.6 SQLAlchemy-0.9.4 altgraph-0.10.2 bdist-mpkg-0.5.0 bpython-0.12 csvkit-0.7.3 dbf-0.94.3 dj-database-url-0.4.1 future-0.11.2 futures-3.0.5 gevent-1.1.2 greenlet-0.4.1 grequests-0.2.0 gunicorn-19.6.0 humanize-0.5 iso8601-0.1.8 jdcal-1.3 livestreamer-1.12.2 macholib-1.5.1 modulegraph-0.10.4 openpyxl-2.0.3 py2app-0.7.3 pyOpenSSL-0.13.1 pycrypto-2.6.1 pycurl-7.19.0.2 pyparsing-2.0.1 python-dateutil-1.5 pytz-2013.7 requests-2.0.1 singledispatch-3.4.0.3 six-1.4.1 virtualenv-15.0.3 whitenoise-3.2.2 xattr-0.6.4 xlrd-0.9.3 zope.interface-4.1.1nremote: nremote:      $ python manage.py collectstatic --noinputnremote:        Traceback (most recent call last):nremote:          File ""manage.py"" line 10 in <module>nremote:            execute_from_command_line(sys.argv)nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/management/__init__.py"" line 453 in execute_from_command_linenremote:            utility.execute()nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/management/__init__.py"" line 392 in executenremote:            self.fetch_command(subcommand).run_from_argv(self.argv)nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/management/__init__.py"" line 272 in fetch_commandnremote:            klass = load_command_class(app_name subcommand)nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/management/__init__.py"" line 78 in load_command_classnremote:            return module.Command()nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/contrib/staticfiles/management/commands/collectstatic.py"" line 58 in __init__nremote:            self.storage.path('')nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/utils/functional.py"" line 204 in innernremote:            self._setup()nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/contrib/staticfiles/storage.py"" line 307 in _setupnremote:            self._wrapped = get_storage_class(settings.STATICFILES_STORAGE)()nremote:          File ""/app/.heroku/python/lib/python2.7/site-packages/django/core/files/storage.py"" line 290 in get_storage_classnremote:            raise ImproperlyConfigured('Error importing storage module %s: ""%s""' % (module e))nremote:        django.core.exceptions.ImproperlyConfigured: Error importing storage module whitenoise.django: ""No module named urllib.parse""nremote: nremote:  !     Error while running '$ python manage.py collectstatic --noinput'.nremote:        See traceback above for details.nremote: nremote:        You may need to update application code to resolve this error.nremote:        Or you can disable collectstatic for this application:nremote: nremote:           $ heroku config:set DISABLE_COLLECTSTATIC=1nremote: nremote:        https://devcenter.heroku.com/articles/django-assetsnremote:  !     Push rejected failed to compile Python app.nn' 'You're using an unsupported version of Django. Django 1.5 has been out of mainstream support for three years and out of extended support for two.nSee here: https://www.djangoproject.com/download/#supported-versionsnnThe latest version of WhiteNoise is tested with Django 1.8 and up.n'",['django'],['django']
40121221,"'gunicorn not starting on port 80 but starting on port 8000' ""I am using gunicorn and trying to write the upstart script. I am testing the command in the command line and for port 80 it just gets errorsnncommandnngunicorn --bind 0.0.0.0:80 --workers 3 myapp.wsgi:applicationnnnlognn2016-10-19 02:36:51 +0000 12752 INFO Starting gunicorn 19.6.0n2016-10-19 02:36:51 +0000 12752 ERROR Retrying in 1 second.n2016-10-19 02:36:52 +0000 12752 ERROR Retrying in 1 second.n2016-10-19 02:36:53 +0000 12752 ERROR Retrying in 1 second.n2016-10-19 02:36:54 +0000 12752 ERROR Retrying in 1 second.n2016-10-19 02:36:55 +0000 12752 ERROR Retrying in 1 second.n2016-10-19 02:36:56 +0000 12752 ERROR Can't connect to ('0.0.0.0' 80)nnnany ideas why this is not working? Sometimes it works for port 8000.n"" nan",['django'],['django']
40121231,"'Python string to dictionary with json (not working)' 'I have a text file like this :nn""imei"": ""123456789""n""sim_no"": ""+90 xxx xxx xx xx""n""device_type"": ""standart""n""hw_version"": ""1.01""n""sw_version"": ""1.02""nnand i want to convert to dictionary this file. Because i want to take values. nnimport jsonnfrom time import sleepnndef buffer(data):n    dicto=json.loads(data) n    print(type(dicto))      nnfile=open(""config.txt"" ""r"").read()njsondata=json.dumps(file)  nbuffer(jsondata)nnresult : <class 'str'>nnnWhen i working in shell like this :nn>>> import jsonn>>> h = '{""foo"":""bar"" ""foo2"":""bar2""}'n>>> type(h)n<class 'str'>n>>> d=json.loads(h)n>>> dn{'foo2': 'bar2' 'foo': 'bar'}n>>> type(d)n<class 'dict'>n>>> nnnits working but i can't understand why my code not working. When i convert this file to dictionary i want to hold in a buffer. How can i hold this data inside array? Please excuse me i am new in Python.n' 'import jsonnfrom time import sleepnndef buffer(data):n    s = json.loads(data) n    dicto = {}n    tmp_list = s.split('')n    for e in tmp_list:n        tmp = e.split(':')n        dictotmp0 = tmp1 n    print(type(dicto))      nnfile=open(""config.txt"" ""r"").read()njsondata=json.dumps(file)  nbuffer(jsondata)nn' ""Seems like you could just add the outer curly braces JSON requires:nnwith open('config.txt' 'r+') as f:n    newdata = '{{ {} }}'.format(f.read())n    f.seek(0)n    f.write(newdata)nnnOtherwise the file is already JSON so no actual use of the json module is required (unless you want to check if it's already legal before modifying or verify legality after).n"" 'I have to solve this question :nnWe have a text file like this :nn""imei"": ""123456789""n""sim_no"": ""+90 xxx xxx xx xx""n""device_type"": ""standart""n""hw_version"": ""1.01""n""sw_version"": ""1.02""nnnAnd we should read this JSON data then we should read this data each 1 min and put to buffer(idk how can i put is buffer array or dict?) then we should delete the oldest file each 5 min. Exceptions are important. Format sould be like ""imei"" ""hw_version"" ""sw_version"" ""device_type"". We sould solve buffer overflowing.nnI write this code :nnimport jsonnfrom time import sleepnndef buffer(data):n    passn    #imei = data.get(""imei"") # I want to read like thisn    # this function should put the variables to arrayncounter=0nwhile True:n    with open(""config.txt"") as f:n        mydict = json.loads('{{ {} }}'.format(f.read()))    n    buffer(mydict)n    sleep(60)n    counter+=1n    if counter%5==0n        # delete the oldest datann'",['python-3.x'],"['dictionary', 'python-2.7']"
40121281,"'Remove elements from DB that are not in an array adding elements from an array that are not in DB' 'I'm currently trying to create a view in Django to receive and process JSON data from a POST request. I'm currently having issues trying to add/update multiple NotificationEmail objects in my database.nnWhat I would like to do is to check if the emails inside the array (email) sent via the POST  request are already stored in a NoticationEmail  object as the emailAddress element for that object. If it already exists as the emailAddress  for a NotificationEmail  object I would like to keep it. If the email inside the array is not stored in any NotificationEmail  object as the emailAddress  value I would like to add a new NotificationEmail  object with this email as the emailAddress  value. And finally if there's any NotificationEmail  for that specific id (given through the POST request) with an  emailAddress  value that is not listed in the emails array I want to delete it.nnI'm currently just getting an error message for the for  loops I've created so I can't run the server and try it out. I've checked that without the for  loops it does receive the POST  request and is able to add the full array  of emails as an emailAddress  value inside an NotificationEmail  object for that id . But this is not the behavior I would like to have in my program.nnMy code for the Django view  is the following:nn@csrf_exemptndef editMachines(request):n       if request.method == 'POST':n                json_data = json.loads(request.body)n                a = Machine.objects.filter(id = json_data'id').update(name = json_data'machine_name')n                userid = a.user_idn                b = NotificationEmail.objects.filter(machine_id = json_data'id'.values()n                for i in range (len(json_data'email')):n                        exists = falsen                        count = 0n                        while exists == false or count < len(b):n                                if json_data'email'i == bcount'emailAddress':n                                        exists = truen                                        count++n                                else:n                                        bcount.delete()n                                        d = NotificationEmail(machine_id = json_data'id' email = json_data'email'i.values() user = userid)n                                        d.save()n                                        count++nnnn                return HttpResponse(status = 200)nnnAnd this is the JavaScript code that sends the POST request:nn function updateMachine(){n                            var e = $('#emailAdd').val()n                            var emails = e.split(' ')n                            console.log(emails);n                            var data = {id : machineid machine_name : $('#name').val() email : emails};n                                    console.log(data)n                                    $.ajax({n                                            type:'POST'n                                            url:'/edit/machines/' n                                            data: JSON.stringify(data)n                                            dataType: 'json'n                                            contentType: 'application/json'n                                            statusCode : {n                                                    200 : function(){n                                                                      alert(""User updated."");n                                                                        window.location = ""/users/dashboard/"";n                                                    }n                                            }n                                            async : falsen                                    });n                             }nnnI know the Ajax in Javascript is working fine since I was able to do some changes with it but I'm having a lot of troubles trying to get the Django view to do what I need.nnI would highly appreciate if anyone can guide me on what I can do to achieve it. :(nnThanks in advance!n' nan","['django', 'python-3.x']",['django']
40121350,"'str.replace function raise erorr that an integer is required' ""I wanna ask the problem I encountered. At first nLet me show you my whole codenndf1 = pd.read_excel(r'E:ëx82´ëx85¼ë¬¸ìx9ex90ë£x8cê³¨ëª©ìx83x81ê¶x8c ëx8d°ìx9d´íx84°ìx9d´íx83x9cìx9bx90ë¡x9c 54ê¸¸ ëx82´ìx9a©ëºx80ê±°.xlsx'  sheetname='first_day_datas')ndf1.registerdate= df1.registerdate.astype(str) # ì¹¼ëx9f¼ ìx86x8dìx84± ë°x94ê¾¸ê¸°ndf2 = pd.to_datetime(df1'registerdate'.str0:10)ndf3 = df2'registerdate'.str.replace('-' '').str.strip()nnnI just wanna change the string in registerdate column.nwhen I put print(df2.head(3)). It shows like belownn0   2016-10-11n1   2016-10-15n2   2016-10-15nnnso I wanna replace '-' with ''. nI type the code and 'TypeError: an integer is required' popped out.nHow can I solve this problem??n"" ""df2 = pd.to_datetime(df1'registerdate'.str0:10)n#     ____________/n#    returns a seriesnnnnndf2'registerdate'.str.replace('-' '').str.strip()n#_______________/n# is only somethingn# if 'registrationn# is in the indexn# this is probably the source of your errornnnnnAt this point df2 is a pd.Series of Timestamps.  the format yyyy-mm-dd is just the way that Timestamp is being displayed.  To display it as yyyymmdd do thisnndf2.dt.strftime('%Y%m%d')nn0    20160331n1    20160401n2    20160402n3    20160403n4    20160404nName: registerdate dtype: objectnn"" ""It seems df2 has no column 'registerdate' It is a timestamp list.nI think df2.map(lambda x: x.strftime('%Y%m%d') can convert timestamp to the format you need.n""",['pandas'],['pandas']
40121393,'How to get HID reader details connected to my system while my applications runs on AWS' 'My web application is running on AWS. I written code for to get card details when a card is flashed on the HID omnikey reader and it is working fine in local environment but when i kept in AWS its not working. nncan someone tell me what exatly happening. Cause my code runs on AWS means different IP address HID connected my system which is diff IP address. nnHow to communicate for the above scenario.n' nan,['python-2.7'],['python-2.7']
40121562,'Clustered Stacked Bar in Python Pandas' 'I have created a single stacked bar chart but I want to have them clustered. Exactly something like the picture. nnWondering if it's possible. nnlink to picturen' 'df = pd.DataFrame(dict(Subsidy=3 3 3n                       Bonus=1 1 1n                       Expense=2 2 2)n                  list('ABC'))nndfnnnnnax = df'Subsidy' 'Bonus'.plot.bar(stacked=True position=1n                            width=.2 ylim=0 8 color='orange' 'red')ndf'Expense'.plot.bar(ax=ax position=0 width=.2 color='green')nnnn',"['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40121582,'Efficient matrix multiplication in Matlab' 'I have two matrices A (N by K) and B (N by M) and I would like to concentrate A and B into a tensor C (N by K by M) where C(nkm) = A(nk) * B(nm). I know how to do it in python like    nnC = B:numpy.newaxis: * A::numpy.newaxisnnnCan anyone please tell me the matlab code that does the same thing efficiently?n' 'Take advantage of the implicit expansion feature of bsxfun. Use permute to have your B as an Nx1xM matrix:nnC = bsxfun(@times A permute(B 1 3 2));nnnAnd from MATLAB R2016b onward you can get the same result in this way:nnC = A * permute(B 1 3 2);nn',['numpy'],['numpy']
40121678,"'Tips on building my first Python program (gender classifier)' 'I'm building my first Python application (a gender classifier) after not taking any classes in Python. I've worked with tips from this website and from a book and online course to build a GUI a gender classifier and a human names extractor but I am now clueless as to how to combine these 3 things. In the GUI I've created I can click a button and select a .txt file and then I have a ""run"" button. With this run button I'd like it to extract the names from the text and then classify each name by gender. Can somebody help me out and maybe give me somewhere to start? For example should I simply create 2 functions (1 for the extraction and 1 for the classifier) and then link them to the .txt file that will be selected? If so how do I do this? I'm using Python 3.5.nnEDIT: More specifically: I've already got a working GUI classifier and extractor however I'm not sure on where to begin with using the classifier and the extractor together with the GUI. This is what I have so far for the extraction part (but I get an error with file.filename):nndef file():n  file_opt = options = {}n  options'defaultextension' = '.txt'n  options'filetypes' = ('text files' '.txt')n  file.filename = filedialog.askopenfilename(parent=self title='Choose a file' initialdir=""/"" **file_opt)n  directory = os.path.split(file.filename)-1n  var.set(directory)nnn#Button for file selection actionnloadfile = tkinter.Button(self text=""Select a File"" command=file)nloadfile.place(x=350 y=75 anchor=""n"")nnndef get_names(text):n  tokens = nltk.tokenize.word_tokenize(text)n  pos = nltk.pos_tag(tokens)n  sent = nltk.ne_chunk(pos binary=False)n  person_list = n  person = n  name = """"n  for subtree in sent.subtrees(filter=lambda t: t.label() == ""PERSON""):n    for leaf in subtree.leaves():n      person.append(leaf0)n    if len(person) > 1:n      for part in person:n        name += part + ' 'n    if name:-1 not in person_list:n        person_list.append(name:-1)n      name = ''n    person = nn  return (person_list)nnnnames = get_names(?file.filename?)nnndef runprogram():n  for name in names:n    last_first = HumanName(name).last + ' ' + HumanName(name).firstn    print(""LAST FIRST"")n    print(last_first)nnnnn#RUN buttonnrunbutton = tkinter.Button(self text=""Run"" command=runprogram)nrunbutton.place(x=250 y=110 anchor=""n"")nn' nan",['python-3.x'],"['tkinter', 'python-3.x', 'python-2.7']"
40121686,"'how to convert date-time to epoch in python?' 'I want this particular date-time to be converted to epoch but it is giving me format error. what format should i use to do the following so that it can be json rendered. ""2016-10-14 14:34:14+00:00"". I am using python 2.7 and django 1.10nnstra = ""instance0.Timing""nformata = ""%Y-%m-%d %H:%M:%S+00:00""ntiming = calendar.timegm(time.strptime(stra formata))n     return HttpResponse(json.dumps(n           {'result': 'True'n            'timing': timingn            }))nn' ""Option 1 you can use isoformat():nnfrom datetime import datetimennprint(datetime.utcnow().isoformat())n# '2016-10-19T03:39:40.485521'nnnOption 2 strftime() do not confuse it with strptime:nnprint(datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S+00:00'))n# '2016-10-19 03:42:58+00:00'nn"" 'Actually in django datetime object are converted in epoch as following way.nnEmample 1nnimport datetimenncurrent_date = datetime.datetime.now()nepoch = int(current_date.strftime(""%s"")) * 1000nnnExample 2nnimport datetimendate_object = datetime.datetime.strptime('Jun 1 2005  1:33PM' '%b %d %Y %I:%M%p')nepoch = int(date_object.strftime(""%s"")) * 1000nn' 'This is a literal string it's not pulling data out of whatever instance you have:nnstra = ""instance0.Timing""nnnPerhaps you meant the following instead?nnstra = instance0.Timingnn'",['django'],['django']
40121822,"'Extracting year from string in python' ""How can I parse the foll. in python to extract the year:nn'years since 1250-01-01 0:0:0'nnnThe answer should be 1250n"" 'There are all sorts of ways to do it here are several options:nnndateutil parser in a ""fuzzy"" mode:nnIn 1: s = 'years since 1250-01-01 0:0:0'nnIn 2: from dateutil.parser import parsennIn 3: parse(s fuzzy=True).year  # resulting year would be an integernOut3: 1250nnregular expressions with a capturing group:nnIn 2: import rennIn 3: re.search(r""years since (d{4})"" s).group(1)nOut3: '1250'nnsplitting by ""since"" and then by a dash:nnIn 2: s.split(""since"" 1)1.split(""-"" 1)0.strip()nOut2: '1250'nnor may be even splitting by the first dash and slicing the first substring:nnIn 2: s.split(""-"" 1)0-4:nOut2: '1250'nnnnThe last two involve more ""moving parts"" and might not be applicable depending on possible variations of the input string.n' ""You can use a regex with a capture group around the four digits while also making sure you have a particular pattern around it. I would probably look for something that:nnn4 digits and a capture (d{4})nhyphen -ntwo digits d{2}nhyphen -ntwo digits d{2}nnnGiving: (d{4})-d{2}-d{2}nnDemo:nn>>> import ren>>> d = re.findall('(d{4})-d{2}-d{2}' 'years since 1250-01-01 0:0:0')n>>> dn'1250'n>>> d0n'1250'nnnif you need it as an int just cast it as such:nn>>> int(d0)n1250nn"" 'The following regex should make the four digit year available as the first capture group:nn^.*(d{4})-d{2}-d{2}.*$nn'",['regex'],['regex']
40121844,"'Compare list of dictionary in Robot Framework' ""I have two list of list of dictionary and i want to compare the vale of first list dictionary to second list of dictionarynnFor example:nnDictionary A contains {Name:C} {Name:A} {Name:B}nDictionary B contains {Name:A} {Name:B} {Name:C}nnnHow to take A's 1st Dictionary {Name:C} and check if it exists in Dictionary B. n"" ""You want to see if some list of dictionaries contains at least one dictionary that maps 'name': 'C' ?nnany(d'name' == 'C' for d in list_of_dict if 'name' in dict)nn"" 'If I understand your question correctly you should be able to do this using the built in Collections library. This code took the values in one dictionary and checked to see if the value exists in the other. nn*** Settings ***nLibrary  Collectionsnn*** Variables ***n&{DICTONARY_ONE} =  name1=a  name2=b  name3=c  name4=dn&{DICTONARY_TWO} =  name1=c  name2=a  name3=d  name4=bnn*** Test Cases ***nDictonary Testn    @{dictonary2_list} =  Get Dictionary Values  ${DICTONARY_TWO}n    :For  ${item}  in  @{dictonary2_list}n       Dictionary Should Contain Value  ${DICTONARY_ONE}  ${item}nnnIf this is not quite what you are after there should be something in collections that will let you do what you need. Here is a link to the documentation.nhttp://robotframework.org/robotframework/latest/libraries/Collections.htmlnnI hope that helps.n'","['list', 'dictionary']","['dictionary', 'list']"
40121871,"'how can I test for ordered subset' ""firstlynI need to be able to test that 'abc' is an ordered subset of 'axbyc' and 'egd' is not an ordered subset of 'edg'.  Another way to say it is that it is an ordered subset if I can remove specific characters of of one string and have it be equal to another.nnsecondlynI need to compare one pd.Series with another pd.Series to determine if the elements of one are ordered subsets of the corresponding element of the other.nnconsider the pd.Series s1 and s2nns1 = pd.Series('abc' 'egd')ns2 = pd.Series('axbyc' 'edg')nnnI need to compare them such that the results of the questionnAre the elements of s1 ordered subsets of s2 equalsnn0     Truen1    Falsendtype: boolnn"" 'For the first part of the question:nndef ordered_subset(s1 s2):n    s2 = iter(s2)n    try:n        for c in s1:n            while next(s2) != c:n                passn        else:n            return Truen    except StopIteration:n        return FalsennnFor the second part of the question:nnpd.concat(s1 s2 axis=1).apply(lambda x: ordered_subset(*x) axis=1)nn0     Truen1    Falsendtype: boolnn' ""use '.*'.join to create a regex pattern to match against sequence.nnimport renimport pandas as pdnns1 = pd.Series('abc' 'egd')ns2 = pd.Series('axbyc' 'edg')nnmatch = lambda x: bool(re.match(*x))npd.concat(s1.str.join('.*') s2 axis=1).T.apply(match)nn0     Truen1    Falsendtype: boolnnnnnNotice thatnns1.str.join('.*')nn0    a.*b.*cn1    e.*g.*dnName: x dtype: objectnn""",['pandas'],['pandas']
40121905,"'How to find 5 consecutive increasing/decreasing key/value pairs in dict based on the value' 'I am a DBA and trying to get some data as per management request. I am also new to python.nI have input like below(Few hundreds of records) with out the headers Date and Value. I put this data into a dictionary (Date as key). Now I am trying to loop through the dictionary for trying to find any 5 consecutive rows with either ascending or descending values (NOT Keys).nAlso I am looking for exactly 5 consecutive values not >5.nnDate            valuen2015-11-16      112.33n2015-11-17      116.12n2015-11-18      115.52n2015-11-19      117.51n2015-11-20      117.91n2015-11-23      118.07n2015-11-24      119.35n2015-11-25      117.23n2015-11-27      118.43n2015-11-30      117.41n2015-12-01      116.82n2015-12-02      116.13n2015-12-03      114.83n2015-12-04      117.25nnnFor the above input data I am expecting the following output:nn(5 consecutive ascending values)n2015-11-18  115.52n2015-11-19  117.51n2015-11-20  117.91n2015-11-23  118.07n2015-11-24  119.35nnnandnn(5 consecutive descending values)n2015-11-27      118.43n2015-11-30      117.41n2015-12-01      116.82n2015-12-02      116.13n2015-12-03      114.83nnnWhat is the best way to approach this problem?n' 'The following approach should work for Python 2. It is best to work with the data as a list ordered by date so it first converts the dictionary into an ordered list based on the dates.nnIt then creates a list comparing each adjacent entry if it ascends it stores 1 equal 0 and descending -1. It then uses the groupby() to group this list into similar values. If the length of each group is exactly 4 then you have a run of 5 entries:nnimport itertoolsnndef pairwise(iterable):n    ""s -> (s0s1) (s1s2) (s2 s3) ...""n    a b = itertools.tee(iterable)n    next(b None)n    return itertools.izip(a b)nndata = {n    ""2015-11-16"" : ""112.33""n    ""2015-11-17"" : ""116.12""n    ""2015-11-18"" : ""115.52""n    ""2015-11-19"" : ""117.51""n    ""2015-11-20"" : ""117.91""n    ""2015-11-23"" : ""118.07""n    ""2015-11-24"" : ""119.35""n    ""2015-11-25"" : ""117.23""n    ""2015-11-27"" : ""118.43""n    ""2015-11-30"" : ""117.41""n    ""2015-12-01"" : ""116.82""n    ""2015-12-02"" : ""116.13""n    ""2015-12-03"" : ""114.83""n    ""2015-12-04"" : ""117.25""}nn# Convert dict back to an ordered listnsorted_by_date = k datak for k in sorted(data.keys())nn# Compare adjacent entriesndata_cmp = cmp(v21 v11) v1 v2 for v1 v2 in pairwise(sorted_by_date)nnfor k g in itertools.groupby(data_cmp key=lambda x: x0):n    elements = list(g)n    if len(elements) == 4:n        if k == 1:n            print ""Ascending"" v1 for c v1 v2 in elements + v2n        else:n            print ""Descending"" v1 for c v1 v2 in elements + v2nnnThis would give you the following output:nnAscending '2015-11-18' '115.52' '2015-11-19' '117.51' '2015-11-20' '117.91' '2015-11-23' '118.07' '2015-11-24' '119.35'nDescending '2015-11-27' '118.43' '2015-11-30' '117.41' '2015-12-01' '116.82' '2015-12-02' '116.13' '2015-12-03' '114.83'           nnnIf you are using Python 3 cmp() will need to be coded. nnpairwise() is a well know Python recipe for reading consecutive entry pairs out of a list.n'",['dictionary'],"['dictionary', 'list']"
40121953,"'Python script to count pixel values fails on a less-than/greater-than comparison' 'I wrote a short script to count the pixel values in an image:nnimport osnimport sysnimport cv2nimport numpy as npnnimn = (sys.argv1)na = cv2.imread(imn 0)nb = cv2.imread(imn 1)nc = cv2.GaussianBlur(cv2.imread(imn 0) (77) 2)nndef NC(img):n    y = img.reshape(1 -1)n    numA = (y < 127.5).sum()n    numB = (y > 127.5).sum()n    return ({'less': numA 'greater': numB})nnaa = NC(a)nbb = NC(b)ncc = NC(c)nprint ""File:  {}"".format(imn.split('/')-1)nprint ""Image: {} - Set: {}"".format('A' aa)nprint ""Image: {} - Set: {}"".format('B' bb)nprint ""Image: {} - Set: {}"".format('C' cc)nnnAnd it works perfectly:nnFile:  ObamaBidenSituationRoom.jpgnImage: A - Set: {'greater': 480558 'less': 611282}nImage: B - Set: {'greater': 1441948 'less': 1833572}nImage: C - Set: {'greater': 471559 'less': 620281}nnnBut when I tried to expand it:nndef NC(img):n    y = img.reshape(1 -1)nn    numA = (00.99 < y < 85.00).sum()n    numB = (85.00 < y < 170.0).sum()n    numC = (170.0 < y < 256.0).sum()nn    return ({'low': numA 'middle': numB 'high': numC})nnnIt gave me an error:nnTraceback (most recent call last):n  File ""Bins--02.py"" line 25 in <module>n    aa = NC(a)n  File ""Bins--02.py"" line 17 in NCn    numA = (00.99 < y < 85.00).sum()nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()nnnI got this image a while ago but that was with a matplotlib library that I ended up not using. Why is it coming up here? Am I bounding that greater-than/less-than signs wrong? I tried to fix itnnnumA = (00.99 < y).sum() and (y < 85.00).sum()nnBut that just gave me random super high values.nnUPDATE - Oct20nnSo I changed it:nndef NC(img):n    x = img.reshape(1 -1)nnn    numA = xnp.where((00.99 < x) & (x < 85.00)).sum()n    numB = xnp.where((85.00 < x) & (x < 170.0)).sum()n    numC = xnp.where((170.0 < x) & (x < 256.0)).sum()n    numD = x.shapenn    return ({'total': numD 'low': numA 'middle': numB 'high': numC})nnnAnd now it works but there's a problem: the pixel counts don't match up. nnImage:  lenna.pngnImage:  A Set:{'high': 8367459 'middle': 20278460 'total': (1 262144) 'low': 3455619}nImage:  B Set:{'high': 45250935 'middle': 43098232 'total': (1 786432) 'low': 11609051}nImage:  C Set:{'high': 8216989 'middle': 20633144 'total': (1 262144) 'low': 3531090}nnnThe measurements are pixels there can't be more than the total. Where am I getting 2 million from?nnFor example I ran it on a 100x100 image of a blue circle: nnImage:  lightblue.pngnImage:  A Set:{'high': 0 'middle': 1035999 'total': (1 10000) 'low': 0}nImage:  B Set:{'high': 1758789 'middle': 1212681 'total': (1 30000) 'low': 417612}nImage:  C Set:{'high': 0 'middle': 1014135 'total': (1 10000) 'low': 31801}nnnand it's completely wrong.nnEdit TwonnI just ran it on a test array:nni = np.array(1 1 1 1 1 1 1 1 3 3 3 3 3 3 3 3 200 200 200 200 200 200 200 200)nndef NC(img):n    x = img.reshape(1 -1)n    numA = xnp.where((00.99 < x) & (x < 85.00)).sum()n    numB = xnp.where((85.00 < x) & (x < 170.0)).sum()n    numC = xnp.where((170.0 < x) & (x < 256.0)).sum()n    numD = (img.shape0 * img.shape1)n    return ({'total': numD 'low': numA 'middle': numB 'high': numC})nnaa = NC(i)nbb = NC(i)ncc = NC(i)nnprint ""Image:  {} Set:{}"".format('A' aa)nprint ""Image:  {} Set:{}"".format('B' bb)nprint ""Image:  {} Set:{}"".format('C' cc)nnnAnd it's entirely broken:nnImage:  A Set:{'high': 1600 'middle': 0 'total': 24 'low': 32}nImage:  B Set:{'high': 1600 'middle': 0 'total': 24 'low': 32}nImage:  C Set:{'high': 1600 'middle': 0 'total': 24 'low': 32}nnnWhy is it doing this?n' ""There are a couple of issues with your approach.nnWhen you donn(y < 85.00).sum()nnnYou're actually summing over the truth condition. So you end up counting where the condition evaluates to True. You can easily see it with a quick example:nnIn 6: x = np.arange(10)nnIn 7: xnOut7: array(0 1 2 3 4 5 6 7 8 9)nnIn 8: x < 4nOut8: array( True  True  True  True False False False False False False dtype=bool)nnIn 9: (x < 4).sum()nOut9: 4nnnNow if you want to get the indices where the condition is satisfied you can use np.wherennIn 10: np.where(x < 4)nOut10: (array(0 1 2 3))nnnAnd use them for your sumnnIn 11: xnp.where(x < 4).sum()nOut11: 6nnnThe other issue comes from using the compact notation for the range which is easily solved splitting it in two with & or np.logical_and()nnIn 12: xnp.where((2 < x) & (x < 6)).sum()nOut12: 12nn""",['numpy'],['numpy']
40121961,"'python 3.2 wont print my list list' 'I am doing a payroll system and somehow it doesn't print the computations on the last logic. Also how can I print the data of the employee based on its employee number when it is inputted in the create section? for example I created 2 employees and when in the create section I input 1002 then it will print the data of the employee with the 1002 employee number. Any help would be appreciated.nnHere's my code:nnuser = ""ADMIN""npas = ""CKSC""nAnother = ""Y""nChoice = ""C""nChoice2 = ""C""nnwhile(Choice == ""C"" or Choice2 == ""C""):n    User = input(""Username: "").upper()n    Pass = input(""Password: "").upper()n    print()n    if(User == user and Pass == pas):n        print(""A. Employee"")n        print(""B. Payroll"")n        print(""C. Logout"")n        print(""D. Exit"")n        print()nn        Choice = input(""Enter a letter: "").upper()n        if(Choice == ""A""):n            EmployeeName = n            Status = n            Rate = n            num = 1001n            x = 0   n            EmploNum =   n            while(Another == ""Y""):n                NumX = num + xn                print(""Employee:"" NumX)n                EmployeeName.append(input(""Name: ""))n                print(""Regular = R  Probationary = P  Contractual = C"")n                Status = input(""Status: "").upper()n                if(Status == ""R""):n                    R = 1000n                    print(""Rate: "" R)n                    Rate.append(R)n                if(Status == ""P""):n                    P = 800n                    print(""Rate: "" P)n                    Rate.append(P)n                elif(Status == ""C""):n                    C = 600n                    print(""Rate: "" C)n                    Rate.append(C)n                EmploNum.append(NumX)   n                Another = input(""Another employee Y/N?: "").upper()n                x = x + 1n                print()n                if(Another != ""Y""):n                    continuen        if(Choice == ""B""):n           Another2 = ""Y""n           print(""No data yet"")n           Another2 = input(""Back to main menu Y/N?: "").upper()n           if(Another2 == ""Y""):          n               passn           else:n               print(""Thank you!"")n               exit()n        if(Choice == ""C""):n            continuen        print(""A. Employee"")n        print(""B. Payroll"")n        print(""C. Logout"")n        print(""D. Exit"")n        print()n        Choice2 = input(""Enter a letter: "").upper()n        if(Choice2 == ""B""):n            print(""A. Create"")n            print(""B. Display"")n            print()n            Choice3 = input(""Choose a letter: "").upper()n            while(Choice3 == ""A""):n                Days = n                Late = n                Overtime = n                EmpNo = n                Another3 = ""Y""n                while(Another3 == ""Y""):n                         EmpNo.append(input(""Employee No: ""))  n                         Days.append(int(input(""Number of Days: "")))n                         Late.append(float(input(""Late/Undertime(minutes): "")))n                         Overtime.append(float(input(""Overtime(minutes): "")))n                         Another3 = input(""Another employee Y/N?: "").upper()n                         if(Another3 != ""Y""):n                              continuenn                print(""A. Create"")n                print(""B. Display"")n                print()n                Choice3 = input(""Choose a letter: "").upper()n                if(Choice3 == ""B""):n                    index = 0n                    for i in range(len(Days)):n                        print(""hello1"") n                        TotalSalary = Ratei * Daysin                        Deduction = (Ratei/8/60)*Latein                        Additional = (Ratei/8/60)*Overtimein                        Net = TotalSalary + Deduction + Additionaln                        if(EmpNo in EmploNum):   n                            print(""Employee Number: ""EmploNumindex)n                            print(""Name: "" EmployeeNameindex)n                            print(""Basic Pay: ""TotalSalary)n                            print(""Deduction: "" Deduction)n                            print(""Additional: "" Additional)n                            print(""NetPay: "" Net)n                            index = index + 1n                            print()n        if(Choice2 == ""C""):n            continuen        if(Choice == ""D""):n            exit()           n    else:n        exit()nn' nan",['list'],"['python-2.7', 'python-3.x']"
40122058,"'Python: find a series of Chinese characters within a string and apply a function' 'I've got a series of text that is mostly English but contains some phrases with Chinese characters. Here's two examples:nns1 = ""You say: ä½xa0å¥½. I say: åx86x8dè¦x8b""ns2 = ""çxadx94æ¡x88 my friend åx9c¨é¢¨åx9c¨åx90¹""nnnI'm trying to find each block of Chinese apply a function which will translate the text (I already have a way to do the translation) then replace the translated text in the string. So the output would be something like this:nno1 = ""You say: hello. I say: goodbye""no2 = ""The answer my friend is blowing in the wind""nnnI can find the Chinese characters easily by doing this:nnutf_line = s1.decode('utf-8') nre.findall(ur'u4e00-u9fff+'utf_line)nnn...But I end up with a list of all the Chinese characters and no way of determining where each phrase begins and ends.n' ""A possible solution is to capture everything but in different capture groups so you can differentiate later if they're in Chinese or not.nnret = re.findall(ur'(u4e00-u9fff+)|(^u4e00-u9fff+)' utf_line)nresult = nfor match in ret:n    if match0:n        result.append(translate(match0))n    else:n        result.append(match1)nnprint(''.join(result))nn"" 'Regular expression Match objects give you the start and end indexes of a match. So instead of findall do your own search and record the indexes as you go. Then you can translate each extent and replace in the string based on the known indexes of the phrases.nnimport renn_scan_chinese_re = re.compile(r'u4e00-u9fff+')nns1 = ""You say: ä½xa0å¥½. I say: åx86x8dè¦x8b""ns2 = ""çxadx94æ¡x88 my friend åx9c¨é¢¨åx9c¨åx90¹""nndef translator(chinese_text):n    """"""My no good translator""""""n    return ' '.join('??' for _ in chinese_text)nndef scanner(text):n    """"""Scan text string translate chinese and return copy""""""n    print('----> text:' text)nn    # list of extents where chinese text is foundn    chinese_inserts =  # start endnn    # keep scanning text to endn    index = 0n    while index < len(text):n        m = _scan_chinese_re.search(textindex:)n        if not m:n            breakn        # get extent from match object and add to listn        start = index + m.start()n        end = index + m.end()n        print('chinese at index' start textstart:end)n        chinese_inserts.append(start end)n        index += endnn    # copy string and replace backwards so we don't mess up indexesn    copy = list(text)n    while chinese_inserts:n        start end = chinese_inserts.pop()n        copystart:end = translator(textstart:end)n    text = ''.join(copy)n    print('final' text)n    return textnnscanner(s1)nscanner(s2)nnnWith my questionable translator the result isnn----> text: You say: ä½xa0å¥½. I say: åx86x8dè¦x8bnchinese at index 9 ä½xa0å¥½nchinese at index 20 åx86x8dè¦x8bnfinal You say: ?? ??. I say: ?? ??n----> text: çxadx94æ¡x88 my friend åx9c¨é¢¨åx9c¨åx90¹nchinese at index 0 çxadx94æ¡x88nchinese at index 15 åx9c¨é¢¨åx9c¨åx90¹nfinal ?? ?? my friend ?? ?? ?? ??nn' ""You could always use a in-place replace of the matched regular expression by using    re.sub() in python.nnTry this:nnprint(re.sub(r'(u4e00-u9fff+)' translate('g<0>') utf_line))nn"" 'You can't get the indexes using re.findall(). You could use re.finditer() instead and refer to m.group() m.start() and m.end().nnHowever for your particular case it seems more practical to call a function using re.sub().nnn  If repl is a function it is called for every non-overlapping occurrence of pattern. The function takes a single match object argument and returns the replacement stringnnnCode:nnimport renns = ""You say: ä½xa0å¥½. I say: åx86x8dè¦x8b. çxadx94æ¡x88 my friend åx9c¨é¢¨åx9c¨åx90¹""nutf_line = s.decode('utf-8')nndict = {""ä½xa0å¥½"" : ""hello""n        ""åx86x8dè¦x8b"" : ""goodbye""n        ""çxadx94æ¡x88"" : ""The answer""n        ""åx9c¨é¢¨åx9c¨åx90¹"" : ""is blowing in the wind""n       }nndef translate(m):n    block = m.group().encode('utf-8')n    # Do your translation herenn    # this is just an examplen    if block in dict:n        return dict block n    else:n        return ""{unknown}""nnnutf_translated = re.sub(ur'u4e00-u9fff+' translate utf_line re.UNICODE)nnprint utf_translated.encode('utf-8')nnnOutput:nnYou say: hello. I say: goodbye. The answer my friend is blowing in the windnnnnIdeone demonn'",['regex'],['regex']
40122077,"'Why sparse matrix computing on python is too slow' 'The format I have used is the csr sparse matrix which is recommended to be the fastest sparse structure for add and dot opertor. I compared its performance with the add and dot operator of np.array. However it seems very weird that the computing for sparse matrix is much slower than the case under dense format. Why is it? And is there any more efficient way to implement sparse computing?nnimport numpy as npnimport scipy.sparse as spnimport randomnn#%% generate dense vectornvector_length = 10000nnonzero_term = 200nnx = np.zeros((vector_length ))ny = np.zeros((vector_length ))nnindex = random.sample(range(vector_length) nonzero_term)nxindex = np.random.rand(nonzero_term)nindex = random.sample(range(vector_length) nonzero_term)nyindex = np.random.rand(nonzero_term)nn#%% transform to sparse vectornx_sp = sp.csr_matrix(x)ny_sp = sp.csr_matrix(y)nn#%% testnn# dense addn%timeit x + yn# sparse addn%timeit x_sp + y_sp     n# dense dotn%timeit x.dot(y)n# sparse dotn%timeit x_sp.dot(y_sp.T) nnnand the result showsnn100000 loops best of 3: 6.06 Âµs per loopn10000 loops best of 3: 97.8 Âµs per loopn100000 loops best of 3: 3.45 Âµs per loopn1000 loops best of 3: 225 Âµs per loopnn' ""Both sets of operations use compiled code. But the data is stored quite differently.nnx.shape is (10000); y likewise.  x+y just has to allocate an array of the same shape and efficiently in c step through the 3 data buffers.nnx_sp has 200 nonzero values the values are in x_sp.data and their column indices in x_sp.indices.  There is a third array x_sp.indptr but with only 2 values.  Similarly for y_sp.  But to add them it has to step through 4 arrays and assign values to two arrays.  Even when coded in c there's a lot more work.  In my test case x_sp+y_sp has 397 nonzero values.  nnWith these 1d arrays (1 row matrices) the dot involves the same sort of stepping through values only summing them all to one final value.nnIf the density of the matrices is low enough sparse calculations can be faster.  That's true I think of matrix multiplication more so than addition.  nnIn sum the per element calculation is more complicated with sparse matrices.  So even if there are few elements the overall time tends to longer.n""",['numpy'],['numpy']
40122557,'How to separately plot the figures in one big single figure using matplotlib?' 'I have just started learning Python I am analyzing a data from .csv file and I want to separate figures but I am getting all the plots in one graph and I am not able to separate the graphs. Please help!nnn = 10ni=0nfor i in range(0n):n    inflammation = matplotlib.pyplot.plot(datai:40)#inflammation graph for patient 0nnnThis is the image i got but I want separate graphs:nnn' 'Just use a new figure()nnn = 10ni=0nfor i in range(0n):n    matplotlib.pyplot.figure()n    inflammation = matplotlib.pyplot.plot(datai:40) #inflammation graph for patient 0nnnEach figure uses a lot of memory. So use it sparingly. Learn about clf() and cla() and savefig() if you have too many figures ...n' 'You could always take a look at using subplot() which would work as follows:nnimport matplotlib.pyplot as pltnnfor n in range(1 11):n    plt.subplot(2 5 n)n    plt.plot(range(12))nnplt.show()nnnThis would display the following in a single figure:nnn',['matplotlib'],['matplotlib']
40122684,"'Correct way of sending JSON Data with encoding in Python' 'I am developing API's on Django and I am facing a lot of issues in encoding the data in python at the back-end and decoding it at front-end on java. nnAny standard rules for sending correct JSON Data to client application efficiently? nnThere are some Hindi Characters which are not received properly on front end it gives error saying that ""JSON unterminated object at character"" So I guess the problem is on my siden' 'json.loads and json.dumps are generally used to encode and decode JSON data in python.  nndumps takes an object and produces a string and load would take a file-like object read the data from that object and use that string to create an object.  nnThe encoder understands Pythonâx80x99s native types by default (string unicode int float list tuple dict).nnimport jsonnndata =  { 'a':'A' 'b':(2 4) 'c':3.0 } nprint 'DATA:' repr(data)nndata_string = json.dumps(data)nprint 'JSON:' data_stringnnnValues are encoded in a manner very similar to Pythonâx80x99s repr() output.nn$ python json_simple_types.pynnDATA: {'a': 'A' 'c': 3.0 'b': (2 4)}nJSON: {""a"": ""A"" ""c"": 3.0 ""b"": 2 4}nnnEncoding then re-decoding may not give exactly the same type of object.nnimport jsonnndata =  { 'a':'A' 'b':(2 4) 'c':3.0 } ndata_string = json.dumps(data)nprint 'ENCODED:' data_stringnndecoded = json.loads(data_string)nprint 'DECODED:' decodednnprint 'ORIGINAL:' type(data0'b')nprint 'DECODED :' type(decoded0'b')nnnIn particular strings are converted to unicode and tuples become lists.nn$ python json_simple_types_decode.pynnENCODED: {""a"": ""A"" ""c"": 3.0 ""b"": 2 4}nDECODED: {u'a': u'A' u'c': 3.0 u'b': 2 4}nORIGINAL: <type 'tuple'>nDECODED : <type 'list'>nn'",['django'],['django']
40122713,"'How to know which is more advatageous with assigning same value to different attributes in python' 'Between the two in python which will be faster and advatageousnna = b = c = d = 1nnnandnna = 1nb = 1nc = 1nd = 1nn' ""Simply run a test:nn>>> import timeitn>>> min(timeit.repeat('a = b = c = d = 1' number=10000000))n0.4885740280151367n>>> min(timeit.repeat('a = 1; b = 1; c = 1; d = 1' number=10000000))n0.6283371448516846nnnAlso note:nn>>> min(timeit.repeat('a b c d = 1 1 1 1' number=10000000))n0.4040501117706299nn""",['python-2.7'],['python-2.7']
40122717,"'python url not found - Accessing views.py from AJAX' 'New to Python and Django and I'm trying to make a simple ajax call from a button click to pass certain data to my views.py however when I try to make a url as seen on my ajax code below the documentId.id does not append unless I directly append in without the ""?id="".nn    {%for document in documents%}n       {{document.filename}}n       <input type=""button"" id=""{{document.id}}"" onclick=""loadData(this)"" name=""load-data"" value=""Add""/>n    {%endfor%}nn <script type =""text/javascript"">n    function loadData(documentId){n       $.ajax({n       url:""upload-data/load"" + ""?id="" + documentId.idn       data: {'documentId': documentId}n       type: 'GET'n       success: function(){n          window.location.href = ""http://127.0.0.1:8000/url/locations"";n       }n    });n    }n </script>nnnThis gives me then an error that says the url cannot be found. I have a line in my urls.py below:nnurl(r^""upload-data/load/(0-9+)/$' views.loadFile name=""load-data"")nnnOther than this method I am stumped as to how I am going to extract my data to my views.py.nndef loadFile(request):n    documentId = request.GET.get('id')n    newLayer = Layer(get_object_or_404(Document pk = documentId))n    newLayer.save()n    layers = Layer.objects.all()nn    return render(request 'url/loaded.html' { 'layers': layers})nnnThe persisting error in the console would be:nnn  http://127.0.0.1:8000/upload-data/load/                 HTTP/1.0 404 Not Foundnn' 'In JavaScript you need nn""upload-data/load/"" + documentId.idnnnDjango doesn't use ?id= in url definition r^""upload-data/load/(0-9+)/$'. It expects ie. upload-data/load/123 instead of upload-data/load?id=123nnnnEDIT: and you need id in def loadFile(request id). nnAnd then you don't have to use request.GET.get('id')n' 'Use something like this:nndef loadFile(request):n    documentId= request.GET.get('id' '').n    newLayer = Layer(get_object_or_404(Document pk = documentId))n    newLayer.save()n    layers = Layer.objects.all()nn    return render(request 'url/loaded.html' { 'layers': layers})nnnAnd update your url as :nn    url(r^""upload-data/load/' views.loadFile name=""load-data"")nnnAnd the script would be like :nn<script type =""text/javascript"">n    function loadData(documentId){n       $.ajax({n       url:""upload-data/load/?id=""+ documentId.idn       data: {'documentId': documentId}n       type: 'GET'n       success: function(){n          window.location.href = ""http://127.0.0.1:8000/url/locations"";n       }n    });n    }n </script>nnnThanks.n' 'From the above answers and comments it seems like rather than passing id as a url param you want to pass the same as a get param. In that case make your urls like below.nnurl(r^""upload-data/load/' views.loadFile name=""load-data"")nnnand in views check for get params by replacing id with documentId. document id will be in your dict named as data passed to view. So look for request.GET.get('data''') and from data extract id as belownndef loadFile(request):n    data = request.GET.get('data' None)n    if data:n        documentId = data'documentId'n        newLayer = Layer(get_object_or_404(Document pk = documentId))n        newLayer.save()n        layers = Layer.objects.all()nn        return render(request 'url/loaded.html' { 'layers': layers})n    else:n        return JsonResponse({'error': 'pass document id'} status=400)nnnSince you are passing a get param from javascript named as documentId not id.nnHTHn'",['django'],['django']
40123112,"'python loop to find the largest integer from a list' ""I wrote a script to pull down a list of aws tags and then read the last octect and tell me which one is the highest IP. For example. here is the list of tags that are returned:nn'vlslabmc 172.16.0.13/24' 'vlslabmc172.16.0.5/24' 'vlslabmc172.16.0.3/24' 'vlslabmc172.16.0.12/24' 'vlslabmc172.16.0.16/24' 'vlslabmc172.16.0.6/24' 'vlslabmc172.16.0.1/24' 'vlslabmc172.16.0.11/24' 'vlslabmc172.16.0.15/24' 'vlslabmc172.16.0.17/24' 'vlslabmc172.16.0.4/24' 'vlslabmc172.16.0.7/24' 'vlslabmc172.16.0.10/24' 'vlslabmc172.16.0.9/24' 'vlslabmc172.16.0.8/24' 'vlslabmc172.16.0.2/24' 'vlslabmc172.16.0.14/24'nnHere's my code to workout the largest IP from the tagLis (note that the largest is 17 172.16.0.17)nn 21 def findLargestIP():n 22         for i in tagList:n 23                 #remove all the spacing in the tagsn 24                 ec2Tags = i.strip()n 25                 #seperate any multiple tagsn 26                 ec2SingleTag = ec2Tags.split('')n 27                 #find the last octect of the ip addressn 28                 fullIPTag = ec2SingleTag1.split('.')n 29                 #remove the CIDR from ip to get the last octectn 30                 lastIPsTag = fullIPTag3.split('/')n 31                 lastOctect = lastIPsTag0n 32                 ipList.append(lastOctect)n 33                 largestIP  = int(ipList0)n 34                 for latestIP in ipList:n 35                         if int(latestIP) > largestIP:n 36                                 largestIP = latestIPn 37         return largestIPnnnI'm not sure why.. but when I print the value of largestIP it always prints out 16. Ive gone through the code it should have worked (I'm avoiding using the max function as I'm just learning to code)nnAny help as aways is greatly appreciated.nnThanksnnEdit with the answer below and a questionnnOk so thanks to a clue from cmarie I got it working the problem was mainlynn33                 largestIP  = int(ipList0)nnnHere's the code running before with an added print statement on the list append:nn'13'n'13' '5'n'13' '5' '3'n'13' '5' '3' '12'n'13' '5' '3' '12' '16'n16n'13' '5' '3' '12' '16' '6'n16n'13' '5' '3' '12' '16' '6' '1'n16n'13' '5' '3' '12' '16' '6' '1' '11'n16n... ...n'13' '5' '3' '12' '16' '6' '1' '11' '15' '17' '4' '7' '10' '9' '8' '2'n    16n'13' '5' '3' '12' '16' '6' '1' '11' '15' '17' '4' '7' '10' '9' '8' '2' '14'n16nnnBasically what was happening is that during this loop :nn33                 largestIP  = int(ipList0)n 34                 for latestIP in ipList:n 35                         if int(latestIP) > largestIP:n 36                                 largestIP = latestIPnnnThe loop stops at the 1st largest integer. in this case that is 16. *I'm not sure why it does but it doesnnHere's the working code:nn19 def findLargestIP():n 20         ipList =n 21         for i in tagList:n 22                 #remove all the spacing in the tagsn 23                 ec2Tags = i.strip()n 24                 #seperate any multiple tagsn 25                 ec2SingleTag = ec2Tags.split('')n 26                 #find the last octect of the ip addressn 27                 fullIPTag = ec2SingleTag1.split('.')n 28                 #remove the CIDR from ip to get the last octectn 29                 lastIPsTag = fullIPTag3.split('/')n 30                 lastOctect = lastIPsTag0n 31                 ipList.append(int(lastOctect))n 32                 print ipListn 33                 largestIP  = 0n 34                 for latestIP in ipList:n 35                         if latestIP > largestIP:n 36                                 largestIP = latestIPn 37                                 print latestIPn 38         print largestIPn 39         return largestIPnnnand the result:nn13 5 3 12 16n13n16n13 5 3 12 16 6n13n16n13 5 3 12 16 6 1n13n16n13 5 3 12 16 6 1 11n13n16n13 5 3 12 16 6 1 11 15n13n16n13 5 3 12 16 6 1 11 15 17n13n16n17nnnNote it found 17.n"" 'So I had to refactor your code a little bit. I assumed ipList was an empty list. Are you sure you tested to see if it actually ran? Specifically your if statementnnif int(latestIP) > largestIP:n    largestIP = latestIPnnnwould return annTypeError: unorderable types: int() > str()nnnbecause you would be assigning a string to largestIP and then in the next iteration you would compare a string with an int. Aside from that your code seems functional. It returns 17 as the largest last octet for me which seems right.nnIf your intention is to return the largest last octet of your list of ip addresses you might want to approach this a little bit differently.nnOption 1: Accumulate list of IP Addresses firstnnInstead of nesting a for loop in your loop to iterate through all the tags you can first just accumulate the tags and then go through and find the max. This way you go through the tag list once and then the ip list once instead of going through your entire ip list each time you iterate through your tag list.nnOption 2: Create a list of only the last octetnnSimilar to option 1 you would iterate through your tagList and accumulate all the last octets of the ip addresses casted to ints into a list instead of the entire ip address. In a loop afterwards you can call max on the list with the octets (I'm guessing you want to avoid this).nnOption 3: Have a running greatest valuennI think this is the best solution. As you're going through the tag list you can keep a variable that will have the greatest last octet so far. This way you only need to loop through the tag list once and still come out with the greatest last octet thus far.nnIf you want to grab the entire IP address options 1 and 3 would still work but for option 2 you might want to look into python dictionaries.n' ""Why are doing this so complex. Here is oneliner for thisnnip_list = 'vlslabmc 172.16.0.13/24' 'vlslabmc172.16.0.5/24' 'vlslabmc172.16.0.3/24' 'vlslabmc172.16.0.12/24' 'vlslabmc172.16.0.16/24' 'vlslabmc172.16.0.6/24' 'vlslabmc172.16.0.1/24' 'vlslabmc172.16.0.11/24' 'vlslabmc172.16.0.15/24' 'vlslabmc172.16.0.17/24' 'vlslabmc172.16.0.4/24' 'vlslabmc172.16.0.7/24' 'vlslabmc172.16.0.10/24' 'vlslabmc172.16.0.9/24' 'vlslabmc172.16.0.8/24' 'vlslabmc172.16.0.2/24' 'vlslabmc172.16.0.14/24'nnlargestIP = max(ip_list key=lambda i: int(i.split('/')0.split('.')-1))nn"" 'The code is quite convoluted (much more than needed) but the error is that ipList gets filled with strings and then its elements are compared with an integer.nnThis in Python 2 was a silent source of problems (you got a nonsensical but stable True/False result when comparing different types instead of an error) and in Python 3 it became an error.nna much simpler implementation would in my opinion be:nnreturn max(int(x.split("""")1.split(""/"")0.split(""."")-1)n           for x in taglist)nnnwith the meaning:nnnsplit("""")1 to take the part after the commansplit(""/"")0 to take the part before the slashnsplit(""."")-1 to take the last part of IP addressnint(...) to convert to integernmax(... for x in taglist to do this for all elements and keeping the maxnnnor using a regexp withnnreturn max(int(re.match("".*?(0-9+)/"" x).group(1))n           for x in taglist)nn' ""Although other people have already provide you some alternative ways to find the answer if you want to keep using your program here is some way of fixing it:nndef findLargestIP():n    ipList = n    for i in tagList:n        #remove all the spacing in the tagsn        ec2Tags = i.strip()n        #seperate any multiple tagsn        ec2SingleTag = ec2Tags.split('')n        #find the last octect of the ip addressn        fullIPTag = ec2SingleTag1.split('.')n        #remove the CIDR from ip to get the last octectn        lastIPsTag = fullIPTag3.split('/')n        lastOctect = lastIPsTag0n        ipList.append(int(lastOctect))n    largestIP  = 0n    for latestIP in ipList:n        if latestIP > largestIP:n            largestIP = latestIPn    return largestIPnnnThe differences from this and your program are that here I:nnnset ipList = nmake ipList contain integers rather than stringsnset largestIP = 0 instead of taking the first number of the ipList (since you shouldn't assume the list is sorted)nremove the loop to find the largest number outside the first loop on the tagList - just for eliminating unnecessary iterationsnnnIf I would do that task however I would try to use regular expressions. Here is a way to do it:nnimport rendef alternativeFindLargestIP():n    ipList = re.findall(r'(?<=.)d+(?=/)' ' '.join(tagList))n    ipList = int(num) for num in ipListn    return max(ipList)nn""",['list'],"['list', 'regex', 'python-2.7']"
40123132,"'Vectorizing calculations in pandas' ""I'm trying to calculate group averages inside of the cross-validation scheme but this iterating method is extremely slow as my dataframe contains more than 1mln rows. Is it possible to vectorize this calculation? Thanks.nnimport pandas as pdnimport numpy as npndata = np.column_stack(np.arange(1101) np.random.randint(111 100)np.random.randint(1101 100))ndf = pd.DataFrame(data columns='id' 'group''total')nfrom sklearn.cross_validation import KFoldnkf = KFold(df.shape0 n_folds=3 shuffle = True)nf = {'total': 'mean'}ndf'fold' = 0ndf'group_average' = 0nfor train_index test_index in kf:n    df.ixtrain_index 'fold' = 0n    df.ixtest_index 'fold' = 1n    aux = df.locdf.fold == 0 :.groupby('group')n    aux2 = aux.agg(f)n    aux2.reset_index(inplace = True)n    aux2.columns = 'group' 'group_average'n    for i row in df.locdf.fold == 1 :.iterrows():n        new = aux2.ix(aux2.group == row.group)'group_average'n        if new.empty == True:n            new = 0n        else:n            new = new.values0n        df.ixi 'group_average' = newnn"" ""Replace the for i row in df.locdf.fold == 1 :.iterrows():-loop with this:nndf0 = pd.merge(dfdf.fold == 1aux2on='group').set_index('id')ndf = df.set_index('id')ndf.loc(df.fold == 1)'group_average' = df0.loc:'group_average_y'ndf = df.reset_index()nnnThis gives me the same result as your code and is almost 7 times faster.n""",['pandas'],['pandas']
40123159,"'creating pandas multiindex based on CustomBusinessHour start' ""I have a dataframe that looks like this:nn             datetime    price  tickvol      bid      askn0 2016-10-11 12:24:03  2130.25        1  2130.00  2130.25n1 2016-10-11 13:31:03  2130.25        1  2130.00  2130.25n...nnnI have a CustomBusinessHour that looks like this:nncbh = CustomBusinessHour(start='13:30' end='13:15' weekmask='Sun Mon Tue Wed Thu')nnnI was hoping that I could create a new index level using the start timestamp of the custom business hour but I'm having trouble getting things working.nnWhat I'm hoping to get to is something like:nn                cbh            datetime    price  tickvol      bid      askn2016-10-10 13:30:00 2016-10-11 12:24:03  2130.25        1  2130.00  2130.25n2016-10-11 13:30:00 2016-10-11 13:31:03  2130.25        1  2130.00  2130.25nn"" nan",['pandas'],['pandas']
40123689,"'Pandas Compare rows in Dataframe' ""I have following data frame (represented by dictionary below):nn{'Name': {0: '204'n  1: '110838'n  2: '110999'n  3: '110998'n  4: '111155'n  5: '111710'n  6: '111157'n  7: '111156'n  8: '111144'n  9: '118972'n  10: '111289'n  11: '111288'n  12: '111145'n  13: '121131'n  14: '118990'n  15: '110653'n  16: '110693'n  17: '110694'n  18: '111577'n  19: '111702'n  20: '115424'n  21: '115127'n  22: '115178'n  23: '111578'n  24: '115409'n  25: '115468'n  26: '111711'n  27: '115163'n  28: '115149'n  29: '115251'}n 'Sequence_new': {0: 1.0n  1: 2.0n  2: 3.0n  3: 4.0n  4: 5.0n  5: 6.0n  6: 7.0n  7: 8.0n  8: 9.0n  9: 10.0n  10: 11.0n  11: 12.0n  12: nann  13: 13.0n  14: 14.0n  15: 15.0n  16: 16.0n  17: 17.0n  18: 18.0n  19: 19.0n  20: 20.0n  21: 21.0n  22: 22.0n  23: 23.0n  24: 24.0n  25: 25.0n  26: 26.0n  27: 27.0n  28: 28.0n  29: 29.0}n 'Sequence_old': {0: 1n  1: 2n  2: 3n  3: 4n  4: 5n  5: 6n  6: 7n  7: 8n  8: 9n  9: 10n  10: 11n  11: 12n  12: 13n  13: 14n  14: 15n  15: 16n  16: 17n  17: 18n  18: 19n  19: 20n  20: 21n  21: 22n  22: 23n  23: 24n  24: 25n  25: 26n  26: 27n  27: 28n  28: 29n  29: 30}}nnnI am trying to understand what changed between old and new sequences. If by Name Sequence_old = Sequence_new nothing changed. If Sequence+_new is 'nan' Name removed. Can you please help implement this in pandas?nWhat tried till now without success:nnfor i in range(0 len(Merge)):n    if Merge.iloci'Sequence_x' == Merge.iloci'Sequence_y':n        Merge.iloci'New' = 'N'n    else:n        Merge.iloci'New' = 'Y'nnnThank youn"" 'You can use double numpy.where with condition with isnull:nnmask = df.Sequence_old == df.Sequence_newnndf'New' = np.where(df.Sequence_new.isnull() 'Removed' n            np.where(mask 'N' 'Y'))nnnnnprint (df)n     Name  Sequence_new  Sequence_old      Newn0      204           1.0             1        Nn1   110838           2.0             2        Nn2   110999           3.0             3        Nn3   110998           4.0             4        Nn4   111155           5.0             5        Nn5   111710           6.0             6        Nn6   111157           7.0             7        Nn7   111156           8.0             8        Nn8   111144           9.0             9        Nn9   118972          10.0            10        Nn10  111289          11.0            11        Nn11  111288          12.0            12        Nn12  111145           NaN            13  Removedn13  121131          13.0            14        Yn14  118990          14.0            15        Yn15  110653          15.0            16        Yn16  110693          16.0            17        Yn17  110694          17.0            18        Yn18  111577          18.0            19        Yn19  111702          19.0            20        Yn20  115424          20.0            21        Yn21  115127          21.0            22        Yn22  115178          22.0            23        Yn23  111578          23.0            24        Yn24  115409          24.0            25        Yn25  115468          25.0            26        Yn26  111711          26.0            27        Yn27  115163          27.0            28        Yn28  115149          28.0            29        Yn29  115251          29.0            30        Ynn' ""dic_new = {0: 1.0 1: 2.0 2: 3.0 3: 4.0 4: 5.0 5: 6.0 6: 7.0 7: 8.0 8: 9.0 9: 10.0 10: 11.0 11: 12.0n           12: 'Nan' 13: 13.0 14: 14.0 15: 15.0 16: 16.0 17: 17.0 18: 18.0 19: 19.0 20: 20.0 21: 21.0n           22: 22.0 23: 23.0 24: 24.0 25: 25.0 26: 26.0 27: 27.0 28: 28.0 29: 29.0}ndic_old = {0: 1 1: 2 2: 3 3: 4 4: 5 5: 6 6: 7 7: 8 8: 9 9: 10 10: 11 11: 12 12: 13 13: 14 14: 15 15: 16n           16: 17 17: 18 18: 19 19: 20 20: 21 21: 22 22: 23 23: 24 24: 25 25: 26 26: 27 27: 28 28: 29n           29: 30}nn# Does the same thing as the code belownfor a b in zip(dic_new.items() dic_old.items()):n    if b1.lower() != 'nan':n        # You can add whatever print statement you want heren        print(a1 == b1)nn# Does the same thing as the code abovenprint(a1 == b1) for a b in zip(dic_new.items() dic_old.items()) if b1.lower() != 'nan'nn""",['pandas'],"['pandas', 'dictionary']"
40123739,'Force matplotlib to fully render plots in an IPython/Jupyter notebook cell before advancing to next cell' 'In an IPython/Jupyter notebook I have a situation similar to the following pseudo code:nncell 1:nrun some computationnplot several plots (separate figures)nncell 2:nrun some computationnplot several plots (separate figures)nnnThis is working nicely except for one annoyance. When I run both cells sequentially (Shift-enter Shift-enter) the computation in the second cell starts running before the plots in the first cell are rendered and the plots for both cells are only rendered after the computation for both cells is completed. Just to be clear the figures for the plots in the first cell are created immediately after the computation in the first cell is completed but they remain empty until after the computation in the seconds cell is also completed.nnThis would not be a huge problem except that if there is an uncaught exception in the second cell which kills the computation for some reason the plots in the first cell will never be rendered and the figures will remain empty.nnI am looking for a way to instruct matplotlib or jupyter (I am not sure where the issue is) at the end of cell 1 - finish rendering all outstanding plots before continuing code execution.nnI am using the %matplotlib notebook magic and matplotlib 1.5.3.nnThanks!n' nan,['matplotlib'],['matplotlib']
40123779,"'mongodb regex embeded search' 'My data looks like this:nnblade = {n    'model': 'FW254'n    'items':{n              'a': {'time':5 'count':7}n              'b': {'time':4 'count':8}n              'c': {'time':2 'count':9}n    }n}nnnI want to do something like this:nncollection.find({""items./.*/.time"": { ""$gte"":4}})nnnhere the element /.*/ is the regex to match 'a' 'b' 'c'nnOf course this won't work. My goal is to find the blades with embedded time >= 4. Is that possible? thanks!n' 'Where did you read about using a regex in a spot like that?nnYou should recosider the structure of you data and turns items into an array allowing you to use $elemMatchnn{ ""_id"" : ObjectId(""58071dd31f4fbf7309ae639a"") ""model"" : ""FW254"" n  ""items"" :  { ""name"": ""a"" ""time"" : 5 ""count"" : 7 }n              { ""name"": ""b"" ""time"" : 4 ""count"" : 8}n              { ""name"" : ""c"" ""time"" : 2 ""count"" : 9 }n        }nncollection.find({items: {$elemMatch: {'time': 4}}})nn'",['regex'],['regex']
40124242,"'the use of regular expression' ""I'm new in regular expression but I want to match a pattern in about 2 million strings.nThere three forms of the origin strings shown as follows:nnEC-2A-07<EC-1D-10>nEC-2-07nT1-ZJF-4nnnI want to get three parts of substrings besides - which is to say Iãx80x80want to get EC 2A 07respectively. Especially for the first string I just want to divide the part before <.nnI have tried .+dW but cannot recognize EC-2-07 then I use .split('-') to split the string and then use index in the returned list to get what I want. But it is low efficient.nnCan you figure out a high efficient regular expression to meet my requirements?? Thanks a lot!n"" 'You can try this:nn^(w+)-(w+)-(w+)(?=W).*$nnnExplanationnnPython Demon'",['regex'],['regex']
40124260,"'ImportError: No module named _winreg python2.7' 'I tried to install wmi in my system which is running with python2.7.12.nninstalled WMI using pip :  pip install wminnBut it shows below errornn>>> import wminTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""/usr/local/lib/python2.7/dist-packages/wmi.py"" line 88 in <module>n    from win32com.client import GetObject DispatchnImportError: No module named win32com.clientn>>> nnnThen I tried to install win32 python module. But its failed with ""ImportError: No module named _winreg"".nnFull error message:nnroot@srv1:/home/srv1/Downloads/pywin32-220# python setup.py installnTraceback (most recent call last):n  File ""setup.py"" line 82 in <module>n    import _winregnImportError: No module named _winregnroot@srv1:/home/srv1/Downloads/pywin32-220#nn' nan",['python-2.7'],['python-2.7']
40124423,"'Weighted clustering of tags' 'I have a list of products and each product is tagged and weights associated to it each tag. Now I want to cluster them into similar products. How do I go forward it. I have tried k-means of scikit-learn. But That is not helping much.nnProduct 1: a=2.5 b=3.5 c=1 d=1nProduct 2: a=0.25 c=2nProduct 3: e=2 k=5n.n.n.n.n.n.n.n.nProduct n: a=3 b=0.75nnnNow I want these to be clustered. I also want a product to be in many clusters if necessary. Because 1 2 3 can form a cluster and 2 4 5 can form othern' 'You could use a Gaussian Mixture Model which can be seen as a generalisation of k-means which allows soft clusters. You can have K clusters and each entry belongs to all clusters with a certain amount. This amount is the probability of the entry under that cluster.nLuckily there is scikit-learn code for this.nnYou can treat the set of tags across all products as defining a feature space for the entries. The presence of a tag on a product means that product will have a non-zero entry equal to the weight in the position corresponding to that tag. From there you have a fixed vector to describe entries and GMMs can be applied.nnnnHowever it is really hard to evaluate unsupervised learning approaches like this. Rather you should evaluate methods in light of the downstream task they are used for. like suggesting products to people or detecting fraud or detecting duplicates etc. n' 'If the direct and naÃ¯ve application of k-means is not helping much you may need to dig a bit deeper.nnAssuming you have N distinct tags of which 0..N can be applied to each product p. Each assignment describes a weighted relationship with a positive weight w. Absence of a tag for a product equals w = 0.nnThis is your setup that yields an N-dimensional feature space for your products. You should be able to use arbitrary clustering methods; you just have to select the correct measures.nnYour distance (or similarity) measure should depend on your data.nnConsequently the first thing to ask yourself is: When are two measures considered similar?nnnIf they have as many overlapping tags as possible?nIf the sum of differences between non-overlapping tag weights is max?nIf the sum of differences between overlapping tags is min?n...nnnDepending on your defined similarity you should be able to choose or implement a measure that yields the grade of similarity (not just the euclidean distance in N dimensions) when comparing two elements.nnAlso you may want to check this post at CrossValidated or (if you want to learn more about clustering) Section 7.3 of ""Mining of Massive Datasets"" (2014 Anand Rajaraman Jure Leskovec and Jeffrey D. Ullman) Entire bookn'",['python-3.x'],['numpy']
40124519,"'Efficient way to perform a quesry on a jsonfield in django' 'am trying to extract some data on a jsonfield in django but the queryset that i have written is taking forever to perfom this action.The database that am querying has over 10 million records :( can is their a more efficent way to do this?nHere is the querynnfrom django.contrib.postgres.fields import JSONFieldnfrom maidea.apps.upload_service.models import MobileUploadHouseholdLognnrejected_hh_somalia = MobileUploadHouseholdLog.objects.filter(status=4 household__contains={'info':{'location':{'label':'Hantiwadag'}}})nnnmy models.pynnclass MobileUploadHouseholdLog(MAIDEAModel):n    objects = MobileUploadHouseholdLogManager()nn    UNPROCESSED = 0n    IMPORTED_TO_SCOPE = 1n    ERROR = 2n    DUPLICATE = 3n    DISCARDED = 4nn    IMPORT_STATUS = (n        (UNPROCESSED _('New'))n        (IMPORTED_TO_SCOPE _('Import successful'))n        (ERROR _('Import failed'))n        (DUPLICATE _('Duplicate upload'))n        (DISCARDED _('Discarded upload'))n    )nn    uuid = UUIDField(verbose_name=_(""Unique ID"") auto=True version=4 help_text=_('unique id'))n    household = JSONField(_(""JSON for a single household"") help_text=_('Contains data for a single Household')n                          blank=True null=False)n    status = models.IntegerField(_(""Processing status"") choices=IMPORT_STATUS)n    mobile_upload_log = models.ForeignKey(MobileUploadLogn                                          verbose_name=_('Upload session where the Household is coming from')n                                          related_name='mobile_upload_logs')n    processed_datetime = models.DateTimeField(null=True blank=Truen                                              verbose_name=_('Timestamp when household was processed'))n    error = models.TextField(_(""Error trace for this import"") help_text=_('Contains the exception of why this household cannot be imported')n                             blank=True null=False)nn    def save_error(self error):n        self.status = MobileUploadHouseholdLog.ERRORn        self.error = errorn        self.processed_datetime = timezone.now()n        self.save()nn    def save_imported(self):n        self.status = MobileUploadHouseholdLog.IMPORTED_TO_SCOPEn        self.processed_datetime = timezone.now()n        self.save()nn    def save_duplicate(self):n        self.status = MobileUploadHouseholdLog.DUPLICATEn        self.processed_datetime = timezone.now()n        self.save()nnnAny insight will be appreciated.Thanksn' nan",['django'],['django']
40124568,"'Serve uploaded files from NGINX server instead of gunicorn/Django' ""I have separate servers one running NGINX and other running gunicorn/Django I managed to serve static files from NGINX directly as recommended from Django documentation but I have an issue with files uploaded by users which will be upload to server has gunicorn not the server has NGINX thus users can't find  their files and browse them.nnHow to upload files from Django to another server? or How to transfer files from other server after uploading to NGINX?nnNote: I don't have the CDN option I'll server my statics from my servers.n"" ""You need to implement a solution for sharing files from one server to another. NFS is the standard in Unixes like Linux. An alternative is to use live mirroring i.e. create a copy of the media files directory in the nginx server and keep it synchronized. There are probably many options for setting this up; I've successfully used lsyncd.n""",['django'],['django']
40124807,"'How to add space after label in ModelForms of django' 'I want to add space after ""Mobile No: ""meaning in between label and text area. But by using django ModelForms I am not able to do that it shows ""Mobile No:"" without any space between label and textarea.nnThis is how I have described it in models.py file.nnphone = models.CharField(max_length=10 verbose_name=""Mobile No"" validators=mobileno)nnnforms.py filennclass UserInfoForm(forms.ModelForm):n    class Meta:n        model = UserInfon        fields = ('phone')nnnThis is the content of my html file.nn<form method=""post"">    n    {% csrf_token %}n    {{ form }}n       </form>nnnThis is how it is showing by default.nnnnHow can I add space between label and textarea. Thanks for you help.n' 'You should iterate through your form fields.nnLike this:nn<form method=""post"" > {% csrf_token %}nn        {% for field in form %}nn        <div class=""form-group"">n            <label class=""col-sm-4 control-label"" for=""{{ field.name }}"">{{ field.label }} : </label>nn            <div class=""col-sm-8"">n                {{ field }}n            </div>n        </div>nn        {% endfor %}n    </div>nn' 'The layout and spacing of form labels and fields is a presentation matter and best handled through CSS.nnSee also: CSS styling in Django formsn'",['django'],['django']
40124865,'How can I copy one excel file data to another excel file by excluding hidden row content using Python' 'I need to copy one excel file data into another excel file by excluding rows which were hidden in source excel file.nnSource excel filennAs shown in the image from the source excel file I need to copy the data of row numbers 116135 and 139 and exclude all the remaining rows which were hidden because of not matching the criteria.nnI have tried below code but this is copying entire data into new excel sheet.nnwb = openpyxl.load_workbook('sourcefile.xlsx')nsheet = wb.activensheet.title = 'Sheet1'nwb.save('destinationfile.xlsx')nn' nan,['python-2.7'],[]
40124901,"'How do I set a specific action to happen when the ""enter"" key on my keyboard is pressed in python' 'I am making a python calculator with GUI for school. nnI have got some basic code from the internet and I have to customize it by changing things around. So far I have added a DEL button a ^2 button and a sqrt() button. nnI now want that if I type in an equation on my keyboard e.g. ""2*4"" and press Enter it will simulate as pressing the equals button. I am having trouble finding out how to get python to register me clicking the Enter and then give me an answer. nnThis is the code:nnfrom __future__ import divisionnfrom math import *nfrom functools import partialntry:n    # Python2n    import Tkinter as tknexcept ImportError:n    # Python3n    import tkinter as tknclass MyApp(tk.Tk):n    def __init__(self):n        # the root will be selfn        tk.Tk.__init__(self)n        self.title(""Magic"")n        # use width x height + x_offset + y_offset (no spaces!)n        #self.geometry(""300x150+150+50"")n        # or set x y position onlyn        self.geometry(""+150+50"")n        self.memory = 0n        self.create_widgets()n    def create_widgets(self):n        # this also shows the calculator's button layoutn        btn_list = n        '7'  '8'  '9'  '*'  'AC'n        '4'  '5'  '6'  '/'  'xÂ²'n        '1'  '2'  '3'  '-'  'âx88x9ax'n        '0'  '.'  '='  '+'  'DEL' n        rel = 'ridge'n        # create all buttons with a loopn        r = 1n        c = 0n        for b in btn_list:n            # partial takes care of function and argumentn            cmd = partial(self.calculate b)n            tk.Button(self text=b width=5 relief=reln                command=cmd).grid(row=r column=c)n            c += 1n            if c > 4:n                c = 0n                r += 1n        # use an Entry widget for an editable displayn        self.entry = tk.Entry(self width=37 bg=""white"")n        self.entry.grid(row=0 column=0 columnspan=5)nn    def undo():n            new_string = whole_string:-1n            print(new_string)n            clear_all()n            display.insert(0 new_string)nn    def calculate(self key):n        if key == '=':n            # here comes the calculation partn            try:n                result = eval(self.entry.get())n                self.entry.insert(tk.END "" = "" + str(result))n            except:n                self.entry.insert(tk.END """")n        elif key == 'AC':n            self.entry.delete(0 tk.END)n        elif key == 'xÂ²':n            self.entry.insert(tk.END ""**"")n            # extract the resultn        elif key == 'âx88x9ax':n            self.memory = self.entry.get()n            self.entry.delete(0 tk.END)n            self.entry.insert(tk.END ""sqrt("")n            self.entry.insert(tk.END self.memory)n            self.entry.insert(tk.END "")"")n        elif key == 'DEL':n            self.memory = self.entry.get()n            self.entry.delete(0 tk.END)n            self.entry.insert(tk.END self.memory:-1)nn        else:# previous calculation has been done clear entryn            if '=' in self.entry.get():n                self.entry.delete(0 tk.END)n            self.entry.insert(tk.END key)nnapp = MyApp()napp.mainloop()nn' 'You can use bind() to assign function to Entry which will be executed when you press EnternnExample:nnimport tkinter as tknndef on_return(event):n    print('keycode:' event.keycode)n    print('text in entry:' event.widget.get())nnroot = tk.Tk()nne = tk.Entry(root)ne.pack()ne.bind('<Return>' on_return)   # standard Enterne.bind('<KP_Enter>' on_return) # KeyPad Enternnroot.mainloop()nnnIn your code it can be - for testnnself.entry = tk.Entry(self width=37 bg=""white"")nself.entry.grid(row=0 column=0 columnspan=5)nnself.entry.bind('<Return>' lambda event:print(""ENTER:"" event.widget.get()))nself.entry.bind('<KP_Enter>' lambda event:print(""ENTER:"" event.widget.get()))nnnIf you have class method def on_return(self event): then nnself.entry.bind('<Return>' self.on_return)nself.entry.bind('<KP_Enter>' self.on_return)nnnnnnEvents and BindingsnKey namesnn'",['tkinter'],['tkinter']
40124914,"'Logout with python-social-auth' ""I am using python-social-auth for my third-party login and logout. Sign in with Facebook Twitter and Google Plus were a success at first (it will ask my username/email and password). My problem is when I log out and then sign in again through either of them I will be signed in automatically without even asking my username/email and password again. Am I not logged out? nnThis is my disconnect pipeline:nnSOCIAL_AUTH_DISCONNECT_PIPELINE = (n    'social.pipeline.disconnect.allowed_to_disconnect'n    'social.pipeline.disconnect.get_entries'n    'social.pipeline.disconnect.revoke_tokens'n    'social.pipeline.disconnect.disconnect'n)nnnThis is my logout view:nnfrom django.contrib.auth import logout as auth_logoutnndef logout(request):n    auth_logout(request)n    return render_to_response('logged-out.html' {} RequestContext(request))nn"" nan",['django'],['django']
40125110,"'Using multiple columns as ForeignKey to return in another table' ""I'm new to Django so I make 3 simple tables to return a WishList. The thing is that I want whenever user asks for WishList his/her user_id is used to make a SELECT query to return his/her own WishList. And I want to get product title and product url from my WishList table. I'm using to_field but with that way I only can get product title back. I don't know much about Django so help me!nnProductnnclass Product(models.Model):n    class Meta:n        unique_together = (('id' 'title'))n    title = models.CharField(max_length=200 unique=Truen                             help_text='Name of the product')n    url = models.CharField(max_length=300 default=''n                           help_text='Url of the product')nn    def __str__(self):n        return 'Product: {}'.format(self.title)nnnWishListnnclass WishList(models.Model):n    class Meta:n        unique_together = (('user' 'product'))nn    user = models.ForeignKey(fbusern                         on_delete=models.CASCADEn                         help_text='Facebook user'n                         to_field='user_id')n    product = models.ForeignKey(Product to_field='title' db_column='title'n                            on_delete=models.CASCADE)nn    def __str__(self):n        return 'WishList: {}'.format(self.user)nn"" 'Django documentation is your friend read it.nnIm serious read the entire documentation.nnMoreover its not a good practice to override to_field to another field different than your model.pk unless you have a really good reason and you know what you are doing (definitely not the case right now).nnSo after you read the docs you will know that in order to get wishlisht related to a user you can use the ForeignKey reverse relation to get all related wishlists for a user.nnuser_wishlists = my_user.wishlist_set.all()n#Because we know that you want to access the wishlist.productsn#in order to optimize things (in terms of db queries)n#you can add and .select_related('product')n#e.g user_wishlists = my_user.wishlist_set.all().select_related('product')nn#now follow the wishlist.product foreign key to access the related product for every wishlistnfor wishlist in user_wishlists:n    product = wishlist.productn    print (product.id product.title product.url)nnnNow after you read a little bit more of the documentationnyou will notice that your WishList model is in fact an intermediate model for a ManyToMany relation between User and his wished products then you will know that you can define a M2M field between user and products via WishList like so:nnclass FbUser(models.Model):n    #...n    wished_products = models.ManyToManyField(n        Productn        through='WishList'n        through_fields=('user' 'product')n    )nn#and now accessing user wished products would be easy as:nuser_wished_products = my_user.wished_products.all()nfor product in user_wished_products:n    print (product.id product.title product.url)nn'",['django'],['django']
40125221,'Tkinter GUI designer working with absolute values?' 'I Need to make a GUI for a guitar effect pedal (yes I am building one and it has a Screen).nSo i do not have to make the gui dynamic cause it is only working on one single Display and I want to place the widgets (only Labels) with absolute Pixel values.nI am doing this with a pi and python.nI want to design my gui with tkinter.nCan you tell me a nice Designer-Programm for designing this gui?nnthanks!n' nan,['tkinter'],"['tkinter', 'python-2.7']"
40125236,'Python vectorization with a constant' 'I have a series X of length n(=300000). Using a window length of w (=40) I need to implement:nnmu(i)= X(i)-X(i-w)nns(i) = sum{k=i-w to i} X(k)-X(k-1) - mu(i)^2nnI was wondering if there's a way to prevent loops here. The fact that mu(i) is constant in second equation is causing complications in vectorization. I did the following so far:nnx1=x.shift(1)nxw=x.shift(w)nmu= x-xw ndx=(x-x1-mu)**2 # wrong because mu wouldn't be constant for each ins=pd.rolling_sum(dxw)nnnThe above code would work (and was working) in a loop setting but takes too long so any help regarding vectorization or other speed improvement methods would be helpful. I posted this on crossvalidated with mathjax formatting but that doesn't seem to work here.nnhttp://stats.stackexchange.com/questions/241050/python-vectorization-with-a-constantnnAlso just to clarify I wasn't using a double loop just a single one originally:nn        for i in np.arange(w len(X)):n            x=X.ixi-w:i0 # clip a series of size wn            x1=x.shift(1)   n            mu.ixi= x.ix-1-x.ix0   n            temp= (x-x1-mu.ixi)**2   # returns a series of size w but now mu is constantn            s.ixi= temp.sum()nn' 'Approach #1 : One vectorized approach would be using broadcasting -nnN = X.shape0na = np.arange(N)nk2D = a:None - np.arange(w+1)::-1nmu1D = X - Xa-wnout = ((Xk2D - Xk2D-1 - mu1D:None)**2).sum(-1)nnnWe can further optimize the last step to get squared summations with np.einsum -nnsubs = Xk2D - Xk2D-1 - mu1D:Nonenout = np.einsum('ijij->i'subssubs)nnnFurther improvement is possible with the use of NumPy strides to get Xk2D and Xk2D-1.nnnnApproach #2 : To save on memory when working very large arrays we can use one loop instead of two loops used in the original code like so -nnN = X.shape0ns = np.zeros((N))nk_idx = np.arange(-w1)nfor i in range(N):n    mu = Xi-Xi-wn    si = ((Xk_idx-Xk_idx-1 - mu)**2).sum()n    k_idx += 1nnnAgain np.einsum could be used here to compute si like so -nnsubs = Xk_idx-Xk_idx-1 - munsi = np.einsum('ii->'subssubs)nn',"['pandas', 'numpy']","['numpy', 'pandas']"
40125256,"'webpage access while using scrapy' 'I am new to python and scrapy. I followed the tutorial and tried to crawl few webpages. I used the code in the tutorial and replaced the URLs - http://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=0 and http://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=1 respectively.nnwhen the html file is generated the whole data is not getting displayed. only the data upto this URL - http://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=0&sd=0&states=ALL&near=&ps=20&p=0 is shown. nnAlso while the command is run the second URL has been removed stating it as duplicate and only one html file is being created.nnI want to know if the webpage denies access to that specific data or should i change my code to get the precise data. nnWhen i further give the shell command i am getting error.nThe result when i used the crawl command and shell command was -nn    C:UsersMinorMiraclesDesktoptutorial>python -m scrapy.cmdline crawl citydatan2016-10-19 12:00:27 scrapy INFO: Scrapy 1.2.0 started (bot: tutorial)n2016-10-19 12:00:27 scrapy INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tuntorial.spiders' 'SPIDER_MODULES': 'tutorial.spiders' 'ROBOTSTXT_OBEY': Truen 'BOT_NAME': 'tutorial'}n2016-10-19 12:00:27 scrapy INFO: Enabled extensions:n'scrapy.extensions.logstats.LogStats'n 'scrapy.extensions.telnet.TelnetConsole'n 'scrapy.extensions.corestats.CoreStats'n2016-10-19 12:00:27 scrapy INFO: Enabled downloader middlewares:n'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'n 'scrapy.downloadermiddlewares.retry.RetryMiddleware'n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware'n 'scrapy.downloadermiddlewares.stats.DownloaderStats'n2016-10-19 12:00:27 scrapy INFO: Enabled spider middlewares:n'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'n 'scrapy.spidermiddlewares.referer.RefererMiddleware'n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'n 'scrapy.spidermiddlewares.depth.DepthMiddleware'n2016-10-19 12:00:27 scrapy INFO: Enabled item pipelines:nn2016-10-19 12:00:27 scrapy INFO: Spider openedn2016-10-19 12:00:27 scrapy INFO: Crawled 0 pages (at 0 pages/min) scraped 0 intems (at 0 items/min)n2016-10-19 12:00:27 scrapy DEBUG: Telnet console listening on 127.0.0.1:6023n2016-10-19 12:00:27 scrapy DEBUG: Filtered duplicate request: <GET http://www.ncity-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=n&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAXn&i6819=1&ps=20&p=1> - no more duplicates will be shown (see DUPEFILTER_DEBUG tonshow all duplicates)n2016-10-19 12:00:28 scrapy DEBUG: Crawled (200) <GET http://www.city-data.com/nrobots.txt> (referer: None)n2016-10-19 12:00:29 scrapy DEBUG: Crawled (200) <GET http://www.city-data.com/nadvanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=691n4&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20n&p=0> (referer: None)n2016-10-19 12:00:29 citydata DEBUG: Saved file citydata-advanced.htmln2016-10-19 12:00:29 scrapy INFO: Closing spider (finished)n2016-10-19 12:00:29 scrapy INFO: Dumping Scrapy stats:n{'downloader/request_bytes': 459n 'downloader/request_count': 2n 'downloader/request_method_count/GET': 2n 'downloader/response_bytes': 44649n 'downloader/response_count': 2n 'downloader/response_status_count/200': 2n 'dupefilter/filtered': 1n 'finish_reason': 'finished'n 'finish_time': datetime.datetime(2016 10 19 6 30 29 751000)n 'log_count/DEBUG': 5n 'log_count/INFO': 7n 'response_received_count': 2n 'scheduler/dequeued': 1n 'scheduler/dequeued/memory': 1n 'scheduler/enqueued': 1n 'scheduler/enqueued/memory': 1n 'start_time': datetime.datetime(2016 10 19 6 30 27 910000)}n2016-10-19 12:00:29 scrapy INFO: Spider closed (finished)nnC:UsersMinorMiraclesDesktoptutorial>python -m scrapy.cmdline shell 'http://wnww.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&nenar=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=nMAX&i6819=1&ps=20&p=0'n2016-10-19 12:21:51 scrapy INFO: Scrapy 1.2.0 started (bot: tutorial)n2016-10-19 12:21:51 scrapy INFO: Overridden settings: {'NEWSPIDER_MODULE': 'tuntorial.spiders' 'ROBOTSTXT_OBEY': True 'DUPEFILTER_CLASS': 'scrapy.dupefiltersn.BaseDupeFilter' 'SPIDER_MODULES': 'tutorial.spiders' 'BOT_NAME': 'tutorial'n 'LOGSTATS_INTERVAL': 0}n2016-10-19 12:21:51 scrapy INFO: Enabled extensions:n'scrapy.extensions.telnet.TelnetConsole'n 'scrapy.extensions.corestats.CoreStats'n2016-10-19 12:21:51 scrapy INFO: Enabled downloader middlewares:n'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware'n 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware'n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware'n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware'n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware'n 'scrapy.downloadermiddlewares.retry.RetryMiddleware'n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware'n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware'n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware'n 'scrapy.downloadermiddlewares.chunked.ChunkedTransferMiddleware'n 'scrapy.downloadermiddlewares.stats.DownloaderStats'n2016-10-19 12:21:51 scrapy INFO: Enabled spider middlewares:n'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware'n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware'n 'scrapy.spidermiddlewares.referer.RefererMiddleware'n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware'n 'scrapy.spidermiddlewares.depth.DepthMiddleware'n2016-10-19 12:21:51 scrapy INFO: Enabled item pipelines:nn2016-10-19 12:21:51 scrapy DEBUG: Telnet console listening on 127.0.0.1:6023n2016-10-19 12:21:51 scrapy INFO: Spider openedn2016-10-19 12:21:53 scrapy DEBUG: Retrying <GET http://'http:/robots.txt> (fainled 1 times): DNS lookup failed: address ""'http:"" not found: Errno 11004 getadndrinfo failed.n2016-10-19 12:21:56 scrapy DEBUG: Retrying <GET http://'http:/robots.txt> (fainled 2 times): DNS lookup failed: address ""'http:"" not found: Errno 11004 getadndrinfo failed.n2016-10-19 12:21:58 scrapy DEBUG: Gave up retrying <GET http://'http:/robots.tnxt> (failed 3 times): DNS lookup failed: address ""'http:"" not found: Errno 1100n4 getaddrinfo failed.n2016-10-19 12:21:58 scrapy ERROR: Error downloading <GET http://'http:/robots.ntxt>: DNS lookup failed: address ""'http:"" not found: Errno 11004 getaddrinfo fnailed.nDNSLookupError: DNS lookup failed: address ""'http:"" not found: Errno 11004 getnaddrinfo failed.n2016-10-19 12:22:00 scrapy DEBUG: Retrying <GET http://'http://www.city-data.cnom/advanced/search.php#body?fips=0> (failed 1 times): DNS lookup failed: addressn ""'http:"" not found: Errno 11004 getaddrinfo failed.n2016-10-19 12:22:03 scrapy DEBUG: Retrying <GET http://'http://www.city-data.cnom/advanced/search.php#body?fips=0> (failed 2 times): DNS lookup failed: addressn ""'http:"" not found: Errno 11004 getaddrinfo failed.n2016-10-19 12:22:05 scrapy DEBUG: Gave up retrying <GET http://'http://www.citny-data.com/advanced/search.php#body?fips=0> (failed 3 times): DNS lookup failed:n address ""'http:"" not found: Errno 11004 getaddrinfo failed.nTraceback (most recent call last):n  File ""C:Python27librunpy.py"" line 174 in _run_module_as_mainn    ""__main__"" fname loader pkg_name)n  File ""C:Python27librunpy.py"" line 72 in _run_coden    exec code in run_globalsn  File ""C:Python27libsite-packagesscrapycmdline.py"" line 161 in <module>n    execute()n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 142 in executen    _run_print_help(parser _run_command cmd args opts)n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 88 in _run_printn_helpn    func(*a **kw)n  File ""C:Python27libsite-packagesscrapycmdline.py"" line 149 in _run_commnandn    cmd.run(args opts)n  File ""C:Python27libsite-packagesscrapycommandsshell.py"" line 71 in runnn    shell.start(url=url)n  File ""C:Python27libsite-packagesscrapyshell.py"" line 47 in startn    self.fetch(url spider)n  File ""C:Python27libsite-packagesscrapyshell.py"" line 112 in fetchn    reactor self._schedule request spider)n  File ""C:Python27libsite-packagestwistedinternetthreads.py"" line 122 inn blockingCallFromThreadn    result.raiseException()n  File ""<string>"" line 2 in raiseExceptionntwisted.internet.error.DNSLookupError: DNS lookup failed: address ""'http:"" not fnound: Errno 11004 getaddrinfo failed.n'csize' is not recognized as an internal or external commandnoperable program or batch file.n'sc' is not recognized as an internal or external commandnoperable program or batch file.n'sd' is not recognized as an internal or external commandnoperable program or batch file.n'states' is not recognized as an internal or external commandnoperable program or batch file.n'near' is not recognized as an internal or external commandnoperable program or batch file.n'nam_crit1' is not recognized as an internal or external commandnoperable program or batch file.n'b6914' is not recognized as an internal or external commandnoperable program or batch file.n'e6914' is not recognized as an internal or external commandnoperable program or batch file.n'i6914' is not recognized as an internal or external commandnoperable program or batch file.n'nam_crit2' is not recognized as an internal or external commandnoperable program or batch file.n'b6819' is not recognized as an internal or external commandnoperable program or batch file.n'e6819' is not recognized as an internal or external commandnoperable program or batch file.n'i6819' is not recognized as an internal or external commandnoperable program or batch file.n'ps' is not recognized as an internal or external commandnoperable program or batch file.n'p' is not recognized as an internal or external commandnoperable program or batch file.nnnMy code is nnimport scrapynnnclass QuotesSpider(scrapy.Spider):n    name = ""citydata""nn    def start_requests(self):n        urls = n            'http://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=0'n            'http://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=1'n        n        for url in urls:n            yield scrapy.Request(url=url callback=self.parse)nn    def parse(self response):n        page = response.url.split(""/"")-2n        filename = 'citydata-%s.html' % pagen        with open(filename 'wb') as f:n            f.write(response.body)n        self.log('Saved file %s' % filename)nnnSomeone please guide me through this.n' 'First of all this website looks like a JavaScript-heavy one. Scrapy itself only downloads HTML from servers but does not interpret JavaScript statements.nnSecond the URL fragment (i.e. everything including and after #body) is not sent to the server and only http://www.city-data.com/advanced/search.php is fetched (scrapy does the same as your browser.nYou can confirm that with your browser's dev tools network tab.)nnSo for Scrapy the requests to nnhttp://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=0nnnandnnhttp://www.city-data.com/advanced/search.php#body?fips=0&csize=a&sc=2&sd=0&states=ALL&near=&nam_crit1=6914&b6914=MIN&e6914=MAX&i6914=1&nam_crit2=6819&b6819=15500&e6819=MAX&i6819=1&ps=20&p=1nnnare the same resource so it's only fetch once. They differ only in their URL fragments.nnWhat you need is a JavaScript renderer. You could use Selenium or something like Splash. I recommend using the scrapy-splash plugin which includes a duplicate filter that takes into account URL fragments.n'",['python-2.7'],['python-2.7']
40125528,"'modify pandas boxplot output' 'I made this plot in pandas according to the documentation:nnimport pandas as pdnimport numpy as npnimport pyplot as pltnndf = pd.DataFrame(np.random.rand(140 4) columns='A' 'B' 'C' 'D')ndf'models' = pd.Series(np.repeat('model1''model2' 'model3' 'model4' 'model5' 'model6' 'model7' 20))nplt.figure()nbp = df.boxplot(by=""models"")nnnnnHow can I modify this plot?nnI want:nnnmodify arrangement from (22) to (14)nchange the labels and titles text and font sizenremove the 'models' textnnnand how do I save this plot as pdf ?n' 'A number of things you can do already using the boxplot function in pandas see the documentation. nnnYou can already modify the arrangement and change the fontsize: nnimport pandas as pdnimport numpy as npnimport pyplot as pltnndf = pd.DataFrame(np.random.rand(140 4) columns='A' 'B' 'C' 'D')ndf'models' = pd.Series(np.repeat('model1''model2' 'model3' 'model4' 'model5' 'model6' 'model7' 20))nbp = df.boxplot(by=""models"" layout = (41) fontsize = 14)nnChanging the columns the labels can be done by changing the columns labels of the dataframe itself:nndf.columns('E' 'F' 'G' 'H' 'models')nnFor further customization I would use the functionality from matlotlib itself; you can take a look at the examples here. nn' 'nFor the arrangement use layoutnFor setting x label use set_xlabel('')nFor figure title use figure.subtitle()nFor changing the figure size use figsize=(wh) (inches)nnnnote: the line np.asarray(bp).reshape(-1) is converting the layout of the subplots (2x2 for instance) to an array. nncode : nnimport pandas as pdnimport numpy as npnimport matplotlib.pyplot as pltnndf = pd.DataFrame(np.random.rand(140 4) columns='A' 'B' 'C' 'D')ndf'models' = pd.Series(np.repeat('model1''model2' 'model3' 'model4' 'model5' 'model6' 'model7' 20))nbp = df.boxplot(by=""models""layout=(41)figsize=(68))nax_tmp.set_xlabel('') for ax_tmp in np.asarray(bp).reshape(-1)nfig = np.asarray(bp).reshape(-1)0.get_figure()nfig.suptitle('New title here')nplt.show()nnnresult: nnn'","['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40125654,"'cant groupby on certain column after merging 2 dataframes in python' ""I have 2 data frames data and data_car_types. nAfter merging them:nndata_all = pd.merge(data data_car_types on = 'vin' how = 'right')nnnI get a data frame with this info:nnData columns (total 21 columns):nvin                           11391 non-null objectntime_stamp                    5700 non-null objectntime_stamp1                   5700 non-null objectnabs                           5700 non-null objectncity                          5700 non-null objectnaccelerator_pedal_position    5700 non-null float64nbrake_pedal_status            5700 non-null objectnengine_temperature            5700 non-null float64nengineoil                     5700 non-null float64nfuel                          5700 non-null float64nheadlamp_status               5700 non-null objectnignition_status               5700 non-null objectnodometer                      5700 non-null float64noutside_temperature           5700 non-null float64nparking_brake_status          5700 non-null objectnspeed                         5700 non-null float64ntirepressure                  5700 non-null float64ntransmission_gear_position    5700 non-null objectnwindshild_wiper_status        5700 non-null objectntime_stamp2                   5700 non-null objectncar_type                      11391 non-null objnnnetc.nnWhen I want to group by car_type it fails:nndata_all.groupby('car_type')nnnI get:nnn  pandas/index.pyx in pandas.index.IndexEngine.get_locn  (pandas/index.c:3979)() pandas/index.pyx inn  pandas.index.IndexEngine.get_loc (pandas/index.c:3843)()n  n  pandas/hashtable.pyx in pandas.hashtable.PyObjectHashTable.get_itemn  (pandas/hashtable.c:12265)()n  n  pandas/hashtable.pyx in pandas.hashtable.PyObjectHashTable.get_itemn  (pandas/hashtable.c:12216)()n  n  KeyError: 'car_type'nnnI don't understand what is wrong?n"" nan",['pandas'],['pandas']
40126029,"'Numpy Array reshape' ""I have an Numpy array immatrix which is of immatrix.shape is (4535)  and each element in the array immatrix is another array imArray of shape (12288) . How can I reshape the array immatrix   to (453536464) nn    from PIL import Imagen    import PIL.Image as Pimnn    img_rows img_cols = 64 64n    # number of channelsn    img_channels = 3nn    ret = n    for im2 in imlist_lettering:n        img = Image.open(dirPath_of_non_spam + '/' + im2);n        img = img.resize(( img_rows img_cols) Pim.BILINEAR)n        imArray = array(img dtype=float).flatten();n        if img_channels * img_cols *  img_rows == imArray.shape0:n            ret.append(imArray)nn    immatrix = array(ret)nnnIn here  the immatrix shape is (4535)  and imArray shape is (12288) I want to reshape the immatix to (453536464) .How to do that??n"" nan",['numpy'],['numpy']
40126129,"'x.objects.all() empty user.x_set.all() not empty' 'This is probably really simple but I don't think I've come across this problem before.nnI have an object in my database called WeatherForecast this object has a foreign key to User so the user can have a number of different forecasts displayed in a template.nnclass WeatherForecast(models.Model):nnn    owner = models.ForeignKey(User null=True)nnnI create the forecasts and set the foreign key as such:nnnewForecast = WeatherForecast.objects.create(owner = request.user)nnnWhen I call WeatherForecast.objects.all() it returns an empty query set. However when I call user.weatherforecast_set.all() it returns the WeatherForecasts with the correct foreign key.nnI'm probably missing something obvious but why is this happening?nnEDIT:nnHere is where I am calling it.nnOriginally I was doing this to get a number of selected forecasts (selections were made from the template via a form the IDs were taken from the form and put into a list and I have verified that the IDs are being passed from the form correctly).nnfor weatherForecastID in selectedIDs:nnselectedForecast = WeatherForecast.objects.get(id = weatherForecastID)nnnI was getting WeatherForecast matching this query does not exist errors from that. After looking into it I found the issue I am having where the objects.all() is empty but the weatherforecast_set.all() isn't.nnTo make sure I wasn't missing something silly I also printed the query sets like so:nnprint ""all weather forecasts:"" WeatherForecast.objects.all()nprint ""user weather forecasts:"" request.user.weatherforecast_set.all()nnnwhich gives:nnall weather forecasts: <QuerySet >nuser weather forecasts: <QuerySet <WeatherForecast: WeatherForecast object>>nnnEDIT 2nnFIXED! There was a model in a different app with the same name causing the query to be looking in the wrong table! Feel like a bit of an idiot now!nnThank you everyone for the help!n' nan",['django'],['django']
40126260,"'get dictionary contains in list if key and value exists' ""How to get complete dictionary data inside lists. but first I need to check them if key and value is exists and paired.nntest = {'a': 'hello'   'b': 'world' 'c': 1}n        {'a': 'crawler' 'b': 'space' 'c': 5}n        {'a': 'jhon'    'b': 'doe'   'c': 8}nnnwhen I try to make it conditional like thisnnif any((d'c' is 8) for d in test):nnnthe value is True or False But I want the result be an dictionary likenn{'a': 'jhon' 'b': 'doe' 'c': 8}nnnsame as if I donnif any((d'a' is 'crawler') for d in test):nnnthe results is:nn{'a': 'crawler' 'b': 'space' 'c': 5}nnnThanks before.n"" 'Use comprehension:nndata = {'a': 'hello'   'b': 'world' 'c': 1}n        {'a': 'crawler' 'b': 'space' 'c': 5}n        {'a': 'jhon'    'b': 'doe'   'c': 8}nnprint(d for d in data if d""c"" == 8)n# {'c': 8 'a': 'jhon' 'b': 'doe'}nn' 'is tests for identity not for equality which means it compares the memory address not the values those variables are pointing to. So it is very likely it might return False for same values. You should use == instead for checking equality.nnAs for your question you can use filter or list comprehensions over any:nn>>> dct for dct in data if dct""a"" == ""crawler""n>>> filter(lambda dct: dct""a"" == ""crawler"" data)nnnThe result is a list containing the matched dictionaries. You can get the 0th element if you think it contains only one item.n'","['list', 'dictionary']","['dictionary', 'list']"
40126274,"'Any way to replace pandas pd.merge?' ""I have two dataframe nn>>df1.info()n>><class 'pandas.core.frame.DataFrame'>n  Int64Index: 2598374 entries 3975 to 3054366n  Data columns (total 14 columns): ......n>>df2.info()n>><class 'pandas.core.frame.DataFrame'>n  Int64Index: 2520405 entries 2066 to 2519507n  Data columns (total 5 columns): ......nnnI wanna inner join them. I tried pd.merge and I got memory error. Thus I tried to do same things without pd.merge.nnExample dataframe for original method (failed: memory error)nndf1 = pd.DataFrame({'A': '1' '2' '3' '4''5'n              'B': '1' '1' '1' '1''1'n              'C': 'c' 'A1' 'a' 'c3''a'n              'D': 'B1' 'B1' 'B2' 'B3''B4'n              'E': '3' '3' '3' '3''3'n              'F': '3' '4' '5' '6''7'n              'G': '2' '2' '2' '2''2'})nndf2 = pd.DataFrame({'A': '1' '2'  '8''4'n              'B': '1' '2'  '5''1'n              'x': '3' '3' '2''2'n              'y': '3' '4' '6''7'n              'z': '2' '2' '2''2'})n>>   df1n         A  B   C   D  E  F  Gn      0  1  1   c  B1  3  3  2n      1  2  1  A1  B1  3  4  2n      2  3  1   a  B2  3  5  2n      3  4  1  c3  B3  3  6  2n      4  5  1   a  B4  3  7  2nn     df2n         A  B  x  y  zn      0  1  1  3  3  2n      1  2  2  3  4  2n      2  8  5  2  6  2n      3  4  1  2  7  2nndf1 = pd.merge(df1df2how='inner'on='A''B') nn>>   df1    n         A  B   C   D  E  F  G  x  y  zn      0  1  1   c  B1  3  3  2  3  3  2n      1  4  1  c3  B3  3  6  2  2  7  2nnnExample for new methodn(1) I tried to delete rows in df1 which are not in df2 by column'A''B'.n(2) concat xyz columns to df1nndf1 = pd.DataFrame({'A': '1' '2' '3' '4''5'n              'B': '1' '1' '1' '1''1'n              'C': 'c' 'A1' 'a' 'c3''a'n              'D': 'B1' 'B1' 'B2' 'B3''B4'n              'E': '3' '3' '3' '3''3'n              'F': '3' '4' '5' '6''7'n              'G': '2' '2' '2' '2''2'})nndf2 = pd.DataFrame({'A': '1' '2'  '8''4'n              'B': '1' '2'  '5''1'n              'x': '3' '3' '2''2'n              'y': '3' '4' '6''7'n              'z': '2' '2' '2''2'})n>>   df1n         A  B   C   D  E  F  Gn      0  1  1   c  B1  3  3  2n      1  2  1  A1  B1  3  4  2n      2  3  1   a  B2  3  5  2n      3  4  1  c3  B3  3  6  2n      4  5  1   a  B4  3  7  2nn     df2n         A  B  x  y  zn      0  1  1  3  3  2n      1  2  2  3  4  2n      2  8  5  2  6  2n      3  4  1  2  7  2nndf1 = df1.loc((df1'A'.isin(df2.A)) & (df1'B'.isin(df2.B)) ) nn>>   df1    n         A  B   C   D  E  F  G  n      0  1  1   c  B1  3  3  2  n      1  2  1  A1  B1  3  4  2n      3  4  1  c3  B3  3  6  2  nnnhowever I got a logical error and I have no idea to solve this problem.nCan anyone help? n"" 'You can try concat with set_index:nndf1 = pd.concat(df1.set_index('A''B')n                 df2.set_index('A''B') axis=1 join='inner')nprint (df1)              n      C   D  E  F  G  x  y  znA B                          n1 1   c  B1  3  3  2  3  3  2n4 1  c3  B3  3  6  2  2  7  2nnnOr combination with boolean indexing:nndf1 = df1((df1'A'.isin(df2.A)) & (df1'B'.isin(df2.B)) ) nprint (df1)n   A  B   C   D  E  F  Gn0  1  1   c  B1  3  3  2n1  2  1  A1  B1  3  4  2n3  4  1  c3  B3  3  6  2nndf2 = df2((df2'A'.isin(df1.A)) & (df2'B'.isin(df1.B)) ) nprint (df2)n   A  B  x  y  zn0  1  1  3  3  2n3  4  1  2  7  2nndf3 = pd.concat(df1.set_index('A''B')n                 df2.set_index('A''B') axis=1 join='inner')nprint (df3)              n      C   D  E  F  G  x  y  znA B                          n1 1   c  B1  3  3  2  3  3  2n4 1  c3  B3  3  6  2  2  7  2nnnIf df1 after filtering is not large use merge:nndf1 = df1((df1'A'.isin(df2.A)) & (df1'B'.isin(df2.B)) ) nprint (df1)n   A  B   C   D  E  F  Gn0  1  1   c  B1  3  3  2n1  2  1  A1  B1  3  4  2n3  4  1  c3  B3  3  6  2nndf2 = df2((df2'A'.isin(df1.A)) & (df2'B'.isin(df1.B)) ) nprint (df2)n   A  B  x  y  zn0  1  1  3  3  2n3  4  1  2  7  2nndf3 = pd.merge(df1df2 on='A''B') nprint (df3)              n   A  B   C   D  E  F  G  x  y  zn0  1  1   c  B1  3  3  2  3  3  2n1  4  1  c3  B3  3  6  2  2  7  2nn'",['pandas'],['pandas']
40126403,"'Inplace functions in Python' ""In Python there is a concept of inplace functions. For example shuffle is inplace in that it returns none.nnHow do I determine if a function will be inplace or not?nnfrom random import shufflennprint(type(shuffle))nn<class 'method'>nnnSo I know it's a method from class random but is there a special variable that defines some functions as inplace?n"" ""You can't have a-priory knowledge about the operation for a given function. You need to either look at the source and deduce this information or examine the docstring for it and hope the developer documents this behavior.nnFor example in list.sort:nnhelp(list.sort)nHelp on method_descriptor:nnsort(...)n    L.sort(key=None reverse=False) -> None -- stable sort *IN PLACE*nnnFor functions operating on certain types their mutability generally lets you extract some knowledge about the operation. You can be certain for example that all functions operating on strings will eventually return a new one meaning they can't perform in-place operations.n"" ""I don't think there is special variable that defines some function as in-place but a standard function should have a doc string that says that it is in-place and does not return any value. For example:nn>>> print(shuffle.__doc__)nnShuffle list x in place and return None.nn    `Optional argument random is a 0-argument function returning an    random float in 0.0 1.0); if it is the default None then    standard random.random will be used.`nn""",['python-3.x'],"['list', 'python-2.7']"
40126449,"'Tkinter how to update second combobox automatically according this combobox' 'I have encountered an issue with combobox updates in Tkinter Python.nnI have two comboboxes:nnncombobox A with values ='A''B''C' andncombobox BnnnWhat i want is that:nnnwhen value A is selected in combobox A then in combobox B show the values '1''2''3'nwhen value B is selected in combobox A then in combobox B show the values '11''12''13'nwhen value C is selected in combobox A then in combobox B show the value s '111''112''113'nnnCurrently part of my code as follows:nndef CallHotel(*args):n    global ListBn    if hotel.get()==ListA0n        ListB=ListB1n    if hotel.get()==ListA1n        ListB=ListB2n    if hotel.get()==ListA2n        ListB=ListB3nnListA='A''B''C'nnListB1='1''2''3'nnListB2='11''12''13'nnListB3='111''112''113'nnListB=ListB1nnhotel = StringVar()nhotel.set('SBT')nncomboboxA=ttk.Combobox(win0textvariable=hotelvalues=ListAwidth=8)ncomboboxA.bind(""<<ComboboxSelected>>""CallHotel)ncomboboxA.pack(side='left')  nnstp = StringVar()nstp.set('STP')nncomboboxB=ttk.Combobox(win0textvariable=stpvalues=ListBwidth=15)ncomboboxB.pack(side='left')nn' ""Actually you don't need the global variable ListB.  And you need to add comboboxB.config(values=...) at the end of CallHotel() to set the options of comboboxB:nndef CallHotel(*args):n    sel = hotel.get()n    if sel == ListA0:n        ListB = ListB1n    elif sel == ListA1:n        ListB = ListB2n    elif sel == ListA2:n        ListB = ListB3n    comboboxB.config(values=ListB)nnnAnd change the initial values of comboboxB to ListB1 directly:nncomboboxB=ttk.Combobox(win0textvariable=stpvalues=ListB1width=15)nn""",['tkinter'],['tkinter']
40126683,"'How to generate effectively a random number that only contains unique digits in Python?' ""import randomnndef get_number(size):n  result = random.randint(19)n  digits = list(range(010))n  digits.remove(result0)n  if(size > 1):n    result += random.sample(digitssize-1)n  return ''.join(map(strresult))nnprint(get_number(4))nnnI solved the problem but I feel that it's clumsy. nHow can I do this more effectively and more elegant? n"" 'Shuffle is the way to go as suggested by @jonrsharpe:nnimport randomnndef get_number(size):n    l =  str(i) for i in list(range(10))n    while l0 == '0':n        random.shuffle(l)n    return int("""".join(l:size))nnnLimits:nnnis you ask for a number of more than 10 digits you will only get 10 digitsnit can take some steps if first digit is initially a 0nn' 'Just use shuffle:nnimport stringnnx = list(string.digits)nrandom.shuffle(x)nnprint int(str(random.choice(range(1 10))) + """".join(x:3))nn'",['list'],"['python-2.7', 'list', 'python-3.x']"
40126853,"'Fastest way to build a Matrix with a custom architecture' ""What's the fastest way in numpy or pandas to build a matrix that has this form:nn1 1 1 1 1n1 2 2 2 1n1 2 3 2 1n1 2 2 2 1n1 1 1 1 1nnnThat preserves both odd and even architectures?n"" 'Using NumPy brodacasting!nnIn 289: a = np.array(12321)nnIn 290: np.minimum(a:Nonea)nOut290: narray(1 1 1 1 1n       1 2 2 2 1n       1 2 3 2 1n       1 2 2 2 1n       1 1 1 1 1)nnnTo build the range array we can do something like this -nnIn 303: N = 3nnIn 304: np.concatenate((np.arange(1N+1)np.arange(N-10-1)))nOut304: array(1 2 3 2 1)nnnAdding some biasnnLet's say we want to move the highest number/peak up or down. We need to create another biasing array and use the same strategy of broadcasting like so -nnIn 394: a = np.array(12321)nnIn 395: b = np.array(23210) # Biasing arraynnIn 396: np.minimum(b:Nonea)nOut396: narray(1 2 2 2 1n       1 2 3 2 1n       1 2 2 2 1n       1 1 1 1 1n       0 0 0 0 0)nnnSimilarly to have the bias shifted left or right modify a like so -nnIn 397: a = np.array(23210) # Biasing arraynnIn 398: b = np.array(12321)nnIn 399: np.minimum(b:Nonea)nOut399: narray(1 1 1 1 0n       2 2 2 1 0n       2 3 2 1 0n       2 2 2 1 0n       1 1 1 1 0)nn'","['pandas', 'numpy']",['numpy']
40126979,"'Dump database table or work remotely for analysis?' ""I have a table of 80 million rows and I was given the task to do some light analysis like finding patterns for fields which fields are mutually exclusive etc.nnMy initial instinct was to dump the whole table into a CSV so I can work with Pandas or similar since I assumed it would be faster and easier to work with. While figuring out ways on how to get the whole table into a CSV a colleague insisted that it is overkill and the conventional approach is to work directly with the Oracle database.nnFrom my software background my understanding has been that databases are more for keeping the state of big applications and less for a human to fiddle with. What is the common approach for analysis when having such big tables? What is faster? Personally I don't mind the time it takes to dump the database but more about the time it takes to get back feedback when doing the actual analysis.n"" 'Directly on the database with SQL is perfectly fine for any analysis when you already know what you're looking for.nnWhen you don't know what you're looking for and you want to do e.g. pattern recognition the effort to dump and process in another tool is probably worth it.nnAlso consider the possibility to connect Pandas directly to your Oracle database (which allows you to skip dumping data) see here for an example. n'",['pandas'],['pandas']
40127350,"'NetworkX: how to properly create a dictionary of edge lengths?' ""Say I have a regular grid network made of 10x10 nodes which I create like this:nnimport networkx as nxnfrom pylab import *nimport matplotlib.pyplot as pltn%pylab inlinennncols=10 nnN=10 #Nodes per sidenG=nx.grid_2d_graph(NN)nlabels = dict( ((ij) i + (N-1-j) * N ) for i j in G.nodes() )nnx.relabel_nodes(GlabelsFalse)ninds=labels.keys()nvals=labels.values()ninds=(N-j-1N-i-1) for ij in indsnposk=dict(zip(valsinds))nnx.draw_networkx(G pos=posk with_labels=True node_size = 150 node_color='blue'font_size=10)nplt.axis('off')nplt.title('Grid')nplt.show()nnnNow say I want to create a dictionary which stores for each edge its length. This is the intended outcome:nnd={(01): 3.4 (02): 1.7 ...}nnnAnd this is how I try to get to that point:nnfrom math import sqrtnnlengths={G.edges(): math.sqrt((x-a)**2 + (y-b)**2) for (xy)(ab) in G.edges()}nnnBut there clearly is something wrong as I get the following error message:nn---------------------------------------------------------------------------nTypeError                                 Traceback (most recent call last)n<ipython-input-7-c73c212f0d7f> in <module>()n      2 from math import sqrtn      3 n----> 4 lengths={G.edges(): math.sqrt((x-a)**2 + (y-b)**2) for (xy)(ab) in G.edges()}n      5 n      6 nn<ipython-input-7-c73c212f0d7f> in <dictcomp>(***failed resolving arguments***)n      2 from math import sqrtn      3 n----> 4 lengths={G.edges(): math.sqrt((x-a)**2 + (y-b)**2) for (xy)(ab) in G.edges()}n      5 n      6 nnTypeError: 'int' object is not iterablennnWhat am I missing?n"" 'There is a lot going wrong in the last line first and foremost that G.edges() is an iterator and not a valid dictionary key and secondly that G.edges() really just yields the edges not the positions of the nodes.nnThis is what you want instead: nnlengths = dict()nfor source target in G.edges():n    x1 y1 = posksourcen    x2 y2 = posktargetn    lengths(source target) = math.sqrt((x2-x1)**2 + (y2-y1)**2)nn'",['dictionary'],"['matplotlib', 'dictionary']"
40127436,'How to make test case fail if a django template has a rendering error that would silently fail in production' 'I'm aware that django test cases are done with DEBUG=False and TEMPLATE_DEBUG=False and that I can change it to True for a specific function using nnfrom django.test.utils import override_settingsnn@override_settings(DEBUG=True)ndef test_one_function(self):n    # This test should be failing and is not.n    # If I did not test manually I would'nt know !n    passnnnBut maybe there is a better more generic solution that apply for eveything at once ?nnI have an error in my template : I included another template and the link is broken. If I manually check with DEBUG=True I get a TemplateDoesNotExist error. But during my test case the url is rendered without the broken include it does not throw an error and the http_status is 200. I already tested the very generic included template somewhere else so I don't want to add test to see if what is inside was rendered correctly. But I want to see rendering fails that's what my test are for !nnI tried to set TEMPLATE_STRING_IF_INVALID to an Exception (found here) but it does not seem to be working for a broken include.nnIs there a way to make all rendering error raise en exception during tests without breaking the django's design principle of not running test in debug ?n' nan,['django'],['django']
40127675,"'Serve Static files from Google Cloud Storage Bucket (for Django App hosted on GCE)' ""I am trying to serve the static Files for my django App from Cloud Storage Bucket but don't know the exact process. Can someone please suggest a proper way to do so ? nnSteps I did:nnnUploaded all the static files on Google Cloud Storage Bucket(www.example.com) using gsutil command.nEdited /etc/apache2/sites-available/default-ssl.conf File.nnnFile Content:nn<VirtualHost *:443>n        ServerName example.comn        ServerAdmin admin@example.comnn #       Alias /static /opt/projects/example-google/example_staticn        Alias /static https://storage.googleapis.com/www.example.com/staticn        <Directory /opt/projects/example-google/example_static>n           Require all grantedn        </Directory>nn        <Directory /opt/projects/example-google/example/example>n            <Files wsgi.py>n                Require all grantedn            </Files>n        </Directory>nn        WSGIDaemonProcess example python-path=/opt/projects/example-google/example:/opt/projects/example-google/venv/lib/python2.7/site-packagesn        WSGIProcessGroup examplenWSGIApplicationGroup %{GLOBAL}n        WSGIScriptAlias / /opt/projects/example-google/example/example/wsgi.pynn        SSLEngine onn        SSLCertificateFile  /etc/apache2/ssl/example.com.crtn        SSLCertificateKeyFile /etc/apache2/ssl/example.com.keyn        SSLCertificateChainFile /etc/apache2/ssl/intermediate.crtn</VirtualHost>nnnSettings.py File:nn# Static files (CSS JavaScript Images)nSTATIC_URL = '/static/'n# STATIC_URL = 'https://storage.googleapis.com/www.example.com/static/'nSTATIC_ROOT = os.path.join(BASE_DIR '../example_static')nnMEDIA_URL = '/media/'nMEDIA_ROOT = os.path.join(BASE_DIR '../example_media')nSTATICFILES_DIRS = (os.path.join(BASE_DIR 'static') MEDIA_ROOT)nnnAny suggestion on what all additional changes are required for this task ?nnThanksn"" nan",['django'],['django']
40127698,"'How to get latest unique entries from sqlite db with the counter of entries via Django ORM' 'I have a SQLite db which looks like this:nn|ID|DateTime|Lang|Details|n|1 |16 Oct  | GB |  GB1  |n|2 |15 Oct  | GB |  GB2  |n|3 |17 Oct  | ES |  ES1  |n|4 |13 Oct  | ES |  ES2  |n|5 |15 Oct  | ES |  ES3  |n|6 |10 Oct  | CH |  CH1  |nnnI need a Django query to select this:nn|1 |16 Oct  | GB | GB1   | 2 |n|3 |17 Oct  | ES | ES1   | 3 |n|6 |10 Oct  | CH | CH1   | 1 |nnnSo this is unique (by Lang) latest (by DateTime) entries with the number of occurrences (by Lang). Is it possible to do this with a single SQL or Django-ORM query?n' 'You can use Django annotate() and value() together: link. nnn  when a values() clause is used to constrain the columns that are returned in the result set the method for evaluating annotations is slightly different. Instead of returning an annotated result for each result in the original QuerySet the original results are grouped according to the unique combinations of the fields specified in the values() clause. An annotation is then provided for each unique group; the annotation is computed over all members of the group.nnnYour ORM query should looks like this:nnqueryset = Model.objects.values(""Lang"").annotate(n    max_datetime=Max(""DateTime"")n    count=Count(""ID"")n).values(n    ""ID"" ""max_datetime"" ""Lang"" ""Details"" ""count""n)nn' 'As you want distinct entries by ""Lang"" and latest entries by ""DateTime"" below query will help younnqueryset = Model.objects.distinct(""Lang"").order_by(""-DateTime"")n'",['django'],['django']
40127739,"'Dictionary keys cannot be encoded as utf-8' ""I am using the twitter streaming api (tweepy) to capture several tweets. I do this in python2.7. nnAfter I have collected a corpus of tweets I break each tweet into words and add each word to a dictionary as keys where the values are the participation of each word in positive or negative sentences.nnWhen I retrieve the words as keys of the dictionary and try to process them for a next iteration I get nnn  UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 2: ordinal not in range(128)nnnerrorsnnThe weird thing is that before I place them as dictionary keys I encode them without errors. Here is a sample codennpos = {}nneg = {}nfor status in corpus:n    p = s.analyze(status).polarityn    words = n    # gather real wordsn    for w in status.split(' '):n        try:n            words.append(w.encode('utf-8'))n        except UnicodeDecodeError as e:n            print(e)n    # assign sentiment of the sentence to the wordsn    for w in words:n        if w not in pos:n            posw = 0n            negw = 0nn        if p >= 0:                    n            posw += 1n        else:n            negw += 1nnk = pos.keys()nk = i.encode('utf-8') for i in k  # <-- for this line a get an errornp = v for i v in pos.items()nn = v for i v in neg.items()nnnSo this piece of code will catch no errors during the splitting of the words but it will throw an error when trying to encode the keys again. I should note than normally I wouldn't try to encode the keys again as I would think they are already properly encoded. But I added this extra encoding to narrow down the source of the error. nnAm I missing something? Do you see anything wrong with my code?nnto avoid confusion here is a sample code more close to the original that is not trying to encode the keys againnnk = 'happy'nfor i in range(3):n    print('sampling twitter --> {}'.format(i))n    myStream.filter(track=k)  # <-- this is where I will receive the error in the second iterationn    for status in corpus:n        p = s.analyze(status).polarityn        words = n        # gather real wordsn        for w in status.split(' '):n            try:n                words.append(w.encode('utf-8'))n            except UnicodeDecodeError as e:n                print(e)n        # assign sentiment of the sentence to the wordsn        for w in words:n            if w not in pos:n                posw = 0n                negw = 0nn            if p >= 0:                    n                posw += 1n            else:n                negw += 1nn    k = pos.keys()nnn(please suggest a better title for the question)n"" 'Note that the error message says ""'ascii' codec can't decode ..."". That's because when you call encode on something that is already a bytestring in Python 2 it tries to decode it to Unicode first using the default codec.nnI'm not sure why you thought that encoding again would be a good idea. Don't do it; the strings are already byetestrings leave them as that.n' 'You get a decode error while you are trying to encode a string. This seems weird but it is due to implicit decode/encode mechanism of Python.nnPython allows to encode strings to obtain bytes and decode bytes to obtain strings. This means that Python can encode only strings and decode only bytes.nnSo when you try to encode bytes Python (which does not know how to encode bytes) tries to implicitely decode the byte to obtain a string to encode and it uses its default encoding to do that.nThis is why you get a decode error while trying to encode something: the implicit decoding.nnThat means that you are probably trying to encode something which is already encoded.n'",['python-2.7'],"['dictionary', 'python-2.7']"
40127746,"'merge two plot to one graph' 'I have two dataframe and I plot both of them.none is for female and the other for male.nnnnI want merge them in one graph with different colorn(since they have same feature)nnhere are codesnnfemalefeature.plot(kind='bar')nmalefeature.plot(kind = ""bar"")nnnfeature is the column name of data frame.nthe date frame is look likesnn          X1  X2  X3 ..... X46nmale     100  65  75 ..... 150nfemale   500  75  30 ..... 350nn' 'I think you can use DataFrame.plot.bar with transposing DataFrame by T:nnimport pandas as pdnimport matplotlib.pyplot as pltnndf = pd.DataFrame({n'X2': {'female': 75 'male': 65} n'X46': {'female': 350 'male': 150} n'X1': {'female': 500 'male': 100} n'X3': {'female': 30 'male': 75}})nprint (df)n         X1  X2  X3  X46nfemale  500  75  30  350nmale    100  65  75  150nndf.T.plot.bar()nplt.show()nnnn'","['pandas', 'matplotlib']","['pandas', 'matplotlib']"
40128061,"'Tkinter Class structure (class per frame) issue with duplicating widgets' ""Ive been trying out OOP for use with Tkinter - Im getting there (I think) slowly...nnI wanted to build a structure where each frame is handled by its own class including all of its widgets and functions. Perhaps I am coming from the wrong angle but that is what makes most logical sense to me. - Feel free to tell me if you agree / disagree!nnI know why the problem is happening - when im calling each class my __init__ runs everytime and builds the relevant widgets regardless of whether they are already present in the frame. However the only way I can think of getting round this would be to build each frame in the __init__ of my primary class GUI_Start. - Although this seems like a messy and un-organised soloution to the problem. nnIs there a way I can achieve a structure where each class takes care of its own functions and widgets but doesn't build the frame each time?nnSee below for minimal example of the issue:nnfrom Tkinter import *nnclass GUI_Start:nn    def __init__(self master):n        self.master = mastern        self.master.geometry('300x300')n        self.master.grid_rowconfigure(0 weight=1)n        self.master.grid_columnconfigure(0 weight=1)n        self.win_colour = '#D2B48C'n        self.frames = {}nn        for window in 'win1' 'win2':n            frame = Frame(self.master bg=self.win_colour bd=10 relief=GROOVE)n            frame.grid(row=0 column=0 sticky='news')n            setattr(self window frame)n            self.frameswindow = framenn        Page_1(self.frames)nn    def Next_Page(self frames controller):n        controller(frames)nnnclass Page_1(GUI_Start):nn    def __init__(self master):n        self.master = mastern        self.master'win1'.tkraise()nn        page1_label = Label(self.master'win1' text='PAGE 1')n        page1_label.pack(fill=X)nn        page1_button = Button(self.master'win1' text='Visit Page 2...' command=lambda: self.Next_Page(self.master Page_2))n        page1_button.pack(fill=X side=BOTTOM)nnnclass Page_2(GUI_Start):nn    def __init__(self master):n        self.master = mastern        self.master'win2'.tkraise()nn        page2_label = Label(self.master'win2' text='PAGE 2')n        page2_label.pack(fill=X)nn        page2_button = Button(self.master'win2' text='Back to Page 1...' command=lambda: self.Next_Page(self.master Page_1))n        page2_button.pack(fill=X side=BOTTOM)nnnroot = Tk()ngui = GUI_Start(root)nroot.mainloop()nnnFeel free to critique the structure as I may be trying to approach this from the wrong angle!nnAny feedback would be much appreciated!nLuken"" ""Your use of OOP is not very logical here. Your main program is in the class GUI_start. If your pages inherit from GUI_start basically you create a whole new program with every page instance you create. You should instead inherit from Frame as Bryan Oakley has pointed our in the comments. Here is a somewhat repaired version of what you have posted. The original one by Bryan is still much better.nnfrom Tkinter import *nnclass GUI_Start:nn    def __init__(self master):n        self.master = mastern        self.master.geometry('300x300')n        self.master.grid_rowconfigure(0 weight=1)n        self.master.grid_columnconfigure(0 weight=1)n        self.win_colour = '#D2B48C'n        self.current_page=0nn        self.pages = n        for i in range(5):n            page = Page(self.masteri+1)n            page.grid(row=0column=0sticky='nsew')n            self.pages.append(page)nn        for i in range(2):n            page = Page_diff(self.masteri+1)n            page.grid(row=0column=0sticky='nsew')n            self.pages.append(page)nn        self.pages0.tkraise()nn        def Next_Page():n            next_page_index = self.current_page+1n            if next_page_index >= len(self.pages):n                next_page_index = 0n            print(next_page_index)n            self.pagesnext_page_index.tkraise()n            self.current_page = next_page_indexnn        page1_button = Button(self.master text='Visit next Page'command = Next_Page)n        page1_button.grid(row=1column=0)nnnnclass Page(Frame):nn    def __init__(selfmasternumber):n        super().__init__(masterbg='#D2B48C')n        self.master = mastern        self.master.tkraise()nn        page1_label = Label(self text='PAGE '+str(number))n        page1_label.pack(fill=Xexpand=True)nnnnclass Page_diff(Frame):nn    def __init__(selfmasternumber):n        super().__init__(master)n        self.master = mastern        self.master.tkraise()nn        page1_label = Label(self text='I am different PAGE '+str(number))n        page1_label.pack(fill=X)nnnnroot = Tk()ngui = GUI_Start(root)nroot.mainloop()nn"" 'The point of using classes is to encapsulate a bunch of behavior as a single unit. An object shouldn't modify anything outside of itself. At least not by simply creating the object -- you can have methods that can have side effects.nnIn my opinion the proper way to create ""pages"" is to inherit from Frame. All of the widgets that belong to the ""page"" must have the object itself as its parent. For example:nnclass PageOne(tk.Frame):n    def __init__(self parent):n        # use the __init__ of the superclass to create the actual framen        tk.Frame.__init__(self parent)nn        # all other widgets use self (or some descendant of self)n        # as their parentnn        self.label = tk.Label(self ...)n        self.button = tk.Button(self ...)n        ...nnnOnce done you can treat instances of this class as if they were a single widget:nnroot = tk.Tk()npage1 = PageOne(root)npage1.pack(fill=""both"" expand=True)nnnYou can also create a base Page class and have your actual pages inherit from it if all of your pages have something in common (for example a header or footer)nnclass Page(tk.Frame):n    def __init__(self parent):n        tk.Frame.__init__(self parent)n        <code common to all pages goes here>nnclass PageOne(Page):n    def __init__(self parent):n        # initialize the parent classn        Page.__init__(self parent)nn        <code unique to page one goes here>nn'","['python-2.7', 'tkinter']",['tkinter']
40128388,"'Replace 0 with blank in dataframe Python pandas' ""I made the following code that takes out all of the zero's from my df. However when there is a number containing a zero it takes them out as well.nne.g.n3016.2     316.2n   0.235      .235nnndata_usage_df'Data Volume (MB)' = data_usage_df'Data Volume (MB)'.str.replace('0' '')nnnCould you help me to figure out how I do an exact match of the cell that equals 0 and replace it with a blank value.n"" 'I think you need add ^ for matching start of string and $ for end of string:nndata_usage_df'Data Volume (MB)'=data_usage_df'Data Volume (MB)'.str.replace('^0.0$' '')nnnSample:nndata_usage_df = pd.DataFrame({'Data Volume (MB)':3016.2 0.235 1.4001 0 4.00})nnprint (data_usage_df)nrunfile('C:/Dropbox/work-joy/so/_t/test.py' wdir='C:/Dropbox/work-joy/so/_t')n   Data Volume (MB)n0         3016.2000n1            0.2350n2            1.4001n3            0.0000n4            4.0000nndata_usage_df'Data Volume (MB)' = data_usage_df'Data Volume (MB)'.astype(str)ndata_usage_df'Data Volume (MB)'=data_usage_df'Data Volume (MB)'.str.replace('^0.0$' '')nnprint (data_usage_df)n  Data Volume (MB)n0           3016.2n1            0.235n2           1.4001n3                 n4              4.0nnnAnother solution is converting column to_numeric and where is 0 give empty space:nndata_usage_df'Data Volume (MB)' = data_usage_df'Data Volume (MB)'.astype(str)nndata_usage_df.ixpd.to_numeric(data_usage_df'Data Volume (MB)' errors='coerce') == 0 n                                                              'Data Volume (MB)' = ''nnprint (data_usage_df)n  Data Volume (MB)n0           3016.2n1            0.235n2           1.4001n3                 n4              4.0nn' ""data_usage_df = data_usage_df.astype(str)ndata_usage_df'Data Volume (MB)'.replace('0' '0.0' '' inplace=True)nn""",['pandas'],['pandas']
40128494,'Python- running tests: Cannot delete or update a parent row: a foreign key constraint fails' 'I am starting to learn Python and Django having never used them before. I'm following the tutorial at: https://docs.djangoproject.com/en/1.10/intro/tutorial05/ and have got as far as the 'Running Tests' section.nnWhen I try to run the test using the command:nnpython manage.py test pollsnnnthe tutorial says that I should get an error that says:nnn  AssertionError: True is not FalsennnHowever when I run this having followed what the tutorial says the error that I'm getting says:nnn  django.db.utils.IntegrityError: (1217 'Cannot delete or update a parent row: a foreign key constraint fails')nnnMy models.py file looks like this:nnfrom __future__ import unicode_literalsnimport datetimennfrom django.db import modelsnfrom django.utils import timezonenn# Create your models here.nclass Question(models.Model):n  question_text = models.CharField(max_length=200)n  pub_date = models.DateTimeField('date published')n  def __str__(self):n    return self.question_textn  def was_published_recently(self):n    return self.pub_date >= timezone.now() - datetime.timedelta(days=1)nnclass Choice(models.Model):n  question = models.ForeignKey(Question on_delete=models.CASCADE)n  choice_text = models.CharField(max_length=200)n  votes = models.IntegerField(default=0)n  def __str__(self):n    return self.choice_textnnnCan anyone explain why I'm getting a different error to the one the tutorial tells me to expect? What am I doing wrong here?n' nan,['django'],['django']
40128515,"'pairwise comparisons within a dataset' 'My data is 18 vectors each with upto 200 numbers but some with 5 or other numbers.. organised as:nn2 3 35 63 64 298 523 624 625 626 823 824n2 752 753 808 843n2 752 753 843n2 752 753 808 843n3 36 37 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 ...nnnI would like to find the pair that is the most similar in this group of lists. The numbers themselves are not important they may as well be strings - a 2 in one list and a 3 in another list are not comparable. nnI am looking if the variables are the same. for example the second list is exactly the same as the 4th list but only  1 variable different from list 3.nnAdditionally it would be nice to also find the most similar triplet or n that are the most similar but pairwise is the first and most important task.nnI hope i have layed out this problem clear enough but i am very happy to supply any more information that anyone might need!nnI have a feeling it involves numpy or scipy norm/cosine calculations but i cant quite work out how to do it or if this is the best method.nnAny help would be greatly appreciated!n' 'You can use itertools to generate your pairwise comparisons. If you just want the items which are shared between two lists you can use a set intersection. Using your example:nnimport itertoolsnna = 2 3 35 63 64 298 523 624 625 626 823 824nb = 2 752 753 808 843nc = 2 752 753 843nd = 2 752 753 808 843ne = 3 36 37 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112nndata = a b c d enndef number_same(a b):n    # Find the items which are the samen    return set(a).intersection(set(b))nnfor i in itertools.permutations(i for i in range(len(data) - 1) r=2):n    print ""Indexes: "" i len(number_same(datai0 datai1))nn>>>Indexes  (0 1) 1nIndexes  (0 2) 1nIndexes  (0 3) 1nIndexes  (1 0) 1nIndexes  (1 2) 4nIndexes  (1 3) 5  ... etc nnnThis will give the number of items which are shared between two lists you could maybe use this information to define which two lists are the best pair...n'","['python-2.7', 'numpy']",['list']
40128621,'finding the upper limit of integral using fsolve' 'FOUND IT CODE NOW WORKS!!nnI am writing code for a piecewise deterministic Markov process and to find the time for the next reaction in the subset of discrete reactions t(p-1)+dt I have to find the upper bound of the integral: . Im trying to do this using fsolve but I alsways get 0.0 as the return value thus also generating an integral of 0.0. How can I get a realistic value for t(p-1)+dt?nnimport scipy.integrate as integratenimport scipy.optimize as optimizenimport numpy as npnfrom numpy.random import uniformchoicennnclass Markov:n  def __init__(selfratesv_k=Nonev_stark=Nonestoich=None):n    self.S=stoichn    self.rates=ratesnn  #kind of propensity functionn  def p0(selfztparam):n    return self.ratesparamn  def p1(selfztparam):n    ij=paramn    return self.ratesi*np.prod(zj)n  def p2(selfztparam):n    ij=paramn    return (0.5*self.ratesi*zj*(zj-1))0nn  #generate propensity vectorn  def lambda_k(selfztR):n    prop=np.array()n    for ireac in enumerate(self.S.TR:):n      if all(z>=0 for z in reac):n        prop=np.append(propself.p0(z=zt=tparam=Ri))n      if any(z==-1 for z in reac):n        j=np.where(reac==-1)n        prop=np.append(propself.p1(z=zt=tparam=(Rij)))n      if any(z==-2 for z in reac):n        j=np.where(reac==-2)n        prop=np.append(propself.p2(z=zt=tparam=(Rij)))n    return propnn  #function to be integratedn  def integrand_D(selftzR_D):n    return self.lambda_k(z=zt=tR=R_D).sum()nn  #function to calculate integral from a to bn  def stop_cond(selfxtzu_pR_D):n    return u_p-integrate.quad(func=self.integrand_Da=tb=xargs=(zR_D))0nn  def fixed_PDMP(selft0tfz0R_D=None):n    t=t0n    p=1n    z=z0nn    while t<tf:n      q_p=uniform(low=0.0high=1.0)n      u_p=-np.log(q_p)nn      d=optimize.fsolve(func=self.stop_condx0=u_pargs=(tzu_pR_D)xtol=1e-90) n      print d0 n      print self.stop_cond(d0tzR_D) n      exit()nnstoich=np.array(-2 -1  2  0n                 1  0 -1 -1n                 0  0  0  1)nnnrates=np.array(1.00.02200.00.004)nnz0=np.array(540.0730.00.0)nnSSA=Markov(rates=ratesstoich=stoich)nSSA.fixed_PDMP(t0=0.0tf=100z0=z0R_D=0123)nn' nan,['numpy'],['numpy']
40128623,"'Index data from not related models in Django-Haystack Solr' 'I have a model to which multiple other models point through foreign keys like:nnclass MainModel(models.Model):n    name=models.CharField(max_length=40)nnclass PointingModel1(models.Model):n    color=models.CharField(max_length=40)n    main_model=models.ForeignKey(MainModel)nnclass PointingModel2(models.Model):n    othername=models.CharField(max_length=40)n    main_model=models.ForeignKey(MainModel)nnnSo I want to return the name of the MainModel by searching for color and othername fields in the PointingModels. Is there any way to do this?n' ""It's easy.nncolors = PointingModel1.objects.filter(color='blue')nfor color in colors:n    name = color.main_model.namen    # now you can put `name` to a list or something elsenn""",['django'],['django']
40128684,"'Pythonista user- initiated programs do not run' 'Hi I am using Pythonista 3:0 on the ipad. As a beginner I downloaded examples to try out. They worked for a while but now lwhen I try to run them there is no response.  All the sample  programs in the original Phthonista install work perfectly. nnThis for example does not work. Nothing happens when I press the triangle.nThanksnn# -*- coding: utf-8 -*-from mpl_toolkits.mplot3d import Axes3Dnimport matplotlib.pyplot as pltnimport numpy as npnfrom itertools import product combinationsnfig = plt.figure()nax = fig.gca(projection='3d')nax.set_aspect(""equal"")nn#draw cubenr = -1 1nfor s e in combinations(np.array(list(product(rrr))) 2): n    if np.sum(np.abs(s-e)) == r1-r0: n        ax.plot3D(*zip(se) color=""b"")nn# draw spherenu v = np.mgrid0:2*np.pi:20j 0:np.pi:10jnx=np.cos(u)*np.sin(v)ny=np.sin(u)*np.sin(v)nz=np.cos(v)nax.plot_wireframe(x y z color=""r"")nn#draw a pointnax.scatter(000color=""g""s=100)nn#draw a vectornfrom matplotlib.patches import FancyArrowPatchnfrom mpl_toolkits.mplot3d import proj3dnnclass Arrow3D(FancyArrowPatch):n    def __init__(self xs ys zs *args **kwargs):n        FancyArrowPatch.__init__(self (00) (00) *args **kwargs)n        self._verts3d = xs ys zsnn    def draw(self renderer):n        xs3d ys3d zs3d = self._verts3dn        xs ys zs = proj3d.proj_transform(xs3d ys3d zs3d renderer.M)n        self.set_positions((xs0ys0)(xs1ys1))n        FancyArrowPatch.draw(self renderer)nna = Arrow3D(010101 mutation_scale=20 lw=1 arrowstyle=""-|>"" color=""k"")nax.add_artist(a)nplt.show()nn' 'In my opinion matplotlib of Pythonista might be upgraded from 0.9x to 1.x. You should use different syntax as follows.nn# -*- coding: utf-8 -*-nimport matplotlib.pyplot as pltnfrom mpl_toolkits.mplot3d import Axes3Dnimport numpy as npnfrom itertools import product combinationsnnfig = plt.figure()nax = Axes3D(fig)   ## it's different now.nax.set_aspect(""equal"")nn'",['matplotlib'],['matplotlib']
40128783,"'Adding paths to arguments in popen' 'I want to execute a Linux command through Python. This works in the terminal:nn/usr/bin/myprogram --path ""/home/myuser""nnI've tried this:nnpath = ""/home/myuser""nargs = '/usr/bin/myprogram' '--path ' + pathnproc = subprocess.Popen(args)nnnAnd this:nnpath = ""/home/myuser""nargs = '/usr/bin/myprogram' '--path ""' + path + '""'nproc = subprocess.Popen(args)nnnBut myprogram does not accept the path formatting. I know that paths behave differently when not executing as shell but I can't get it working. I've also tried single quoting the path instead of double quoting it. Bonus points for a solution that also works on Windows (with a different program path obviously).nnEDIT: Sorry was writing this out from memory and used backslashes instead of forward slashes. The actual code did use the (correct) forward slashes.n' 'Here's something to try:nnimport subprocessnimport shlexnnp = subprocess.Popen(shlex.split(""/usr/bin/myprogram --path /home/myuser"")nnnMind the forward slashes (""/""). From what I read Python doesn't like backslashes ("""") even when running on Windows (I've never used it on Windows myself).n' 'The problem comes from your string literal 'usrbinmyprogram'. According to escaping rules b is replaced by x08 so your executable is not found.nnPun an r in front of your string literals (i.e. r'usrbinmyprogram') or use  to represent a backslash (i.e. 'usrbinmyprogram').n'",['python-2.7'],['python-2.7']
40128884,'Where to find the source code for pandas DataFrame __add__' 'I am trying to understand what (how) happens when two pandas.DataFrames are added/subtracted.nnimport pandas as pdndf1 = pd.DataFrame(12 34)ndf2 = pd.DataFrame(1112 1314)nndf1 + df2     # Which function is called?nnnMy understanding is __add__ function should be implemented in a class to overload + operator but in the source code for pandas.core.frame.DataFrame and all its parent classes no such function is found. nnWhere should I look for the function which is doing this job?n' 'I think you need check this:nndef add_special_arithmetic_methods(cls arith_method=Nonen                                   comp_method=None bool_method=Nonen                                   use_numexpr=True force=False select=Nonen                                   exclude=None have_divmod=False):n...n...nn',['pandas'],['pandas']
40128895,'Numpy conversion of column values in to row values' 'I take 3 values of a column (third) and put these values into a row on 3 new columns. And merge the new and old columns into a new matrix AnnInput timeseries in col nr3 values in col nr 1 and 2nnx x 1nx x 2nx x 3nnnoutput : matrix Annx x 1 0 0 0nx x 2 0 0 0nx x 3 1 2 3nx x 4 2 3 4nnnSo for brevity first the code generates the matrix 6 rows / 3 col. The last column I want to use to fill 3 extra columns and merge it into a new matrix A. This matrix A was prefilled with 2 rows to offset the starting position.nnI have implemented this idea in the code below and it takes a really long time to process large data sets. nHow to improve the speed of this conversion nnimport  numpy as npnnmatrix = np.arange(18).reshape((6 3))nnnr=3 nA = np.zeros((nr-1nr))nnfor x in range( matrix.shape0-nr+1):n    newrow =  (np.transpose( matrixx:x+nr2:3 ))n    A = np.vstack(A  newrow)nntotal= np.column_stack((matrixA))nprint (total)nn' 'Here's an approach using broadcasting to get those sliding windowed elements and then just some stacking to get A -nncol2 = matrix:2nnrows = col2.size-nr+1nout = np.zeros((nr-1+nrowsnr))ncol2_2D = np.take(col2np.arange(nrows):None + np.arange(nr))noutnr-1: = col2_2DnnnHere's an efficient alternative using NumPy strides to get col2_2D -nnn = col2.strides0ncol2_2D = np.lib.stride_tricks.as_strided(col2 shape=(nrowsnr) strides=(nn))nnnIt would be even better to initialize an output array of zeros of the size as total and then assign values into it with col2_2D and finally with input array matrix. nnRuntime testnnApproaches as functions -nndef org_app1(matrixnr):    n    A = np.zeros((nr-1nr))n    for x in range( matrix.shape0-nr+1):n        newrow =  (np.transpose( matrixx:x+nr2:3 ))n        A = np.vstack(A  newrow)n    return Anndef vect_app1(matrixnr):    n    col2 = matrix:2n    nrows = col2.size-nr+1n    out = np.zeros((nr-1+nrowsnr))n    col2_2D = np.take(col2np.arange(nrows):None + np.arange(nr))n    outnr-1: = col2_2Dn    return outnndef vect_app2(matrixnr):    n    col2 = matrix:2n    nrows = col2.size-nr+1n    out = np.zeros((nr-1+nrowsnr))n    n = col2.strides0n    col2_2D = np.lib.stride_tricks.as_strided(col2 n                        shape=(nrowsnr) strides=(nn))n    outnr-1: = col2_2Dn    return outnnnTimings and verification -nnIn 18: # Setup input array and paramsn    ...: matrix = np.arange(1800).reshape((60 30))n    ...: nr=3n    ...: nnIn 19: np.allclose(org_app1(matrixnr)vect_app1(matrixnr))nOut19: TruennIn 20: np.allclose(org_app1(matrixnr)vect_app2(matrixnr))nOut20: TruennIn 21: %timeit org_app1(matrixnr)n1000 loops best of 3: 646 Âµs per loopnnIn 22: %timeit vect_app1(matrixnr)n10000 loops best of 3: 20.6 Âµs per loopnnIn 23: %timeit vect_app2(matrixnr)n10000 loops best of 3: 21.5 Âµs per loopnnIn 28: # Setup input array and paramsn    ...: matrix = np.arange(7200).reshape((120 60))n    ...: nr=30n    ...: nnIn 29: %timeit org_app1(matrixnr)n1000 loops best of 3: 1.19 ms per loopnnIn 30: %timeit vect_app1(matrixnr)n10000 loops best of 3: 45 Âµs per loopnnIn 31: %timeit vect_app2(matrixnr)n10000 loops best of 3: 27.2 Âµs per loopnn',['numpy'],['numpy']
40129007,"'Too many requests on Grappelli admin edit form with autocomplete_lookup_fields build' 'I have Django Grappelli model admin form SampleInline with inline model form SampleAttributeInline.nnclass SampleInline(SuperInlineModelAdmin admin.StackedInline):n    model = Samplen    inlines = SampleAttributeInline   n    extra = 0 nnclass SampleAttributeInline(SuperInlineModelAdmin admin.TabularInline):n    model = SampleAttributen    #unificated_name and unificated_value are ForeignKey model fieldsn    raw_id_fields = ('unificated_name''unificated_value')nn    autocomplete_lookup_fields = {n        'fk': 'unificated_name' 'unificated_value'n    }nn    extra = 0nnnThis form usually has many inline instances so during form building I see multiple equal requests that look like this:nn19/Oct/2016 13:10:12 ""GET /grappelli/lookup/related/?object_id=&app_label=articles&model_name=unificatedsamplesattributename HTTP/1.1"" 200 30n19/Oct/2016 13:10:12 ""GET /grappelli/lookup/related/?object_id=&app_label=articles&model_name=unificatedsamplesattributevalue HTTP/1.1"" 200 30n19/Oct/2016 13:10:12 ""GET /grappelli/lookup/related/?object_id=&app_label=articles&model_name=unificatedsamplesattributename HTTP/1.1"" 200 30n19/Oct/2016 13:10:12 ""GET /grappelli/lookup/related/?object_id=&app_label=articles&model_name=unificatedsamplesattributevalue HTTP/1.1"" 200 30nnnwhile there obviously should be only two. nnHow to make only two requests and apply response to all corresponding inline form elements? nnI use super-inlines hence SuperInlineModelAdmin but it should not affect my problem since it is only to make this whole thing nestable under other inlines.n' nan",['django'],['django']
40129410,"'Pandas Create Column with Groupby and Sum with additional condition' ""I'm trying to add a new column in pandas DataFrame after grouping and with additional conditions  nndf = pd.DataFrame({ n    'A'  :45782352114424513979 n    'B'  :95783352114424513579 n    'C' :95783352114424513579 n    'D' :10101100110001110010 n})ndf1 = df.groupby('A' 'B' as_index=False).transform('sum')ndf1 = df.join(df.groupby('A')'C'.sum() on='A' rsuffix='_inward')nndf1nnnIn above query it is able to sum and give output but how do I add condition for df'D' == 1nnExpected output nn    A  B  C  D  C_inwardn0   4  9  9  1        13n2   7  7  7  1        14n4   2  3  3  1         3n5   3  3  3  1         3n8   1  1  1  1         3n9   1  1  1  1         3n13  4  4  4  1        13n14  5  5  5  1        5n15  1  1  1  1         3n18  7  7  7  1        14nn"" 'You can add boolean indexing:nnmask = df'D' == 1ndf1 = dfmask.join(dfmask.groupby('A')'C'.sum() on='A' rsuffix='_inward')nnprint (df1)n    A  B  C  D  C_inwardn0   4  9  9  1        13n2   7  7  7  1        14n4   2  3  3  1         3n5   3  3  3  1         3n8   1  1  1  1         3n9   1  1  1  1         3n13  4  4  4  1        13n14  5  5  5  1         5n15  1  1  1  1         3n18  7  7  7  1        14nn'",['pandas'],['pandas']
40129428,"'How to check the percentile of each row based on a column in pandas?' ""I have a dataset with a id column for each event and a value column (among other columns) in a dataframe. What I want to do is categorize each id based on whether it is on the 90th percentile 50th percentile 25th percentile etc. of the frequency distribution of the value colum.nnExamplennid      valuen1       12.5n2       4.6n....nnnSo I'd add another column category to it depending upon the what percentile of the value column it falls in. How do I do that?n"" ""You're looking for the quantile method. For instance assigning to 0.0 0.25 0.5 0.75 quantiles could be done this way:nndf'quantile' = 0.0nnfor q in 0.25 0.5 0.75:n    df.locdf'value' >= df'value'.quantile(q) 'quantile' = qnn""",['pandas'],['pandas']
40129447,"'Using alphabet as counter in a loop' ""I am looking for the most efficient way to count the number of letters in a list. I need something likennword=h e l l onnfor i in alphabet:n   for j in word:n      if j==i:n         ## do somethingnnnWhere alphabet should be the spanish alphabet that is the english alphabet including the special character 'Ã±'.nnI have thought about creating a list of pairs in the form of a 0 b1 ... but I suppose there is a more efficient/clean way.n"" 'This is pretty easy:nnimport collectionsnprint collections.Counter(""seÃ±or"")nnnThis prints:nnCounter({'s': 1 'r': 1 'e': 1 'xa4': 1 'o': 1})nn' 'It is not actually a dupe as you want to filter to only count characters from a certain set you can use a Counter dict to do the counting  and a set of allowed characters to filter by:nnword = ""h"" ""e"" ""l"" ""l"" ""o""nnfrom collections import Counternfrom string import ascii_lowercasenn# create a set of the characters you want to count.nallowed = set(ascii_lowercase + 'Ã±')nn# use a Counter dict to get the counts only counting chars that are in the allowed set.ncounts = Counter(s for s in word if s in allowed)nnnIf you actually just want the total sum:nntotal = sum(s in allowed for s in word)nnnOr using a functional approach:nntotal = sum(1 for _ in filter(allowed.__contains__ word))nnnUsing  filter is going to be a bit faster for any approach:nnIn 31: from collections import Countern    ...: from string import ascii_lowercase digitsn    ...: from random import choicen    ...: nnIn 32: chars = choice(digits+ascii_lowercase+'Ã±') for _ in range(100000)nnIn 33: timeit Counter(s for s in chars if s in allowed)nn100 loops best of 3: 36.8 ms per loopnnnIn 34: timeit Counter(filter(allowed.__contains__ chars))n10 loops best of 3: 31.7 ms per loopnnIn 35: timeit sum(s in allowed for s in chars)n10 loops best of 3: 35.4 ms per loopnnIn 36: timeit sum(1 for _ in filter(allowed.__contains__ chars))nn100 loops best of 3: 32 ms per loopnnnIf you want a case insensitive match use ascii_letters and add 'Ã±Ãx91':nnfrom string import ascii_lettersnnallowed = set(ascii_letters+ 'Ã±Ãx91')nn'",['list'],"['list', 'python-2.7']"
40130122,'python pandas dataframe merge or join dataframe' 'I want to help yoursnnif i have a pandas dataframe mergennfirst dataframe isnnD = { Year Age Location column1 column2... }n      2013 20  america ... ...n      2013 35 usa ... ...n      2011 32 asia ... ...n      2008 45 japan ... ...nnnshape is 38654rows x 14 columnsnnsecond dataframe is nnD = { Year Location column1 column2... }n      2008 usa ... ...n      2008 usa ... ...n      2009 asia ... ...n      2009 asia ... ...n      2010 japna ... ...nnnshape is 96rows x 7 columnsnnI want to merge or join two different dataframe.nHow can I do it?nnthanksn' 'IIUC you need merge with parameter how='left' if need left join on column Year and Location:nnprint (df1)n   Year  Age Location  column1  column2n0  2013   20  america        7        5n1  2008   35      usa        8        1n2  2011   32     asia        9        3n3  2008   45    japan        7        1nnprint (df2)n   Year Location  column1  column2n0  2008      usa        8        9n1  2008      usa        7        2n2  2009     asia        8        2n3  2009     asia        0        1n4  2010    japna        9        3nndf = pd.merge(df1df2 on='Year''Location' how='left')nprint (df)n   Year  Age Location  column1_x  column2_x  column1_y  column2_yn0  2013   20  america          7          5        NaN        NaNn1  2008   35      usa          8          1        8.0        9.0n2  2008   35      usa          8          1        7.0        2.0n3  2011   32     asia          9          3        NaN        NaNn4  2008   45    japan          7          1        NaN        NaNnnnYou can also check documentation.n',['pandas'],['pandas']
40130126,'Labels show up interactively on click in python matplotlib' 'I am plotting the following numpy array (plotDataFirst) which has 40 x 160 dimensions (and contains double values).nnI would like to be able to hover over a plot (one of the 40 that are drawn) and see the label of that particular plot. nnI have an array (1x40) that contains all of the labels. Is there any way to do this? I am not sure how to add this type of interactive labels. nnplt.interactive(False)nplt.plot(plotDataFirst)nplt.show()nn' 'I'm not sure exactly how you want to show the label (tooltip legend title label ...) but something like this might be a first step:nnimport numpy as npnimport matplotlib.pylab as plnnpl.close('all')nndef line_hover(event):n    ax = pl.gca()n    for line in ax.get_lines():n        if line.contains(event)0:n            print(line.get_label())nnlabels = 'line 1''line 2''line 3'nnfig = pl.figure()nfor i in range(len(labels)):n    pl.plot(np.arange(10) np.random.random(10) label=labelsi)npl.legend(frameon=False)nnfig.canvas.mpl_connect('motion_notify_event' line_hover)           npl.show()nnnSo basically for every mouse motion (motion_notify_event) check if the cursor is over one of the lines and if so (as a quick hack / solution for now) print the label of that line to the command line.nnUsing a tooltip might be a nicer approach but that seems to require backend-specific solutions (see e.g. http://stackoverflow.com/a/4620352/3581217) n',"['numpy', 'matplotlib']","['matplotlib', 'numpy']"
40130128,"'Python matplotlib.pyplot: How to make a histogram with bins counts including right bin edge?' ""could you please help me how to modify the code so to get a histogram with bins counts including right bin edge i.e.  binsi-1 < x <= binsi (and no the Left as by default) ? nnimport matplotlib.pyplot as pltnimport numpy as npndata = 01234nbinwidth = 1nplt.hist(data bins=np.arange(min(data) max(data) + binwidth binwidth))nplt.xlabel('Time')nplt.ylabel('Counts')nplt.show()nnnThank you in advance.n"" 'I do not think there is an option to do it explicitly in either matplotlib or numpy.nnHowever you may use np.histogram() with negative value of your data (and bins) then negate the output and plot it with plt.bar() function.nnbins = np.arange(min(data) max(data) + binwidth binwidth)nhist binsHist = np.histogram(-data bins=sorted(-bins))nplt.plot(-binsHist1: -hist np.diff(binHist))nn'",['matplotlib'],['matplotlib']
40130205,"'Django: Complex Permission Model' ""Suppose I have users projects memberships and in every membership a role is specified (for example: admin read-only user etc.). The memberships define the relation between users and projects and the corresponding role.nnNow I have a problem: how can I use the permission system of Django to assure that only admins can edit projects and the other roles are not allowed to edit projects?nnThe project list template should look like this:nn{% for project in object_list %}n    {# user.has_perm('edit_project' project) #}n{% endfor %}nnnWhat is the best way of doing this? How can I implement the permission based on the membership role?n"" 'You need to build your own permission system. nnDjango's built-in permission system is not suited for what you want to do.nnBuild models for the Project. Create a ManyToMany relationship between a User and a Project through a Membership model. This Membership model will have a role field.nnhttps://docs.djangoproject.com/en/1.10/topics/db/models/#extra-fields-on-many-to-many-relationships has an example that is almost ideally suited for your needs.nnYou can not do user.has_perm('edit_project' project) in a template. Django templates do not allow function calls directly with multiple params. I think in your case a custom template tag that takes a User instance a Project instance and a string describing the desired permission would be the way to go.n'",['django'],['django']
40130413,"'Python How can i use buffer' 'I have to solve this question :nnWe have a text file like this :nn""imei"": ""123456789""n""sim_no"": ""+90 xxx xxx xx xx""n""device_type"": ""standart""n""hw_version"": ""1.01""n""sw_version"": ""1.02""nnnAnd we should read this JSON data then we should read this data each 1 min and put to buffer(idk how can i put is buffer array or dict?) then we should delete the oldest file each 5 min. Exceptions are important. Format sould be like ""imei"" ""hw_version"" ""sw_version"" ""device_type"". We sould solve buffer overflowing.nnI write this code :nnimport jsonnfrom time import sleepnndef buffer(data):n    passn    #imei = data.get(""imei"") # I want to read like thisn    # this function should put the variables to arrayncounter=0nwhile True:n    with open(""config.txt"") as f:n        mydict = json.loads('{{ {} }}'.format(f.read()))    n    buffer(mydict)n    sleep(60)n    counter+=1n    if counter%5==0n        # delete the oldest datannnHow can i use buffer? And how can i continue this code?n' 'What you want are the last 5 values so you should just append the new one to a list and if it is bigger than 5 delete the first one.nnmy_list.append(my_dict)nif len(my_list) > 5:n    my_list.pop(0)nnnSo after that you just sleep for 60 seconds and nothing elsen'",['python-3.x'],"['python-2.7', 'list']"
40130443,"'Creating nested dict from dict with nested tuples as keys using comprehension' ""I got a very useful answer for this problem here earlier this year but there I could use pandas. Now I have to do it with pure Python.nnThere is a dict like this:nninp = {((0 0) 0): -99.94360791266038n       ((0 0) 1): -1.1111111111107184n       ((1 0) 0): -1.111111111107987n       ((1 0) 1): -1.1111111111079839n       ((1 0) 3): -1.111111111108079}nnnNow I want to convert this in a nested dict like this:nnout = {(00): {0: -99.94360791266038 1: -1.1111111111107184}n       (10): {0: -1.111111111107987n               1: -1.1111111111079839n               3: -1.111111111108079}nnnHow can I do this with an elegant diction comprehension? I just can't get my head around it.n"" 'I'd not do this with a dict comprenhesion. Just use a simple loop:nnout = {}nfor key value in inp.items():n    k1 k2 = keyn    out.setdefault(k1 {})k2 = valuennnDemo:nn>>> inp = {((0 0) 0): -99.94360791266038n...        ((0 0) 1): -1.1111111111107184n...        ((1 0) 0): -1.111111111107987n...        ((1 0) 1): -1.1111111111079839n...        ((1 0) 3): -1.111111111108079}n>>> out = {}n>>> for key value in inp.items():n...     k1 k2 = keyn...     out.setdefault(k1 {})k2 = valuen...n>>> from pprint import pprintn>>> pprint(out)n{(0 0): {0: -99.94360791266038 1: -1.1111111111107184}n (1 0): {0: -1.111111111107987n          1: -1.1111111111079839n          3: -1.111111111108079}}nnnTo do the same with a dict comprehension is possible but you need to then sort the keys and use itertools.groupby() to group the keys on on the first tuple element. The sorting takes O(NlogN) time and a simple loop like the above beats that easily.nnStill for completeness sake:nnfrom itertools import groupbynout = {g: {k1: v for k v in items} n       for g items in groupby(sorted(inp.items()) key=lambda kv: kv00)}nn' 'Naive solution:nnmy_dict = {n            ((0 0) 0): -99.94360791266038n            ((0 0) 1): -1.1111111111107184n            ((1 0) 0): -1.111111111107987n            ((1 0) 1): -1.1111111111079839n            ((1 0) 3): -1.111111111108079n        }nndef get_formatted_dict(my_dict):n    formatted_dict = {}n    for k v in my_dict.items():n        index_1 index_2 = kn        if index_1 not in formatted_dict:n            formatted_dictindex_1 = {}n        formatted_dictindex_1index_2 = vn    return formatted_dictnnprint(get_formatted_dict(my_dict))nnnOutput:nn{(1 0): {0: -1.111111111107987 1: -1.1111111111079839 3: -1.111111111108079} (0 0): {0: -99.94360791266038 1: -1.1111111111107184}}nn'",['dictionary'],['dictionary']
40130491,"'Python large array comparison' ""I have a large array containing URL (it can contains 100 000 URL strings) and I would like to know if my actual URL is one of the URL from the array. For that I have to compare the actual URL string with all the URL string in the array. Is there any way to compare with this large array but with less time than I do now ? For now it's :nnerror = 0nfor oldUrl in urlList:n    error = 1 if oldUrl == actualUrl else errornn"" 'To check if a list contains an item use: item in list.nnSo you can write:nnerror = oldUrl in urlListnn' 'Don't use a list for this. Lookups in lists have a worst case complexity of O(n).nnUse a set (or dictionary if you have other metadata) instead. This has a lookup of roughly O(1). See here for comparisons between a set dictionary and list.nnUsing a set the lookup is simple:nnurls = set('url1' 'url2' 'url3')nnprint ('url2' in urls)nprint ('foobar' in urls)nnnOr in your case convert your list object as a set:nnurlListSet = set(urlList)nprint(oldUrl in urlListSet)nnnYou can also add new urls to your set:nnurlListSet.add(newurl)nurlListSet.update(listOfNewUrls)nn' 'As already mentioned by @Laurent and @sisanared you can use the in operator for either lists or sets to check for membership. For example:nnfound = x in some_listnif found: n    #do stuffnelse:n    #other stuffnnnHowever you mentioned that speed is an issue. TL;DR -- sets are faster if the set already exists. From https://wiki.python.org/moin/TimeComplexity checking membership using the in operator is O(n) for list and O(1) for set (like @enderland pointed out). nnFor 100000 items or for one-time-only checks it probably doesn't make much of a difference which you use but for a larger number of items or situations where you'll be doing many checks you should probably use a set. I did a couple of tests from the interpreter and this is what I found (Python 2.7 i3 Windows 10 64bit): nnimport timeitn#Case 1: Timing includes building the list/setndef build_and_check_a_list(n):n    a_list =  '/'.join( ('http:stackoverflow.com'str(i)) ) for i in xrange(1n+1) n    check = '/'.join( ('http:stackoverflow.com'str(n)) )n    found = check in a_listn    return (a_list found)nndef build_and_check_a_set(n):n    a_set = set(  '/'.join( ('http:stackoverflow.com'str(i)) ) for i in xrange(1n+1)  )n    check = '/'.join( ('http:stackoverflow.com'str(n)) )n    found = check in a_setn    return (a_set found)nntimeit.timeit('a_list found = build_and_check_a_list(100000)' 'from __main__ import build_and_check_a_list' number=50)n3.211972302022332nntimeit.timeit('a_set found = build_and_check_a_set(100000)' 'from __main__ import build_and_check_a_set' number=50)n4.5497120006930345nn#Case 2: The list/set already exists (timing excludes list/set creation)ncheck = '/'.join( ('http:stackoverflow.com'str(100000)) )nntimeit.timeit('found = check in a_list' 'from __main__ import a_list check' number=50)n0.12173540635194513nntimeit.timeit('found = check in a_set' 'from __main__ import a_set check' number=50)n1.01052391983103e-05nnnFor 1 million entries to build and/or check membership on my computer:nn#Case 1: list/set creation includedntimeit.timeit('a_list found = build_and_check_a_list(1000000)' 'from __main__ import build_and_check_a_list' number=50)n35.71641090788398nntimeit.timeit('a_set found = build_and_check_a_set(1000000)' 'from __main__ import build_and_check_a_set' number=50)n51.41244436103625nn#Case 2: list/set already existsncheck = '/'.join( ('http:stackoverflow.com'str(1000000)) )nntimeit.timeit('found = check in a_list' 'from __main__ import a_list check' number=50)n1.3113457772124093nntimeit.timeit('found = check in a_set' 'from __main__ import a_set check' number=50)n8.180430086213164e-06nn'",['python-2.7'],"['list', 'python-2.7']"
40130652,"'Build API with ASP.NET Web API on Django project' ""We are currently building our event management platform at a company i work for The authentication service is being built with ASP.NET identity framework.nnThe main event management platform is built in Django using python which i have built.nnWe are also planning on building a custom admin portal in ASP.NET MVCnwhich will manage users and event data.nnThe problem is that the C# guys(Who are contractors albeit very experienced developers) want to build out the API using ASP.NET for the event app which is built in django using the Database first model that .NET provides thus the database migrations will be handled by Django but the actual API will be built using ASP.NETS Web API directly from the database.nnThis approach does not seem to make much sense in my opinion as it would  make a lot more sense to build out the the API using Django rest framework and manage the database migrations for the event app. Instead of tightly coupling the database with Web API.nnEither way both approaches are are effectively doing the same thing but i don't think it's efficient to constantly manage two environments migrations in one environment and api management in the other this does not allow for flexibility.nnWhat are the potential disadvantages of the WEB API approach.n"" nan",['django'],['django']
40130788,"'flask email error: Errno 101 Network is unreachable' 'facing issue with flsk mail  flask-mail nnam unable to send mails using the below script nn    import smtplibn    from flask import Flaskn    from flask_mail import Mail  Messagenn    app =Flask(__name__)nnn    app.config.update(n        DEBUG=Truen        #EMAIL SETTINGSn        MAIL_SERVER='smtp.gmail.com'n        MAIL_PORT=465n        MAIL_USE_SSL=Truen        MAIL_USERNAME = 'myemail@gmail.com'n        MAIL_PASSWORD = 'mypassword'n        )nn    mail=Mail(app)nn    @app.route(""/"")n    def index():n        msg = Message(n                  'Hello'n               sender='myemail@gmail.com'n               recipients=n                   'to@gmail.com')n        msg.body = ""This is the email body""n        mail.send(msg)n        return ""Sent""nn    if __name__ == ""__main__"":n        app.run(port=15419threaded=True)nnnam i doing any thing wrong?nnis this any network issue or my code problem.n' nan","['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40130958,"'python 2 Error 32 The process cannot access the file because it is being used by another process' 'I'm working with python 2 and have read several posts about this error i.e(this post). nHowever I'm still getting the error.nWhat I do is:nI read the files in a directory if any of the files contains a specific string I delete the directory. nndef select_poo():npath = os.walk('/paila_candonga/')ntexto = 'poo'nextension = '.tex'nfor root dirs files in path:n    for documento in files:n        if extension in documento:n            with open(os.path.join(root documento) 'r') as fin:n                for lines in fin:n                    if texto in lines:n                        shutil.rmtree(root)n                    else:n                        continuennnThen I get the error:nnWindowsError: Error 32 The process cannot access the file because it is being used by another processnnnI have also tried using the absolute path:  nndef select_poo():npath = os.walk('/paila_candonga/')ntexto = 'poo'nextension = '.tex'nfor root dirs files in path:n    for documento in files:n        if extension in documento:n            with open(os.path.join(root documento) 'r') as fin:n                for lines in fin:n                    if texto in lines:n                        route = (os.path.join(root documento))n                        files = os.path.basename(route)n                        folder = os.path.dirname(route)n                        absolut= os.path.dirname(os.path.abspath(route))n                        todo = os.path.join(absolut files)n                        print todonn                    else:n                        continuennnThen I will get: nnC:paila_candongala_Arepa.texnC:paila_candongasejodiolaOlla.texnC:paila_candongasejodiolaPaila.texnnnIf I remove one file at a time using the same absolute path and os.remove('') I won't have problems. If I try to delete all files at once using select_poo() and shutil.rmtree(folder) or os.remove(absolut) I will have the Error 32. nnIs there a way I can do a loop through each of the paths in todo and remove them without having the error 32?nnThanksn' ""it happens here :nnwith open(os.path.join(root documento) 'r') as fin:nnnSo you have your file open and locked that is why you are not able delete this folder using:nnshutil.rmtree(root)nnnwithin this statement you have to do outside of with statementn""",['python-2.7'],['python-2.7']
40131264,"""'ascii' codec can't decode byte 0xff in position 11: ordinal not in range(128)"" 'I am using django-imagekit to create thumbnails of my image field.nnclass CustomUser(AbstractBaseUser PermissionsMixin):n    email = models.EmailField(_('email address') max_length=254 unique=True)n    image = ProcessedImageField(upload_to= generate_random_filenamen                                processors=ResizeToFill(640 640)n                                format='JPEG'n                                options={'quality': 60})n    avatar = ImageSpecField(source='image'n                            processors=ResizeToFill(96 96)n                            format='JPEG'n                            options={'quality': 60})nnnNow I created a serializer for the above model using django-rest-framework:nnclass UserRegistrationSerializer(serializers.ModelSerializer):n    class Meta:n        model = Usern        fields = tuple(User.REQUIRED_FIELDS) + (n            User.USERNAME_FIELDn            User._meta.pk.namen            'image'n            'avatar'n        )nnnI have created a generics.CreateAPIView to save a new user but it gives error:nnUnicodeDecodeError at /register/n'ascii' codec can't decode byte 0xff in position 11: ordinal not in range(128)nnUnicode error hintnnThe string that could not be encoded/decoded was: ""ï¿½ï¿½ï¿½ï¿½unnnI don't understand this. Please help. It works fine if I remove avatar from the serializer.n' nan",['django'],['django']
40131281,"'Comparing pandas dataframes of different length' ""I have two dataframes of different lengths both indexed by date. I need both dataframes to have the same dates ie. delete the extra entries in the longest dataframe. nnI have found that I can reset index and make it another another column then call that column as a pandas dataseries and compare to the other data series giving me a pandas series with only the entries that are also in the shorter dataframe: nndf1 = ...ndf2 = ...ndfadj = df1.reset_index('Date')ndfstock = dfadj'Date'dfadj'Date'.isin(dfindex'Date')nnnBut then I would need to find the index positions from these values and in another step delete it from the longest dataframe. Am I missing a completely different approch which would be more logical and/or simple?n"" 'You can use Index.intersection and then select data in df2 by ix:nnidx = df2.index.intersection(df1.index)nprint (idx)nDatetimeIndex('2015-02-24' '2015-02-25' '2015-02-26' '2015-02-27'n               '2015-02-28' '2015-03-01' '2015-03-02' '2015-03-03'n               '2015-03-04' '2015-03-05'n              dtype='datetime64ns' freq='D')nnprint (df2.ixidx)n             bn2015-02-24  10n2015-02-25  11n2015-02-26  12n2015-02-27  13n2015-02-28  14n2015-03-01  15n2015-03-02  16n2015-03-03  17n2015-03-04  18n2015-03-05  19nnnAnother solution is use merge with inner join what is by deafult so can be omited how='inner':nndf = pd.merge(df1df2 left_index=True right_index=True)nnnSample:nnrng1 = pd.date_range(pd.to_datetime('2015-02-24') periods=10)ndf1 = pd.DataFrame({'a': range(10)} index=rng1)   nprint (df1)n            an2015-02-24  0n2015-02-25  1n2015-02-26  2n2015-02-27  3n2015-02-28  4n2015-03-01  5n2015-03-02  6n2015-03-03  7n2015-03-04  8n2015-03-05  9nnrng2 = pd.date_range(pd.to_datetime('2015-02-24') periods=20)ndf2 = pd.DataFrame({'b': range(1030)} index=rng2)  nprint (df2)n            bn2015-02-24  10n2015-02-25  11n2015-02-26  12n2015-02-27  13n2015-02-28  14n2015-03-01  15n2015-03-02  16n2015-03-03  17n2015-03-04  18n2015-03-05  19n2015-03-06  20n2015-03-07  21n2015-03-08  22n2015-03-09  23n2015-03-10  24n2015-03-11  25n2015-03-12  26n2015-03-13  27n2015-03-14  28n2015-03-15  29nnnnndf = pd.merge(df1df2 left_index=True right_index=True)nprint (df)n            a   bn2015-02-24  0  10n2015-02-25  1  11n2015-02-26  2  12n2015-02-27  3  13n2015-02-28  4  14n2015-03-01  5  15n2015-03-02  6  16n2015-03-03  7  17n2015-03-04  8  18n2015-03-05  9  19nnnLast if need delete some columns use drop:nnprint (df.drop('a' axis=1))n             bn2015-02-24  10n2015-02-25  11n2015-02-26  12n2015-02-27  13n2015-02-28  14n2015-03-01  15n2015-03-02  16n2015-03-03  17n2015-03-04  18n2015-03-05  19nn'",['pandas'],['pandas']
40131360,"'Why df2342:4 works and df2:42:4 does not in Python' ""suppose we have a dataramennimport pandas as pdndf = pd.read_csv('...')ndfn  0 1 2 3 4n0 1 2 3 4 5n1 1 2 3 4 5n2 1 2 3 4 5n3 1 2 3 4 5n4 1 2 3 4 5nnnWhy one approach is working and other returns syntax error?n"" 'I think you need ix:nnprint (df.ix2:42:4)n   2  3n2  3  4n3  3  4n4  3  4nn' 'It fails because 2:4 is invalid syntax for accessing the keys/columns of a df:nnIn 73:ndf2:4n  File ""<ipython-input-73-f0f09617b349>"" line 1n    df2:4n         ^nSyntaxError: invalid syntaxnnnThis is no different to if you defined a dict and tried the same syntax:nnIn 74:nd = {0:01:12:23:34:45:5}ndnnOut74:n{0: 0 1: 1 2: 2 3: 3 4: 4 5: 5}nnIn 76:nd2:4nn  File ""<ipython-input-76-ea5d68adc389>"" line 1n    d2:4n        ^nSyntaxError: invalid syntaxnnnThe  syntax is used to access column labels that match you can't pass a slice in a list to access a range of columns like this it needs to be a list of values as you've already foundnnThe newer methods such as iloc ix and loc support slice rangesnnWhat worked for you initially selected the columns using the labels in a list:nnIn 77:ndf234nnOut77:n   2  3  4n0  3  4  5n1  3  4  5n2  3  4  5n3  3  4  5n4  3  4  5nnnAnd then selected the rows via a slice:nnIn 79:ndf2342:4nnOut79:n   2  3  4n2  3  4  5n3  3  4  5nn'",['pandas'],['pandas']
40131479,"'Making a for loop print with an index' 'I made a program which displays a user-provided number of the fibonacci series. I wanted to format it into an indexed list but I don't what could I use to do so. I found the enumerate() function but seems it only works for premade lists whereas mine is generated accordingly to the user. nnDo I use a for loop to generate a variable along with the series then put the variable in the for loop that prints the numbers like so: nnprint(""{0}. {1}"".format(index_variable wee(n)))nnnor am I going an entirely wrong road here?n' 'def fib(n):n    x = 0n    y = 1n    for i in range(n):n        yield yn        tmp = xn        x = yn        y += tmpnndef main():n     n = input('How many do you want: ')n     for i f in enumerate(fib(n)):n         print(""{0}. {1}"".format(i f)nnnMake  a generator that yields the values you want and then pass that to enumerate n'",['python-3.x'],"['list', 'python-2.7']"
40131556,"'How to get a well-scaled table in python using matplotlib' 'I have been trying to present a table of data in python. I've been generating the table using the matplotlib pyplot module. Unfortunately the data sets I want to present are quite large. Hence when the table displays I either get it showing the entire table but the data is too tiny to read or it shows the data at readable size but cuts off the rest of the table.nnMy first thought was perhaps if I got the table formatted in a readable way I could then use standard pan/zoom button in the interactive navigation. However clicking and dragging around the screen doesn't seem to shift the table at all. I have tried this on pycharm and anaconda just in case it made a difference for some reason.nnThus I am wondering once I  format the table in a readable way how can I pan around the table? Otherwise are there any other ways to present large amounts of data in tables using python?nnAlso please note that I want the table to be shown when the code is executed not saved as an image.nnSome test code I have been working with trying to solve this issue:nnimport numpy as npnimport matplotlib.pyplot as pltnndata=np.random.rand(100 1)ncols=(""column"")nnrows ncols = len(data)+1 len(cols)nhcell = 0.2nwcell = 1.0nhpad wpad = 0 0nfig=plt.figure(figsize=(ncols*wcell+wpad nrows*hcell+hpad))nax =fig.add_subplot(111)nax.axis('off')ncellText=datantable=ax.table(cellText=cellText colLabels=cols loc='cent')nplt.tight_layout()nplt.show()nn' 'Try with Tabulate module which is very simple to use and support numpy:nntabulate modulennsample code to start with:nnimport numpy as npnimport matplotlib.pyplot as pltnnfrom tabulate import tabulatendata=np.random.rand(100 1)nnprint tabulate(data)nnnUsing matplotlib:nnimport numpy as npnimport matplotlib.pyplot as pltnndata = np.random.rand(100 1)nncolLabels=(""Fist Column"")nnrows ncols = len(data)+1 len(colLabels)nhcell wcell = 0.1 0.1 # tweak as per your requirementsnhpad wpad = 0.5 0.5    nfig=plt.figure(figsize=(ncols*wcell+wpad nrows*hcell+hpad))nax = fig.add_subplot(111)nax.axis('off')nnthe_table = ax.table(cellText=datan          colLabels=colLabelsn          loc='center')nnplt.show()nnnReferences:nnnhttp://stackoverflow.com/a/26937531/2575259nCreating tables in matplotlibnIn Matplotlib what does the argument mean in fig.add_subplot(111)?nn'",['matplotlib'],['matplotlib']
40131704,"'PyDev Seaborn in Eclipse: ""QPixmap: It is not safe to use pixmaps outside the GUI thread"" on PyDev autocompletion popup' 'I'm getting the errornnn  QPixmap: It is not safe to use pixmaps outside the GUI threadnnnwhen manually entering the following statements in Seaborn in the ipython-shell using PyDev in Eclipse:nnimport matplotlib.pyplot as mplnimport seaborn as snsnimport pandas as pdnimport numpy as npnn# Turn interactive mode off:nmpl.ioff()nn# Create some example Data:ndf = pd.DataFrame({'A':np.random.rand(20)'B':np.random.rand(20)})nn# Create seaborn PairGrid instance:npg = sns.PairGrid(df)nnnAt this point when I continue the last statement with a dot to e.g. chain a map()-method like this:nnpg = sns.PairGrid(df).nnnthen Eclipse is trying to show a popup of all possible completions but that popup is immediatly getting closed and the console is getting filled with the aforementioned error 42 lines of it to be precise.nnI can continue and do this without problem:nngp = sns.PairGrid(df).map(mpl.scatter)ngp.fig.show()nnnAnd I get my plot just fine.nnThe same happens when doing sns.JointGrid(df.Adf.B). and sns.FacetGrid(df).nnWhile playing around earlier I also got into situations where the console was actually killed by this error I just can't replicate the steps that lead to this anymore.nnResearching on this site it looked like it has to do with threading which I'm not using at all. Does Seaborn use it?nnI want to create my plots by first creating a Grid/Figure and doing the plotting later but this error suggests that this isn't a safe way to do things though the Seaborn doc says it's fine to do it like that:nnhttps://seaborn.github.io/generated/seaborn.FacetGrid.htmlnnEDIT:nnWhen doing the same thing in Spyder I'm not getting the error but this warning when doing gp.fig.show():nnC:Anaconda2libsite-packagesmatplotlibfigure.py:397: UserWarning: nmatplotlib is currently using a non-GUI backend so cannot show the figuren""matplotlib is currently using a non-GUI backend ""nnnWhen interactive mode is off I'm not seeing any graphic. With interactive mode on I'm still seeing the warning but get the graphic inline. nnNo popup in either case though. In Eclipse I'm getting both the error and the popup.nnEDIT 2:nnRunning the whole thing as a script in Eclipse does not produce any error only the manual entering like described above does.n' nan",['matplotlib'],"['matplotlib', 'pandas']"
40131782,"'In Django how to assign one model to another model using a form?' 'I am not sure that I am asking the correct question but here is my setup.nsurvey_form.htmlnn<form action="""" method=""post"">n{% csrf_token %}n{% if questions %}n  {% for question in questions %}n   <div class=""form-group"">n     <label for=""{{ question.id }}"">{{ question.question_text }}</label>n     {{ form.response_text }}n   </div>n  {% endfor %}n{% else %}n  <p>No questions currently!</p>n{% endif %}n<button type=""submit"" class=""btn btn-default"">Submit</button>n</form>nnnforms.pynnclass SurveyForm(forms.ModelForm):n    class Meta:n        model = SurveyResponsen        fields = 'response_text'nnnmodels.pynnclass SurveyResponse(models.Model):n    question = models.ForeignKey(SurveyQuestion)n    response_text = models.CharField(blank=False max_length=500)nnnviews.pynnclass SurveyResponseCreate(generic.CreateView):n    model = SurveyResponsen    fields = 'response_text'n    success_url =  reverse_lazy('content/thankyou.html')n    template_name = 'content/surveyresponse_form.html'nn    def get_context_data(self **kwargs):n        context = super(SurveyResponseCreate self).get_context_data(**kwargs)n        context'questions' = SurveyQuestion.objects.all()n        return contextnn    def post(self request *args **kwargs):n        form = self.get_form()n        if form.is_valid():n            instance = form.save(commit=False)n            question = SurveyQuestion.objects.get(id=form.data'question')n            response = SurveyResponse.objects.create(question=question response_text=form.data'response_text')n            response.save()n            return HttpResponseRedirect('/thankyou/')n        else:n            return self.form_invalid(form)nnnSo when I run server and go to /survey/ the form displays:nn<form action="""" method=""post"">n<input type='hidden' name='csrfmiddlewaretoken' value='HS8Tzq1Z2wI8JIG7Q5fj6VB960aHEkUh' />      n   <div class=""form-group"">n     <label for=""1"">Question1</label>n     <input id=""id_response_text"" maxlength=""500"" name=""response_text"" type=""text"" />n   </div>n   <div class=""form-group"">n     <label for=""2"">Question2</label>n     <input id=""id_response_text"" maxlength=""500"" name=""response_text"" type=""text"" />n   </div>n<button type=""submit"" class=""btn btn-default"">Submit</button>n</form>nnnI want the form to display a Question from the Question model and create an input box with a ResponseForm and associate the Response to the Question so that I can add it to the database.nnRight now the form is valid as but when I trace and see the form data it only grabs the last response_text from the form and I cannot access the first response_text even though it is listed in the QueryDict.nnI hope you understand because Class-Based Views and Forms are all new and a bit confusing at this point.n' nan",['django'],['django']
40131793,"'Selecting a Network Interface with Python' ""I want to connect to two different GoPro cameras using my computer's integrated network card and a USB drive wifi adapter (GoPros connect through Wifi). both GoPros receive commands through the same IP address 10.5.5.9. So if I get_ip_address on both available cameras they return the same result - and as far as I can see this invalidates using socket to select an interface which seems to be the most common/popular response to question like this on the interwebs. What I usually see for a potential solution isnns1 = socket.socket()ns1.bind((get_ip_address('gopro1') 0))ns1.connect(('url' 0))nnn...except that as I said the IP address is the same. So this doesn't select an interface at all; all it can do it open a connection from whatever the 'default' interface is. (Sending commands through this I think would be simple since they're all sent as URLs but if it only ever goes through one camera than the point is defeated.)nnI'm not sure where to go with this or have many more ideas of how to phrase it differently for Google. How can I control traffic through two different interfaces with identical IP addresses?nnThanks!n"" nan",['python-2.7'],['python-2.7']
40131979,"""Buttons change but the frame itself doesn't? (pythontkinter)"" 'In my code I'm looking to get it so that when I press Submit a new black frame comes up for the other 3 remaining frames. This is so that I can then populate them at a later date. However when I press submit the only thing which occurs is a change of buttons and not the actual frame. Please help as I have found nothing on the internet so far and yes I am very new to Tkinter so please excuse any mistakes made.nnfrom tkinter import *nfrom tkinter import Tknndef raise_frame(frame):nframe.tkraise()nnroot = Tk()nnf1 = Frame(root)nf2 = Frame(root)nf3 = Frame(root)nf4 = Frame(root)nnfor frame in (f1 f2 f3 f4):nframe.grid(row=3 column=1 sticky='nsew')nnn#SUBMIT YOUR NAME#nnLabel(root text=""First Name"").grid(row=0 sticky=W padx=4)nEntry(root).grid(row=0 column=1 sticky=E pady=4)nnLabel(root text=""Last Name"").grid(row=1 sticky=W padx=4)nEntry(root).grid(row=1 column=1 sticky=E pady=4)nnButton(f1 text='Submit' command=lambda:raise_frame(f2)).grid()nLabel(f1 text='FRAME 1').grid() nnraise_frame(f1)nn#PAGE 2#nnButton(f2 text='Go to frame 3' command=lambda:raise_frame(f3)).grid()nLabel(f2 text='FRAME 2').grid()nnraise_frame(f2)nn#PAGE 3#nnButton(f3 text='Go to frame 4' command=lambda:raise_frame(f4)).grid()nLabel(f3 text='FRAME 3').grid()nnraise_frame(f3)nn#PAGE 4#nnButton(f4 text='Go to to frame 1' command=lambda:raise_frame(f1)).grid()nLabel(f4 text='FRAME 4').grid()nnraise_frame(f4)nroot.mainloop()nn' nan",['tkinter'],['tkinter']
40132067,"'Python user input inside infinite loop too slow easily confused' 'I have a Python script running on a Raspberry Pi that sits waiting for user input and records the input in a SQLite database:nn#!/usr/bin/env pythonnnimport loggingnimport dbnnwhile True:n    barcode = raw_input(""Scan ISBN: "")n    if ( len(barcode) > 1 ):n        logging.info(""Recording scanned ISBN: "" + barcode)n        print ""Recording scanned ISBN: "" + barcoden        db.recordScan(barcode 1)nnnThat db.recordScan() method looks like this:nn# Adds an item to queuendef recordScan(isbn shop_id):n    insert = ""INSERT INTO scans ( isbn shop_id ) VALUES ( ? ? )""n    conn = connect()n    conn.cursor().execute(insert isbn shop_id)n    conn.commit()n    conn.close()nnn(Note: The whole code repo is available at https://github.com/martinjoiner/bookfetch-scanner-python/ if you wanna see how I'm connecting to the db and such) nnMy problem is that using a USB barcode scanner (which is effectively just a keyboard input that sends a series of keystrokes followed by the Enter key) it is really easy to input at such a fast rate that the command line seems to get ""confused"". nnFor example compare the following results... nnWhen you go slow the script works well and the command looks neat like this:nnScan ISBN: 9780465031467nRecording scanned ISBN: 9780465031467nScan ISBN: 9780141014593nRecording scanned ISBN: 9780141014593nScan ISBN: nnnBut when you hammer it hard and go really fast the input prompt kind of gets ahead of itself and the messages printed by the script get written on top of the input prompt:nnRecording scanned ISBN: 9780141014593n9780141014593n9780141014593n9780465031467nRecording scanned ISBN: 9780141014593nScan ISBN: Recording scanned ISBN: 9780141014593nScan ISBN: Recording scanned ISBN: 9780141014593nScan ISBN: Recording scanned ISBN: 9780465031467nScan ISBN: 9780571273188n9780141014593nnnIt sometimes hangs in that position indefinitely I don't know what it's doing but you can wake it back up again with another input and it carries on as normal although the input before the one it hung on doesn't get recorded which is bad because it makes the whole system unreliable. nnMy question is: Is this an inevitability that I just have to live with? Will I always be able to out-pace the low-powered Raspberry Pi by hitting it with too many inputs in close succession or is there some faster way of doing this? Can I push the database write operation to another thread or something along those lines? Forgive my ignorance I am learning. n' 'Don't build SQL strings from user input. Ever. nnAlways use parameterized queries.nn# Adds an item to queuendef recordScan(isbn shop_id):n    insert = ""INSERT INTO scans ( isbn shop_id ) VALUES ( ? ? )""n    conn = connect()n    conn.cursor().execute(insert isbn shop_id)n    conn.commit()n    conn.close()nnnPlease read https://docs.python.org/2/library/sqlite3.html at the very least the upper part of the page where they explain this approach.n' 'You appear to be opening and closing the database each and every time. That will clearly add a huge overhead especially as you are ""hammering"" away at it.nConnect to the database once at the beginning and close it upon exit.nIn between simply perform your insert update and delete statements. nnEdit:nFor the purposes of this I renamed db.py to be called barcode1.py so edit appropriately.nAlter listen.py to be as follows:    nn#!/usr/bin/env pythonnnimport loggingnimport barcode1nDB_FILE_NAME = ""scan-queue.db""nmy_db = barcode1.sqlite3.connect(DB_FILE_NAME)nmy_cursor = my_db.cursor()nndef InsertScan(isbn shop_id):n    insert = ""INSERT INTO scans ( isbn shop_id ) VALUES ( ? ? )""n    my_cursor.execute(insert isbn shop_id)n    my_db.commit()nnwhile True:n    barcode = raw_input(""Scan ISBN: "")n    if ( len(barcode) > 1 ):n        logging.info(""Recording scanned ISBN: "" + barcode)n        print ""Recording scanned ISBN: "" + barcoden        InsertScan(barcode 1)nmy_db.close()nnnFor your purposes replace references to ""barcode1"" with ""db""nAs you can see all that happens here is that a separate function has been added to do the writing and only the writing.nClearly this is a quick mock up and could be improved immeasurably in fact I'd rewrite it as a single script. This is one of those classic examples where in an attempt to write object oriented code you end up shooting yourself in the foot.nIn fact you could do without the function and just include the insert code within the while statement.nnLocking:nfrom the sqlite3 documents:nn sqlite3.connect(database timeout detect_types isolation_level check_same_thread factory cached_statements uri)nnnOpens a connection to the SQLite database file database. You can use "":memory:"" to open a database connection to a database that resides in RAM instead of on disk.nnWhen a database is accessed by multiple connections and one of the processes modifies the database the SQLite database is locked until that transaction is committed. The timeout parameter specifies how long the connection should wait for the lock to go away until raising an exception. The default for the timeout parameter is 5.0 (five seconds).n' 'After much experimenting based on helpful advice from users @tomalak @rolf-of-saxony and @hevlastka my conclusion is that yes this is an inevitability that I just have to live with. nnEven if you strip the example down to the basics by removing the database write process and making it a simple parrot script that just repeats back inputs (See Python on Raspberry Pi user input inside infinite loop misses inputs when hit with many) it is still possible to scan items so fast that inputs get missed/skipped/ignored. The Raspberry Pi simply cannot keep up. nnSo my approach will now be to add an audio feedback feature such as a beep sound to indicate to the user when the device is ready to receive the next input. A route I didn't want to go down but it seems my code is the most efficient it can be and we're still able to hit the limits. Responsibility is with the user to not go at breakneck speed and the best we can do a responsible product builders is give them good feedback. n'",['python-2.7'],['python-2.7']
40132128,'python pandas: Reallocate index columns and values within dataframe' 'I have a dataframe that looks as follows. x is the indexnn                  y      valuenx                   n1                 0  0.016175n1                 1  0.017832n1                 2  0.021536n1                 3  0.024777n2                 0  0.027594n2                 1  0.029950n2                 2  0.031890n2                 3  0.033570n3                 0  0.035070n3                 1  0.036329n3                 2  0.037297n3                 3  0.037983nnnI would like to reallocate the data in the frame so that the result looks like:nn                 y       1(x)       2(x)         3(x)nn                 0  0.016175    0.027594    0.035070n                 1  0.017832    0.029950    0.036329n                 2  0.021536    0.031890    0.037297n                 3  0.024777    0.033570    0.037983nnnThe original index should be placed as column headings and y should be the new index. Any ideas how to implement this in Python?n' 'You can use first reset_index then pivot and last add_suffix:nnprint (df.reset_index().pivot(index='y' columns='x' values='value').add_suffix('(x)'))nx      1(x)      2(x)      3(x)ny                              n0  0.016175  0.027594  0.035070n1  0.017832  0.029950  0.036329n2  0.021536  0.031890  0.037297n3  0.024777  0.033570  0.037983nnnLast if need remove column names add rename_axis (new in pandas 0.18.0):nnprint (df.reset_index()n         .pivot(index='y' columns='x' values='value')n         .add_suffix('(x)')n         .rename_axis(None axis=1))n       1(x)      2(x)      3(x)ny                              n0  0.016175  0.027594  0.035070n1  0.017832  0.029950  0.036329n2  0.021536  0.031890  0.037297n3  0.024777  0.033570  0.037983nn',['pandas'],['pandas']
40132352,"'python filter 2d array by a chunk of data' 'import numpy as npnndata = np.array(n    20  0  5  1n    20  0  5  1n    20  0  5  0n    20  1  5  0n    20  1  5  0n    20  2  5  1n    20  3  5  0n    20  3  5  0n    20  3  5  1n    20  4  5  0n    20  4  5  0n    20  4  5  0n)nnnI have the following 2d array. lets called the fields a b c d in the above order where column b is like id. I wish to delete all cells that doesnt have atlist 1 appearance of the number ""1"" in column d for all cells with the same number in column b (same id) so after filtering i will have the following results:nn20  0  5  1n 20  0  5  1n 20  0  5  0n 20  2  5  1n 20  3  5  0n 20  3  5  0n 20  3  5  1nnnall rows with b = 1 and b = 4 have been deleted from the datannto sum up because I see answers that doesnt fit. we look at chunks of data by the b column. if a complete chunk of data doesnt have even one appearance of the number ""1"" in column d we delete all the rows of that b item. in the following example we can see a chunk of data with b = 1 and b = 4 (""id"" = 1 and ""id"" = 4) that have 0 appearances of the number ""1"" in column d. thats why it gets deleted from the data n' 'code: nnimport numpy as npnnmy_list = 20051n    20051n    20050n    20150n    20150n    20251n    20350n    20350n    20351n    20450n    20450n    20450nnall_ids = np.array(my_list):1nunique_ids = np.unique(all_ids)nindices = np.where(all_ids==ui)00 for ui in unique_ids nnfinal = nfor id in unique_ids:n    try:n        tmp_group = my_listindicesid:indicesid+1n    except:n        tmp_group = my_listindicesid:n    if 1 in np.array(tmp_group):3:n        final.extend(tmp_group)nnprint np.array(final)nnnresult: nn20  0  5  1n 20  0  5  1n 20  0  5  0n 20  2  5  1n 20  3  5  0n 20  3  5  0n 20  3  5  1nn' ""This gets rid of all rows with 1 in the second position:nnsublist for sublist in list_ if sublist1 != 1nnnThis get's rid of all rows with 1 in the second position unless the fourth position is also 1:nnsublist for sublist in list_ if not (sublist1 == 1 and sublist3 != 1) nn"" 'Generic approach : Here's an approach using np.unique and np.bincount to solve for a generic case -nnunqtags = np.unique(data:1return_inverse=1)ngoodIDs = np.flatnonzero(np.bincount(tagsdata:3==1)>=1)nout = datanp.in1d(tagsgoodIDs)nnnSample run -nnIn 15: datanOut15: narray(20 10  5  1n       20 73  5  0n       20 73  5  1n       20 31  5  0n       20 10  5  1n       20 10  5  0n       20 42  5  1n       20 54  5  0n       20 73  5  0n       20 54  5  0n       20 54  5  0n       20 31  5  0)nnIn 16: outnOut16: narray(20 10  5  1n       20 73  5  0n       20 73  5  1n       20 10  5  1n       20 10  5  0n       20 42  5  1n       20 73  5  0)nnnSpecific case approach :  If the second column data is always sorted and have sequential numbers starting from 0 we can use a simplified version like so -nngoodIDs = np.flatnonzero(np.bincount(data:1data:3==1)>=1)nout = datanp.in1d(data:1goodIDs)nnnSample run -nnIn 44: datanOut44: narray(20  0  5  1n       20  0  5  1n       20  0  5  0n       20  1  5  0n       20  1  5  0n       20  2  5  1n       20  3  5  0n       20  3  5  0n       20  3  5  1n       20  4  5  0n       20  4  5  0n       20  4  5  0)nnIn 45: outnOut45: narray(20  0  5  1n       20  0  5  1n       20  0  5  0n       20  2  5  1n       20  3  5  0n       20  3  5  0n       20  3  5  1)nnnAlso if data:3 always have ones and zeros we can just use data:3 in place of data:3==1 in the above listed codes.nnnnBenchmarking nnLet's benchmark the vectorized approaches on the specific case for a larger array -nnIn 69: def logical_or_based(data): #@ Eric's solnn    ...:     b_vals = data:1n    ...:     d_vals = data:3n    ...:     is_ok = np.zeros(np.max(b_vals) + 1 dtype=np.bool_)n    ...:     np.logical_or.at(is_ok b_vals d_vals)n    ...:     return is_okb_valsn    ...: n    ...: def in1d_based(data):n    ...:     goodIDs = np.flatnonzero(np.bincount(data:1data:3)!=0)n    ...:     out = np.in1d(data:1goodIDs)n    ...:     return outn    ...: nnIn 70: # Setup inputn    ...: data = np.random.randint(0100(100004))n    ...: data:1 = np.sort(np.random.randint(0100(10000)))n    ...: data:3 = np.random.randint(02(10000))n    ...: nnIn 71: %timeit logical_or_based(data) #@ Eric's solnn1000 loops best of 3: 1.44 ms per loopnnIn 72: %timeit in1d_based(data)n1000 loops best of 3: 528 Âµs per loopnn' 'Let's assume the following:nnnb >= 0nb is an integernb is fairly dense ie max(b) ~= len(unique(b))nnnHere's a solution using np.ufunc.at:nn# unpack for clarity - this costs nothing in numpynb_vals = data:1nd_vals = data:3nn# build an array indexed by b valuesnis_ok = np.zeros(np.max(b_vals) + 1 dtype=np.bool_)nnp.logical_or.at(is_ok b_vals d_vals)n# is_ok == array( True False  True  True False dtype=bool)nn# take the rows which have a b value that was deemed OKnresult = datais_okb_valsnnnnnnp.logical_or.at(is_ok b_vals d_vals) is a more efficient version of:nnfor idx val in zip(b_vals d_vals):n    is_okidx = np.logical_or(is_okidx val)nn' 'Untested since in a hurry but this should work:nnimport numpy_indexed as nping = npi.group_by(data: 1)nids valid = g.any(data: 3)nresult = datavalidg.inversenn'",['numpy'],['numpy']
40132576,"'How do I schedule a job in Django?' 'I have to schedule a job using Schedule on my django web application.nndef new_job(request): n   print(""I'm working..."")   n   file=schedulesdb.objects.filter (user=request.userf_name__icontains =""mp4"").last()    n   file_initiated = str(f_name)  n   os.startfile(f_name_initiated)nnnI need to do it with filtered time in dbnnGIVEN DATETIME = schedulesdb.objects.datetimes('request_time' 'second').last()nschedule.GIVEN DATETIME.do(job)nn' 'Django is a web framework. It receives a request does whatever processing is necessary and sends out a response. It doesn't have any persistent process that could keep track of time and run scheduled tasks so there is no good way to do it using just Django.nnThat said Celery (http://www.celeryproject.org/) is a python framework specifically built to run tasks both scheduled and on-demand. It also integrates with Django ORM with minimal configuration. I suggest you look into it.nnYou could of course write your own external script that would use schedule module that you mentioned. You would need to implement a way to write shedule objects into the database and then you could have your script read and execute them. Is your ""scheduledb"" model already implemented?n'",['django'],['django']
40132625,"'Import error in django REST serializer' 'I have 3 models: Album Photo and standard User. Album have foreign key to user and photo have foreign key to album and user. I want UserSerializer to have nested Serializers for Albums and Photos but it's seems to be cycle and Django REST gives errornnn  Filen  ""C:UsersUserAppDataLocalProgramsPythonPython35-32libunittestloader.py""n  line 428 in _find_test_pathn      module = self._get_module_from_name(name)   File ""C:UsersUserAppDataLocalProgramsPythonPython35-32libunittestloader.py""n  line 369 in _get_module_from_namen      import(name)   File ""D:codeactivephoto-hubphoto-hubapitests.py"" line 8 in n      from .serializers import RegisterSerializer   File ""D:codeactivephoto-hubphoto-hubapiserializers.py"" line 14 inn  n      from api.serializers import AlbumSerializer PhotoSerializer ImportError: cannot import name 'AlbumSerializer'nnnBut how can i get urls of user's albums and photos without nesting Serializers?nnserializers.py:nnfrom django.contrib.auth.models import Usernnfrom rest_framework import serializersnfrom rest_framework import mixinsnnfrom api.models import Album Photonimport apinnclass UserSerializer(serializers.HyperlinkedModelSerializer):n    albums = AlbumSerializer(required=False)n    photos = PhotoSerializer(required=False)nn    class Meta:n        model = Usern        fields = ('url' 'pk' 'username' 'email' 'albums' 'photos')nnclass PhotoSerializer(serializers.HyperlinkedModelSerializer):n    album = serializers.HyperlinkedRelatedField(view_name='album-detail' queryset=Album.objects required=False)n    user = serializers.HyperlinkedRelatedField(view_name='user-detail' queryset=User.objects required=False)nn    class Meta:n        model = Photon        fields = ('url' 'pk' 'name' 'image' 'creation_date' 'user' 'album')n        read_only_fields=('creation_date' )nnclass AlbumSerializer(serializers.HyperlinkedModelSerializer):n    user = serializers.HyperlinkedRelatedField(view_name='user-detail' queryset=User.objects required=False)n    photos = serializers.HyperlinkedRelatedField(view_name='photo-list'  queryset=Photo.objects many=True required=False)nn    class Meta:n        model = Albumn        fields = ('url' 'pk' 'name' 'creation_date' 'user' 'photos')n        read_only_fields=('creation_date')nnnmodels.py:nnfrom django.db import modelsnfrom django.contrib.auth.models import Usernimport osnfrom django.utils import timezonenndef get_image_path(instance filename):n    return instance.user.username + '//' + ''.join(str(timezone.now()).replace(' ' '').replace(':' ''))  + '//'nnnclass Album(models.Model):n    user = models.ForeignKey(User  related_name='albums' on_delete=models.CASCADE)n    name = models.CharField(max_length=80 default='New album')n    creation_date = models.DateField(auto_now_add=True)nn    def __str__(self):n        return self.namenn    class Meta:n        ordering = 'creation_date' nnnclass Photo(models.Model):n    user = models.ForeignKey(User  related_name='photos' on_delete=models.CASCADE)n    album = models.ForeignKey(Album related_name='photos' on_delete=models.CASCADE null=True blank=True)n    name = models.CharField(max_length=80 default='New photo')n    image = models.ImageField(name upload_to=get_image_path)n    creation_date = models.DateField(auto_now_add=True)nn    def __str__(self):n        return self.namenn    class Meta:n        ordering = 'creation_date' nnnviews.py:nnclass PhotoViewSet(viewsets.ModelViewSet):n    queryset = Photo.objects.all()n    serializer_class = PhotoSerializer n    permission_classes = (permissions.IsAuthenticatedOrReadOnly IsOwnerOrReadOnly)nn    def perform_create(self serializer):n        serializer.save(user=self.request.user)nnclass AlbumViewSet(viewsets.ModelViewSet):n    queryset = Album.objects.all()n    serializer_class = AlbumSerializer n    permission_classes = (permissions.IsAuthenticatedOrReadOnly IsOwnerOrReadOnly)n    def perform_create(self serializer):n        serializer.save(user=self.request.user)nnclass UserViewSet(viewsets.ReadOnlyModelViewSet):n    queryset = User.objects.all()n    serializer_class = UserSerializer n    permission_classes = (permissions.IsAuthenticatedOrReadOnly IsOwnerOrReadOnly)nn' nan",['django'],['django']
40132927,"'Set specific values in a mixed valued DataFrame to fixed value?' ""I have a data frame with response and predictor variables in the columns and observations in the rows. Some of the values in the responses are below a given limit of detection (LOD). As I am planing to apply a rank transformation on the responses I would like to set all those values equal to LOD. Say the data frame isnndata.head()nn  age  response1  response2  response3 risk     sex smokingn0  33   0.272206   0.358059   0.585652   no  female     yesn1  38   0.425486   0.675391   0.721062  yes  female      non2  20   0.910602   0.200606   0.664955  yes  female      non3  38   0.966014   0.584317   0.923788  yes  female      non4  27   0.756356   0.550512   0.106534   no  female     yesnnnI would like to donnresponses = 'response1' 'response2' 'response3'nLOD = 0.2nndataresponsesdataresponses <= LOD = LODnnnwhich for multiple reasons does not work ( as pandas doesn't know if it should produce a view on the data or not and it won't I guess)nnHow do I set all values innndataresponses <= LODnnnequal to LOD?nnnnMinimal example:nnimport numpy as npnimport pandas as pdnnfrom pandas import Series DataFramennx = Series(random.randint(0250) dtype='category')nx.cat.categories = 'no' 'yes'nny = Series(random.randint(0250) dtype='category')ny.cat.categories = 'no' 'yes'nnz = Series(random.randint(0250) dtype='category')nz.cat.categories = 'male' 'female'nna = Series(random.randint(206050) dtype='category')nndata = DataFrame({'risk':x 'smoking':y 'sex':zn    'response1': random.rand(50)n    'response2': random.rand(50)n    'response3': random.rand(50)n    'age':a})nn"" 'You can use DataFrame.mask:nnimport numpy as npnimport pandas as pdnnnp.random.seed(123)nx = pd.Series(np.random.randint(0210) dtype='category')nx.cat.categories = 'no' 'yes'ny = pd.Series(np.random.randint(0210) dtype='category')ny.cat.categories = 'no' 'yes'nz = pd.Series(np.random.randint(0210) dtype='category')nz.cat.categories = 'male' 'female'nna = pd.Series(np.random.randint(206010) dtype='category')nndata = pd.DataFrame({n'risk':x n'smoking':y n'sex':z n'response1': np.random.rand(10)n'response2': np.random.rand(10)n'response3': np.random.rand(10)n'age':a})nprint (data)n  age  response1  response2  response3 risk     sex smokingn0  24   0.722443   0.425830   0.866309   no    male     yesn1  23   0.322959   0.312261   0.250455  yes    male     yesn2  22   0.361789   0.426351   0.483034   no  female      non3  40   0.228263   0.893389   0.985560   no  female     yesn4  59   0.293714   0.944160   0.519485   no  female      non5  22   0.630976   0.501837   0.612895   no    male     yesn6  40   0.092105   0.623953   0.120629   no  female      non7  27   0.433701   0.115618   0.826341  yes    male     yesn8  55   0.430863   0.317285   0.603060  yes    male     yesn9  48   0.493685   0.414826   0.545068   no    male      nonnnnnresponses = 'response1' 'response2' 'response3'nLOD = 0.2nnprint (dataresponses <= LOD)n  response1 response2 response3n0     False     False     Falsen1     False     False     Falsen2     False     False     Falsen3     False     False     Falsen4     False     False     Falsen5     False     False     Falsen6      True     False      Truen7     False      True     Falsen8     False     False     Falsen9     False     False     Falsenndataresponses = dataresponses.mask(dataresponses <= LOD LOD)nprint (data)n  age  response1  response2  response3 risk     sex smokingn0  24   0.722443   0.425830   0.866309   no    male     yesn1  23   0.322959   0.312261   0.250455  yes    male     yesn2  22   0.361789   0.426351   0.483034   no  female      non3  40   0.228263   0.893389   0.985560   no  female     yesn4  59   0.293714   0.944160   0.519485   no  female      non5  22   0.630976   0.501837   0.612895   no    male     yesn6  40   0.200000   0.623953   0.200000   no  female      non7  27   0.433701   0.200000   0.826341  yes    male     yesn8  55   0.430863   0.317285   0.603060  yes    male     yesn9  48   0.493685   0.414826   0.545068   no    male      nonn'",['pandas'],['pandas']
40133016,"'How to group pandas DataFrame by varying dates?' ""I am trying to roll up daily data into fiscal quarter data.  For example I have a table with fiscal quarter end dates:nnCompany Period Quarter_EndnM       2016Q1 05/02/2015nM       2016Q2 08/01/2015nM       2016Q3 10/31/2015nM       2016Q4 01/30/2016nWFM     2015Q2 04/12/2015nWFM     2015Q3 07/05/2015 nWFM     2015Q4 09/27/2015nWFM     2016Q1 01/17/2016nnnand a table of daily data:nnCompany Date       PricenM       06/20/2015 1.05nM       06/22/2015 4.05nM       07/10/2015 3.45nM       07/29/2015 1.86nM       08/24/2015 1.58nM       09/02/2015 8.64nM       09/22/2015 2.56nM       10/20/2015 5.42nM       11/02/2015 1.58nM       11/24/2015 4.58nM       12/03/2015 6.48nM       12/05/2015 4.56nM       01/03/2016 7.14nM       01/30/2016 6.34nWFM     06/20/2015 1.05nWFM     06/22/2015 4.05nWFM     07/10/2015 3.45nWFM     07/29/2015 1.86nWFM     08/24/2015 1.58nWFM     09/02/2015 8.64nWFM     09/22/2015 2.56nWFM     10/20/2015 5.42nWFM     11/02/2015 1.58nWFM     11/24/2015 4.58nWFM     12/03/2015 6.48nWFM     12/05/2015 4.56nWFM     01/03/2016 7.14nWFM     01/17/2016 6.34nnnAnd I would like to create the table below.nnCompany Period  Quarter_end Sum(Price)nM       2016Q2  8/1/2015    10.41nM       2016Q3  10/31/2015  18.2nM       2016Q4  1/30/2016   30.68nWFM     2015Q3  7/5/2015    5.1nWFM     2015Q4  9/27/2015   18.09nWFM     2016Q1  1/17/2016   36.1nnnHowever I don't know how to group by varying dates without looping through each record. Any help is greatly appreciated.nnThanks!n"" 'I think you can use merge_ordered:nn#first convert columns to datetimendf1.Quarter_End = pd.to_datetime(df1.Quarter_End)ndf2.Date = pd.to_datetime(df2.Date)nnndf = pd.merge_ordered(df1 n                      df2 n                      left_on='Company''Quarter_End' n                      right_on='Company''Date' n                      how='outer')nprint (df)n   Company  Period Quarter_End       Date  Pricen0        M  2016Q1  2015-05-02        NaT    NaNn1        M     NaN         NaT 2015-06-20   1.05n2        M     NaN         NaT 2015-06-22   4.05n3        M     NaN         NaT 2015-07-10   3.45n4        M     NaN         NaT 2015-07-29   1.86n5        M  2016Q2  2015-08-01        NaT    NaNn6        M     NaN         NaT 2015-08-24   1.58n7        M     NaN         NaT 2015-09-02   8.64n8        M     NaN         NaT 2015-09-22   2.56n9        M     NaN         NaT 2015-10-20   5.42n10       M  2016Q3  2015-10-31        NaT    NaNn11       M     NaN         NaT 2015-11-02   1.58n12       M     NaN         NaT 2015-11-24   4.58n13       M     NaN         NaT 2015-12-03   6.48n14       M     NaN         NaT 2015-12-05   4.56n15       M     NaN         NaT 2016-01-03   7.14n16       M  2016Q4  2016-01-30 2016-01-30   6.34n17     WFM  2015Q2  2015-04-12        NaT    NaNn18     WFM     NaN         NaT 2015-06-20   1.05n19     WFM     NaN         NaT 2015-06-22   4.05n20     WFM  2015Q3  2015-07-05        NaT    NaNn21     WFM     NaN         NaT 2015-07-10   3.45n22     WFM     NaN         NaT 2015-07-29   1.86n23     WFM     NaN         NaT 2015-08-24   1.58n24     WFM     NaN         NaT 2015-09-02   8.64n25     WFM     NaN         NaT 2015-09-22   2.56n26     WFM  2015Q4  2015-09-27        NaT    NaNn27     WFM     NaN         NaT 2015-10-20   5.42n28     WFM     NaN         NaT 2015-11-02   1.58n29     WFM     NaN         NaT 2015-11-24   4.58n30     WFM     NaN         NaT 2015-12-03   6.48n31     WFM     NaN         NaT 2015-12-05   4.56n32     WFM     NaN         NaT 2016-01-03   7.14n33     WFM  2016Q1  2016-01-17 2016-01-17   6.34nnnThen backfill NaN in columns Period and Quarter_End by bfill and aggregate sum. If need remove all NaN values add Series.dropna and last reset_index:nndf.Period = df.Period.bfill()ndf.Quarter_End = df.Quarter_End.bfill()nnprint (df.groupby('Company''Period''Quarter_End')'Price'.sum().dropna().reset_index())nn  Company  Period Quarter_End  Pricen0       M  2016Q2  2015-08-01  10.41n1       M  2016Q3  2015-10-31  18.20n2       M  2016Q4  2016-01-30  30.68n3     WFM  2015Q3  2015-07-05   5.10n4     WFM  2015Q4  2015-09-27  18.09n5     WFM  2016Q1  2016-01-17  36.10nn' 'nset_indexnpd.concat to align indicesngroupby with aggnnnnnprd_df = period_df.set_index('Company' 'Quarter_End')nnprc_df = price_df.set_index('Company' 'Date' drop=False)nndf = pd.concat(prd_df prc_df axis=1)nndf.groupby(df.index.get_level_values(0) df.Period.bfill())  n  .agg(dict(Date='last' Price='sum')).dropna()nnnn'","['pandas', 'numpy']",['pandas']
40133059,"'Python: logging and TCP handler' 'I wrote my TCP handler as follows (adapted from: https://docs.python.org/2/library/socketserver.html#socketserver-tcpserver-example):nn#!/usr/bin/env pythonn# -*- coding: UTF-8 -*-nnimport SocketServernnfrom MyModule import myFunctionnnclass MyHandler(SocketServer.StreamRequestHandler):nn    def handle(self):n        self.data = self.rfile.readline().strip()n        result = myFunction(self.data)n        self.wfile.write(result)nnif __name__ == ""__main__"":n    HOST PORT = myhost myportn    server = SocketServer.TCPServer((HOST PORT) MyHandler)n    server.serve_forever()nnnIt works perfectly and now I'm trying to add a logger:nn#!/usr/bin/env pythonn# -*- coding: UTF-8 -*-nnimport SocketServernimport loggingnfrom logging.handlers import TimedRotatingFileHandlernnfrom MyModule import myFunctionnnclass MyHandler(SocketServer.StreamRequestHandler):nn    def __init__(self):n        self.logger = logging.getLogger()n        self.logger.setLevel(logging.DEBUG)n        self.formatter = logging.Formatter('%(asctime)s :: %(levelname)s :: %(message)s')n        self.file_handler = TimedRotatingFileHandler('my_log_file.log' when='D' interval=1 utc=True)n        self.file_handler.setLevel(logging.DEBUG)n        self.file_handler.setFormatter(self.formatter)n        self.logger.addHandler(self.file_handler)nn    def handle(self):n        self.data = self.rfile.readline().strip()n        result = myFunction(self.data)n        self.wfile.write(result)nn        self.logger.info(result)nnif __name__ == ""__main__"":n    HOST PORT = myhost myportn    server = SocketServer.TCPServer((HOST PORT) MyHandler)n    server.serve_forever()nnnWhen I run it I get the following error:nnTypeError: __init__() takes exactly 1 argument (4 given)nnI don't understand what the 4 arguments given are.nIs there anything wrong with the code other than that?nnEDIT: Full TraceBack:nnException happened during processing of request from ('MyIP' 54028)nTraceback (most recent call last):n  File ""/usr/lib/python2.7/SocketServer.py"" line 290 in _handle_request_noblockn    self.process_request(request client_address)n  File ""/usr/lib/python2.7/SocketServer.py"" line 318 in process_requestn    self.finish_request(request client_address)n  File ""/usr/lib/python2.7/SocketServer.py"" line 331 in finish_requestn    self.RequestHandlerClass(request client_address self)nTypeError: __init__() takes exactly 1 argument (4 given)nn' 'MyHandler is a subclass of SocketServer.StreamRequestHandler which is a subclass of BaseRequestHandler. The call signature of BaseRequestHandler.__init__ is nndef __init__(self request client_address server):nnnThe traceback error message shows that inside the BaseServer.finish_request methodnnself.RequestHandlerClass(request client_address self)nnnis called. self.RequestHandlerClass is MyHandler. ThereforenMyHandler.__init__ should have call signaturennclass MyHandler(SocketServer.StreamRequestHandler):n    def __init__(self request client_address server):nnninstead of nnclass MyHandler(SocketServer.StreamRequestHandler):n    def __init__(self):nnnnnWhen self.RequestHandlerClass(request client_address self) is called Python calls nthe RequestHandlerClass method with self as its first argument. In other words nRequestHandlerClass(self request client_address self) gets called. self request client_address self are the four arguments that are getting passed to MyHandler. nThe error messagennTypeError: __init__() takes exactly 1 argument (4 given)nnnis complaining that MyHandler.__init__ was defined to expect only 1 argument and yet it was being passed 4 arguments.n'",['python-2.7'],['python-2.7']
40133216,"'How to return JSON from Python REST API' 'I have a Python API that receives data from mysql select query. The data looks like this:nn| val | type | status |n|-----|------|--------|n|  90 |    1 |      a |nnnThat data was received well in python. Now I want to present that data as JSON to my REST client - how?nnHere is my python code:nndef somefunction(self by identifier):n    # validate argsn    procedure = 'mysproc' + str(by)nn    try:n        with self.connection.cursor() as cursor:n            cursor.callproc(procedurestr(identifier))n            self.connection.commit()n            result = cursor.fetchone()nn            print(""+++ Result: "" + str(result) + "" +++"")n    except:n        result = ""Request Failed""n        raisen    finally:n        self.DestroyConnection()nn    return json.dumps(result)nnnwith that my client is receiving:nn""90 1 ""a""""nnnQuestion:nnis there a way for me to receive it as a proper JSON? like:nn{'val': 90 'type': 1  : 'status': ""a""}nn' 'You will first need to get the mysql query to return a dict object instead of a list. If your library is MySQLdb then this answer: Python - mysqlDB sqlite result as dictionary is what you need.nnHere is a link to the docs for MySQLdb: http://www.mikusa.com/python-mysql-docs/docs/MySQLdb.connections.htmlnnI think if you pass in the cursor class you want to use when you create your cursor the result of fetchone will be a dictionary. nnwith self.connection.cursor(MySQLdb.cursors.DictCursor) as cursor:nnnRunning json.dumps(result) on a dictionary will give the output you are looking for.n'",['python-3.x'],"['python-2.7', 'dictionary']"
40133557,"'Correct way to define a RetrieveAPIView view class' ""After reading the documentation of django-rest-framework this is what I have done:nserializers.py:nnclass UserRegistrationDetailSerializer(serializers.ModelSerializer):n    class Meta:n        model = Usern        fields = (n            User._meta.pk.namen        )nnnviews.pynnclass RegistrationDetailView(generics.RetrieveAPIView):n    serializer_class = serializers.UserRegistrationDetailSerializern    permission_classes = (n        permissions.AllowAnyn    )n    lookup_field='email'nn    def get_queryset(self):n        email = self.kwargs.get('email')n        user = get_object_or_404(User email = email)n        if user:n            if settings.get('SEND_ACTIVATION_EMAIL'):n                self.send_activation_email(user)n            elif settings.get('SEND_CONFIRMATION_EMAIL'):n                self.send_confirmation_email(user)nn        return User.objects.all()nnnurls.py:nnurlpatterns = n    url(r'^register/(?P<email>w+|w.%+-+@A-Za-z0-9.-+.A-Za-z{24})/$' views.RegistrationDetailView.as_view() name='register_detail')nnnnI have defined def get_queryset(self):  instead of just providing the queryset variable because I wanted to send an email to the user if the user exists in the database. It works as required but since I am new to djngo-rest-framework I am not quite sure if this is the right way to do this. Am I doing anything unnecessary here?n"" nan",['django'],['django']
40133688,"'Bokeh Python: Laying out multiple plots' ""I want to array plots horizontally use the hplot() function.nMy problem is that I generate my plot names dinamically.nDfdict is a dictionary of dataframesnnfor key in dfdict.keys():n    plotkey = BoxPlot(dfdictkey values='oex' ...)n    filename = '{}.html'.format(str(key))n    output_file(filename)n    show(plotkey)np = hplot(plot.values())nshow(p)nnnBut i have an error:nnValueError: expected an element of List(Instance(Component)) got seq with invalid items      nnThanksn"" 'I do it intead of thisnnp = hplot(plot.values())nnnI am using thisnnp = hplot(*plot.values())nn' 'Please note that hplot is deprecated in recent releases. You should use bokeh.layout.row:nnfrom bokeh.layouts import rownn# define some plots p1 p2 p3nnlayout = row(p1 p2 p3)nnshow(layout)nnnFunctions like row (and previously hplot) take all the things to put in the row as individual arguments. nnThere is an entire section on layouts in the user's guide: nnhttp://bokeh.pydata.org/en/latest/docs/user_guide/layout.htmln'",['dictionary'],['matplotlib']
40133720,"'find repeated element in list of list python' 'I have been struggling with this problem for two days and I need help with it. I need to find repeated element in a list of listsnlist_of_list = (a1 b1 c1) (a2 b2 c2) ... (an bn cn) where ""a"" and ""b"" elements are integers and ""c"" elements are floats.nnSo if for example a1 == a2 or a1 == bn I need to create a new list with the entire list elements and I need to iterate this for all the lists (a b c) in the list of lists. To put it another way I need all lists that have elements that are present in more than one list. I need to compare only ""a"" and ""b"" elements but obtain the associated value ""c"" in the final list.nnFor example:nnlist_of_list = (1 2 4.99) (3 6 5.99) (1 4 3.00) (5 1 1.12) (7 8 1.99) nndesired_result=(1 2 4.99) (1 4 3.00) (5 1 1.12) nnnI try many ideas...but nothing nice came up:nnMI_network =  #repeated elements listngenesis = list(complete_net) #clon to work onngenesis_next = list(genesis) #clon to remove elements in iterationsngenesis_next.remove(genesis_next0)nnwhile genesis_next != :n    for x in genesis:n        if x0 in genesis_next and x1 not in genesis_next:n            MI_network.append(x)n        if x0 not in genesis_next and x1 in genesis_next:n            MI_network.append(x)n    genesis_next.remove(genesis_next0)nn' 'You can count occurrences of specific list elements and take lists with counts > 1. Something like this using collections.defaultdict():nn>>> from collections import defaultdictn>>> count = defaultdict(int)n>>> for lst in list_of_list:n...     countlst0 += 1n...     countlst1 += 1n...n>>> lst for lst in list_of_list if countlst0 > 1 or countlst1 > 1n(1 2 4.99) (1 4 3.0) (5 1 1.12)nn' 'And this is how i would do it since i was not aware of the collections.defaultdict().nnlist_of_list = (1 2 4.99) (3 6 5.99) (1 4 3.00) (5 1 1.12) (7 8 1.99) nresults = nfor i_sub subset in enumerate(list_of_list):n# test if ai == ajn    rest = list_of_list:i_sub + list_of_listi_sub + 1:n    if any(subset0 == subrest0 for subrest in rest):n        results.append(subset)n# test if ai == bjn    elif any(subset0 == subrest1 for subrest in rest):n        results.append(subset)n# test if bi == ajn    elif any(subset1 == subrest0 for subrest in rest):n        results.append(subset)nprint(results)  # -> (1 2 4.99) (1 4 3.0) (5 1 1.12)nn' 'Using your idea you can try this:nnMI_network = ncomplete_net = (1 2 4.99) (3 6 5.99) (1 4 3.00) (5 1 1.12) (7 8 1.99)ngenesis = list(complete_net)nnwhile genesis != :n    for x in genesis:n        for gen in genesis:n            if x0 in gen and x1 not in gen:n                if x0 != gen2 and x1 != gen2:n                    if x not in MI_network:n                        MI_network.append(x)n            elif x0 not in gen and x1 in gen:n                if x0 != gen2 and x1 != gen2:n                    if x not in MI_network:n                        MI_network.append(x)n            elif x0 not in gen and x1 not in gen:n                passn    genesis.remove(genesis0)   nnprint(MI_network)n(1 2 4.99) (1 4 3.0) (5 1 1.12)nn'",['list'],"['list', 'python-2.7']"
40133761,"'is there any way to split Spark Dataset in given logic' ""i am looking for Spark Dataset split application which is similar to bellow mentioned logic. nn>>> import pandas as pdn>>> import numpy as npnn>>> df1 = pd.DataFrame(np.random.randn(10 4) columns='a' 'b' 'c' 'd')n>>> df1n          a         b         c         dn0 -0.398502 -1.083682  0.850632 -1.443868n1 -2.124333  1.093590 -0.338162 -1.414035n2  0.753560  0.600687 -0.998277 -2.094359n3 -0.635962 -0.291226  0.428961  1.158153n4 -0.900506 -0.545226 -0.448178 -0.567717n5  0.112911  0.351649  0.788940  2.071541n6 -0.358625  0.500367  1.009819 -1.139761n7  1.003608  0.246925  0.225138 -0.586727n8  0.355274 -0.540685  1.482472  0.364989n9  3.089610 -1.415088 -0.072107 -0.203137n>>>nn>>> mask = df1.applymap(lambda x: x <-0.7)n>>>n>>> maskn       a      b      c      dn0  False   True  False   Truen1   True  False  False   Truen2  False  False   True   Truen3  False  False  False  Falsen4   True  False  False  Falsen5  False  False  False  Falsen6  False  False  False   Truen7  False  False  False  Falsen8  False  False  False  Falsen9  False   True  False  Falsen>>> mask.any(axis=1)n0     Truen1     Truen2     Truen3    Falsen4     Truen5    Falsen6     Truen7    Falsen8    Falsen9     Truendtype: booln>>> df1 = df1-mask.any(axis=1)n>>> df1n          a         b         c         dn3 -0.635962 -0.291226  0.428961  1.158153n5  0.112911  0.351649  0.788940  2.071541n7  1.003608  0.246925  0.225138 -0.586727n8  0.355274 -0.540685  1.482472  0.364989n>>>nnnIn spark i gone though df.filter but its trying pick only matched   but in my case i need to filter(remove) data into 3 -4 level. only one level i shown above.  which is kind of filtering. n"" 'Preserving order is very difficult in Spark applications due to the assumptions of the RDD abstraction. The best approach you can take is to translate the pandas logic using the Spark api like I've done here. Unfortunately I do not think you can apply the same filter criteria to every column so I had to manually translate the mask into operations on multiple columns. This Databricks blog post is helpful for anyone transitioning from Pandas to Spark. nnimport pandas as pdnimport numpy as npnnp.random.seed(1000)ndf1 = pd.DataFrame(np.random.randn(10 4) columns='a' 'b' 'c' 'd')nmask = df1.applymap(lambda x: x <-0.7)ndf2 = df1-mask.any(axis=1)nnnThe result we want is: nn          a         b         c         dn1 -0.300797  0.389475 -0.107437 -0.479983n5 -0.334835 -0.099482  0.407192  0.919388n6  0.312118  1.533161 -0.550174 -0.383147n8 -0.326925 -0.045797 -0.304460  1.923010nnnSo in Spark we create the dataframe using the Pandas data frame and use filter to get the correct result set: nndf1_spark = sqlContext.createDataFrame(df1).repartition(10)ndf2_spark = df1_spark.filter(n   (df1_spark.a > -0.7)n & (df1_spark.b > -0.7)n & (df1_spark.c > -0.7)n & (df1_spark.d > -0.7)n )nnnWhich gives us the proper result (notice the order is not preserved): nndf2_spark.show()n+-------------------+--------------------+--------------------+-------------------+n|                  a|                   b|                   c|                  d|n+-------------------+--------------------+--------------------+-------------------+n|-0.3348354532115408| -0.0994816980097769| 0.40719210034152314|  0.919387539204449|n| 0.3121180100663634|  1.5331610653579348| -0.5501738650283003|-0.3831474108842978|n|-0.3007966727870205|  0.3894745542873072|-0.10743730169089667|-0.4799830753607686|n| -0.326924675176391|-0.04579718800728687| -0.3044600616968845|  1.923010130400007|n+-------------------+--------------------+--------------------+-------------------+nnnIf you absolutely needed to create the mask using Pandas you would have to preserve the index of the original Pandas dataframe and remove individual records from the Spark by creating a broadcast variable and filtering based on the index column. Here's an example YMMV. nnAdd an index: nndf1'index_col' = df1.indexnndf1n          a         b         c         d  index_coln0 -0.804458  0.320932 -0.025483  0.644324          0n1 -0.300797  0.389475 -0.107437 -0.479983          1n2  0.595036 -0.464668  0.667281 -0.806116          2n3 -1.196070 -0.405960 -0.182377  0.103193          3n4 -0.138422  0.705692  1.271795 -0.986747          4n5 -0.334835 -0.099482  0.407192  0.919388          5n6  0.312118  1.533161 -0.550174 -0.383147          6n7 -0.822941  1.600083 -0.069281  0.083209          7n8 -0.326925 -0.045797 -0.304460  1.923010          8n9 -0.078659 -0.582066 -1.617982  0.867261          9nnnConvert the mask into a Spark broadcast variable: nnmyIdx = sc.broadcast(df2.index.tolist())nnnCreate and modify the dataframes using the Spark api: nndf1_spark.rdd.filter(lambda row: row and row'index_col' not in myIdx.value).collect()ndf2_spark = df1_spark.rdd.filter(lambda row: row and row'index_col' in myIdx.value).toDF()nndf2_spark.show()n+-------------------+--------------------+--------------------+-------------------+---------+n|                  a|                   b|                   c|                  d|index_col|n+-------------------+--------------------+--------------------+-------------------+---------+n|-0.3007966727870205|  0.3894745542873072|-0.10743730169089667|-0.4799830753607686|        1|n|-0.3348354532115408| -0.0994816980097769| 0.40719210034152314|  0.919387539204449|        5|n| 0.3121180100663634|  1.5331610653579348| -0.5501738650283003|-0.3831474108842978|        6|n| -0.326924675176391|-0.04579718800728687| -0.3044600616968845|  1.923010130400007|        8|n+-------------------+--------------------+--------------------+-------------------+---------+nn'",['pandas'],['pandas']
40133763,"""Django Admin Actions: selected checkboxes don't sum up"" 'i got a Problem with jquery 3.0.0 and django 1.10.nnIn Django Admin when i select checkboxes the number ""0 of x selected"" next to the select field does not change and a js error is raised:nReferenceError: interpolate is not definednadmin/static/admin/js/actions.js Line 47 Can't find variable: interpolaten' nan",['django'],['django']
40134026,"'Adding data to a Python list' ""I've just started playing around with python lists I've written the simple code below expecting the printed file to display the numbers 121416182022 but only 22 is displayed. Any help would be great.nna=10nb=14nwhile a <= 20:n    a=a+2n    b=b-1n    datapoints=n    datapoints.insert(0a)nprint datapointsnn"" 'a=10nb=14ndatapoints=  # this needs to be established outside of your loopnnwhile a <= 20:n    a=a+2n    b=b-1n    datapoints.append(a)nprint datapointsnnnYou need to set up datapoints outside your loop and then inside your loop append each additional datum to datapointsn' 'Joel already answered but if you want a more compact code you can use rangennnumbers = nfor number in range(12242):n    # do whatevery you want with bn    numbers.append(number)nnprint numbersnnnor if you only want to print the numbers you can donnprint number for number in range(12242)nn' 'you can achieve the expected list as output by using the range() method. It takes three parameters start stop and step. nndata_points = range(12 23 2)  # range returns list in python 2nprint data_pointsnnnNote that in python 3 the range() is a sequence-type. So you will have to cast it to list in python 3nndata_points = list(range(12 23 2))  # python 3nprint(data_points) nn'",['python-2.7'],"['list', 'python-3.x']"
40134313,"'Conditionally calculated column for a Pandas DataFrame' ""I have a calculated column in a Pandas DataFrame which needs to be assigned base upon a condition.  For example:nnif(data'column_a' == 0):n    data'column_c' = 0nelse:n    data'column_c' = data'column_b'nnnHowever that returns an error:nnnValueError: The truth value of a Series is ambiguous. Use a.empty a.bool() a.item() a.any() or a.all().nnnI have a feeling this has something to do with the fact that is must be done in a matrix style.  Changing the code to a ternary statement doesn't work either:nndata'column_c' = 0 if data'column_a' == 0 else data'column_b'nnnAnyone know the proper way to achieve this?  Using apply with a lambda?  I could iterate via a loop but I'd rather keep this the preferred Pandas way.n"" ""You can do:nndata'column_c' = data'column_a'.where(data'column_a' == 0 data'column_b')nnnthis is vectorised your attempts failed because the comparison with if doesn't understand how to treat an array of boolean values hence the errornnExample:nnIn 81:ndf = pd.DataFrame(np.random.randn(53) columns=list('abc'))ndfnnOut81:n          a         b         cn0 -1.065074 -1.294718  0.165750n1 -0.041167  0.962203  0.741852n2  0.714889  0.056171  1.197534n3  0.741988  0.836636 -0.660314n4  0.074554 -1.246847  0.183654nnIn 82:ndf'd' = df'b'.where(df'b' < 0 df'c')ndfnnOut82:n          a         b         c         dn0 -1.065074 -1.294718  0.165750 -1.294718n1 -0.041167  0.962203  0.741852  0.741852n2  0.714889  0.056171  1.197534  1.197534n3  0.741988  0.836636 -0.660314 -0.660314n4  0.074554 -1.246847  0.183654 -1.246847nn"" ""use where() and notnull() nn   data'column_c' = data'column_b'.where(data'column_a'.notnull() 0)nn""",['pandas'],['pandas']
40134421,"'How to solve ""No module named 'cStringIO'"" when importing the logging module in Python 3' 'I'm trying to run the following script named msgpack_checker.py in Python 3:nnimport msgpacknfrom faker import Fakernimport loggingnfrom logging.handlers import RotatingFileHandlernnfake = Faker()nfake.seed(0)nndata_file = ""my_log.log""nnlogger = logging.getLogger('my_logger')nlogger.setLevel(logging.DEBUG)nhandler = RotatingFileHandler(data_file maxBytes=2000 backupCount=10)nhandler.terminator = """"         # Suppress the newline character (only works in Python 3)nlogger.addHandler(handler)nnfake_dicts = {'name': fake.name()} for _ in range(100)nnfor item in fake_dicts:n    dump_string = msgpack.packb(item)n    # print dump_stringn    logger.debug(dump_string)nnunpacker = msgpack.Unpacker(open(data_file))nnprint(""Printing unpacked contents:"")nfor unpacked in unpacker:n    print(unpacked)nnnwhen I run it with Python 2 it prints the following output:nnPrinting unpacked contents:n{'name': 'Joshua Carter'}n10n{'name': 'David Williams'}n10n{'name': 'Joseph Jones'}n10n{'name': 'Gary Perry'}n10n{'name': 'Terry Wells'}n10n{'name': 'Vanessa Cooper'}n10n{'name': 'Michael Simmons'}n10n{'name': 'Nicholas Kline'}n10n{'name': 'Lori Bennett'}n10nnnThe numbers ""10"" I believe come from the logger and should be removed in Python 3 by the handler.terminator = """" command. However if I try to run the script using python3 msgpack_checker.py I get the following error:nnTraceback (most recent call last):n  File ""msgpack_checker.py"" line 3 in <module>n    import loggingn  File ""/home/kurt/Documents/Scratch/logging/__init__.py"" line 26 in <module>n    import sys os time cStringIO traceback warnings weakrefnImportError: No module named 'cStringIO'nnnApparently the logging module tries to import cStringIO directly which no longer exists in Python 3. I've seen fixes which involve importing StringIO from io instead of StringIO but I not sure they would work here. Any suggestions on how to get this script to work in Python 3?n' 'As pointed out in several comments I accidentally left a directory logging in the same directory which is what the error message refers to. After removing that directory I get a different error messagennPrinting unpacked contents:nTraceback (most recent call last):n  File ""msgpack_checker.py"" line 27 in <module>n    for unpacked in unpacker:n  File ""msgpack/_unpacker.pyx"" line 459 in msgpack._unpacker.Unpacker.__next__ (msgpack/_unpacker.cpp:459)n  File ""msgpack/_unpacker.pyx"" line 380 in msgpack._unpacker.Unpacker._unpack (msgpack/_unpacker.cpp:380)n  File ""msgpack/_unpacker.pyx"" line 370 in msgpack._unpacker.Unpacker.read_from_file (msgpack/_unpacker.cpp:370)nTypeError: expected bytes str foundnnnbut that is a separate issue; at least the importing of logging was successful.n'",['python-3.x'],"['python-3.x', 'python-2.7']"
40134453,"'Most efficient way to set value in column based on prefix of the index' 'I have a dataframe like this:nndf = pd.DataFrame(index='pre1_xyz' 'pre1_foo' 'pre3_bar' 'pre3_foo' 'pre10_foo' 'pre10_bar' 'pre10_xyz')nnnto which I want to add a column values whereby the value is determined based on the prefix of the index of the respective row using a function return_something(pref). Right now I implement that as follows:nnimport pandas as pdnimport numpy as npnn# this just returns a random value for the sake of simplicityndef return_something(pref):nn    return np.random.choice(len(pref)+10)nnndf = pd.DataFrame(index='pre1_xyz' 'pre1_foo' 'pre3_bar' 'pre3_foo' 'pre10_foo' 'pre10_bar' 'pre10_xyz')nn# get all the unique prefixesnunique_pref = set(pi.partition('_')0 for pi in df.index)nn# determine the value for each prefixnval_pref = {pref: return_something(pref) for pref in unique_pref}nn# add the values to the dataframenfor prefi vali in val_pref.items():nn    # determine all rows with the same prefixn    rows = rowi for rowi in df.index if rowi.startswith(prefi+'_')nn    df.locrows 'values' = valinnnThat then gives me the desired output:nn           valuesnpre1_xyz        0npre1_foo        0npre3_bar        7npre3_foo        7npre10_foo      13npre10_bar      13npre10_xyz      13nnnQuestion is whether there is anything smarter than this e.g. a solution which avoids creating unique_pref and/or val_pref and/or makes use of set_value which seems to be the fastest solution to add values to a dataframe as discussed in this question.n' ""Because you have repeats of the prefix you want to first separate out the prefix to make sure you don't generate a new random number for the same prefix. Therefore the removal of duplicates is necessary from your prefix list. I did this in a more condensed way by making a new column for the prefix and then using df.prefix.unique(). nndf'prefix' = i.split('_')0 for i in df.indexndf'values' = df.prefix.map(dict(zip(df.prefix.unique()return_something(i) for i in df.prefix.unique())))nn""",['pandas'],['pandas']
40134604,"'How to copy content of a numpy matrix to another?' ""I have a simple question about basics of python and numpy module. I have a function as following:nndef update_x_last(self x):n    self.x_last = xnnnThe class attribute x_last and function argument x are both initialized as of type numpy.matrix and of the same shape. (x.shape = x_last.shape = (41)nnI have noticed that the code above does not copy the content of the argument x to x_last but it makes the object x_last point to the address of x.nnHowever what I want to do is the following:nnnDon't change the address of self.x_lastnCopy only the content of x to self.x_lastnnnWhat is the best way to do this?nnEdit:nthe requirement 'Don't change the address of 'self.x_last' was unimportant for me. The only required behaviour is the second requirement to copy only the content.n"" 'import numpy as npnnself.x_last = np.copy(x)nn' ""If the shapes are the same then any of these meet both of your requirements:nnself.x_last... = xn# or self.x_last() = xn# or self.x_last: = xnnnI'd argue that the first one is probably most clearnnnnLet's take a look at your requirements quickly:nnn  Copy only the content of x to self.x_lastnnnSeems reasonable. This means if that if x continues to change then x_last won't change with itnnn  Don't change the address of self.x_lastnnnThis doesn't buy you anything. IMO this is actively worse because functions using x_last in another thread will see it change underneath them unexpectedly and worse still could work with the data when it is incompletely copied from xn""",['numpy'],['numpy']
40134637,"'Getting column values from multi index data frame pandas' ""I have a multi index data frame shown below:nn    1                2nnpanning  sec        panning     secnn None    5.0        None        0.0n None    6.0        None        1.0nPanning  7.0        None        2.0 n None    8.0        Panning     3.0n None    9.0        None        4.0n Panning  10.0      None        5.0nnnI am iterating over the rows and getting the index wherever there is a value 'panning' in the panning column bynn ide=n for indexrow in dfs.iterrows():n        if row: 'Panning'row: 'Panning' == 'Panning':n               ide.append(row: 'Panning'row: 'Panning' == 'Panning'.index.tolist())nnprint idennnIf I execute the above code I get the output nn121nnnwhich represents the index where the value is panningnnNow I also want to get the corresponding sec value also like for example for row 3 for value panning I would like to get sec value 7.0 along with index 1. I would like OP to benn17.023.0110nnnBasically I need the O/P as combination of the index where the value is panning and the subsequent value in the seconds column.n"" 'df.iterrows() return a Series if you want the original index you need to call the name of that Series such has:nnfor indexrow in df.iterrows():n    print row.namenn' 'consider the pd.DataFrame df in the setup reference belownnmethod 1 nnnxs for cross sectionnany(1) to check if any in rownnnnndf.locdf.xs('Panning' axis=1 level=1).eq('Panning').any(1)nnnnnmethod 2 nnnstacknquerynunstacknnnnndf.stack(0).query('Panning == ""Panning""').stack().unstack(-2 -1)nnnnnnnTo return just the sec columnsnndf.xs('sec' axis=1 level=1)df.xs('Panning' axis=1 level=1).eq('Panning').any(1)nnnnnsetupnReferencennfrom StringIO import StringIOnimport pandas as pdnntxt = """"""None    5.0        None        0.0nNone    6.0        None        1.0nPanning  7.0        None        2.0 nNone    8.0        Panning     3.0nNone    9.0        None        4.0nPanning  10.0      None        5.0""""""nndf = pd.read_csv(StringIO(txt) delim_whitespace=True header=None)nndf.columns = pd.MultiIndex.from_product(1 2 'Panning' 'sec')ndfnnnn'",['pandas'],['pandas']
40134664,"'problems dealing with pandas read csv' 'I've got a problem with pandas read_csv. I had a many txt files that associate with stock market.It's like this:nnSecCodeSecNameTdateTtimeLastCloseOPCPTqTmTtCqCmCtHiPLoPSYL1SYL2Rf1Rf2bss5s4s3s2s1b1b2b3b4b5sv5sv4sv3sv2sv1bv1bv2bv3bv4bv5bsratiospdrpddepth1depth2  n600000æµ¦åx8fx91éx93¶è¡x8c201201040915018.490.000.0000.00000.0000.000.000.000.000.000.000 .000.000.000.0008.6008.600.000.000.000.00000001100110038900000.00.000.00.00.00n600000æµ¦åx8fx91éx93¶è¡x8c201201040915068.490.000.0000.00000.0000.000.000.000.000.000.000 .000.000.000.0008.5208.520.000.000.000.0000000567955679533605000.00.000.00.00.00n600000æµ¦åx8fx91éx93¶è¡x8c201201040915118.490.000.0000.00000.0000.000.000.000.000.000.000 .000.000.000.0008.5208.520.000.000.000.0000000567955679534605000.00.000.00.00.00n600000æµ¦åx8fx91éx93¶è¡x8c201201040915518.490.000.0000.00000.0000.000.000.000.000.000.000 .000.000.000.0008.5208.520.000.000.000.0000000567955679535205000.00.000.00.00.00n600000æµ¦åx8fx91éx93¶è¡x8c201201040916218.490.000.0000.00000.0000.000.000.000.000.000.000 .000.000.000.0008.5208.520.000.000.000.0000000577955779534205000.00.000.00.00.00nnnwhile I use this code to read it :nnfields = 'SecCode' 'Tdate''Ttime''LastClose''OP''CP''Rf1''Rf2'  ndf = pd.read_csv('SHL1_TAQ_600000_201201.txt'usecols=fields)nnnBut I got a problem: nnTraceback (most recent call last):n  File ""E:/workspace/Senti/highlevel/highlevel.py"" line 8 in <module>n    df = pd.read_csv('SHL1_TAQ_600000_201201.txt'usecols=fieldsheader=1)n  File ""D:Anaconda2libsite-packagespandasioparsers.py"" line 562 in parser_fn    return _read(filepath_or_buffer kwds)n  File ""D:Anaconda2libsite-packagespandasioparsers.py"" line 315 in _readn    parser = TextFileReader(filepath_or_buffer **kwds)n  File ""D:Anaconda2libsite-packagespandasioparsers.py"" line 645 in __init__n    self._make_engine(self.engine)n  File ""D:Anaconda2libsite-packagespandasioparsers.py"" line 799 in _make_enginen    self._engine = CParserWrapper(self.f **self.options)n  File ""D:Anaconda2libsite-packagespandasioparsers.py"" line 1257 in __init__n    raise ValueError(""Usecols do not match names."")nValueError: Usecols do not match names.nnnI can't find any problem similar to mine.And also it's wired when I copy the txt file into another one the code runs wellbut the original one cause the above problem.How can I solve it ?n' 'Use names instead of usecols while specifying parameter.n' ""In your message you said that you're a running:nndf = pd.read_csv('SHL1_TAQ_600000_201201.txt'usecols=fields)nnnWhich did not throw an error for me and @Anil_M. But from your traceback it is possible to see that the command used is another one:nndf = pd.read_csv('SHL1_TAQ_600000_201201.txt'usecols=fields header=1)nnnwhich includes a header=1 and it throws the error mentioned.nnSo I would guess that the error comes from some confusion on your code.n""",['pandas'],['pandas']
40134745,'Making a quiver plot from .dat files' 'Hi I am trying to make a quiver (vector field) plot from data that is stored in .dat files.  I have 4 .dat files which are 1D arrays one for the x axis y axis f(xy) along x and f(xy) along y.nnNote I am able to construct a quiver plot without importing data from .dat files I just followed this basic example here.  nnHowever I am unable to apply this basic example to my example in which I need to import the data from .dat files.  My code is below I am not getting any error messages but I am getting a blank quiver plot.  Any help/suggestions would be greatly appreciated thanks!nnimport numpy as npnimport matplotlib.pyplot as pltnnn=12nndata0 = np.genfromtxt('xaxis.dat')ndata1 = np.genfromtxt('yaxis.dat')ndata2 = np.genfromtxt('fx.dat')ndata3 = np.genfromtxt('fy.dat')nnx  = data00ny  = data10nfx = data20nfy = data30nnplt.axes(0.025 0.025 0.95 0.95)nplt.quiver(xyfxfy alpha=.5)nplt.quiver(xyfxfyedgecolor='k'facecolor='none' linewidth=.5)nnplt.xlim(-1n)nplt.xticks(())nplt.ylim(-1n)nplt.yticks(())nnplt.show()nn' 'In the example for the quiver plot you provided all X Y U and V are 2D arrays with shape (nn).nnIn your example you are importing an array of values for x y fx and fy and then selecting only the first line with 0.nnWhen using the code:nnimport numpy as npnimport matplotlib.pyplot as pltnnn=3 # number of points changed itnndata0 = np.genfromtxt('xaxis.dat')ndata1 = np.genfromtxt('yaxis.dat')ndata2 = np.genfromtxt('fx.dat')ndata3 = np.genfromtxt('fy.dat')nnx  = data00ny  = data10nfx = data20nfy = data30nnplt.axes(0.025 0.025 0.95 0.95) # position of bottom left point of graph inside window and its sizenplt.quiver(xyfxfy alpha=.5) # draw inside of arrows half transparentnplt.quiver(xyfxfyedgecolor='k'facecolor='none' linewidth=.5) # draw contours of arrowsnnplt.xlim(-1n) # left and right most values in the x axisnplt.xticks(()) # remove the numbers from the x axisnplt.ylim(-1n) # ...nplt.yticks(()) # ...nnplt.show()nnnI get:nnWith 0 1 2 0 1 2 0 1 2 in xaxis.dat and fx.dat 0 0 0 1 1 1 2 2 2 in yaxis.dat and 1 1 1 2 2 2 3 3 3 in fy.dat.nIf I just remove the 0 from the arrays assignment I get:nnwith all points shown.nnOne change I would make is to use plt.xlim(min(x)-1max(x)+1) and plt.ylim(min(y)-1max(y)+1) to ensure you get to view the right area of the graph. For instance if I make all four arrays equal to np.random.rand(10) (a 1D array with 10 random elements between 0 and 1) I get:nnnNotes on array formatnnThe plt.quiver will also accept the arrays in the format:nnx  = 0 1 2 # 1D array (list actually...)ny  = 0 1 2nfx = 0 1 2n      0 1 2n      0 1 2 # 2D arraynfy = 0 0 0n      1 1 1n      2 2 2nnnnBut not if all arrays are 1D:nnfx = np.array(fx).flatten()nfy = np.array(fy).flatten()nnnnnPrevious answer (wrong)nnfirst two paragraphs...nnThis means you probably noticed genfromtxt returns a 2D array (as it is able to import several columns from a single file so the returned array will mimic the 2D structure of your file if nothing else is told) making data00 the first line on your document xaxis.dat.nnEDIT: the sentence below is erroneous plt.quiver can receive 1D arrays just in the right shape.nnHowever the quiver expects 2D arrays from where it will retrieve the values for each point: for point ij the position will be (Xij Yij) and the arrow will be (Uij Vij).nnIf you have the repeated values for x and y in the file like this:nnnxaxis.dat:nn0 1 2 0 1 2 0 1 2nyaxix.dat:nn0 0 0 1 1 1 2 2 2nnnYou can just reshape all four of your arrays to (# points in x # points in y) and it should work out.nnIf you don't you will have to use something similar to np.mgrid (or np.meshgrid) to make a valid combination of X and Y arrays and format fx and fy accordingly.n',['matplotlib'],"['matplotlib', 'numpy']"
40134810,"'cast numpy array into memmap' ""I generate some data in my memory and I want to cast it into numpy.memmap to save up RAM. What should I do? my data is in:nn    X_list_total_standardized=np.array(X_list_total_standardized)nnnI know that I could initialize an empty numpy.memmap:nnX_list_total_standardized_memmap=np.memmap(self._prepared_data_location_npmemmap_Xdtype='float32'mode='w+')nnnWhat is the most convenient way to store X_list_total_standardized into the memmap? Thank younnPS: would the following command be ok?nn    X_list_total_standardized_memmap:=X_list_total_standardized:nn"" ""I found next example in numpy documentation :nndata = np.arange(12 dtype='float32')ndata.resize((34))nfp = np.memmap(filename dtype='float32' mode='w+' shape=(34))nfp: = data:nnnSo your last command is ok.n""",['numpy'],['numpy']
40134811,"'Issues with try/except attempting to convert strings to integers in pandas data frame where possible' ""I made a function to clean up any HTML code/tags from strings in my dataframe. The function takes every value from the data frame cleans it with the remove_html function and returns a clean df. After converting the data frame to string values and cleaning it up I'm attempting to convert where possible the values in the data frame back to integers. I have tried try/except but don't get the result that I want. This is what I have at the moment:nndef clean_df(df):n    df = df.astype(str)n    list_of_columns = list(df.columns)n    for col in list_of_columns:n        column = n        for row in list(dfcol):n            column.append(remove_html(row))n            try:n                return int(row)n            except ValueError:n                passnn        del dfcolnn        dfcol = columnnn    return dfnnnWithout the try/except statements the function returns a clean df where the integers are strings. So its just the try/except statement that seems to be an issue. I've tried the try/except statements in multiple ways and none of them return a df. The current code for example returns an 'int' object.n"" 'insert the columm.append into the try:nnfor col in list_of_columns:n    column = n    for row in list(dfcol):n        try:n            column.append(remove_html(row))n        except ValueError:n            passnn    del dfcolnn    dfcol = columnnnreturn dfnn' 'consider the pd.DataFrame dfnndf = pd.DataFrame(dict(A=1 '2' '_' '4'))nnnnnYou want to use the function pd.to_numeric...nNotenpd.to_numeric operates on scalars and pd.Series.  It doesn't operate on a pd.DataFramenAlsonUse the parameter errors='coerce' to get numbers where you can and NaN elsewhere.nnpd.to_numeric(df'A' 'coerce')nn0    1.0n1    2.0n2    NaNn3    4.0nName: A dtype: float6nnnOr to get numbers where you can and what you already had elsewherennpd.to_numeric(df'A' 'coerce').combine_first(df'A')nn0    1n1    2n2    _n3    4nName: A dtype: objectnnnyou can then assign it back to your dfnndf'A' = pd.to_numeric(df'A' 'coerce').combine_first(df'A')nn' 'Works like this:nndef clean_df(df):ndf = df.astype(str)nlist_of_columns = list(df.columns)nfor col in list_of_columns:n    column = n    for row in list(dfcol):n        try:n            column.append(int(remove_html(row)))n        except ValueError:n            column.append(remove_html(row))nn    del dfcolnn    dfcol = columnnnreturn dfnn' 'Use the try/except in a function and use that function with DataFrame.applymap()nndf = pd.DataFrame('a''b''1'n                   '2''c''d'n                   'e''3''f')ndef foo(thing):n    try:n        return int(thing)n    except ValueError as e:n        return thingnn>>> df02n'e'n>>> df01n'2'n>>> df = df.applymap(foo)n>>> df02n'e'n>>> df01n2n>>>nn'",['pandas'],['pandas']
40134832,"'Python: Cast int to double' ""I am practicing calling matlab functions from pythonnand I am getting this error that I don't seem to understand how to fix.nnProblem:nTypeError: unsupported operand type(s) for *=: 'double' and 'int'nnThis is my code:nnimport matlab.enginenmat = matlab.engine.start_matlab()nndims = mat.ones(1 3)ndims *= 5 // here is the problemnnprint(dims)nnnI can assume that ones returns a double and 5 is intn    And this changes my problem to casting the int to double.nnI tried using float(5) but then I get this:nTypeError: unsupported operand type(s) for *=: 'double' and 'float'nnHow do I cast an int to a double in python ?n"" nan",['python-2.7'],"['python-3.x', 'python-2.7']"
40134852,"'Metaclass inheritance in Python 2 and Python 3' ""I have following sample code for Python 2.7:nnclass MetaA(type):nn    def __new__(cls name bases attrs):n        print('MetaA::__new__')n        print('CLS:' + str(cls))n        print('Name:' + name)n        print('============================')n        return super(MetaA cls).__new__(cls name bases attrs)nnnclass A(object):n    __metaclass__ = MetaAnnnclass MetaB(type(A)):n    passnnnclass SomeMixin(A):n    passnnnclass B(A):n    __metaclass__ = MetaBnnnclass C(SomeMixin B):n    passnnnAfter executing it I have such output:nnMetaA::__new__nCLS:<class '__main__.MetaA'>nName:An============================nMetaA::__new__nCLS:<class '__main__.MetaA'>nName:SomeMixinn============================nMetaA::__new__nCLS:<class '__main__.MetaB'>nName:Bn============================nMetaA::__new__nCLS:<class '__main__.MetaA'>nName:Cn============================nMetaA::__new__nCLS:<class '__main__.MetaB'>nName:Cn============================nnnThe thing is when class C defined at first method __new__ is invoked for metaclass MetaA (base one) and then for metaclass MetaB invoked.nnIf I change the order of mixin and inherit class in my class C like thisnnclass C(B SomeMixin):nnnthe output is following:nnMetaA::__new__nCLS:<class '__main__.MetaA'>nName:An============================nMetaA::__new__nCLS:<class '__main__.MetaA'>nName:SomeMixinn============================nMetaA::__new__nCLS:<class '__main__.MetaB'>nName:Bn============================nMetaA::__new__nCLS:<class '__main__.MetaB'>nName:Cn============================nnnMethod __new__ for metaclass MetaA not invoked in this case only for metaclass MetaB.nnIf I run almost same code in Python 3 despite of inheritance order in class C method __new__ will be invoked only for metaclass MetaA.nnCould someone please explain why this happens and what was changed in Python 3 in terms of this behavior?nnThanks!n"" nan",['django'],"['python-2.7', 'python-3.x']"
40134859,'Django says there are no changes to be made when I migrate' 'I'm attempted to create a database for a fictional school. Unfortunatley when I try to migrate the tables this happens:nnC:Python34ScriptsschoolDatabase>manage.py makemigrations schoolnnC:Python34ScriptsschoolDatabase>python manage.py makemigrations schoolnNo changes detected in app 'school'nnThis is the model I am referring to:nnTYPE_OF_PERSON = (n('T' 'Teacher')n('S' 'Student')) nDETENTION_COMPLETED = (n('Y' 'Yes')n'N' 'No'nOUTCOME = (n('P' 'Pass')n('F' 'Fail')n)nclass Person:nfirst_name = models.CharField(max_length = 25)nsurname = models.CharField(max_length = 25)naddress = models.CharField(max_length = 45)nyear_group = models.CharField(max_length = 10)nform = models.CharField(max_length = 15)ntype_of_person = models.CharField(choices = TYPE_OF_PERSON)nperson_id = models.CharField(primary_key = True)nnclass Subject:nname = models.CharField(max_length = 25)nclass SchoolClass:nclass_id = models.IntegerField(primary_key = True)nperson_id = models.ForeignKey('Person')nsubject = models.ForeignKey('Subject')nyear_group = models.ForeignKey('Person')nnclass Attendance:nschool_class = models.ForeignKey('SchoolClass')ndate = models.DateField()nstart_time = models.TimeField()nend_time = models.TimeField()nperson_id = models.ForeignKey('Person')nnclass Assignment:nassignment_id = models.IntegerField(primary_key = True)nsubject = models.ForeignKey('Subject')nschool_class = models.ForeignKey('SchoolClass')nteacher = models.ForeignKey('Person')ndescription =models.TextField()ndate_set = models.DateField()ndue_date = models.DateField()nmark = models.CharField(max_length = 20)ncomments = models.TextField()nnclass Detention:ndetention_date = models.DateField()nstudent_id = models.ForeignKey('Person')nreason = models.CharField(max_length = 30)ncompleted = models.CharField(choices = DETENTION_COMPLETED)nnclass Exam:nexam_id = models.IntegerField(primary_key = True)nsubject = models.ForeignKey('Subject')npaper = models.CharField(max_length = 30)nscore = models.CharField(max_length = 20)noutcome = models.CharField(choices = OUTCOME)nnnI heard that if managed was set to False then Django won't create tables when you migrate but I don't know how to set it to True. nnWhen I typed in:nnmanage.py inspectdb it showed me that managed was set to False but how do I change it to True so that my database will be migrated?nnHere is the traceback:nnC:Python34ScriptsschoolDatabase>manage.py makemigrations schoolnnC:Python34ScriptsschoolDatabase>python manage.py makemigrations schoolnNo changes detected in app 'school'nn                                                                                                                          class DjangoMigrations(models.Model):                              id = models.IntegerField(primary_key=True)  # AutoField?       app = models.CharField(max_length=255)                         name = models.CharField(max_length=255)                        applied = models.DateTimeField()                                                                                              class Meta:                                                        managed = False                                                db_table = 'django_migrations'                         nnnHere is the tree:nnnnnSorry about the poor formatting but stackoverflow won't let me put it in the code block. nnAny help would be appreciated. nnSettings.py:nnINSTALLED_APPS =n'django.contrib.admin'n'django.contrib.auth'n'django.contrib.contenttypes'n'django.contrib.sessions'n'django.contrib.messages.'n'django.contribe.staticfiles'n'school'nnn' 'Your models should derive from models.Model:nn class Person(models.Model):n ...n class Subject(models.Model):n ...n ...nn',['django'],['django']
40134943,'2 shells 1 cup. Sharing a queue between 2 Python scripts on Raspberry Pi' 'I have 2 Python scripts on a Raspberry Pi 1 runs in a background shell emptying a queue the other runs in the foreground adding user inputs to the queue. I've build a version where the queue is stored as a SQLite database and in order to make this work each script has to connect to the database before each operation and disconnect afterwards which avoids locking conflict but slows the process down significantly. This overhead means I am actually able to hammer the inputs fast enough to confuse the script and make it miss/ignore some inputs. Is a single SQLite datbase the fastest method for storing my shared queue or is there some faster alternative (possibly one that uses RAM instead of writing to disk) that both scripts can access quicker? nn(Note: I'm open to drastic suggestions like switching language to NodeJS)nnI didn't post the code because it's more a question of appropriate technology for the job but if you want to see my current repo it's at https://github.com/martinjoiner/bookfetch-scanner-python n' nan,['python-2.7'],['python-2.7']
40135001,"'getting an average of values from dictionaries with keys with a list of values' 'For my final python assignment at my university I need to create functions within Jupyter Notebook to conduct a small research. I need to create dictionaries and lists from .csv files and build functions for the dictionaries that I get from my read_csv() function. For this assignment I am allowed to ask and google because the functions I have to make are fairly common problems people walk into.nnThe way these dictionaries look like after my read_csv() returns them is as follows:nndata_dict = { ""abc"" : 1 2 3 4n              ""def"" : 4 5 6 7n              ""ghi"" : 8 9 10 11n            }nnnSo basically a dictionary with a large amount of keys with each a list of values. What I need to do is sum up all the numbers of the first index of each list and get the average from the sum then the second index third index and so on returning a list of all averages. With the result being something like:nnaverages = 4.333 5.333 6.333 7.333nnnHow would one go about this without importing anything? In the past weeks we haven't really talked about working with dictionaries and I've tried looking for solutions on the internet but couldn't find any dealing with summing up integers or floats at specific indexes from different lists.n' ""zip the values to get the columns and divide each column's sum by its len.n"" ""First collect the values transpose them and then its easy:nn# values of the dictnvalues = data_dict.values()nn# transposed averagenaverages = sum(x)/float(len(x)) for x in zip(*values)nprint (averages)nnnreturns:nn4.333333333333333 5.333333333333333 6.333333333333333 7.333333333333333nnnA shorter 'less-explanatory' one-liner would be:nnaverages = sum(x)/float(len(x)) for x in zip(*data_dict.values())nn"" 'One approach could be:nndata_dict = { ""abc"" : 1 2 3 4n              ""def"" : 4 5 6 7n              ""ghi"" : 8 9 10 11n            }nnprint data_dictnfor i in data_dict:n    sum_items = 0n    num_items = 0n    for j in data_dicti:n        num_items += 1n        sum_items += jn    print data_dictin    print sum_itemsn    print sum_items/num_itemsnn'","['list', 'python-2.7', 'dictionary']","['dictionary', 'list']"
40135106,"""TypeError: __init__() got an unexpected keyword argument 'current_app' Django"" 'I just uploaded my app into a production server (Centos7) with migrations  via Gitlab and everything works fine the problem here is that once I want to access through the browser I get this error on my logs:nnFile ""/usr/lib/python2.7/site-packages/django/shortcuts/__init__.py"" line 49 in rendern    context_instance = RequestContext(request current_app=current_app)nTypeError: __init__() got an unexpected keyword argument 'current_app'nnnThe weird thing is that everything works properly in my local machine and I can run it without any issue the only difference in the server side is that I run the server with production-settings (with a configuration for a production server)nnHint: if I run funtions through url everything runs properly seems the problem is that every time it goes into the ""return render"" I get that message too.nnThanks for your attentionn' nan",['django'],['django']
40135179,"'Django: create database tables programmatically/dynamically' 'I've been working on a Django app for some time now and have encountered a need for dynamic model and database table generation. I've searched far and wide and it seems as though the Django API does not include this function. From what I have gathered South has a function to do this (i.e. south.db.create_table). However from what I have gathered from South's release notes South is not compatible with Django 1.7 and higher and my project was built using Django 1.9. nnI have already written a script that creates model instances of the schema I would like to migrate to my database using the following method:nnattrs = {'__module__':model_location 'Meta':Meta}nmodel = type(table_name (models.Model) attrs)nnnp.s. please note that this is not the entirety of the mentioned script. If you think this would be useful for me to provide I can add it upon request.nnHas anyone found a workaround for using South 1.0.2 with Django 1.9? If not does anyone have any ideas on how I could achieve this functionality without South? I have tried to think of alternative methods (rather than dynamically generating tables) but this really seems like it would provide the most concise and clean results given the scope of my project.nnThank you!n' 'The reason South is incompatible with recent Django versions is that it has been rolled into Django as of Django 1.7 under the name ""migrations"". If you are looking for similar functionality the starting point would be the documentation on migrations. In particular you may be interested in the section on RunSQL.nnIf you wish to avoid the migrations module you can also perform raw SQL queries.n'",['django'],['django']
40135227,"'Running unit test for websockets in different class in python autobahn' 'I am trying to create some tests in a client for a websocket server using autobahn in python. I basically want to start a client right at the beginning then add multiple test cases which sends messages or process received messages. Below is my code:nn class someFunction(WebSocketClientProtocol):nn    def onOpen(self):n        print ""Connection established""nn    def onMessage(self payload isBinary):n        if not isBinary:n            res = json.loads(payload.decode('utf8'))n            print(""Result received: {}"".format(res))n            self.sendClose()nn    def onClose(self wasClean code reason):n        if reason:n            print(reason)n        reactor.stop()nnclass NLVRTR(TestFixture someFunction):nn    @classmethodn    def setUpClass(cls):        n        log.startLogging(sys.stdout)n        factory = WebSocketClientFactory(u""ws://someURL:8078"")n        factory.protocol = someFunctionn        reactor.connectTCP(""someURL"" 8078 factory)n        wsThread = threading.Thread(target = reactor.run kwargs={'installSignalHandlers':0})n        wsThread.start()nn    def test_00_simple(self):n        WSJsonFormatter = WSformat()n        x = WSJsonFormatter.formatGetInfo(122)n        self.sendMessage(json.dumps(x).encode('utf8'))n        print(""Request {} sent."".format(x))nnnWhen I go to run this I get the following error:nnAttributeError: 'NLVRTR' object has no attribute 'state'nnnI'm assuming that when it runs my test when it reaches  nnself.sendMessage(json.dumps(x).encode('utf8'))nnnthat it does not see the protocol that I started the client with and thus it thinks that a connection was never established. Is this correct? if so then how would I go about calling it from NLVRTR class? if not then what could be the issue and how would I solve this? n' nan",['python-2.7'],"['python-2.7', 'python-3.x']"
40135280,"'How to create a subset of document using lxml?' ""Suppose you have an lmxl.etree element with the contents like:nn<root>n    <element1>n        <subelement1>blabla</subelement1>n    </element1>n    <element2>n        <subelement2>blibli</sublement2>n    </element2>n</root>nnnI can use find or xpath methods to get something an element rendering something like:nn<element1>n    <subelement1>blabla</subelement1>n</element1>nnnIs there a way simple to get:nn<root>n    <element1>n        <subelement1>blabla</subelement1>n    </element1>n</root>nnni.e The element of interest plus all it's ancestors up to the document root?n"" 'I am not sure there is something built-in for it but here is a terrible ""don't ever use it in real life"" type of a workaround using the iterancestors() parent iterator:nnfrom lxml import etree as ETnndata = """"""<root>n    <element1>n        <subelement1>blabla</subelement1>n    </element1>n    <element2>n        <subelement2>blibli</subelement2>n    </element2>n</root>""""""nnnroot = ET.fromstring(data)nelement = root.find("".//subelement1"")nnresult = ET.tostring(element)nfor node in element.iterancestors():n    result = ""<{name}>{text}</{name}>"".format(name=node.tag text=result)nnprint(ET.tostring(ET.fromstring(result) pretty_print=True))nnnPrints:nn<root>n  <element1>n    <subelement1>blabla</subelement1>n  </element1>n</root>nn' 'The following code removes elements that don't have any subelement1 descendants and are not named subelement1.nnfrom lxml import etreenntree = etree.parse(""input.xml"")  # First XML document in questionnnfor elem in tree.iter():n    if elem.xpath(""not(.//subelement1)"") and not(elem.tag == ""subelement1""):n        if elem.getparent() is not None:n            elem.getparent().remove(elem)nnprint etree.tostring(tree) nnnOutput:nn<root>n  <element1>n    <subelement1>blabla</subelement1>n  </element1>n  </root>nn'",['python-2.7'],['python-2.7']
40135459,"'Reading a text file using Pandas where some rows have empty elements?' 'I have a dataset in a textfile that looks like this.nn    0    0CF00400 X       8  66  7D  91  6E  22  03  0F  7D       0.021650 Rn    0    18EA0080 X       3  E9  FE  00                           0.022550 Rn    0    00000003 X       8  D5  64  22  E1  FF  FF  FF  F0       0.023120 RnnnI read this usingnnfile_pandas = pd.read_csv(fileName delim_whitespace = True header = None engine = 'python')nnnAnd got the outputnn    0   0  0CF00400  X   8  66  7D  91        6E  22    03    0F    7D  0.02165   n    1   0  18EA0080  X   3  E9  FE   0  0.022550   R  None  None  None      NaN   n    2   0  00000003  X   8  D5  64  22        E1  FF    FF    FF    F0  0.02312   nnnBut I want this read asnn    0   0  0CF00400  X   8  66  7D  91        6E  22    03    0F    7D  0.021650   R  n    1   0  18EA0080  X   3  E9  FE  00                                  0.022550   Rn    2   0  00000003  X   8  D5  64  22        E1  FF    FF    FF    F0  0.023120   RnnnI've tried removing delim_whitespace = True and replacing it with delimiter = ""  "" but that just combined the first four columns in the output shown above but it did parse the rest of the data correctly meaning that the rest of the columns were like the origin txt file (barring the NaN values in whitespaces).nnI'm not sure how to proceed from here. nnSide note: the 00 is being parsed as only 0. Is there a way to display 00 instead?n' 'It seems like your data is fixed width columns you can try pandas.read_fwf():nnfrom io import StringIOnimport pandas as pdnndf = pd.read_fwf(StringIO(""""""0    0CF00400 X       8  66  7D  91  6E  22  03  0F  7D       0.021650 Rn0    18EA0080 X       3  E9  FE  00                           0.022550 Rn0    00000003 X       8  D5  64  22  E1  FF  FF  FF  F0       0.023120 R"""""") n                 header = None widths = 1122844444444162)nnnn'",['pandas'],['pandas']
40135464,'Django âx80x93 remove trailing zeroes for a Decimal in a template' 'Is there a way to remove trailing zeros from a Decimal field in a django template? nnThis is what I have: 0.0002559000 and this is what I need: 0.0002559. nnThere are answers suggesting to do this using floatformat filter:nn{{ balance.bitcoins|floatformat:3 }}nnnHowever floatformat performs rounding (either down or up) which is unwanted in my case as I only need to remove trailing zeros without any rounding at all.n' 'The solution is to use normalize() method of a Decimal field:nn{{ balance.bitcoins.normalize }}nn',['django'],['django']
40135550,'Update the data for each cell in a database' 'I need some help with updating the data into the database.nnI am adding the list of button object controls to get the button ids so I can adding them in a database. There are 10 button ids for per channel from the first top ten programs.nnI am trying to find the matched string in a database so I could replace them with a empty string before I could find the next string to replace with the strings that start with 3002 to 3009 to replace it with the strings from 3001 to 3010 for each cell.nnHere is what I use:nnprogram_id = ''.join(str(x) for x in self.program_id)nprogramX = self.getControl(int(program_id)).getX()nprogram_width = self.getControl(int(program_id)).getWidth()nnif int(programX) == 375 and int(program_width) >= 342 and int(program_width) <= 344: n    get_id = int(program_id) + 1n    empty_string = ''n    cur.execute('UPDATE programs SET program_id=? WHERE program_id=?' program_id empty_string)n    con.commit()nnnWhen I try the code on above it will insert the data on every cell in a database which is not what I want.nnI want to find the string of 3001 to replace it with a empty string then find the next string 3002 to replace it with 3001 find the string 3003 to replace it with 3002 find the string 3004 to replace it with 3003 find the string 3005 to replace it with 3004 and so on until I insert the 3010 data in a new cell just after the string 3009. nnJust like this:nnhttp://i.imgur.com/ZUK6ATG.jpgnnI have got no idea how I can search for the strings that I want to find them in a database before I could replace them with the empty string and then replace with the following strings that I want to replace that start from 3001 to 3010 in every cell.nnDo you know how I could find the string in a database using the variable program_id to replace them with a empty string and then find the next string to replace it with the string that start from 3001 to 3010 in each cell?n' nan,['python-2.7'],['python-2.7']
40135578,"'Loading Tensorflow inception_V3 error' 'So I am atrying to load a pretrained inception_V3 model in tensorflow so that I can get image feature embeddings.nHowever when I try and build the inception model I get the following error:nnFailedPreconditionError (see above for traceback): Attempting to use uninitialized value InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variancen Node: InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance/read = IdentityT=DT_FLOAT _class=""loc:@InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance"" _device=""/job:localhost/replica:0/task:0/cpu:0""(InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance)nnnThe code for building the model and embedding the images:nnclass VidCapModel(object):ndef __init__(self config mode train_inception=False):n    """"""n    Basic setup.nn    Args:n      config: Object containing configuration parameters.n      mode: ""train"" ""eval"" or ""inference"".n      train_inception: Whether the inception submodel variables are trainable.n    """"""n    assert mode in ""train"" ""eval"" ""inference""n    self.config = confign    self.mode = moden    self.train_inception = train_inceptionn    self.batchSize = config.batchSizen    self.vocab = config.vocabnnn    # To match the ""Show and Tell"" paper we initialize all variables with an    # random uniform initializer.n    self.initializer = tf.random_uniform_initializer(n        minval=-self.config.initializer_scalen        maxval=self.config.initializer_scale)nn    # A float32 Tensor with shape batch_size height width channels.n    self.images = tf.placeholder(dtype=tf.float32 n                                 shape=config.batchSizen                                        config.heightn                                        config.widthn                                        config.channelsn                                 name=""images"")nnn    # An int32 Tensor with shape batch_size vocab.n    self.target_seqs = tf.placeholder(dtype=tf.int32 n                                      shape=self.batchSize self.vocab )nnn    # A float32 Tensor with shape batch_size embedding_size.n    self.image_embeddings = Nonennn    # A float32 scalar Tensor; the total loss for the trainer to optimize.n    self.total_loss = Nonenn    # A float32 Tensor with shape batch_size * padded_length.n    self.target_cross_entropy_losses = Nonenn    # A float32 Tensor with shape batch_size * padded_length.n    self.target_cross_entropy_loss_weights = Nonenn    # Collection of variables from the inception submodel.n    self.inception_variables = nn    # Function to restore the inception submodel from checkpoint.n    self.init_fn = Nonenn    # Global step Tensor.n    self.global_step = Nonenndef is_training(self):n    """"""Returns true if the model is built for training mode.""""""n    return self.mode == ""train""nndef build_image_embeddings(self):n    """"""Builds the image model subgraph and generates image embeddings.nn    Inputs:n      self.imagesnn    Outputs:n      self.image_embeddingsn    """"""n    inception_output = inception_v3(n        self.imagesn        trainable=self.train_inceptionn        is_training=self.is_training())n    self.inception_variables = tf.get_collection(n        tf.GraphKeys.VARIABLES scope=""InceptionV3"")nn    # Map inception output into embedding space.n    with tf.variable_scope(""image_embedding"") as scope:n        image_embeddings = tf.contrib.layers.fully_connected(n        inputs=inception_outputn        num_outputs=self.config.embedding_sizen        activation_fn=Nonen        weights_initializer=self.initializern        biases_initializer=Nonen        scope=scope)nn    # Save the embedding size in the graph.n    tf.constant(self.config.embedding_size name=""embedding_size"")nn    self.image_embeddings = image_embeddingsnndef setup_inception_initializer(self):n    """"""Sets up the function to restore inception variables from checkpoint.""""""n    if self.mode != ""inference"":n        # Restore inception variables only.n        saver = tf.train.Saver(self.inception_variables)nn        def restore_fn(sess):n            tf.logging.info(""Restoring Inception variables from checkpoint file %s""n                        self.config.inception_checkpoint_file)n            saver.restore(sess self.config.inception_checkpoint_file)nn    self.init_fn = restore_fnnndef build(self):n    """"""Creates all ops for training and evaluation.""""""n    self.build_image_embeddings()n    self.setup_inception_initializer()nnnand:nndef inception_v3(imagesn             trainable=Falsen             is_training=Truen             weight_decay=0.00004n             stddev=0.1n             dropout_keep_prob=0.8n             use_batch_norm=Truen             batch_norm_params=Nonen             add_summaries=Truen             scope=""InceptionV3""):n""""""Builds an Inception V3 subgraph for image embeddings.nnArgs:n    images: A float32 Tensor of shape batch height width channels.n    trainable: Whether the inception submodel should be trainable or not.n    is_training: Boolean indicating training mode or not.n    weight_decay: Coefficient for weight regularization.n    stddev: The standard deviation of the trunctated normal weight initializer.n    dropout_keep_prob: Dropout keep probability.n    use_batch_norm: Whether to use batch normalization.n    batch_norm_params: Parameters for batch normalization. Seen      tf.contrib.layers.batch_norm for details.n    add_summaries: Whether to add activation summaries.n    scope: Optional Variable scope.nnReturns:n    end_points: A dictionary of activations from inception_v3 layers.n""""""n# Only consider the inception model to be in training mode if it's trainable.nis_inception_model_training = trainable and is_trainingnnif use_batch_norm:n# Default parameters for batch normalization.n    if not batch_norm_params:n        batch_norm_params = {n          ""is_training"": is_inception_model_trainingn          ""trainable"": trainablen          # Decay for the moving averages.n          ""decay"": 0.9997n          # Epsilon to prevent 0s in variance.n          ""epsilon"": 0.001n          # Collection containing the moving mean and moving variance.n          ""variables_collections"": {n              ""beta"": Nonen              ""gamma"": Nonen              ""moving_mean"": ""moving_vars""n              ""moving_variance"": ""moving_vars""n          }n      }nelse:n    batch_norm_params = Nonennif trainable:n    weights_regularizer = tf.contrib.layers.l2_regularizer(weight_decay)nelse:n    weights_regularizer = Nonennwith tf.variable_scope(scope ""InceptionV3"" images) as scope:n    with slim.arg_scope(n                        slim.conv2d slim.fully_connectedn                        weights_regularizer=weights_regularizern                        trainable=trainable):n        with slim.arg_scope(n                            slim.conv2dn                            weights_initializer=tf.truncated_normal_initializer(stddev=stddev)n                            activation_fn=tf.nn.relun                            normalizer_fn=slim.batch_normn                            normalizer_params=batch_norm_params):n            net end_points = inception_v3_base(images scope=scope)n            with tf.variable_scope(""logits""):n                shape = net.get_shape()n                net = slim.avg_pool2d(net shape1:3 padding=""VALID"" scope=""pool"")n                net = slim.dropout(n                                   netn                                   keep_prob=dropout_keep_probn                                   is_training=is_inception_model_trainingn                                   scope=""dropout"")n                net = slim.flatten(net scope=""flatten"")nn# Add summaries.nif add_summaries:n    for v in end_points.values():n        tf.contrib.layers.summaries.summarize_activation(v)nnreturn netnnnFinally images are fed into the network using a feed_dict witha  list of images as the input batchSizeXheightXwidthXchannelsnn    class Config():n    embedding_size = 512n    batchSize = 12n    numEpochs = 1n    vocab = 12n    initializer_scale = 0.08nn    #imagesn    height = 299n    width  = 299n    channels = 3nn    #inceptionn    inception_checkpoint_file = '/home/eli/im2txt/data/inception_v3.ckpt'nndef runEpoch(session model config dataPath):n    images = n    for batch in frameReader(dataPath config.batchSize):n        for image in batch:n            images.append(np.asarray(image))nn        imageEmbeddings = session.run(model.image_embeddings {model.images: images})nn        for embedding in imageEmbeddings:n            print embeddingnndef getConfig():n    return Config()nndef main():nn    dataPath = 'some/path'nn    config = getConfig()n    mode = 'train'nn    with tf.Graph().as_default() tf.Session() as session:n        m = VidCapModel(config mode train_inception=False)n        m.build()n        for epoch in range(config.numEpochs):n            runEpoch(session m config dataPath)nnnframeReader is a generator which generates a batches of images. nnMy method for building the graph and loading the inception_v3 pretrained weights is taken from https://github.com/tensorflow/models/tree/master/im2txt nnI'm really unsure as to what this error is telling me as it seems to be coming from code within the tensorflow library not my code itself (undoubtedly not the case).nnI'm using python 2.7 with tensorflow 0.11.0rc0 on Ubuntu 14.04nnAny help would be much appreciated!nnFull stack trace:nn    Traceback (most recent call last):n  File ""vidcapMain.py"" line 61 in <module>n    main()n  File ""vidcapMain.py"" line 56 in mainn    runEpoch(session m config dataPath)n  File ""vidcapMain.py"" line 37 in runEpochn    imageEmbeddings = session.run(model.image_embeddings {model.images: images})n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"" line 717 in runn    run_metadata_ptr)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"" line 915 in _runn    feed_dict_string options run_metadata)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"" line 965 in _do_runn    target_list options run_metadata)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"" line 985 in _do_calln    raise type(e)(node_def op message)ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variancen     Node: InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance/read = IdentityT=DT_FLOAT _class=""loc:@InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance"" _device=""/job:localhost/replica:0/task:0/cpu:0""(InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance)nnCaused by op u'InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance/read' defined at:n  File ""vidcapMain.py"" line 61 in <module>n    main()n  File ""vidcapMain.py"" line 54 in mainn    m.build()n  File ""/home/eli/Documents/Workspace/VidCap/vidcap/embedImage.py"" line 212 in buildn    self.build_image_embeddings()n  File ""/home/eli/Documents/Workspace/VidCap/vidcap/embedImage.py"" line 177 in build_image_embeddingsn    is_training=self.is_training())n  File ""/home/eli/Documents/Workspace/VidCap/vidcap/embedImage.py"" line 83 in inception_v3n    net end_points = inception_v3_base(images scope=scope)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/nets/inception_v3.py"" line 302 in inception_v3_basen    scope='Conv2d_0c_1x7')n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"" line 177 in func_with_argsn    return func(*args **current_args)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"" line 441 in convolution2dn    outputs = normalizer_fn(outputs **normalizer_params)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"" line 177 in func_with_argsn    return func(*args **current_args)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py"" line 235 in batch_normn    collections=moving_variance_collections)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"" line 177 in func_with_argsn    return func(*args **current_args)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/variables.py"" line 269 in model_variablen    caching_device=caching_device device=device)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"" line 177 in func_with_argsn    return func(*args **current_args)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/variables.py"" line 233 in variablen    caching_device=caching_device)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"" line 1022 in get_variablen    custom_getter=custom_getter)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"" line 849 in get_variablen    custom_getter=custom_getter)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"" line 345 in get_variablen    validate_shape=validate_shape)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"" line 330 in _true_gettern    caching_device=caching_device validate_shape=validate_shape)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"" line 676 in _get_single_variablen    validate_shape=validate_shape)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"" line 215 in __init__n    dtype=dtype)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py"" line 327 in _init_from_argsn    self._snapshot = array_ops.identity(self._variable name=""read"")n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py"" line 1128 in identityn    result = _op_def_lib.apply_op(""Identity"" input=input name=name)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"" line 749 in apply_opn    op_def=op_def)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"" line 2380 in create_opn    original_op=self._default_original_op op_def=op_def)n  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"" line 1298 in __init__n    self._traceback = _extract_stack()nnFailedPreconditionError (see above for traceback): Attempting to use uninitialized value InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variancen     Node: InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance/read = IdentityT=DT_FLOAT _class=""loc:@InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance"" _device=""/job:localhost/replica:0/task:0/cpu:0""(InceptionV3/Mixed_6d/Branch_2/Conv2d_0c_1x7/BatchNorm/moving_variance)nn' nan",['python-2.7'],['python-2.7']
40136034,'My code works for short bursts of time' 'I am trying to get my python code to run continuously for three weeks. The code will run continuously for a few hours and then get a nnrequests.exceptions.ConnectionError nnnor a nnhttplib.ServerNotFoundErrornnnI know that my code runs because it once ran continuously for 30 hours. nnBackground: My code takes values from scales and puts them in a Google Sheet. The code is running on a Raspberry Pi. I have added except lines for both errors as well as a general except line but the errors still persist.n' nan,['python-2.7'],['python-2.7']
40136155,"'How to combine row elements from table' ""If I have the following table:nntable = '5paa' '3pggg' 'pippo3' 'gigio777'nnnand I want generate for each row all combinations as follows:nn5p3p 5pggg aa3p aaggg pippogigio pippo777 3gigio 3777nnnWhat do you suggest?nnI'm moving the first steps in python scripting.n"" nan",['list'],['python-2.7']
40136283,"'Writing rows in a csv using dictionaries in a loop (python 3)' ""IÂ´m writing on a csv file by adding each row in a loop and using dictionaries. The following is the code:nnfieldnames = 'id' 'variable1' 'variable2'nf = open('file.csv' 'w')   nmy_writer = csv.DictWriter(f fieldnames)nmy_writer.writeheader()nf.close()   nnfor i in something:nn    something where I get data for mydict      nn    with open('file.csv' 'a+b') as f:n    header = next(csv.reader(f))n    dict_writer = csv.DictWriter(f header)n    dict_writer.writerow(mydict)nnnI was sure this code worked for me some years ago but probably I was using python2. Now IÂ´m using python 3 and it shows the following error:nnheader = next(csv.reader(f))nnStopIterationnnnWhat may be the problem? Thanksn"" ""My solution was:nnfieldnames = 'id' 'variable1' 'variable2'nnf= open('file.csv' 'w' newline='')nmy_writer = csv.DictWriter(f fieldnames)nmy_writer.writeheader()nnfor i in something:nn   something where I get data for mydict   nn    writer.writerow(mydict)nnf.close()nn""","['python-3.x', 'dictionary']","['dictionary', 'python-3.x']"
40136285,"'How to expose user passwords in the most ""secure"" way in django?' ""I am working on Django 1.9 project and I have been asked to enable some users to print a page with a list of a set of users and their passwords.nOf course passwords are encrypted and there is no out-of-the-box ways of doing this.nI know this would imply a security breach so my question is kind of contradictory but is there any logical way of doing this that doesn't imply a huge security breach in the software?n"" 'No there is no logical way of doing this that doesn't imply a huge security breach in the software.  nnIf the passwords are stored correctly (salted and hashed) then even site admins with unrestricted access on the database can not tell you what the passwords are in plain text.  nnYou should push back against this unreasonable request.  If you have a working ""password reset"" functionality then nobody but the user ever needs to know a user's password.  If you don't have a reliable ""password reset"" feature then try and steer the conversation and development effort in this direction.  There is rarely any real business need for knowing/printing user passwords and these kind of feature requests may be coming from non-technical people who have misunderstandings (or no understanding) about the implementation detail of authentication and authorization.  n'",['django'],['django']
40136310,"'how do i find my ipv4 using python?' 'my server copy it if you want! :) nhow do i find my ipv4 using python?ncan i you try to keep it real short?nnimport socketnndef Main():n    host = '127.0.0.1'n    port = 5000nn    s = socket.socket()n    s.bind((hostport))nn    s.listen(1)n    c1 addr1 = s.accept()n    sending = ""Connection:"" + str(addr1)n    connection = (sending) n    print(connection)n    s.listen(1)n    c2 addr2 = s.accept()n    sending = ""Connection:"" + str(addr2)n    connection = (sending)n    print(connection)n    while True:n        data1 = c1.recv(1024).decode('utf-8')n        data2 = c2.recv(1024).decode('utf-8')n        if not data1:                            n            breakn        if not data2:n            breakn        if data2:n            c1.send(data2.encode('utf-8'))n        if data1:n            c2.send(data1.encode('utf-8'))n    s.close() nnif __name__== '__main__':n    Main() nnnthx for the help i appreciate it!n' ""That's all you need for the local address (returns a string):nnsocket.gethostbyname(socket.gethostname())nn""",['python-3.x'],"['python-2.7', 'python-3.x']"
40136428,"'Python: How to filter a DataFrame of dates in Pandas by a particular date within a window of some days?' 'I have a DataFrame of dates and would like to filter for a particular date +- some days.nnimport pandas as pdnimport numpy as npnimport datetimenndates = pd.date_range(start=""08/01/2009""end=""08/01/2012""freq=""D"")ndf = pd.DataFrame(np.random.rand(len(dates) 1)*1500 index=dates columns='Power')nnnIf I select lets say date 2009-08-03 and a window of 5 days output would be similar to:nn>>> n                  Powern2010-07-29   713.108020n2010-07-30  1055.109543n2010-07-31   951.159099n2010-08-01  1350.638983n2010-08-02   453.166697n2010-08-03  1066.859386n2010-08-04  1381.900717n2010-08-05   107.489179n2010-08-06  1195.945723n2010-08-07  1209.762910n2010-08-08   349.554492nnnN.B.: The original problem I am trying to accomplish is under Python: Filter DataFrame in Pandas by hour day and month grouped by yearn' 'The function I created to accomplish this is filterDaysWindow and can be used as follows:nnimport pandas as pdnimport numpy as npnimport datetimenndates = pd.date_range(start=""08/01/2009""end=""08/01/2012""freq=""D"")ndf = pd.DataFrame(np.random.rand(len(dates) 1)*1500 index=dates columns='Power')nndef filterDaysWindow(df date daysWindow):n    """"""n    Filter a Dataframe by a date within a window of daysnn    @type df: DataFramen    @param df: DataFrame of datesnn    @type date: datetime.daten    @param date: date to focus onnn    @type daysWindow: intn    @param daysWindow: Number of days to perform the days window selectionnn    @rtype: DataFramen    @return: Returns a DataFrame with dates within date+-daysWindown    """"""    n    dateStart = date - datetime.timedelta(days=daysWindow)n    dateEnd = date + datetime.timedelta(days=daysWindow)n    return df dateStart:dateEndnndf_filtered = filterDaysWindow(df datetime.date(201083) 5)nprint df_filterednn'",['pandas'],['pandas']
40136496,"'Method like argument in function' ""I want use method in python / pandas like argument in a function.nFor example rolling statistics for dataframe:nndef rolling (df prefix = 'r' window = 3 method = 'here I wanna choose a method' ):n    for name in df.columns:n        dfprefix + name = dfname.rolling(window).'here this method been called'n    return dfnnn'mean()' or 'sum()' or whatever ...nlike nndf.rolling(2).sum()nnnI worked 95% time in R and in R it's simple (put function as an argument or return any function ). But in python I noob. So I creating package to make things easier for me. Like:nndef head(xk = 3):n    return x.head(k)nnnWhat function in python help me to use method like argument in a function?nn#some datanimport numpy as npnimport pandas as pdnfrom pandas_datareader.data import DataReadernfrom datetime import datetimenibm = DataReader('IBM'  'yahoo' datetime(200011) datetime(201611))nnibm2 = rolling(ibm'rr' 5 'sum') # something like thisnn"" 'You can use getattr with a str of the name of the method. This gets the attribute with that name from the object (In this case a method)nndef rolling (df prefix='r' window=3 method='sum'):n    for name in df.columns:n        dfprefix + name = getattr(dfname.rolling(window) method)()n    return dfnnnOr you could just pass in the method. When calling it the first argument will be self.nndef rolling (df prefix='r' window=3 method=DataReader.sum):n    for name in df.columns:n        dfprefix + name = method(dfname.rolling(window))n    return dfnn' ""I do thisnndef rolling (df prefix='r' window=3 method='method_name'):n    for name in df.columns:n        dfprefix + name = dfname.rolling(window).__getattribute__(method)()n    return dfnn"" ""A method is an attribute like any other (it just happens to be callable when bound to an object) so you can use getattr. (A default value of None is nonsense of course but I didn't want to reorder your signature to make method occur earlier without a default value.)nndef rolling (df prefix='r' window=3 method=None):n    for name in df.columns:n        obj = dfname.rolling(window)n        m = getattr(obj method)n        dfprefix + name = m()n    return dfnn""",['pandas'],"['pandas', 'numpy']"
40136636,"'Django: authenticate the user' ""I have the following code:nn# creating user:nndef create_user(request):n    if request.method == 'POST':n        user_info = forms.UserInfoForm(request.POST)n        if user_info.is_valid():n            cleaned_info = user_info.cleaned_datan            User.objects.create_user(username=cleaned_info'username' password=cleaned_info'password')n   render(.......)nnnThis works. I can check the auth_user and I see the username and password along with all the other fields created and added.nnNow I try to authenticate the user with the following code after creating user with username='testcase' and password='test': using above code.nn# Authenticate Usernndef get_entry(request):n    if request.method == 'POST':n        user = authenticate(username='testcase' password='test')n        if user:n            .........nnnThe user is always returned as none. What is going on? I am running django 1.10.2. nnUpdate:nnI can see the user created by create_user function when I log in admin. The status was not staff(as it was supposed to be). I changed that to staff to see if that was causing problem but still the get_entry method yields none for user.nIt is frustrating. I don't really know what I am doing wrong.n"" ""Save the user in one var and then call user.save() because User can't call the method save() try it:nndef create_user(request):n        if request.method == 'POST':n            user_info = forms.UserInfoForm(request.POST)n            if user_info.is_valid():n                cleaned_info = user_info.cleaned_datan                user = User.objects.create_user(username=cleaned_info'username' password=cleaned_info'password')n                user.save()n       render(.......)nnnThen you need to call auth.authenticate in your function get_entry:nndef get_entry(request):n    if request.method == 'POST':n        user = auth.authenticate(username='testcase' password='test')n        if user:n            .........nn"" ""Your code seems to be correct. nnThe problem might be in the way the params are being passed to your create_user view (Param passing in get_entry view highly unlikely to be a problem since the params username and password are hard-coded).nnTry printing out username and password before passing them to User.objects.create_user() since it's possible that the password field is not being saved properly and/or empty password is being passed and Django might be creating a hash for the empty password.nnP.S.: This is just a speculation need your response over this for further diagnosis of the issue.n""",['django'],['django']
40136651,"""'Stack()' output with all Individual index's filled in Pandas DataFrame"" ""I have the following DataFrame:nnimport pandas as pdnimport numpy as npndates = pd.date_range('20130101'periods=6)ndf = pd.DataFrame(np.random.randn(64)index=datescolumns=list('ABCD'))nnnwhich is:nnout:dfn                A          B            C           Dn2013-01-01  0.849638    0.163683    -0.422279   -0.981363n2013-01-02  -0.828562   -0.726762   -0.154431   1.695164n2013-01-03  1.668989    1.057559    -0.958682   -1.443136n2013-01-04  -3.386432   0.115499    -2.095343   -1.887334n2013-01-05  1.595712    0.270327    -0.532860   -0.690501n2013-01-06  -1.734169   0.574431    -0.982097   1.092113nnnI stacked the dataframe with purpose and it appears as below:nn2013-01-01  A    0.849638n            B    0.163683n            C   -0.422279n            D   -0.981363n2013-01-02  A   -0.828562n            B   -0.726762n            C   -0.154431n            D    1.695164n2013-01-03  A    1.668989n            B    1.057559n            C   -0.958682n            D   -1.443136n2013-01-04  A   -3.386432n            B    0.115499n            C   -2.095343n            D   -1.887334n2013-01-05  A    1.595712n            B    0.270327n            C   -0.532860n            D   -0.690501n2013-01-06  A   -1.734169n            B    0.574431n            C   -0.982097n            D    1.092113ndtype: float64nnnI wish to have the dates printed in all the rows instead of having merged together. I want to have something like this:nn2013-01-01  A    0.849638n2013-01-01  B    0.163683n2013-01-01  C   -0.422279n2013-01-01  D   -0.981363n.......n.......nn2013-01-06  A   -1.734169n2013-01-06  B    0.574431n2013-01-06  C   -0.982097n2013-01-06  D    1.092113nndtype: float64nnnCan anyone please help me to achieve this goal. Thank you.n"" ""the relevant pandas option is 'display.multi_sparse'nyou can set it yourself withnnpd.set_option('display.multi_sparse' False)nnnor use pd.option_context to temporarily set it in a with blocknnwith pd.option_context('display.multi_sparse' False):n    dates = pd.date_range('20130101'periods=6)n    print(pd.DataFrame(np.random.randn(64)index=datescolumns=list('ABCD')).stack())nn2013-01-01  A    0.074056n2013-01-01  B    0.565971n2013-01-01  C    0.312375n2013-01-01  D    0.000926n2013-01-02  A    0.669702n2013-01-02  B    0.458241n2013-01-02  C    0.854965n2013-01-02  D    1.608542n2013-01-03  A    0.358990n2013-01-03  B    0.194446n2013-01-03  C   -0.988489n2013-01-03  D   -0.967467n2013-01-04  A   -0.768605n2013-01-04  B    0.791746n2013-01-04  C    0.073552n2013-01-04  D   -0.604505n2013-01-05  A    0.254031n2013-01-05  B    0.143891n2013-01-05  C   -0.351159n2013-01-05  D    0.642623n2013-01-06  A    0.499416n2013-01-06  B   -0.588694n2013-01-06  C    1.418078n2013-01-06  D   -0.071737ndtype: float64nn""",['pandas'],['pandas']
40136716,"'Specifying a custom template for the django-lazysignup convert view' ""In my urls.py I tried to pass the template_name argument to the convert view:nnurl(r'^convert/' include('lazysignup.urls') {'template_name': 'chat/templates/chat/sign_up.html'} name='convert')nnnThat does not seem to have changed anything. Do I need to make a new view to call the convert view?n"" nan",['django'],['django']
40136746,"'AWS Lambda sending HTTP request' 'This is likely a question with an easy answer but i can't seem to figure it out.nnBackground: I have a python Lambda function to pick up changes in a DB then using HTTP post the changes in json to a URL. I'm using urllib2 sort of like this:nn# this runs inside a loop in reality my error handling is much betternrequest = urllib2.Request(url)nrequest.add_header('Content-type' 'application/json')ntry:n    response = urllib2.urlopen(request json_message)nexcept:n    response = ""Failed!""nnnIt seems from the logs either the call to send the messages is skipped entirely or times-out while waiting for a response. nnIs there a permission setting I'm missing the outbound rules in AWS appear to be right. Edit - The VPC applied to this lambda does have internet access and the security groups applied appear to allow internet access. /EditnnI've tested the code locally (connected to the same data source) and it works flawlessly. nnIt appears the other questions related to posting from a lambda is related to node.js and usually because the url is wrong. In this case I'm using a requestb.in url that i know is working as it works when running locally.n' 'If you've deployed your Lambda function inside your VPC it does not obtain a public IP address even if it's deployed into a subnet with a route to an Internet Gateway.  It only obtains a private IP address and thus can not communicate to the public Internet by itself.nnTo communicate to the public Internet Lambda functions deployed inside your VPC need to be done so in a private subnet which has a route to either a NAT Gateway or a self-managed NAT instance.n'",['python-2.7'],"['python-2.7', 'django']"
40136810,"'Python opening images without cmd' 'I am working on a project which includes opening images through a tkinter window using Pillow module.nnWhenever I try to open images they are opened with a black screen on their back.nnHow can I open them alone?nnI click on a photo here: nnnand it opens with a black screen behind:nnnThis is my go_to_function:nn            from PIL import Imagen            def go_to_photo():n            try:n                img = Image.open(source_file_org_images_path + ""/"" + photo_name_name + '.png')n                img.show()n                img.close()n            except:n                try:n                    img = Image.open(source_file_org_images_path + ""/"" + photo_name_name + '.jpg')n                    img.show()n                    img.close()n                except:n                    try:n                        img = Image.open(source_file_org_images_path + ""/"" + photo_name_name + '.jpeg')n                        img.show()n                        img.close()n                    except:n                        print('without a photo')nn' nan",['tkinter'],"['tkinter', 'python-2.7']"
40136945,"'How to msgpack unpack a file generated by logging' 'I have a file my_log.log which is generated as the output of a debugger (with a rotating file handler). In Python 2 if I run the scriptnnimport msgpacknfrom faker import Fakernimport loggingnfrom logging.handlers import RotatingFileHandlernnfake = Faker()nfake.seed(0)nndata_file = ""my_log.log""nnlogger = logging.getLogger('my_logger')nlogger.setLevel(logging.DEBUG)nhandler = RotatingFileHandler(data_file maxBytes=2000 backupCount=10)nhandler.terminator = """"         # Suppress the newline character (only works in Python 3)nlogger.addHandler(handler)nnfake_dicts = {'name': fake.name()} for _ in range(100)nn# Generate the archive lognfor item in fake_dicts:n    dump_string = msgpack.packb(item)n    logger.debug(dump_string)nn# Print out its contentsnunpacker = msgpack.Unpacker(open(data_file 'rb') use_list=False)nfor unpacked in unpacker:n    print(unpacked)nnnI get the following output:nn{'name': 'Joshua Carter'}n10n{'name': 'David Williams'}n10n{'name': 'Joseph Jones'}n10n{'name': 'Gary Perry'}n10n{'name': 'Terry Wells'}n10n{'name': 'Vanessa Cooper'}n10n{'name': 'Michael Simmons'}n10n{'name': 'Nicholas Kline'}n10n{'name': 'Lori Bennett'}n10nnnI understand that the number 10 comes from the newline character which is by default output by the logger. I understand from https://docs.python.org/3/library/logging.handlers.html that from Python 3.2 on the StreamHandler class has a terminator attribute which one can set to an empty string to suppress the insertion of newline characters which is what I'd like to do. nnHowever if I run the same script in Python 3 the printed output looks like an apparently meaningless stream of numbers which ends withnn66n101n110n110n101n116n116n39nnnwhereas I want it to printnn{'name': 'Vanessa Cooper'}n{'name': 'Michael Simmons'}n{'name': 'Nicholas Kline'}n{'name': 'Lori Bennett'}nnnwithout the numbers 10. How can I achieve this?n' nan",['python-3.x'],"['python-3.x', 'python-2.7']"
40136962,"'How to extract items from a file into different lists?' ""So I have a textfile which looks like this:nnARX BV9nDFK EILnARX CAMPnCAMP    EILnBV9 CAMPnARX ARXnCAMP    DFKnBV9 EILnBV9 EILnBV9 FUInnnAll of these are seperated by a tabs. Now I want to extract the left column into list 1 looking like this:nn'ARG''DFK''ARX''CAMP'...nnnAnd the right column into list 2 like this:nn'BV9''EIL''CAMP''EIL'...nnnThank you for your time.n"" nan",['list'],"['list', 'python-2.7']"
40137051,"'How to find the longest sub-array within a threshold?' ""Let's say you have a sorted array of numbers sorted_array and a threshold threshold. What is the fastest way to find the longest sub-array in which all the values are within the threshold? In other words find indices i and j such that:nnnsorted_arrayj - sorted_arrayi <= thresholdnj - i is maximalnnnIn case of a tie return the pair with the smallest i.nnI already have a loop-based solution which I will post as an answer but I'm curious to see if there's a better way or a way that can avoid the loop using a vector-capable language or library like NumPy for example.nnExample input and output:nn>>> sorted_array = 0 0.7 1 2 2.5n>>> longest_subarray_within_threshold(sorted_array 0.2)n(0 0)n>>> longest_subarray_within_threshold(sorted_array 0.4)n(1 2)n>>> longest_subarray_within_threshold(sorted_array 0.8)n(0 1)n>>> longest_subarray_within_threshold(sorted_array 1)n(0 2)n>>> longest_subarray_within_threshold(sorted_array 1.9)n(1 4)n>>> longest_subarray_within_threshold(sorted_array 2)n(0 3)n>>> longest_subarray_within_threshold(sorted_array 2.6)n(0 4)nn"" ""Here's a simple loop-based solution in Python:nndef longest_subarray_within_threshold(sorted_array threshold):n    result = (0 0)n    longest = 0n    i = j = 0n    end = len(sorted_array)n    while i < end:n        if j < end and sorted_arrayj - sorted_arrayi <= threshold:n            current_distance = j - in            if current_distance > longest:n                longest = current_distancen                result = (i j)n            j += 1n        else:n            i += 1n    return resultnn"" 'Here's a vectorized approach using broadcasting -nndef longest_thresh_subarray(sorted_arraythresh):n    diffs = (sorted_array:None - sorted_array)n    r = np.arange(sorted_array.size)n    valid_mask = r:None > rn    mask = (diffs <= thresh) & valid_maskn    bestcolID = (mask).sum(0).argmax()n    idx = np.nonzero(mask:bestcolID)0n    if len(idx)==0:n        out = (00)n    else:n        out = idx0-1 idx-1n    return outnnnSample runs -nnIn 137: sorted_array = np.array(0 0.7 1 2 2.5)nnIn 138: longest_thresh_subarray(sorted_array0.2)nOut138: (0 0)nnIn 139: longest_thresh_subarray(sorted_array0.4)nOut139: (1 2)nnIn 140: longest_thresh_subarray(sorted_array0.8)nOut140: (0 1)nnIn 141: longest_thresh_subarray(sorted_array1)nOut141: (0 2)nnIn 142: longest_thresh_subarray(sorted_array1.9)nOut142: (1 4)nnIn 143: longest_thresh_subarray(sorted_array2)nOut143: (0 3)nnIn 144: longest_thresh_subarray(sorted_array2.6)nOut144: (0 4)nn' 'Most likely the OP's own answer is the best possible algorithm as it is O(n). However the pure-python overhead makes it very slow. However this overhead can easily be reduced by compiling the algorithm using numba with the current version (0.28.1 as of this writing) there is no need for any manual typing simply decorating your function with @numba.njit() is enough.nnHowever if you do not want to depend on numba there is a numpy algorithm in O(n log n):nndef algo_burnpanck(sorted_arraythresh):n    limit = np.searchsorted(sorted_arraysorted_array+thresh'right')n    distance = limit - np.arange(limit.size)n    best = np.argmax(distance)n    return best limitbest-1nnnI did run a quick profiling on my own machine of the two previous answers (OP's and Divakar's) as well as my numpy algorithm and the numba version of the OP's algorithm.nnthresh = 1nfor n in 100 10000:n    sorted_array = np.sort(np.random.randn(n))n    for f in algo_user1475412algo_Divakaralgo_burnpanckalgo_user1475412_numba:n        ab = f(sorted_array thresh)n        d = b-an        diff = sorted_arrayb-sorted_arrayan        closestlonger = np.min(sorted_arrayd+1:-sorted_array:-d-1)n        assert sorted_arrayb-sorted_arraya<=threshn        assert closestlonger>threshn        print('f=%s n=%d thresh=%s:'%(f.__name__nthresh))#dabdiffclosestlonger)n        %timeit f(sorted_array thresh)nnnHere are the results:nnf=algo_user1475412 n=100 thresh=1:n10000 loops best of 3: 111 Âµs per loopnf=algo_Divakar n=100 thresh=1:n10000 loops best of 3: 74.6 Âµs per loopnf=algo_burnpanck n=100 thresh=1:n100000 loops best of 3: 9.38 Âµs per loopnf=algo_user1475412_numba n=100 thresh=1:n1000000 loops best of 3: 764 ns per loopnf=algo_user1475412 n=10000 thresh=1:n100 loops best of 3: 12.1 ms per loopnf=algo_Divakar n=10000 thresh=1:n1 loop best of 3: 1.76 s per loopnf=algo_burnpanck n=10000 thresh=1:n1000 loops best of 3: 308 Âµs per loopnf=algo_user1475412_numba n=10000 thresh=1:n10000 loops best of 3: 82.9 Âµs per loopnnnAt 100 numbers O(n^2) solution using numpy just barely beats the O(n) python solution but quickly after the scaling makes that algorithm useless. The O(n log n) keeps up even at 10000 numbers but the numba approach is unbeaten everywhere.n'",['numpy'],['numpy']
40137114,'Use cases for __init__.py in python 3.3+' 'Now that __init__.py is no longer required to make a directory recognized as a package is it best practice to avoid them entirely if possible? Or are there still well-accepted use cases for __init__.py in python 3.3+?nnFrom what I understand __init__.py were very commonly used to run code at module import time (for example to encapsulate internal file structure of the package or to perform some initialization steps). Are these use cases still relevant with python 3.3+?n' nan,['python-3.x'],['python-3.x']
40137134,"'How to make multiple file from different folder same name in one file in python' 'I want to combine multiple file from different folder data in one file but only same file name is all foldernnScript:nnimport osnnfilenames = os.path.join('C:/Users/Vishnu/Desktop/Test_folder/Input/''*.txt') os.path.join('C:/Users/Vishnu/Desktop/Test_folder/Output/''*.txt')nf = open(r'C:/Users/Vishnu/Desktop/Test_output/' 'wb')nfor fname in filenames:n    with open(fname) as infile:n        for line in infile:n            f.write(line)nnnGetting Error:nnf = open(r""C:/Users/Vishnu/Desktop/Test_output/"" ""wb"")nIOError: Errno 13 Permission denied: 'C:/Users/Vishnu/Desktop/Test_output/'n>>> nn' ""Firstly you are trying to open the folder itself. Secondly we have to close the file everytime we read it to avoid Permission issuesnnI tried this code. It should work nownnimport osnimport glob    #So that * in directory listing can be interpretted as all filenamesnnfilenames = glob.glob(os.path.join(os.path.expanduser('~')'Desktop''Test_folder''Input''*.txt')) glob.glob(os.path.join(os.path.expanduser('~')'Desktop''Test_folder''Output''*.txt'))    nfilenames0.extend(filenames1)nfilenames=filenames0nnif( not os.path.isdir(os.path.join(os.path.expanduser('~') 'Desktop' 'Test_output'))):n    os.mkdir(os.path.join(os.path.expanduser('~') 'Desktop' 'Test_output'))nfor fname in filenames:n    with open(fname) as file:n        for line in file.readlines():n            f = open(os.path.join(os.path.expanduser('~') 'Desktop' 'Test_output''{:}.txt'.format(os.path.split(fname)-1 )) 'a+')n            f.write(line)n            f.close()    #This should take care of the permissions issuenn""","['python-2.7', 'python-3.x']",['python-2.7']
40137140,'Apply different estimators on data points depending on which features are present' 'I have a large training set of data points (rows in pandas DataFrame) where each data point contains values for (e.g. 1000) features. However many feature are NaN. The set of non-NaN features defines which group a data point belongs to.nnThe crucial point: depending on the group a data point belongs to the feature values can have other meanings. So I need to train many estimators one estimator independently for each group.nnI am looking for a library framework e.g. in sklearn which could help me do that.nnOtherwise my naive approach is:nnncalculate a hash value from the non-NaN column names per row (data point). A hashmap (dict) can save which hash value belongs to which group.nThen we sequentially train estimators for groups save them again in a hashmap (group as key estimator as value)nWe go through test data row by row and use the estimator hashmap to decide which estimator to usennnIs there a simpler way?n' nan,['pandas'],['pandas']
40137232,"'Exponentional values in Python Pandas' 'Have a case of quite huge numbers in python pandas so the dataframe looks like this:nntradesn4.536115e+07n3.889124e+07n2.757327e+07nnnHow can these numbers be transformed into ""normal"" values from exponential in pandas?nnThanks!n' '>>> float(4.536115e+07)n45361150.0nnnornn>>> f = 4.536115e+07n>>> ""%.16f"" % fn'45361150.0000000000000000'nn' ""You could change the pandas options as such:nn>>> data = np.array(4.536115e+07 3.889124e+07 2.757327e+07)n>>> pd.set_option('display.float_format' lambda x: '%.f' % x)n>>> pd.DataFrame(data columns='trades')nn    tradesn0   45361150n1   38891240n2   27573270nn""",['pandas'],['pandas']
40137243,"'Error when passing parameter to form' ""I'm trying to pass a parameter to a form in this case is an object_id.nThe form gets used only on the change_view this code works:nnMy form:nnclass MyForm(forms.ModelForm):n    def __init__(self *args **kwargs):n        self.my_id = kwargs.pop('my_id' None)n        super(MyForm self).__init__(*args **kwargs)nnclass Meta:n    model = MyModeln    fields = ('thing_to_show_a')nnnMy admin model: nnclass MyModelAdmin(admin.ModelAdmin):n    def change_view(self request obj_id):n        self.form = MyFormn        return super(MyModelAdmin self).change_view(request obj_id)n...nnnBut if I try to pass the id as a parameter in the form:nnclass MyModelAdmin(admin.ModelAdmin):n    def change_view(self request obj_id):n        self.form = MyForm(my_id=obj_id)n        return super(MyModelAdmin self).change_view(request obj_id)n...nnnI get:nn'MyForm' object has no attribute '__name__'nn"" 'In self.form = MyForm you assign a class object to self.form.nIn self.form = MyForm(my_id=obj_id) you instantiate an object of class MyForm and assign it to self.form. nnDjango expect to find a class in self.form not an instance.n'",['django'],['django']
40137372,"'Concatinating multiple Data frames of different length' ""I have 88 different dataFrame of different lengths which I need to concatenate. And its all are located in one directory and I used the following python script to produce such a single data frame.nnHere is what I triednn path = 'GTFS/' n    files = os.listdir(path)nn    files_txt  = os.path.join(pathi) for i in files if i.endswith('.tsv')nn    ## Change it into dataframen    dfs = pd.DataFrame.from_csv(x sep='t')6 for x in files_txtn    ##Concatenate itn    merged = pd.concat(dfsaxis=1)nnnSince each of those data frames are of different length or shape its throwing me following error messagennValueError: Shape of passed values is (88 57914) indices imply (88 57905)nnnMy aim is to concatenate column-wise into single data frame with 88 columns as my input is 88 separate data frames from which I need to use 7th column as in my script.nAny solutions or suggestion would be great in this case for concatenating data framesnThank youn"" 'The key is to make a list of different data-frames and then concatenate the list instead of individual concatenation.nnI created 10 df filled with random length data of one column and saved to csv files to simulate your data.nnimport pandas as pdnimport numpy as npnfrom random import randintnnn#generate 10 df and save to seperate csv filesnfor i in range(111):n    dfi = pd.DataFrame({'a':np.arange(randint(211))})n    csv_file = ""file{0}.csv"".format(i)n    dfi.to_csv(csv_file sep='t')n    print ""saving file"" csv_filennnThen we read those 10 csv files into separate data-frames and save to a listnn#read previously saved csv files into 10 seperate dfn# and add to listnframes = nfor x in range(110):n    csv_file = ""file{0}.csv"".format(x)n    newdf = pd.DataFrame.from_csv(csv_file  sep='t')n    frames.append(newdf)nnnFinally we concatenate the listnn#concatenate frames listnresult = pd.concat(frames axis=1)nprint resultnnnThe result is 10 frames of variable length concatenated column wise into single df.nnsaving file file1.csvnsaving file file2.csvnsaving file file3.csvnsaving file file4.csvnsaving file file5.csvnsaving file file6.csvnsaving file file7.csvnsaving file file8.csvnsaving file file9.csvnsaving file file10.csvn      a    a    a    a    a    a    a   a    an0   0.0  0.0  0.0  0.0  0.0  0.0  0.0   0  0.0n1   1.0  1.0  1.0  1.0  1.0  1.0  1.0   1  1.0n2   2.0  2.0  2.0  2.0  2.0  2.0  2.0   2  2.0n3   3.0  3.0  3.0  3.0  3.0  NaN  3.0   3  NaNn4   4.0  4.0  4.0  4.0  4.0  NaN  NaN   4  NaNn5   5.0  5.0  5.0  5.0  5.0  NaN  NaN   5  NaNn6   6.0  6.0  6.0  6.0  6.0  NaN  NaN   6  NaNn7   NaN  7.0  7.0  7.0  7.0  NaN  NaN   7  NaNn8   NaN  8.0  NaN  NaN  8.0  NaN  NaN   8  NaNn9   NaN  NaN  NaN  NaN  9.0  NaN  NaN   9  NaNn10  NaN  NaN  NaN  NaN  NaN  NaN  NaN  10  NaNnnnHope this is what you are looking for. A good example on merge join and concatenate can be found here.n'","['pandas', 'numpy']",['pandas']
40137389,"'Calc value count in few columns of DataFrame (Pandas Python)' ""I have a dataFrame: nn   id   code_1   code_2n0  11    1451     ffxn1  15    2233     ffx n2  24    1451     mmgn3  15    1451     ffx nnnI need get number of each code value (for all code_1 values and all code_2 values) for unique id. For example:nn   id   1451   2233   ...   ffx  mmg   ...n0  11    1       0    ...    1    0    ...n1  15    1       1    ...    2    0    ...n2  24    1       0    ...    0    1    ...nnnI do this code:nny = data.groupby('id')n        .apply(lambda x: x'code_1' 'code_2'.unstack().value_counts()) n        .unstack()nnnBut i think that something wrong because number of result table columns less then number of varians code_1 and code_2.n"" 'Consider merging pivot_tables using the aggfunc len for counts.nnfrom io import StringIOnimport pandas as pdnndata = '''nid   code_1   code_2n11    1451     ffxn15    2233     ffx n24    1451     mmgn15    1451     ffx'''nndf = pd.read_table(StringIO(data) sep=""s+"")nndf = pd.merge(df'id' 'code_1'.pivot_table(index='id' columns='code_1' aggfunc=len).n                                               reset_index(drop=True)n              df'id' 'code_2'.pivot_table(index='id' columns='code_2' aggfunc=len).n                                               reset_index(drop=True)n              left_index=True right_index=True).fillna(0)nn#    1451  2233  ffx  mmgn# 0   1.0   0.0  1.0  0.0n# 1   1.0   1.0  2.0  0.0n# 2   1.0   0.0  0.0  1.0nn'",['pandas'],['pandas']
40137536,"'Python - reduce complexity using sets' ""I am using url_analysis tools from spotify API (wrapper spotipy with sp.) to process tracks using the following code:nndef loudness_drops(track_ids):nnnames = set()ntids = set()ntracks_with_drop_name = set()ntracks_with_drop_id = set()nnfor id_ in track_ids:n    track_id = sp.track(id_)'uri'n    tids.add(track_id)n    track_name = sp.track(id_)'name'n    names.add(track_name)n    #get audio featuresn    features = sp.audio_features(tids)n    #and then audio analysis idn    urls = {x'analysis_url' for x in features if x}n    print len(urls)n    #fetch analysis datan    for url in urls:n        # print len(urls)n        analysis = sp._get(url)n        #extract loudness sections from analysisn        x = _'start' for _ in analysis'segments'n        print len(x)n        l = _'loudness_max' for _ in analysis'segments'n        print len(l)n        #get max and min valuesn        min_l = min(l)n        max_l = max(l)n        #normalize streamn        norm_l = (_ - min_l)/(max_l - min_l) for _ in ln        #define silence as a value below 0.1n        silence = li for i in range(len(l)) if norm_li < .1n    #more than one silence means one of them happens in the middle of the trackn    if len(silence) > 1:n        tracks_with_drop_name.add(track_name)n        tracks_with_drop_id.add(track_id)nreturn tracks_with_drop_idnnnThe code works but if the number of songs I search is set to say limit=20 the time it takes to process all the audio segments xand l makes the process too expensive eg:nntime.time() prints 452.175742149nnQUESTION:nnhow can I drastically reduce complexity here?nnI've tried to use sets instead of lists but working with set objects prohibts indexing.nnEDIT: 10 urls:nnu'https://api.spotify.com/v1/audio-analysis/5H40slc7OnTLMbXV6E780Z' u'https://api.spotify.com/v1/audio-analysis/72G49GsqYeWV6QVAqp4vl0' u'https://api.spotify.com/v1/audio-analysis/6jvFK4v3oLMPfm6g030H0g' u'https://api.spotify.com/v1/audio-analysis/351LyEn9dxRxgkl28GwQtl' u'https://api.spotify.com/v1/audio-analysis/4cRnjBH13wSYMOfOF17Ddn' u'https://api.spotify.com/v1/audio-analysis/2To3PTOTGJUtRsK3nQemP4' u'https://api.spotify.com/v1/audio-analysis/4xPRxqV9qCVeKLQ31NxhYz' u'https://api.spotify.com/v1/audio-analysis/1G1MtHxrVngvGWSQ7Fj4Oj' u'https://api.spotify.com/v1/audio-analysis/3du9aoP5vPGW1h70mIoicK' u'https://api.spotify.com/v1/audio-analysis/6VIIBKYJAKMBNQreG33lBF'nn"" ""This is what I see not knowing much about spotify:nnfor id_ in track_ids:n    # this runs N times where N = len(track_ids)n    ...n    tids.add(track_id)  # tids contains all track_ids processed until nown    # in the end: len(tids) == Nn    ...n    features = sp.audio_features(tids)n    # features contains features of all tracks processed until nown    # in the end I guess: len(features) == N * num_features_per_tracknn    urls = {x'analysis_url' for x in features if x}n    # very probably: len(urls) == len(features)nn    for url in urls:n        # for the first track this processes features of the first track onlyn        # for the seconds track this processes features of 1st and 2ndn        # etc.n        # in the end this loop repeats N * N * num_features_per_track timesnnnYou should not any url twice. And you do because you keep all tracks in tids and then for each track you process everything in tids which turns the complexity of this into O(n2).nnIn general always look for loops inside loops when trying to reduce complexity.nnI believe in this case this should work if audio_features expects a set of ids:nn# replace this: features = sp.audio_features(tids)n# with:nfeatures = sp.audio_features({track_id})nn""",['list'],[]
40137597,"'Having troubles with pip and importing' 'I have both Python 3.5 and Python 2.7 installed. I install tweepy via CMD using "" python -m pip install tweepy"" yet when I import tweepy in either IDLE 2.7 or 3.5 I get the error ""Module not installed"" even though CMD says it has downloaded and installed it properly.nnWhat could be the error as I think this may have been the solution to my last projects hiccup I couldn't fix.nnThanks in advance! n' ""Launch python 2.7 and type nn>>>import tweepynnThan launch python 3.5 and type nn>>>import tweepynnnWhichever one does not work means that is probably not your default Python installation.nnOne of your Python installations doesn't have this installed since pip does not install in both versions of Python only the default one found on your path.  n""",['python-2.7'],"['python-2.7', 'python-3.x']"
40137813,"'AttributeError when creating tkinter.PhotoImage object with PIL.ImageTk' 'I am trying to place an image resized with PIL in a tkinter.PhotoImage object. nnimport tkinter as tk # I use Python3nfrom PIL import Image ImageTknnmaster = tk.Tk()nimg =Image.open(file_name)nimage_resized=img.resize((200200))nphotoimg=ImageTk.PhotoImage(image_resized)nnnHowever when I later try to call nnphotoimg.put( ""#000000"" (00) )nnnI get annnAttributError: 'PhotoImage' object has no attribute 'put'nnnWhile this:nnphotoimg=tk.PhotoImage(file=file_name)nphotoimg.put( ""#000000"" (00))nnndoesn't raise an error.nWhat am I doing wrong?n' 'ImageTk.PhotoImage as in PIL.ImageTk.PhotoImage is not the same class as tk.PhotoImage (tkinter.PhotoImage)  they just have the same namennhere is ImageTk.PhotoImage docs:nhttp://pillow.readthedocs.io/en/3.1.x/reference/ImageTk.html#PIL.ImageTk.PhotoImagen as you can see there is no put method in it.nnbut ImageTk.PhotoImage do have it:nhttp://epydoc.sourceforge.net/stdlib/Tkinter.PhotoImage-class.htmln'",['tkinter'],['tkinter']
40137996,"'Run Length Encoding Python' 'I need to create a program in python 2.7 which will open a file with text like ""iiinnpppuut"" and writes this to another file with text "" i3n2p3u2t"". I can't import functions other than sys. This program will have a main function of course. Help would be much appreciated!nnI now have something like this: (I'm sorry for the words in Dutch)nndef coderen(ab ):nwhile IOError:n    string = """"n    try:n        invoer = open(a ""r"")n        kar = str(invoer.read())n        while kar != """":n            string += karn            l= len(string)n            for i in range (0len(string)):n                if string != """":n                    tel = 1n                    plaats = 0n                    kar = stringint(plaats)n                    nextkar = stringint(plaats)+1n                    if nextkar == kar:n                        plaats += 1n                        tel += 1n                        kar = stringint(plaats)n                        nextkar = stringint(plaats)+1 nn            return n    except IOError:n        print ""Bestand niet te openen.""n        sys.exit(1)n    try:n        uitvoer = open(b ""w"")n    except IOError:n        print ""Bestand niet te openen.""nn' nan",['python-2.7'],['python-2.7']
40138031,"'How to read realtime microphone audio volume in python and ffmpeg or similar' 'I'm trying to read in near-realtime the volume coming from the audio of a USB microphone in Python. nnI have the pieces but can't figure out how to put it together. nnIf I already have a .wav file I can pretty simply read it using wavefile:nnfrom wavefile import WaveReadernnwith WaveReader(""/Users/rmartin/audio.wav"") as r:n    for data in r.read_iter(size=512):n        left_channel = data0n        volume = np.linalg.norm(left_channel)n        print volumennnThis works great but I want to process the audio from the microphone in real-time not from a file.nnSo my thought was to use something like ffmpeg to PIPE the real-time output into WaveReader but my Byte knowledge is somewhat lacking. nnimport subprocessnimport numpy as npnncommand = ""/usr/local/bin/ffmpeg""n            '-f' 'avfoundation'n            '-i' ':2'n            '-t' '5'n            '-ar' '11025'n            '-ac' '1'n            '-acodec''aac' '-'nnpipe = subprocess.Popen(command stdout=subprocess.PIPE bufsize=10**8)nstdout_data = pipe.stdout.read()naudio_array = np.fromstring(stdout_data dtype=""int16"")nnprint audio_arraynnnThat looks pretty but it doesn't do much. It fails with a NULL @ 0x7ff640016600 Unable to find a suitable output format for 'pipe:' error. nnI assume this is a fairly simple thing to do given that I only need to check the audio for volume levels. nnAnyone know how to accomplish this simply? FFMPEG isn't a requirement but it does need to work on OSX & Linux. n' nan",['numpy'],['numpy']
40138090,"'Work with a row in a pandas dataframe without incurring chain indexing (not coping just indexing)' 'My data is organized in a dataframe:nnimport pandas as pdnimport numpy as npnndata = {'Col1' : 4567 'Col2' : 10203040 'Col3' : 10050-30-50 'Col4' : 'AAA' 'BBB' 'AAA' 'CCC'}nndf = pd.DataFrame(data=data index = 'R1''R2''R3''R4')nnnWhich looks like this (only much bigger):nn    Col1  Col2  Col3 Col4nR1     4    10   100  AAAnR2     5    20    50  BBBnR3     6    30   -30  AAAnR4     7    40   -50  CCCnnnMy algorithm loops through this table rows and performs a set of operations. nnFor cleaness/lazyness sake I would like to work on a single row at each iteration without typing df.loc'row index' 'column name' to get each cell valuennI have tried to follow the right style using for example:nnrow_of_interest = df.loc'R2' :nnnHowever I still get the warning when I do:nnrow_of_interest'Col2' = row_of_interest'Col2' + 1000nnSettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFramennnAnd it is not working (as I intended) it is making a copynnprint dfnn    Col1  Col2  Col3 Col4nR1     4    10   100  AAAnR2     5    20    50  BBBnR3     6    30   -30  AAAnR4     7    40   -50  CCCnnnAny advice on the proper way to do it? Or should I just stick to work with the data frame directly?nnEdit 1:nnUsing the replies provided the warning is removed from the code but the original dataframe is not modified: The ""row of interest"" Series is a copy not part of the original dataframe. For example:nnimport pandas as pdnimport numpy as npnndata = {'Col1' : 4567 'Col2' : 10203040 'Col3' : 10050-30-50 'Col4' : 'AAA' 'BBB' 'AAA' 'CCC'}nndf = pd.DataFrame(data=data index = 'R1''R2''R3''R4')nnrow_of_interest         = df.loc'R2'nrow_of_interest.is_copy = Falsennew_cell_value          = row_of_interest'Col2' + 1000nrow_of_interest'Col2' = new_cell_valuennprint row_of_interest nnCol1       5nCol2    1020nCol3      50nCol4     BBBnName: R2 dtype: objectnnprint dfnn    Col1  Col2  Col3 Col4nR1     4    10   100  AAAnR2     5    20    50  BBBnR3     6    30   -30  AAAnR4     7    40   -50  CCCnnnEdit 2:nnThis is an example of the functionality I would like to replicate. In python a list of lists looks like:nna = 123456nnnNow I can create a ""label"" nnb = a0nnnAnd if I change an entry in b:nnb0 = 7nnnBoth a and b change.nnprint a bnn723456 723nnnCan this behavior be replicated between a pandas dataframe labeling one of its rows a pandas series?n' ""This should work:nnrow_of_interest = df.loc'R2' :nrow_of_interest.is_copy = Falsenrow_of_interest'Col2' = row_of_interest'Col2' + 1000nnnSetting .is_copy = False is the tricknnEdit 2:nnimport pandas as pdnimport numpy as npnndata = {'Col1' : 4567 'Col2' : 10203040 'Col3' : 10050-30-50 'Col4' : 'AAA' 'BBB' 'AAA' 'CCC'}nndf = pd.DataFrame(data=data index = 'R1''R2''R3''R4')nnrow_of_interest         = df.loc'R2'nrow_of_interest.is_copy = Falsennew_cell_value          = row_of_interest'Col2' + 1000nrow_of_interest'Col2' = new_cell_valuennprint row_of_interest nndf.loc'R2' = row_of_interest nnprint dfnnndf:nn    Col1  Col2  Col3 Col4nR1     4    10   100  AAAnR2     5  1020    50  BBBnR3     6    30   -30  AAAnR4     7    40   -50  CCCnn"" 'most straight forward way to do thisnndf.loc'R2' 'Col2' += 1000ndfnnnn' ""You can remove the warning by creating a series with the slice you want to work on:nnfrom pandas import Seriesnrow_of_interest = Series(data=df.loc'R2' :)nrow_of_interest.loc'Col2' += 1000nprint(row_of_interest)nnnResults in:nnCol1       5nCol2    1020nCol3      50nCol4     BBBnName: R2 dtype: objectnn""",['pandas'],['pandas']
40138350,"'Search for a combination in dataframe to change cell value' 'I want to replace values in a column if the a combination of values in two columns is valid. Lets say I have the following DataFramenndf = pd.DataFrame(n        'Texas 1' '111' '222' '333'n        'Texas 1' '444' '555' '666'n        'Texas 2' '777''888''999'n    )nn         0    1    2    3n0  Texas 1  111  222  333n1  Texas 1  444  555  666n2  Texas 2  777  888  999nnnAnd if I want to replace the value in column 2 if column 0 = Texas 1 and the value of column 2 = 222I'm doing the following:nndf.ix (df.Column 0=='Texas 1')&(df.Column 2 =='222')Column 2 = ""Success"" nnnThat works fine for a few combinations. The part where I'm lost is how to do this for over 300 combinations? I thought maybe I could use a dict and store the key which would be 'Success' or whatever other value. And the list could be the combination. Kind of like this. nna""Success"" = Texas 1 222n>>> an{""Success"": Texas 1 222}nnnBut I'm not sure how to do that in a DataFrame.n' ""You have all almost all your code just create dictionary or list and iterate over it and you are done.nnimport pandas as pdncombinations = 'key1' 'key2' 'msg'ncombinations.append('Texas 1' '222' 'triple two')ncombinations.append('Texas 1' '555' 'triple five')nndf = pd.DataFrame(n        'Texas 1' '111' '222' '333'n        'Texas 1' '444' '555' '666'n        'Texas 2' '777''888''999'n    )nnfor c in combinations:n    df.ix(df0 == c0) & (df2 == c1) 1 = c2nnnOutput:nn         0            1    2    3n0  Texas 1   triple two  222  333n1  Texas 1  triple five  555  666n2  Texas 2          777  888  999nn"" 'Great Use Case for DataFrame.apply(). Lamda functions all the way!!nndf = pd.DataFrame(n        'Texas 1' 111 222 333n        'Texas 1' 444 555 666n        'Texas 2' 777888999n    )nnnval_dict = {}n# assumptionn# str_like_Success : column_0  column_1nval_dict""Success"" = 'Texas 1' 222nval_dict""Failure"" = 'Texas 2' 888nnnThe function fill_values_from_dict will be applied to each row where x is the row (Series) and val_dict is the dictionary created abovenn  def fill_values_from_dict(xval_dict):n        for keyval in val_dict.items():n            if x0 == val0 and x2 == val1:n                x.set_value(1key)n                return xn        return xnnnApply fill_values_from_dict to each row nndf1 = df.apply(lambda x : fill_values_from_dict(xval_dict)axis=1)nnnOutput: nn   print(df1)nn             0        1    2    3n    0  Texas 1  Success  222  333n    1  Texas 1      444  555  666n    2  Texas 2  Failure  888  999nn'",['pandas'],"['pandas', 'dictionary']"
40138380,"""'DataFrame' object is not callable"" 'I'm trying to create a heatmap using Python on Pycharms. I've this code:nnimport numpy as npnimport pandas as pdnimport matplotlibnmatplotlib.use('agg')nimport matplotlib.pyplot as pltnndata1 = pd.read_csv(FILE"")nnfreqMap = {}nfor line in data1:n  for item in line:n    if not item in freqMap:n      freqMapitem = {}nn    for other_item in line:n      if not other_item in freqMap:n        freqMapother_item = {}nn      freqMapitemother_item = freqMapitem.get(other_item 0) + 1n      freqMapother_itemitem = freqMapother_item.get(item 0) + 1nndf = data1freqMap.T.fillna(0)nprint(df)nnnMy data is stored into a CSV file. Each row represents a sequence of products that are associated by a Consumer Transaction.The typically Basket Market Analysis:nn99  32  35  45  56  58  7   72n99  45  51  56  58  62  72  17n55  56  58  62  21  99  35  n21  99  44  56  58  7   72  n72  17  99  35  45  56  7   n56  62  72  21  91  99  35  n99  35  55  56  58  62  72  n99  35  51  55  58  7   21  n99  56  58  62  72  21      n55  56  58  21  99  35      n99  35  62  7   17  21      n62  72  21  99  35  58      n56  62  72  99  32  35      n72  17  99  55  56  58      nnnWhen I execute the code I'm getting the following error:nnTraceback (most recent call last):n  File ""C:/Users/tst/PycharmProjects/untitled1/tes.py"" line 22 in <module>n    df = data1freqMap.T.fillna(0)n  File ""C:UserststAppDataLocalContinuumAnaconda3libsite-packagespandascoreframe.py"" line 1997 in __getitem__n    return self._getitem_column(key)n  File ""C:UserststAppDataLocalContinuumAnaconda3libsite-packagespandascoreframe.py"" line 2004 in _getitem_columnn    return self._get_item_cache(key)n  File ""C:UserststAppDataLocalContinuumAnaconda3libsite-packagespandascoregeneric.py"" line 1348 in _get_item_cachen    res = cache.get(item)nTypeError: unhashable type: 'dict'nnnHow can I solve this problem? nnMany thanks!n' 'You are reading a csv file but it has no header the delimiter is a space not a comma and there are a variable number of columns. So that is three mistakes in your first line.nnAnd data1 is a DataFrame freqMap is a dictionary that is completely unrelated. So it makes no sense to do data1freqMap.nnI suggest you step through this line by line in jupyter or a python  interpreter. Then you can see what each line actually does and experiment.n'","['pandas', 'matplotlib']","['matplotlib', 'pandas']"
40138417,"'Database Connect Error: Centos 6 / Apache 2.4 / Postgres 9.4 / Django 1.9 / mod_wsgi 3.5 / python 2.7' 'I am trying to get my website up and running.   Everything seems to work fine but when I go to a page with a database write - I get this:nnWed Oct 19 09:53:12.319824 2016 mpm_prefork:notice pid 12411 AH00173: SIGHUP received.  Attempting to restartnWed Oct 19 09:53:13.001121 2016 ssl:warn pid 12411 AH01909: sXXX-XXX-XXX-XXX.secureserver.net:443:0 server certificate does NOT include an ID which matches the server namenWed Oct 19 09:53:13.003578 2016 mpm_prefork:notice pid 12411 AH00163: Apache/2.4.18 (Unix) OpenSSL/1.0.1e-fips mod_bwlimited/1.4 mod_wsgi/3.5 Python/2.7.6 configured -- resuming normal operationsnWed Oct 19 09:53:13.003590 2016 core:notice pid 12411 AH00094: Command line: '/usr/local/apache/bin/httpd'n(XID fsf92m) Database Connect Error: Access denied for user 'leechprotect'@'localhost' (using password: YES)nWed Oct 19 09:53:17.637487 2016 mpm_prefork:notice pid 12411 AH00169: caught SIGTERM shutting downnnnThis line shows that a user ""leechprotest"" cannot connect:nn(XID fsf92m) Database Connect Error: Access denied for user 'leechprotect'@'localhost' (using password: YES)nnnHowever I don't have a user called leechprotect.  leechportect is a default user on MySQL (im guessing) because MySQL is installed as the default database on my dedicated server.nnMy Django settings.py file:nnDATABASES = {n    'default': {n        'ENGINE': 'django.db.backends.postgresql'n        'NAME': 'prelaunch_db'n        'USER': 'postgres_user'n        'PASSWORD': 'XXXXXXXXXXXXXXX'n        'HOST': 'localhost'n        'PORT': ''n    }n}nnnI already know my database and entire site works on my test server at home.   I think it might be interference with MySQL and PostgreSQL.nnAny help much appreciated. nnEDIT (After disabling leech protection):nnWed Oct 19 11:40:24.000919 2016 ssl:warn pid 14754 AH01909: sXXX-XXX-XXX-XXX.secureserver.net:443:0 server certificate does NOT include an ID which matches the server namenWed Oct 19 11:40:24.001851 2016 suexec:notice pid 14754 AH01232: suEXEC mechanism enabled (wrapper: /usr/local/apache/bin/suexec)nWed Oct 19 11:40:24.001887 2016 :notice pid 14754 ModSecurity for Apache/2.9.0 (http://www.modsecurity.org/) configured.nWed Oct 19 11:40:24.001892 2016 :notice pid 14754 ModSecurity: APR compiled version=""1.5.2""; loaded version=""1.5.2""nWed Oct 19 11:40:24.001897 2016 :notice pid 14754 ModSecurity: PCRE compiled version=""8.38 ""; loaded version=""8.38 2015-11-23""nWed Oct 19 11:40:24.001900 2016 :notice pid 14754 ModSecurity: LUA compiled version=""Lua 5.1""nWed Oct 19 11:40:24.001903 2016 :notice pid 14754 ModSecurity: LIBXML compiled version=""2.9.2""nWed Oct 19 11:40:24.001905 2016 :notice pid 14754 ModSecurity: Status engine is currently disabled enable it by set SecStatusEngine to On.nWed Oct 19 11:40:25.001596 2016 ssl:warn pid 14755 AH01909: sXXX-XXX-XXX-XXX.secureserver.net:443:0 server certificate does NOT include an ID which matches the server namenWed Oct 19 11:40:25.004276 2016 mpm_prefork:notice pid 14755 AH00163: Apache/2.4.18 (Unix) OpenSSL/1.0.1e-fips mod_bwlimited/1.4 mod_wsgi/3.5 Python/2.7.6 configured -- resuming normal operationsnWed Oct 19 11:40:25.004294 2016 core:notice pid 14755 AH00094: Command line: '/usr/local/apache/bin/httpd -D SSL'n(XID 6jmrjj) Database Connect Error: Access denied for user 'leechprotect'@'localhost' (using password: YES)nWed Oct 19 11:40:31.847492 2016 mpm_prefork:notice pid 14755 AH00169: caught SIGTERM shutting downnnnEDIT 2:nnI found that Apache comes preconfigured on cPanel with a rewrite function:nnThese lines are in the httpd.conf file:nnRewriteEngine onnRewriteMap LeechProtect prg:/usr/local/cpanel/bin/leechprotectnMutex file:/usr/local/apache/logs rewrite-mapnnnI tried to comment out these lines but cPanel jut regenerates the default file. I looked how to edit and I found:nnroot@sXXX-XXX-XXX-XXX# /usr/local/cpanel/bin/apache_conf_distiller --updatennnFrom what I see anyting written outside the  tag with be perminantly saved when running the above command.nnthis got rid of the Database error problem.  But I still get a 500 server error.  And all other error log messages are the same.n' 'MySQL and PostgreSQL both do not come along with a user called 'leechprotect'. But a google search points out that this username is related to cPanel - might be worth reading that to understand whats going on. Afterwards you might consider deactivating it for you project directory.n'",['django'],['django']
40138486,'Not able to type in Conda Run terminal' 'This question could be odd or due to some naive error but so far I have not been able to fix this : I am not able to type anything in my Conda run terminal.nnI wanted to install Pandas in my Win64/Win10 machine and following online tutorials here and other visible links from google I learned that installing with Anaconda is easier.nnThus I installed Anaconda and following the command from this link I am trying to run the following command in my Conda terminalnn    conda install -c conda-forge pandas=0.19.0nnnHowever when I open the Conda.exe the terminal opens but does not accept any input from the keyboard nor mouse. (even when run as admin).nnnnCan anyone point out what the reason could be?n' nan,['pandas'],['pandas']
40138573,"'Python: How to develop a between_time similar method when on pandas 0.9.0?' 'I am stick to pandas 0.9.0 as I'm working under python 2.5 hence I have no between_time method available. nnI have a DataFrame of dates and would like to filter all the dates that are between certain hours e.g. between 08:00 and 09:00 for all the dates within the DataFrame df.nnimport pandas as pdnimport numpy as npnimport datetimenndates = pd.date_range(start=""08/01/2009""end=""08/01/2012""freq=""10min"")ndf = pd.DataFrame(np.random.rand(len(dates) 1)*1500 index=dates columns='Power')nnnHow can I develop a method that provides same functionality as between_time method?nnN.B.: The original problem I am trying to accomplish is under Python: Filter DataFrame in Pandas by hour day and month grouped by yearn' ""UPDATE:nntry to use:nndf.ixdf.index.indexer_between_time('08:00''09:50')nnnOLD answer:nnI'm not sure that it'll work on Pandas 0.9.0 but it's worth to try it:nndf(df.index.hour >= 8) & (df.index.hour <= 9)nnnPS please be aware - it's not the same as between_time as it checks only hours and between_time is able to check time like df.between_time('08:01:15''09:13:28')nnHint: download a source code for a newer version of Pandas and take a look at the definition of indexer_between_time() function in   pandas/tseries/index.py - you can clone it for your needsn"" 'Here is a NumPy-based way of doing it:nnimport pandas as pdnimport numpy as npnimport datetimenndates = pd.date_range(start=""08/01/2009""end=""08/01/2012""freq=""10min"")ndf = pd.DataFrame(np.random.rand(len(dates) 1)*1500 index=dates columns='Power')nnepoch = np.datetime64('1970-01-01')nstart = np.datetime64('1970-01-01 08:00:00')nend = np.datetime64('1970-01-01 09:00:00')nn# convert the dates to a NumPy datetime64 arrayndate_array = df.index.asi8.astype('<M8ns') nn# replace the year/month/day with 1970-01-01ntruncated = (date_array - date_array.astype('M8D')) + epochnn# compare the hour/minute/seconds etc with `start` and `end`nmask = (start <= truncated) & (truncated <=end)nnprint(dfmask)nnnyieldsnn                           Powern2009-08-01 08:00:00  1007.289466n2009-08-01 08:10:00   770.732422n2009-08-01 08:20:00   617.388909n2009-08-01 08:30:00  1348.384210n...n2012-07-31 08:30:00   999.133350n2012-07-31 08:40:00  1451.500408n2012-07-31 08:50:00  1161.003167n2012-07-31 09:00:00   670.545371nn'",['pandas'],"['pandas', 'numpy']"
40138709,"'Concatenate string using .format' 'I have some code similar to the following:nntest_1 = 'bob'ntest_2 = 'jeff'nntest_1 += ""-"" + test_2 + ""n""nnnOutput:nnbob- jeffnnnnI'd like to have the same functionality but using the .format method.nnThis is what I have so far:nntest_1 = ""{}{} {}n"".format(test_1 ""-"" test_2)nnnWhich produces the same output but is there a better/more efficient way of using .format. in this case?n' '''.join is probably fast enough and efficient.nn'-'.join((test_1test_2))  nnnYou can measure different methods using the timeit module. That can tell you which is fastest  nnThis is an example of how timeit can be used:-nn>>> import timeitn>>> timeit.timeit('""-"".join(str(n) for n in range(100))' number=10000)n0.8187260627746582nn'",['python-2.7'],"['python-2.7', 'python-3.x']"
40139135,"'Python - dividing a user input to display a range of answers' ""I'm having problems with a Python question. The question is to write a function that shows all integers that are cleanly divisble by 13 in the range of (1:x) where x is a user input. nI'm new to Python and am struggling with this question. I need to have a user input which Python then divides by 13 and displays the answer(s). So if a user inputs '27' the answers would be '13' and '26'. nnMy code so far is: nn    x = int(raw_input('Enter your Number Here: '))n    def divide(x):ncond = Truenwhile cond:n    x % 13 == 0n    print xnelse:n    cond = Falsen    print 'Your number us not divisble by 13'nn    divide(x)nn"" ""x % 13 == 0 by itself does nothing; it evaluates to True or False but you then ignore that result. If you want to do something with it you need to use it in an if condition.nnNote also that indentation is important - the else needs to be lined up with the if. There's no need for while at all because nothing can change within the loop.nnif x % 13 == 0:n    print xnelse:n    print 'Your number us not divisible by 13'nn"" 'Can do this:nnx = int(input(""Enter your number here: ""))nndef divide(x):n    for i in range(1x):n        if i % 13 == 0:n            print (i)nndivide(x)nn' 'Instead you can do something like:nnx = 27 / 13nnprint 13 * i for i in range(1x+1)nn' 'Borrow the back-ported print function Python 3:nnfrom __future__ import print_functionnnnThe following will print all numbers in the range 1..x inclusivennprint(y for y in range(1x+11) if y%13==0)nn' ""I'd just show all multiples of 13 until x dropping 0:nndef divide(x):n   print range(0 x 13)1:nnnDemo:nn>>> divide(27)n13 26nn""","['python-2.7', 'python-3.x']","['python-3.x', 'python-2.7']"
40139167,"'insert element in the start of the numpy array' ""I have array nnx= 0.30153836  0.30376881  0.29115761  0.29074261  0.28676876 nnnI want to insert -1 to the start of the array to be like nn  x= -1 0.30153836  0.30376881  0.29115761  0.29074261  0.28676876nnnI tried :nnnp.insert(x0-1axis=0)nnnbut it didn't do any change any idea how to do that ?n"" 'You can do the insert by ommiting the axis param:nnx = np.array(0000)nx = np.insert(x 0 -1)nxnnnThat will give:nnarray(-1  0  0  0  0)nn' ""I'm not fully familiar with numpy but it seems that the insert function does not affect the array you pass to it but rather it returns a new array with the inserted value(s).  You'll have to reassign to x if you really want x to change. nn>>> x= -1 0.30153836  0.30376881  0.29115761  0.29074261  0.28676876n>>> np.insert(x0-1axis=0)narray(-1.         -1.          0.30153836  0.30376881  0.29115761n        0.29074261  0.28676876)n>>> xn-1 0.30153836 0.30376881 0.29115761 0.29074261 0.28676876n>>> x = np.insert(x0-1axis=0)n>>> xnarray(-1.         -1.          0.30153836  0.30376881  0.29115761n        0.29074261  0.28676876)nn"" ""From the np.insert documentation:nnReturnsnout : ndarrayn   A copy of `arr` with `values` inserted.  Note that `insert`n   does not occur in-place: a new array is returned. nnnYou can do the same with concatenate joining the new value to the main value.  hstack append etc use concatenate; insert is more general allowing insertion in the middle (for any axis) so it does its own indexing and new array creation.nnIn any case the key point is that it does not operate in-place.  You can't change the size of an array.nnIn 788: x= np.array(0.30153836  0.30376881  0.29115761  0.29074261  0.28n     ...: 676876)nIn 789: y=np.insert(x0-1axis=0)nIn 790: ynOut790: narray(-1.          0.30153836  0.30376881  0.29115761  0.29074261n        0.28676876)nIn 791: xnOut791: array( 0.30153836  0.30376881  0.29115761  0.29074261  0.28676876)nnnSame action with concatenate; note that I had to add  short for np.array(-1) so both inputs are 1d arrays.  Expanding the scalar to array is all that insert is doing special.nnIn 793: np.concatenate(-1x)nOut793: narray(-1.          0.30153836  0.30376881  0.29115761  0.29074261n    0.28676876)nn""",['numpy'],['numpy']
40139184,"""Keeping 'key' column when using groupby with transform in pandas"" 'Finding a normalized dataframe removes the column being used to group by so that it can't be used in subsequent groupby operations.  for example (edit: updated):nn    df = pd.DataFrame({'a':1 1  2 3 2 3 'b':0 1 2 3 4 5})nn       a  bn    0  1  0n    1  1  1n    2  2  2n    3  3  3n    4  2  4n    5  3  5nn    df.groupby('a').transform(lambda x: x)nn       bn    0  0n    1  1n    2  2n    3  3n    4  4n    5  5nnnNow with most operations on groups the 'missing' column becomes a new index (which can then be adjusted using reset_index or set as_index=False) but when using transform it just disappears leaving the original index and a new dataset without the key. nnEdit: here's a one liner of what I would like to be able to donn    df.groupby('a').transform(lambda x: x+1).groupby('a').mean()n    KeyError 'a'nnnIn the example from the pandas docs a function is used to split based on the index which appears to avoid this issue entirely.  Alternatively it would always be possible just to add the column after the groupby/transform but surely there's a better way?nnUpdate:nIt looks like reset_index/as_index are intended only for functions that reduce each group to a single row.  There seem to be a couple options from answersn' 'that is bizzare!nnI tricked it like thisnndf.groupby(df.a.values).transform(lambda x: x)nnnn'",['pandas'],['pandas']
40139187,"'Is it possible to pass a single user input (an int) into an argument to match 2 ints in python?' 'Basically I'm trying to write a tic tac toe game in python and I'm new to the language. At the moment I'm trying to get the user to input an int which I will then pass into an argument which requires two ints of the same number (as the grid will be a square) to make a grid for the game. If you look in the code below I have hard coded in the arguments (grid_maker(66)) but is there a way I can assign the user input into h and w so the grid will be the size the user requests? (The user can input any number they wish e.g. 20 and make a 20 by 20 grid but they still only need 3 in a row the code is more for the practice rather than an efficient game).nnOn a side note would this way be recommended as I will need to check if someone has gotten 3 Xs or Os in a row.nnclass GameBoard:nndef printBoard():nprint('Welcome to my tic tac toe game')n(""Commented gridInput out as it results in an error "")n#gridInput = int(input('Please enter a number between 5-10 to set the grid dimensions for the game boardn'))nndef grid_maker(hw):n grid = "" | "" for _ in range(w) for _ in range(h)n return gridnn print ('n'.join(' '.join(row) for row in grid_maker(66)))nndef print_grid(grid):n  for row in grid:n    for e in row:n        print (e)nn' 'I am not sure what exactly you want to do but I guess there are multiple solutions to it. I will just give one possible solution:nndef grid_maker(hw=None):n  if w is None: w=hn  grid = "" | "" for _ in range(w) for _ in range(h)n  return gridnn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40139216,"'python/pandas/sklearn: getting closest matches from pairwise_distances' 'I have a dataframe and am trying to get the closest matches using mahalanobis distance across three categories like:nnfrom io import StringIOnfrom sklearn import metricsnimport pandas as pdnnstringdata = StringIO(u""""""pidratio1pct1rspn    02.926.795.073615n    111.629.696.963660n    20.737.997.750412n    32.727.9102.750412n    41.219.993.750412n    50.222.196.750412n    """""")nnstats = 'ratio1''pct1''rsp'ndf = pd.read_csv(stringdata)nnd = metrics.pairwise.pairwise_distances(dfstats.as_matrix()n    metric='mahalanobis')nnprint(df)nprint(d)nnnWhere that pid column is a unique identifier.nnWhat I need to do is take that ndarray returned by the pairwise_distances call and update the original dataframe so each row has some kind of list of its closest N matches (so pid 0 might have an ordered list by distance of like 2 1 5 3 4 (or whatever it actually is) but I'm totally stumped how this is done in python.n' 'from io import StringIOnfrom sklearn import metricsnnstringdata = StringIO(u""""""pidratio1pct1rspn    02.926.795.073615n    111.629.696.963660n    20.737.997.750412n    32.727.9102.750412n    41.219.993.750412n    50.222.196.750412n    """""")nnstats = 'ratio1''pct1''rsp'ndf = pd.read_csv(stringdata)nndist = metrics.pairwise.pairwise_distances(dfstats.as_matrix()n    metric='mahalanobis')ndist = pd.DataFrame(dist)nranks = np.argsort(dist axis=1)ndf""rankcol"" = ranks.apply(lambda row: ''.join(map(str row)) axis=1)ndfnn'",['pandas'],['pandas']
40139345,"'How can I append lists with items from another list and leave these empty in a simulation?' 'Here is my code:nnimport randomnlistx = nready = 0nlisty = nlistz = nn#functionnndef function(rsq):n    listy=n    if len(listx)==4 or len(listx)==8:n        listy.append((listx t))n        print ""y"" listynn# here it starts:nnfor t in range(125): nn    randomnumber = random.uniform(0.0 1.0)nn    if randomnumber <= 0.5:n        listx.append((t))   n        print ""x"" listxnn    if ready == 0: #condition lets say: ready is always 0n        function(568) #this function generates listy from input of listxnn    if listy != 0: #if listy is not empy anymore fill listz with items of listyn            listz.append(listy)n            del listyn            print ""z"" listznnnI have 3 lists; listx listy and listz. I generate random numbers to listx. If ready==0 (always) I call the function (function(rsq)). If a condition (len==4 or 8) is met the items in the list are appended to listy.nnAt this point I would like to add these numbers from listy to listz and leave listy empty again. The items that I transported from listy to listz should be removed from listx. nnDoes anyone know how to solve this?n' nan",['list'],"['list', 'python-2.7']"
40139357,"'Luigi task fails on main ""ValueError: No JSON object could be decoded""' 'I only receive this error when I run the task without --local-scheduler on OS X El Cap. Daemon created with luigid command is currently running as well.nnWhen I run the task with --local-scheduler it operates as expected. It also runs fine both with and without --local-scheduler on my Windows 7 vm. Curious as to why it only fails in that one case on OS X.nnCode snippet comes from this post I was referencing begin learning Luigi:https://marcobonzanini.com/2015/10/24/building-data-pipelines-with-python-and-luigi/nnCode:nnimport luiginnnclass PrintNumbers(luigi.Task):n    n = luigi.IntParameter()nn    def requires(self):n        return nn    def output(self):n        return luigi.LocalTarget(""numbers_up_to_{}.txt"".format(self.n))nn    def run(self):n        with self.output().open('w') as f:n            for i in range(1 self.n+1):n                f.write(""{}n"".format(i))nnnif __name__ == '__main__':n    luigi.run()nnnThe trace: nnFile ""scrape.py"" line 24 in n    luigi.run()nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/interface.py"" line 210 in runn    return _run(*args **kwargs)'success'nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/interface.py"" line 238 in _runn    return _schedule_and_run(cp.get_task_obj() worker_scheduler_factory)nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/interface.py"" line 194 in _schedule_and_runn    success &= worker.add(t env_params.parallel_scheduling)nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/worker.py"" line 565 in addn    for next in self._add(item is_complete):nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/worker.py"" line 682 in _addn    retry_policy_dict=_get_retry_policy_dict(task)nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/worker.py"" line 441 in _add_taskn    self._scheduler.add_task(*args **kwargs)nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/scheduler.py"" line 112 in rpc_funcn    return self._request('/api/{}'.format(fn_name) actual_args **request_args)nnFile ""/Users/-/.virtualenvs/adwords/lib/python2.7/site-packages/luigi/rpc.py"" line 145 in _requestn    response = json.loads(page)""response""nnFile ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/init.py"" line 338 in loadsn    return _default_decoder.decode(s)nnFile ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.py"" line 366 in decoden    obj end = self.raw_decode(s idx=_w(s 0).end())nnFile n""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/json/decoder.py"" line 384 in raw_decoden    raise ValueError(""No JSON object could be decoded"")nValueError: No JSON object could be decodedn' nan",['python-2.7'],"['python-2.7', 'django']"
40139405,"'building a dataframe from grouped data in pandas' ""I have a dataframe that looks like this:nn            x1     x2    .....      sign Indexn   0        2      4     .....       Bn   1        5      3     .....       An   .        .      .                 .n   .        .      .     .....       .nnnsig gets only values A and B. the x's can be as many as you like. then I group and average like this (also over all x's):nnv1 = df.groupby('sig')'x1'.mean()nv2 = df.groupby('Sig')'x2'.mean()n...nnnthen I want to create a dataframe with the means in the x's columns: nn d = {'x1': v1 'x2': v2 ....}n df = pd.DataFrame(d)nnnthat should look like this in the end:nn     x1   x2 ........nsign A    3    2  ........n B    5    3  ........ nnnmy question is: how can I create this dataframe in the end regarding the fact that the number of x's can get pretty large? so that means looping through the columns and extending the dictionary that is used for the dataframe (the dictionary solution is not necessary).n"" nan","['pandas', 'dictionary']",['pandas']
40139445,"'Python Arguments and Passing Floats in Arguments' 'I've run into a couple of issues using arguments within a python script. Can i please get some help or direction to get this code functional? Thank you in advance.nnFirst issue: I am unable to specify multiple arguments at once. nFor example I am able to pass a single argument fine:nn$ ./my_arg_scenario.py -anArgument_An$ ./my_arg_scenario.py -cnArgument_Cn$ ./my_arg_scenario.py -dnArgument_DnnnHowever I am looking for a way to pass multiple arguments in any position. Is there a way I can accomplish this?nFor example I would like the below to occur:nn./my_arg_scenario.py -a -c -dnArgument_AnArgument_CnArgument_Dnn# OR    nn./my_arg_scenario.py -c -anArgument_CnArgument_AnnnSecond Issue: I am trying to pass both whole numbers and floats in the -b argument. But when I pass a float/decimal I get the below error. Is there a way I can pass both a float and whole number?nnThis works:nn$ ./my_arg_scenario.py -b 5nThe number provided is: 5nnnBut this does NOT:nn$ ./my_arg_scenario.py -b 5.50nTraceback (most recent call last):n  File ""./my_arg_scenario.py"" line 18 in <module>n    if int(sys.argv2) not in range(011):nValueError: invalid literal for int() with base 10: '5.50'nnnBelow is my testable code:nn#!/usr/local/bin/python3.5nimport sysnnscript_options = '-a' '-b' '-c' '-d'nmanual_flag = ''nbuild_flag = ''nnif len(sys.argv) > 1:n    if sys.argv1 in script_options:n        passn    else:n        print('nttParameter ""' + sys.argv1 + '"" is an invalid argument.n')n        sys.exit()n    if sys.argv1 == '-a':n        print('Argument_A')n        sys.exit()n    elif sys.argv1 == '-b':n        if int(sys.argv2) not in range(011):n            print('Invalid interval. Please select a value bewteen 1-5s.')n            sys.exit()n        else:n            print('The number provided is: ' + (sys.argv2))n    elif sys.argv1 == '-c':n        manual_flag = 'Argument_C'n        print(manual_flag)n    elif sys.argv1 == '-d':n        build_flag ='Argument_D'n        print(build_flag)nelse:n    passnn' 'You didn't actually provide the code you're using (aside from incidentally in the traceback)(Update: Code added later) but the answer is: Stop messing around with parsing sys.argv manually and use the argparse module (or docopt or something that doesn't involve rolling your own switch parsing).nnimport argparsennparser = argparse.ArgumentParser()nparser.add_argument('-a' action='store_true')nparser.add_argument('-b' metavar='INTERVAL' type=int choices=range(11))nparser.add_argument('-c' action='store_true')nparser.add_argument('-d' action='store_true')nargs = parser.parse_args()nnif args.a: print('Argument_A')nif args.b is not None: print('The number provided is:' args.b)nif args.c: print('Argument_C')nif args.d: print('Argument_D')nnnIf you want to accept int or float the easiest solution is to just make type=float and use a consistent type (but the range check must be done outside the parsing step). If you must allow both ast.literal_eval or a homegrown argparse type conversion function are options. Since you want a range check too (which range won't handle properly for float values that aren't equal to int values) roll a type checker:nndef int_or_float(minval=None maxval=None):n    def checker(val):n        try:n            val = int(val)n        except ValueError:n            val = float(val)n        if minval is not None and val < minval:n            raise argparse.ArgumentTypeError('%r must be >= %r' % (val minval))n        if maxval is not None and val > maxval:n            raise argparse.ArgumentTypeError('%r must be <= %r' % (val maxval))n        return valn    return checkernnnThen use it by replacing the definition for -b with:nn# Might want int_or_float(0 10) depending on range exclusivity rulesnparser.add_argument('-b' metavar='INTERVAL' type=int_or_float(0 11))nn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40139455,"'Django strip_tags template filter add space' 'I use djangos template filter striptags. Example:nn>>> from django.utils.html import strip_tagsn>>> strip_tags(""<p>This is a paragraph.</p><p>This is another paragraph.</p>"")n'This is a paragraph.This is another paragraph.'nnnWhat is the best way to add a space character between the paragraphs so that I get this string instead:nn'This is a paragraph. This is another paragraph.'nnnEdit:nnOne idea I have is to write a custom template filter that replaces all </p> tags with space</p> before the striptags filter is used. But is that a clean and robust solution?n' nan","['django', 'python-3.x']",['django']
40139493,"'Django templates: why does __call__ magic method breaks the rendering of a non-model object?' 'Today I faced a strange issue on one of my development. I reproduced it with a very minimal example. Have a look at these 2 dummy classes (non Django model subclasses):nnclass DummyClassA(object):n    def __init__(self name):n        self.name = namenn    def __repr__(self):n        return 'Dummy1 object called ' + self.namennnclass DummyClassB(object):n    """"""Same as ClassA with the __call__ method added""""""n    def __init__(self name):n        self.name = namenn    def __repr__(self):n        return 'Dummy2 object called ' + self.namenn    def __call__(self *args **kwargs):n        return ""bar""nnnThey are identical but the second have a special __call__() method.nnI want to display instances of these 2 objects in a view using the builtin Django template engine:nnclass MyView(TemplateView):nn    template_name = 'myapp/home.html'nn    def get_context_data(self **kwargs):n        ctx = super(MyView self).get_context_data(**kwargs)nn        list1 = n            DummyClassA(name=""John"")n            DummyClassA(name=""Jack"")n        nn        list2 = n            DummyClassB(name=""Albert"")n            DummyClassB(name=""Elmer"")n        nn        ctx.update({n            'list1': list1n            'list2': list2n        })n        return ctxnnnand the corresponding template:nn    <h1>Objects repr</h1>n    <ul>n        {% for element in list1 %}n            <li>{{ element }}</li>n        {% endfor %}n    </ul>n    <ul>n        {% for element in list2 %}n            <li>{{ element }}</li>n        {% endfor %}n    </ul>nn    <h1>Access members</h1>n    <ul>n        {% for element in list1 %}n            <li>{{ element.name }}</li>n        {% endfor %}n    </ul>n    <ul>n        {% for element in list2 %}n            <li>{{ element.name }}</li>n        {% endfor %}n    </ul>nnnI obtain this result:nnnnWhen displaying instances of the second class ({{ element }}) the __call__ method is executed instead of __repr__() and when I want to access a member of the class it returns nothing. nnI don't understand why defining the __call__() change the way Django template engine will handle those instances. I imagine this is not a bug but mostly a feature but I am curious why __call__() is run in such case. And why I can't get the value of element.name in the 2nd list ?n' 'Because that's what the template language is designed to do. As the docs state:nnn  If the resulting value of looking up a variable is callable it is called with no arguments. The result of the call becomes the template value.nnnWithout this there would be no way of calling methods in templates since the template syntax does not allow using parentheses.n'",['django'],['django']
40139603,"'sum numpy array of tags in one hot encoding' ""I have an array that is a one hot encoding of all tags likennn n  000n  100n  001n n n   000n   000n   001n nnnnI want to get this:nnn 101n 001nnnnthe arrays of tags are paded to same size (000 means no tag)nnHow can I do that? I tryed many things but I'm a noob with python and numpy.nnEDITnnI think this should worksnnnp.sum(x axis=0) for x in array_tagsnnnbut python(2.7) collapse if I run that. Any clue?n"" nan",['numpy'],['numpy']
40139628,"'Characters from listbox are still recorded even when deleted from listbox' 'So my little game is programmed to have two characters fight each other. One from the left side and one from the right side. After they fight both should be deleted regardless of who wins or loses. They are in fact deleted from listboxes but after you have two more charachters from each side fight those previous characters sometimes show up. If you start with Zys and Rash fighting no other names are printed in the win and loss section besides theirs. Only when you go backwards from Dant and Ilora does it work the way it should with each character making a place in either wins or loss only once. If you start with some other characters they could be put in the wins and loss section more then once. It is also possible for a character to be placed as a win or loss even if it hasnt been selected to fight. The bottomline is each character gets to fight  a character on the opposite side ONCE and after that it is placed and then deleted with no use in the later part of the program. For some apparent reason it does not do that.nnfrom tkinter import *nfrom tkinter import ttknfrom tkinter import messageboxnnclass Character: n    def __init__(self name attack defense health):n        self.name = namen        self.attack = attackn        self.defense = defensen        self.health = healthn        self.total = attack+defense+healthnn#Left side charactersnRash = Character(""Rash"" 42 50 80)nUntss = Character(""Untss"" 15 54 100)nIlora = Character(""Ilora"" 60 35 80)n                                    #Both sides have totals of 165 168 and 175n#Right side charactersnZys = Character(""Zys"" 12 97 83)nEentha = Character(""Eentha"" 55 17 90)nDant = Character(""Dant"" 73 28 88)nndef fight(): #Part of code that checks for wins and loss checks which has greater total stats and deletes from list boxnn    try:n        namel = """"n        namer=""""n        left = lbox.curselection()0n        right = rbox.curselection()0nn        totalleft = 0n        totalright = 0n        if left == 0:n            namel = ""Rash""n            totalleft = Rash.totaln        elif left==1:n            namel = ""Untss""n            totalleft = Untss.totaln        elif left==2:n            namel = ""Ilora""n            totalleft = 60+35+80nn        if right == 0:n            namer = ""Zys""n            totalright = Zys.totaln        elif right==1:n            namer = ""Eentha""n            totalright = Eentha.totaln        elif right==2:n            namer = ""Dant""n            totalright = Dant.totalnn        lbox.delete(lbox.curselection()0)n        rbox.delete(rbox.curselection()0)n        print(namel)n        print(namer)n        if (totalleft>totalright): #Checks if won or lostn            wins.set(wins.get()+""n""+namel)n            loss.set(loss.get()+""n""+namer)n        else:n            wins.set(wins.get()+""n""+namer)n            loss.set(loss.get()+""n""+namel)n    except IndexError:n            passnnn#The left listbox and its charactersnleftnames = ('Rash' 'Untss' 'Ilora')nlnames = StringVar(value=leftnames)nlbox = Listbox(mainframe listvariable=lnames exportselection=0 height=3)nlbox.grid(column=0 row=0)nnn#Right listboxes charactersnrightnames = ('Zys' 'Eentha' 'Dant')nrnames = StringVar(value=rightnames)nrbox = Listbox(mainframe listvariable=rnames exportselection=0 height=3)nrbox.grid(column=1 row=0)nnn#Shows users wins and losssesnnwins = StringVar()nloss = StringVar()nn#Label that nttk.Label(mainframe text=""Wins"" width=13).grid(column=2 row=0 sticky=N)nttk.Label(mainframe text=""Loss"" width=13).grid(column=2 row=1 sticky=N)nttk.Label(mainframe textvariable=wins).grid(column=2 row=0 sticky=(SE))nttk.Label(mainframe textvariable=loss).grid(column=2 row=1 sticky=(S E))nn#Button for fightingnfightbttn= ttk.Button(mainframe text=""Fight"" command=fight)nfightbttn.grid(column=3 row=3 sticky=(E))nnroot.mainloop()nnnThis is only the part of the code that could relate to the problem not the code as a whole.nnThis is not the same question from yesterday just the same code. I thought it would be more appropriate to work with the bugs one at a time as different problems so they could be more organized.n' 'Problem is because you use always if left == 0: namel = ""Rash"" even if""Rash""was deleted from listbox and nowleft == 0means""Untss"".nnYou have to get selected name instead of index nn    namel = lbox.get(lbox.curselection()0)n    namer = rbox.get(rbox.curselection()0)nnnand use it nn    if namel == ""Rush"":n       totalleft = Rash.totalnnnBut you could use dictionary to get data nnleft_characters = {        n    ""Rash"": Character(""Rash"" 42 50 80)n    ""Untss"": Character(""Untss"" 15 54 100)n    ""Ilora"": Character(""Ilora"" 60 35 80)n}nnright_characters = {n    ""Zys"": Character(""Zys"" 12 97 83)n    ""Eentha"": Character(""Eentha"" 55 17 90)n    ""Dant"": Character(""Dant"" 73 28 88)n}nnleftnames = list(left_characters.keys())nrightnames = list(right_characters.keys())nnnand thennndef fight():nn    try:n        namel = lbox.get(lbox.curselection()0)n        namer = rbox.get(rbox.curselection()0)nn        print(namel)n        print(namer)nn        totalleft = left_charactersnamel.totaln        totalright = right_charactersnamer.totalnn        lbox.delete(lbox.curselection()0)n        rbox.delete(rbox.curselection()0)nn        if totalleft > totalright : #Checks if won or lostn            wins.set(wins.get()+""n""+namel)n            loss.set(loss.get()+""n""+namer)n        else:n            wins.set(wins.get()+""n""+namer)n            loss.set(loss.get()+""n""+namel)n    except IndexError as e:n        print(""ERROR:"" e)nnnIf you add new characters to dictionary then you don't have to change code.nnBTW: don't use pass in except because you don't see error if there is something wrong with code.n'",['tkinter'],['tkinter']
40139674,'Django: Database used for prefetch_related is not the same that the parent query' 'I'm using a multi-db in my Django app with a master database and a read replica but to avoid replication lag problems the router always uses default database except few places where I set DB manually.nnI'm facing an issue as I don't know how to specify the database used for prefetch_related.nnFor example I want the next query to use only read_replica DB but it does 2 queries the first goes to read_replica as expected and the second goes to default DB.nnusers = UserProfile.objects.using('read_replica').prefetch_related('usermedia_set').filter(id__in=user_ids)nnnThis are the output of this query:nnn  SELECT @@SQL_AUTO_IS_NULL; args=Nonen  n  SELECT VERSION(); args=Nonen  n  SELECT ... FROM ftmanager_userprofile WHERE (ftmanager_userprofile.id IN (33); args=(33)n  n  SELECT @@SQL_AUTO_IS_NULL; args=Nonen  n  SELECT VERSION(); args=Nonen  n  SELECT ... FROM ftmanager_usermedia WHERE ftmanager_usermedia.user_id IN (33); args=(33)nnnI see a related ticket on Django tickets but I do not understand how to apply using() to inner queryset.n' nan,['django'],['django']
40139709,"'Percentage data from .csv to excel' 'I read some data under percentage form (11.00%) from a .csv file.nI copy them into an excel file and i want to represent them in a chart.nThe problem is when i copy them into excel data is automatically converted to string type and i cannot represent them in the chart correctly.nI tried few methods but nothing successfully.nnf = open(""any.csv"")nwb = openpyxl.load_workbook(""any.xlsx"")nws = wb.get_sheet_by_name('Sheet1')nreader = csv.reader(f delimiter='')nnfor row in ws.iter_rows(row_offset=0):n        for i in reader:n           ws.append(i2:) code herennnI tried using:nnfor row in ws.iter_rows(row_offset=0): n   for i in reader: n      ws.append(float(i2:)) nnnand i recieve this error:nTypeError: float() argument must be a string or a number nnI have tried using:nnfor i in reader:n       i2: = float(x) for x in i2:n       ws.append(i)nnnand i got this eror:nValueError: invalid literal for float()11.1%nnI use the i2: because first first and second column contain some text that dont need to be convertedn' 'for row in ws.iter_rows(row_offset=0):n        for i in reader:n           ws.append(float(i2:-1)) code herennnFloat the value before you append itn'","['python-2.7', 'python-3.x']","['python-2.7', 'python-3.x']"
40139735,"'Attribute error for PersonalInfoForm' 'I'm a little confused why is 'clickjacking middleware` trowing Attribute Error on my form.nnI'm making a simple application for collecting labor or user information and I'm facing a small problem can someone please help me and clarify what is wrong in this codennDpaste from my Traceback this is my viewnnclass PersonalInfoView(FormView):n    """"""TODO: CreateView for PersonalInfoFormn    return: TODOn    """"""n    template_name = 'apply_to/apply_now.html'n    form_class = PersonalInfoFormn    success_url = 'success/'nn    def get(self form *args **kwargs):n        """"""TODO: define get requestn        return: TODOn        """"""n        self.object = Nonen        form_class = self.get_form_class()n        form = self.get_form(form_class)n        return self.render_to_response(n            self.get_context_data(form=form))nn    def post(self form *args **kwargs):n        """"""TODO: Post request for PersonalInfoFormn        return: TODOn        """"""n        self.object = Nonen        form_class = self.get_form_class()n        form = self.get_form(form_class)n        if form.is_valid():n            return self.form_valid(form)n        else:n            return self.form_class(form)nn    def form_valid(self form *args **kwargs):n        """"""TODO: Validate formn        return: TODOn        """"""n        self.object = form.save()n        return HttpResponseRedirect(self.get_success_url())nn    def form_invalid(self form *args **kwargs):n        """"""TODO: handle invalid form requestn        return: TODOn        """"""n        return self.render_to_response(n            self.get_context_data(form=form))nnnUrls nn""""""superjobs URL Configurationnnthe `urlpatterns` list routes URLs to views. For more information please see:n    https://docs.djangoproject.com/en/1.8/topics/http/urls/nexamples:nfunction viewsn    1. Add an import:  from my_app import viewsn    2. Add a URL to urlpatterns:  url(r'^$' views.home name='home')nclass-based viewsn    1. Add an import:  from other_app.views import Homen    2. Add a URL to urlpatterns:  url(r'^$' Home.as_view() name='home')nincluding another URLconfn    1. Add a URL to urlpatterns:  url(r'^blog/' include('blog.urls'))n""""""nfrom django.conf.urls import include urlnfrom django.contrib import adminnfrom django.views.generic import TemplateViewnnfrom labor_apply_app.views import PersonalInfoViewnnurlpatterns = n    url(r'^admin/' include(admin.site.urls))n    # django-contrib-flatpagesnn    # url(r'^apply_to/' include('labor_apply_app.urls'))n    url(r'^$' 'labor_apply_app.views.index' name='index')nn    url(r'^apply_now/$' PersonalInfoView.as_view())n    url(r'^success/$' TemplateView.as_view())nn    #  Django Allauthn    url(r'^accounts/' include('allauth.urls'))nnn' ""Your traceback is showing that you haven't used the view above at all but the form. Presumably you've assigned the wrong thing in urls.py.nnEdit Actually the problem is that your post method when the form is not valid returns the form itself and not an HttpResponse.nnHowever you should not be defining any of these methods. You are just replicating what the class-based views are already supposed to be doing for you. Make your view actually inherit from CreateView and remove all those method definitions completely.n""",['django'],['django']
40139770,"'Setting Image background for a line plot in matplotlib' 'I am trying to set a background image to a line plot that I have done in matplotlib. While importing the image and using zorder argument also I am getting two seperate images in place of a single combined image. Please suggest me a way out. My code is -- nnrnrnimport quandlrnimport pandas as pdrnimport sys osrnimport matplotlib.pyplot as pltrnimport seaborn as snsrnimport numpy as nprnimport itertoolsrnrndef flip(items ncol):rn    return itertools.chain(*itemsi::ncol for i in range(ncol))rnrndf = pd.read_pickle('neer.pickle')rnrows = list(df.index)rncountries = 'USA''CHN''JPN''DEU''GBR''FRA''IND''ITA''BRA''CAN''RUS'rnx = range(len(rows))rndf = df.pct_change()rnrnfig ax = plt.subplots(1)rnfor country in countries:rntax.plot(x dfcountry label=country)rnrnplt.xticks(x rows size='small' rotation=75)rn#legend = ax.legend(loc='upper left' shadow=True)rnplt.legend(bbox_to_anchor=(1.05 1) loc=2 borderaxespad=0.)rnplt.show(1)rnrnplt.figure(2)rnim = plt.imread('world.png')rnax1 = plt.imshow(im zorder=1)rnax1 = df.iloc::.plot(zorder=2)rnhandles labels = ax1.get_legend_handles_labels()rnplt.legend(flip(handles 2) flip(labels 2) loc=9 ncol=12)rnplt.show()rnrnrnnnSo in the figure(2) I am facing problem and getting two separate plotsn' ""You're creating two separate figures in your code. The first one with fig ax = plt.subplots(1) and the second with plt.figure(2)nnIf you delete that second figure you should be getting closer to your goaln"" 'In order to overlay background image over plot we need imshow and extent parameter from matplotlib.nnHere is an condensed version of your code. Didn't have time to clean up much.nnFirst a sample data is created for 11 countries as listed in your code. It is then pickled and saved to a file (since there is no pickle file data).nnimport quandlnimport pandas as pdnimport sys osnimport matplotlib.pyplot as pltnimport seaborn as snsnimport numpy as npnimport itertoolsnnfrom scipy.misc import imreadnnnncountries = 'USA''CHN''JPN''DEU''GBR''FRA''IND''ITA''BRA''CAN''RUS'nndf_sample = pd.DataFrame(np.random.randn(10 11) columns=list(countries))ndf_sample.to_pickle('c:tempneer.pickle')nnnNext the pickle file is read and we create bar plot directly from pandasnndf = pd.read_pickle('c:tempneer.pickle')nmy_plot = df.plot(kind='bar'stacked=Truetitle=""Plot Over Image"")nmy_plot.set_xlabel(""countries"")nmy_plot.set_ylabel(""some_number"")nnnNext we use imread to read image into plot.nnimg = imread(""c:tempworld.png"")nplt.legend(bbox_to_anchor=(1.05 1) loc=2 borderaxespad=0.)nplt.imshow(imgzorder=0  extent=0.1 10.0 -10.0 10.0)nplt.show()nnnHere is an output plot with image as background.nAs stated this is crude and can be improved further.nn'",['matplotlib'],"['matplotlib', 'pandas']"
40139775,"'Python 3 socket programming: using sendall vs. sendto' 'As context to my question I am a computing student getting started with Python for the first time. Before this I've worked mostly with Java and I am most comfortable with Java conventions and practices right now.nnBackgroundnnAn assignment for socket programming asks that we send strings between a server and client locally on the machine. We are provided sample (Python 2) code that instantiates a server and client. Outside of the context of the assignment I wanted to create a version of this code that also runs in Python 3 but I was having problems getting the client to work the same in Python 3.nnChanging server and clientnnOriginally the server required little changes and I was able to get it working. My code for the server is as follows:nn#!/usr/bin/python3nnimport socketnnHOST=''nPORT=5870nnsock = socket.socket(socket.AF_INET socket.SOCK_STREAM)nsock.bind((HOST PORT))nsock.listen(1)nconn addr = sock.accept()nnprint('Connected by ' addr)nconn.sendto(""Welcome to the server!"" (HOST PORT))nnwhile True:n    data = conn.recv(1024)n    if not data: breakn    conn.sendall(data)nnconn.close()nnnI'm not able to convert the client side to code that runs and functions within Python 3. I've tried digging deeper into the issue but other online resources are not helpful for me (or at least at my experience level). My server code is as follows.nn#!/usr/bin/python3nnimport socketnnHOST='127.0.0.1'nPORT=5870nnsock = socket.socket(socket.AF_INET socket.SOCK_STREAM)nsock.connect((HOST PORT))ndata = sock.recv(1024)nprint('Server sent' data)nnsock.sendto(""Hello world"".encode() (HOST PORT))nndata = sock.recv(1024)nprint(""Server sent"" data)nnsock.sendto(""This is the second message"".encode() (HOST PORT))ndata = sock.recv(1024)nprint('Server sent ' data)nnsock.close()nnnThe actual problemnnOriginally this code for both the server and client used sendall() instead of sendto() but I changed it after getting a TypeError in the client and reading this question. I'm still not exactly sure why this works or why I have to do this (although I would appreciate an explanation).nnNow when I run the client code I'll get the same TypeError on the server even when I'm using sendto() but I'm not sure how to resolve this problem in Python 3. The stacktrace I receive for the server as follows (I get a broken pipe on the client):nn$ python3 mail_server.py nConnected by  ('127.0.0.1' 41866)nTraceback (most recent call last):n  File ""mail_server.py"" line 14 in <module>n    conn.sendto(""Welcome to the server!"" (HOST PORT))nTypeError: a bytes-like object is required not 'str'nnnWhat am I doing wrong and how am I able to get this working in Python 3? Background context as to why this is would be especially helpful as I think part of my problem is that I'm not seeing why this change is necessary to begin with. Thanks!n' nan",['python-3.x'],['python-3.x']
40139826,"'How do I return a nonflat numpy array selecting elements given a set of conditions?' ""I have a multidimensional array say of shape (4 3) that looks likenna = np.array((123)(456)(789)(101112))nnnIf I have a list of fixed conditionsnnconditions = True False False TruennnHow can I return the listnnarray((123)(101112))nnnUsing np.extract returnsnn>>> np.extract(conditions a)narray(1 4)nnnwhich only returns the first element along each nested array as opposed to the array itself. I wasn't sure if or how I could do this with np.where. Any help is much appreciated thanks!n"" ""Let's define you variables:nn>>> import numpy as npn>>> a = np.array((123)(456)(789)(101112))n>>> conditions = True False False TruennnNow let's select the elements that you want:nn>>> anp.array(conditions)narray( 1  2  3n       10 11 12)nnnAsidennNote that the simpler aconditions has some ambiguity:nn>>> aconditionsn-c:1: FutureWarning: in the future boolean array-likes will be handled as a boolean array indexnarray(4 5 6n       1 2 3n       1 2 3n       4 5 6)nnnAs you can see conditions are treated here as (integer-like) index values which is not what we wanted.n"" ""you can use simple list slicing and np.where It's more or less made specifically for this situation..nn>>> anp.where(conditions)narray( 1  2  3n        10 11 12)nn""",['numpy'],['numpy']
40139984,"""Is it possible to use FillBetweenItem to fill between two PlotCurveItem's in pyqtgraph?"" ""I'm attempting to fill between two curves that were created using PlotCurveItem in pyqtgraph.nn            phigh = self.p2.addItem(pg.PlotCurveItem(x y pen = 'k'))           n            plow = self.p2.addItem(pg.PlotCurveItem(x yy pen = 'k'))           n            pfill = pg.FillBetweenItem(phigh plow brush = br)n            self.p2.addItem(pfill)nnnThe curve items are plotting properly however there is no fill. n"" ""This fixed it.  nn            phigh = pg.PlotCurveItem(x y pen = 'k')           n            plow = pg.PlotCurveItem(x yy pen = 'k')                  n            pfill = pg.FillBetweenItem(ph plow brush = br)n            self.p2.addItem(ph)n            self.p2.addItem(plow)n            self.p2.addItem(pfill)nn""",['python-2.7'],['python-2.7']
40140000,"'Python with tcpdump in a subprocess: how to close subprocess properly?' 'I have a Python script to capture network traffic with tcpdumb in a subprocess:nnp = subprocess.Popen('tcpdump' '-I' '-i' 'en1'n                  '-w' 'cap.pcap' stdout=subprocess.PIPE)ntime.sleep(10)np.kill()nnnWhen this script complete work I'm trying to open output .pcap file in Wireshark and getting this error: ""The capture file appears to have been cut short in the middle of a packet.""nnWhat solution could be applied for ""proper"" closing of tcpdumb subprocess?n' nan",['python-2.7'],['python-2.7']
40140032,'Is it possible to monitor what websites a module is accessing?' 'I installed a module from the internet (pip3 install eventregistry) that searches eventregistry.org--a news compiler--for certain terms. I was wondering if I could monitor what webpages that eventregistry accesses while I use it in a Python program. nnIs this possible? Or am I misunderstanding how modules and APIs work?nnThis question arises from the need to do boolean searches for terms. It only seems possible through their module and not seemingly with a specific URL. n' nan,['python-2.7'],"['python-2.7', 'python-3.x']"
40140202,"'if-else in python list comprehensions' 'is it possible to write list comprehensions for the following python code:nnfor str in range(0len(mixed_content)):n    if (mixed_contentstr.isdigit()):n        num_list.append(mixed_contentstr)n    else:n        string_list.append(mixed_contentstr)nnncan we use else block in list comprehensions ? I tried to write list comprehensions for above code :nnnum_list  string_list =    mixed_contentstr  for str in range(0len(mixed_content)) if(mixed_contentstr.isdigit()) else nn' ""You can only construct one list at a time with list comprehension.  You'll want something like:nnnums = foo for foo in mixed_list if foo.isdigit()nstrings = foo for foo in mixed_list if not foo.isdigit()nn"" 'It's not possible as-is but if you're looking for one-liners you can do that with a ternary expression inside your loop (saves a test and is compact):nnnum_list=nstring_list=nfor s in ""45""""hello""""56""""foo"":n    (num_list if s.isdigit() else string_list).append(s)nnprint(num_liststring_list)nnnresult:nn'45' '56' 'hello' 'foo'nnnNotes:nnndespite the parenthesized syntax and the context of the question (num_list if s.isdigit() else string_list) is not a generator a ternary expression (protected between parentheses to counter .append precedence) which returns num_list if s is a sequence of (positive) digits and string_list if s otherwise.nthis code won't work with negative numbers because isdigits will return false. You'll have to code a special function for that (classical problem here on SO)nn' 'You can accomplish what you want with two list comprehensions:nnnum_list = num for num in mixed_content if num.isdigit()nstring_list = string for string in mixed_content if not string.isdigit()nnnThe else clause is not supported in list comprehensions:nn>>> c for c in range(5) if c == 1 else 0nSyntaxError: invalid syntaxnn' 'A super messy and unpractical way of doing is:nnmixed_content = 'a''b''c'""4""nstring_list = nnprint y for y in x if mixed_contentx.isdigit() else string_list.append(mixed_contentx) for x in range(0len(mixed_content)) if y != Nonenprint string_listnnnReturns: nn3n'a' 'b' 'c'nnnBasically list comprehension for your condition and then filter that list comprehension to only accept non Nonen' ""Let's initialize variables:nn>>> mixed_content='ab42c1'; num_list=; string_list=nnnLet's create the lists that you want with a single list comprehension:nn>>> num_list.append(c) if c.isdigit() else string_list.append(c) for c in mixed_contentnNone None None None None NonennnLet's verify that we have the lists that you want:nn>>> num_list string_listn('4' '2' '1' 'a' 'b' 'c')nn"" 'Here is an example of using x if b else y in a list comprehension.nnmixed_content = ""y16m10""nnnum_list string_list = zip(n    *(ch None) if ch.isdigit() else (None ch) for ch in mixed_content)nnum_list = filter(None num_list)nstring_list = filter(None string_list)nprint num_list string_listnn'","['python-2.7', 'python-3.x']",['list']
40140380,"'How to position matplotlib text relative to graph' 'I'm trying to position text on a matplotlib plot but I want to be able to have the text remain relative to the position on the graph. nnIt can be seen that the desired position of the text is central to the section that it's representing (see image). nnI currently have a couple of offset values that I'm using to do this but if I change the x range that I'm operating over or the function these values no longer apply. nnI would like to have a general way of positioning the text so that regardless of the function used the text will be central and sensibly positioned. nnBy sensibly positioned I mean that there should be a gap between $delta x$ and the horizontal line representing it. And the gap between $delta y$ should be equal to that of $delta x$nnOutputnnnnCodenn#!/usr/bin/env pythonnnimport numpy as npnfrom matplotlib import pyplot as pltnimport matplotlibnplt.style.use('ggplot')nnmatplotlib.rcParams'text.usetex' = Truenmatplotlib.rcParams'text.latex.unicode' = Truenn###############################################################################nndef f(x):n    return x**3nndef tri(x1 x2 f):n    """"""input of two x coordinates and function create and label a triangle ton    represent finding the gradientn    """"""nn    color = ""green""n    lw = 3nn    # Plot the triangle beneath the curven    plt.plot(x1 x2 f(x1) f(x1) color=color linewidth=lw)n    plt.plot(x2 x2 f(x1) f(x2) color=color linewidth=lw)nn    fontSz = 45nn    # TODO: I'M NOT SURE HOW TO PLACE THE FONT SO THAT IF I CHANGE THE FUNCTIONn    # OR FONT SIZE THE FONT IS PLACED IN THE SAME POSITION RELATIVELYnn    offset1 = 0.5  # < < < These!n    offset2 = 0.05 # < < <nn    dx_x_place = ((x1) + (x2))/2n    dx_y_place = f(x1) - offset1nn    dy_x_place = x2 + offset2n    dy_y_place = (f(x1) + f(x2))/2nn    # annotate delta xn    plt.text(n        dx_x_placen        dx_y_placen        r'$delta x$'n        horizontalalignment='center'n        verticalalignment='top'n        fontsize=fontSzn        color='black'n    )nn    # Annotate delta yn    plt.text(n        dy_x_placen        dy_y_placen        r'$delta y$'n        horizontalalignment='left'n        verticalalignment='center'n        fontsize=fontSzn        color='black'n    )nn###############################################################################nn# global variablesnX_DOMAIN = -14nX_DENSITY = 300nLINEWIDTH = 3nnnx = np.linspace(X_DOMAIN0 X_DOMAIN1 X_DENSITY)ny = f(x)nn# Just put some axis on the graphn# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.axvlinenplt.axhline(linewidth = 1 color=""grey"")nplt.axvline(linewidth = 1 color=""grey"")nn# create triangle to represent delta xyntri(2 3 f)nnplt.plot(x y linewidth=LINEWIDTH)nplt.show()nnnSystem that I'm usingnn$ lsb_release -anNo LSB modules are available.nDistributor ID: UbuntunDescription:    Ubuntu 14.04.5 LTSnRelease:    14.04nCodename:   trustynnnPython version that I'm usingnn3.5.2 |Continuum Analytics Inc.| (default Jul  2 2016 17:53:06) nGCC 4.4.7 20120313 (Red Hat 4.4.7-1)nnnMatplotlib versionnnimport matplotlibnmatplotlib.__version__nOut37: '1.5.1'nn' nan","['python-3.x', 'matplotlib']",['matplotlib']
40140397,'Matplotlib: Sharing axes when having 3 graphs 2 at the left and 1 at the right' 'I have following graph:nnnHowever I want that graphs 221 and 223 share the same x axis. I have the following code:nnself.fig_part_1 = plt.figure()nself.plots_part_1 = n  plt.subplot(221)n  plt.subplot(223)n  plt.subplot(122)nnnnHow can I achieve that? In the end I do not want the numbers of axis x in plot 221 to be shown.n' 'Just use plt.subplots (different from plt.subplot) to define all your axes with the option sharex=True:nnf axes = plt.subplots(22 sharex=True)nplt.subplot(122)nplt.show()nnnNote that the second call with larger subplot array overlay the preceding one.nnExample (could not display image due to reputation...)n',['matplotlib'],['matplotlib']
40140417,"'How can I use `map` in python to convert dict values to integers?' 'I'm trying to convert dictionary keys (from json.loads()) to ints with map().  I know I can do this with loops but I'm trying to do it functionally so I can implement it in spark.  For example:nnimport pyspark as psnimport jsonnn# Uses all 4 cores on your machinensc = ps.SparkContext('local4')nnfile_rdd = sc.textFile('data/cookie_data.txt')nkv_rdd_json = file_rdd.map(lambda x: json.loads(x))nkv_rdd2 = kv_rdd_json.map(lambda x: map(int x.get)) # here's the issuenkv_rdd.collect()nnnI have another way to do it with a function but I'm curious: how can I do it with .map in pyspark (and python2 bonus for python3)?nnPer the comments:nexample data (plaintext):nn{""Jane"": ""2""}n{""Jane"": ""1""}n{""Pete"": ""20""}n{""Tyler"": ""3""}n{""Duncan"": ""4""}n{""Yuki"": ""5""}n{""Duncan"": ""6""}n{""Duncan"": ""4""}n{""Duncan"": ""5""}nnnexample of how to convert dict values to int:nPython: How to convert a list of dictionaries' values into int/float from string?nnfor key in mydict.keys():n    mydictkey = int(mydictkey)nnnThe .get is kind of like here: Sort a Python dictionary by valuen' nan",['python-2.7'],['dictionary']
40140432,"'How can I extend the unit selection logic in my RTS game to apply to multiple units?' 'Currently if you left-click on the unit it becomes 'selected' (or 'de-selected') and a green square is drawn around it. Then when you right-click somewhere on the screen the unit moves neatly into the square in the location that you clicked.nnAlso if you use the up down left or right keys it will scroll the screen.nnimport pygamenimport randomnpygame.init()nn#Define mouse positionnmouse_position_x = 525nmouse_position_y = 315nn# Define colorsngreen = (02550)nbrown = (150750)nn#Define border positionnborder_x = 0nborder_y = 0nn#Define character selection boxndef character_selection_box():n    pygame.draw.line(screengreen(character_location_xcharacter_location_y)(character_location_x+character_widthcharacter_location_y)2) # Top barn    pygame.draw.line(screengreen(character_location_xcharacter_location_y+character_height)(character_location_x+character_widthcharacter_location_y+character_height)2) # Bottom barn    pygame.draw.line(screengreen(character_location_xcharacter_location_y)(character_location_xcharacter_location_y+character_height)2) # Left barn    pygame.draw.line(screengreen(character_location_x+character_widthcharacter_location_y)(character_location_x+character_widthcharacter_location_y+character_height+1)2) # Right barnn#Define roundndef assign_square(n):n    div = (n/35)n    rou = round(div)n    mul = (35*rou)n    return int(mul)nn#Set windownscreen_width = 981nscreen_height = 700ngame_screen_width = 800ngame_screen_height = 700nscreen_size = (screen_widthscreen_height)nscreen = pygame.display.set_mode(screen_size)npygame.display.set_caption(""Warpath"")nn#Set block characterncharacter_width = 35ncharacter_height = 35ncharacter_location_x = 525ncharacter_location_y = 315nmovement = 1nunit_selected = 0nn#Load imagesnorc_grunt_forward = pygame.image.load('orc_forward3.png') #(35 by 35 pixel image)ncharacter_image = orc_grunt_forwardnn#Loop until the user clicks the close buttonnshutdown = Falsenn#Set clocknclock = pygame.time.Clock()nn#Set scroll limitnscroll_x = 0nscroll_y = 0nn # ---------- Main program loop -----------nwhile not shutdown:nn    # --- Main event loop ---n    for event in pygame.event.get():nn        # --- If quit button pressed shutdownn        if event.type == pygame.QUIT: n            shutdown = Truenn        # --- If mouse button pressedn        elif event.type == pygame.MOUSEBUTTONDOWN: # If a mouse button is pressedn            mouse_position = pygame.mouse.get_pos() # Get mouse positionn            button_type = pygame.mouse.get_pressed() # Check which button was pressednn            # --- If left click pressed and the curser was on a character select that character n            if button_type0 == 1 and mouse_position0 >= character_location_x and mouse_position0 <= character_location_x + character_width and mouse_position1 >= character_location_y and mouse_position1 <= character_location_y + character_height:n                print(""Unit selected""unit_selected)n                print(button_type)n                unit_selected += 1n                unit_selected /= unit_selected #(Otherwise it will add up unit selected if you click more than once)n                int(unit_selected)nn            # --- If right click pressed and a character was selected (and it's within the game screen) move the character to the location     n            elif button_type2 == 1 and unit_selected == 1 and mouse_position0 > 175: n                mouse_position_x *= 0n                mouse_position_y *= 0nn                if mouse_position0 >= assign_square(mouse_position0):n                    mouse_position_x += assign_square(mouse_position0)nn                elif mouse_position0 <= assign_square(mouse_position0):n                    mouse_position_x -= 35n                    mouse_position_x += assign_square(mouse_position0)nn                if mouse_position1 >= assign_square(mouse_position1):n                    mouse_position_y += assign_square(mouse_position1)nn                elif mouse_position1 <= assign_square(mouse_position1):n                    mouse_position_y -= 35n                    mouse_position_y += assign_square(mouse_position1)nn            # --- If left click pressed and the curser was not on a character deselect the character        n            elif button_type0 == 1 and mouse_position0 < character_location_x or mouse_position0 > character_location_x + character_width or mouse_position1 < character_location_y or mouse_position1 > character_location_y + character_height:n                print(""Unit not selected"")n                print(button_type)n                unit_selected *= 0n                int(unit_selected)nn        # --- If key pressed scroll the screenn        elif event.type == pygame.KEYDOWN:nn            if event.key == pygame.K_RIGHT and scroll_x > -10:n                direction = ""right""n                character_location_x -= 35n                mouse_position_x -= 35n                border_x -= 35n                scroll_x -= 1nn            if event.key == pygame.K_LEFT and scroll_x < 10:n                direction = ""left""n                character_location_x += 35n                mouse_position_x += 35n                border_x += 35n                scroll_x += 1nn            if event.key == pygame.K_UP and scroll_y < 10:n                direction = ""up""n                character_location_y += 35n                mouse_position_y += 35n                border_y += 35n                scroll_y += 1nn            if event.key == pygame.K_DOWN and scroll_y > -10:n                direction = ""down""n                character_location_y -= 35n                mouse_position_y -= 35n                border_y -= 35n                scroll_y -= 1nn    # --- Game logic ---nn    # --- Set character movement      n    if character_location_x < mouse_position_x:n        character_location_x += movementn    if character_location_x > mouse_position_x:n        character_location_x -= movementn    if character_location_y < mouse_position_y:n        character_location_y += movementn    if character_location_y > mouse_position_y:n        character_location_y -= movementnn    # --- Drawing ---n    screen.fill(brown) # Draw backgroundn    screen.blit(character_image(character_location_xcharacter_location_y)) # Draw characternn    if unit_selected == 1: n        character_selection_box() # Draw character selection box if unit is selectednn    clock.tick(30)n    pygame.display.flip()nn#Shutdownnif shutdown == True:n    pygame.quit()nnnThe problem is that I can't figure out how to extend this to multiple units - currently if I want to add more units I can only either manage to:nna) Move them all at oncennor nnb) Paste the same code multiple times adjusting the character variable (not a robust / scalable solution)nnHow can I adjust my code so that I have a scalable solution where:nn1) I can select a single unit and move it without moving every unit at oncenn2) I can select multiple units by clicking on each one individually and move them all at once (not worrying about pathfinding right now)nnI also tried using classes to achieve this but it still felt like I was copying / pasting multiple functions rather than having a robust solution.nnI've removed any code that doesn't concern the issue while keeping a functioning program.nnThanksn' 'There are few things to do:nnnChange variables character_* to object that holds all data about the unit.nCreate array of units / characters. That way each unit in array can have unique position velocity ets. nEverywhere in code where you check character_* change to for loops where you iterate over characters array to check every unit.nNext step should be adding functions like move / shoot to character class to make keypress event working for multiple units.nnnThat should give you code where you can select multiple units (if they occupy same spot) and move them independently of deselected units.n'",['python-3.x'],['python-2.7']
40140498,"'Python Homework score of each name pair' ""I've got an exercise to do and I don't know why it is not working...nnI really hope someone could help mennThank you in advancennn  Calculate and display the score of each name pair (using the listsn  list_2D = âx80x9cJohnâx80x9dâx80x9cKateâx80x9dâx80x9cOliâx80x9dandâx80x9cGreenâx80x9d âx80x9cFletcherâx80x9dâx80x9cNelsonâx80x9d). Then  score of a name combination is calculated by taking the length of then  concatenated (merged) string storing the first and last names andn  adding the number of vowels in it. For example Oli Green has length 9n  (counting space between first and last name) + 4 for the four vowelsn  resulting in a total score of 13.nn"" 'I have changed some aspects because I am not going to do your homework for you but I understand just starting out on Stack and learning to program. It isn't easy so here's some explanation.nnSo what you will want to do is loop through all of the possible combinations of the first and last names.nnI would do a nested for loop:nnhere is the first part:nnarray1 = 'John' 'Kate' 'Oli'narray2 = 'Green' 'Fletcher' 'Nelson'nnfor i in range(03):n    for k in range(03):n        val = array1i + "" "" + array2kn        print(val)nnnWhat you are doing is you are keeping i at zero and then looping through everything in the second list. This way you can get every permutation of your list. To find the length you can do a for counting loop starting at position 0 or you can use the .len() function. To find the vowels you will need to look through each string you create and check to see if they match a e i o u. You can do something like nnif (valk == vowelListj):n       score += score nnThat is how I would do it but I am not as experienced as other people here.nnWelcome to Stack! It is scary and a lot of people can be off putting and rude just make sure to check other questions before you post and show some of your own work (what you have tried/attempted.)n'","['python-2.7', 'python-3.x']","['list', 'python-2.7']"
40140574,"'Problems with unsing TKinter and RPi.GPIO together for Skeeball program' 'I'm trying to make a program with Python that will be used for a skeeball game off of a raspberry pi.  I already have a script made up for having a simple 9 ball game using Tkinter and python.  My problem now is that I want to add more games such as a timed game or cricket for example and don't want to have to use the mouse to control the menus.  My original thought was to have tkinter frames stack on top of each other and pull the game that I wanted to the top.  I ran into way too many errors with GPIO not working properly with it (could have just been my inexperience but I decided to scrap that).  I now am trying to use code to pull up separate python scripts when a GPIO button is pressed usingnnimport subprocessnsubprocess.call('/home/pi/Skeeball_python/Skeeball02.py'nnThat code returned an error 13 with permission denied.  I gave root access to all the files and folders with my code in it and even was logged in as root user when I ran the program and still got the same error.nnMy question is how would I get this code to work in order to load separate scripts without returning an error and to also run as superuser since the GPIO part of the script needs root access.Should I keep trying with getting the separate script to load or should I try a different method?nnIf it's at all useful here is my 9 ball game code:nnimport RPi.GPIO as GPIOnfrom tkinter import *nnScreen = Tk()nScreen.geometry ('1920x1080')nGPIO.setmode (GPIO.BCM)nnGPIO.setup (17 GPIO.IN)nGPIO.setup (26 GPIO.IN pull_up_down=GPIO.PUD_DOWN) #GPIO 26 as reset nnscore = IntVar()nballcount = IntVar()nnscore.set(0)nballcount.set(9)nnmLabel1 = Label(Screentext = 'SCORE'fg = 'red'font=(""helvatica"" 100))nmLabel1.place(x='250'y='250')nmLabel2 = Label(Screentext = 'BALLS REMAINING'fg = 'red'font=(""helvatica"" 40))nmLabel2.place(x='250'y='550')nmLabel3 = Label(Screentextvariable = scorefg = 'red'font=(""helvatica"" 100))nmLabel3.place(x='950'y='250')nmLabel4 = Label(Screentextvariable = ballcountfg = 'red'font=(""helvatica"" 100))nmLabel4.place(x='950'y='500')nmLabel5 = Label(Screentext = 'Press Button to Reset'fg = 'red'font=(""helvatica"" 40))nmLabel5.place(x='250'y='550')nnmLabel5.place_forget()nnndef score100(self):n    if not ballcount.get()==0:n        score.set(score.get()+100)n        ballcount.set(ballcount.get()-1)            n    end()nndef reset(self):n    score.set(0)n    ballcount.set(9)n    mLabel2.place(x='250'y='550')n    mLabel4.place(x='950'y='500')n    mLabel5.place_forget()n    LEDwindup()nndef end():n    if ballcount.get() == 0:n        mLabel2.place_forget()n        mLabel4.place_forget()n        mLabel5.place(x='250'y='550')nnGPIO.add_event_detect(17GPIO.RISINGcallback=score100bouncetime=500)nGPIO.add_event_detect(26GPIO.FALLINGcallback=resetbouncetime=500)nnnScreen.mainloop()nGPIO.cleanup() nnnIt's pretty rough yet and I'm still pretty inexperienced in python so any suggestions would help as well too on other things.n' nan",['tkinter'],['tkinter']
40140733,'Django get related objects ManyToMany relationships' 'i have two models:nnclass CartToys(models.Model):n    name = models.CharField(max_length=350)n    quantity = models.IntegerField()nnclass Cart(models.Model):n    cart_item = models.ManyToManyField(CartToys)nnni want to get all related toys to this cart. how can i do this n' 'you would use...nncart = Cart.objects.first()nobjects = cart.cart_item.all() # this line return all related objects for CartToysn# and in reversencart_toy = CartToys.objects.first()ncarts = cart_toy.cart_set.all() # this line return all related objects for Cartnn',['django'],['django']
40140813,"'Brunel API not read dataframe?' ""I use this query in my notbook.nnn  nyvPan = nyvDF.toPandas() %brunel map ('NY') + data('nyvPan') x(lon)n  y(lat) color(Violations) tooltip(FACILITY)nnnbut it give me this errornnValueError: Could not execute Brunel: map ('NY') + data('nyvPan') x(lon) y(lat) color(Violations) tooltip(FACILITY).  Could not read data from: nyvPan(This is my dat frame)nn"" nan",['pandas'],['pandas']
40140817,"'Tkinter open with 1Button the directory of 2 Buttons and save a Textfile' 'I want to make a code to search for file names like *.bsp save the names in a text file delete the .bsp files and save the text file again. I thought maybe I can set it to global and put it in the def Button3 below  but I can't figured out how.nnfrom tkinter import *nfrom tkinter import filedialognnroot = Tk()nndef Button1():n mapdirectory = filedialog.askdirectory()n MapsFile.insert(0 mapdirectory)nndef Button2():n txtdirectory = filedialog.askdirectory()n TxTFile.insert(0 txtdirectory)nndef Button3():                  'This Button should do all the work'nnn#LabelnMapsDirectory = Label(root text=""Maps Directory"")nMapsDirectory.grid(row=0 sticky=W)nTxtDirectory = Label(root text=""Maps.txt Directory"")nTxtDirectory.grid(row=1 sticky=W)nnnMapsFile = Entry(root)nMapsFile.grid(row=0 column=1)nTxTFile = Entry(root)nTxTFile.grid(row=1 column=1)nn#Buttonsnb1 = Button(text=""Choose Map Folder"" command=Button1)nb1.grid(row=0 column=3 sticky=W)nb1.bind = ""<Button-1>""nnb2 = Button(text=""Choose txt Folder"" command=Button2)nb2.grid(row=1 column=3 sticky=W)nb2.bind = ""<Button-1>""nnb3 = Button(text=""Create Maps.txt"" command=Button3)nb3.grid(row=2 column=1)nb3.bind = ""<Button-1>""nnroot.mainloop()nnnThis is the old (non-GUI) code that does what I want:nnWD = r'Path for the files'nos.chdir(WD)nfiles = glob.glob('bhop_*.bsp')nwith open('maps.txt' 'w+') as in_files:n in_files.writelines(os.path.join(fn) + 'n' for fn in files)nninfile = r'Path from the.bspmaps.txt'noutfile = r""C:UsersDesktopmaps.txt""nndelete_list = "".bsp""nfin = open(infile)nfout = open(outfile ""w+"")nfor line in fin:n  for word in delete_list:n    line = line.replace(word """")n  fout.write(line)nfin.close()nfout.close()nn' nan",['tkinter'],"['tkinter', 'python-2.7']"
40140821,"'How do you look for a line in a text file from a sentence a user has inputted by using its keywords?' 'a=input(""Please enter your problem?"")nproblem= ()nnwith open('solutions.txt' 'r') as searchfile:n    for line in searchfile:n        if problem in line:n            print (line)nnnCan someone please help me on how to get the keywords from the inputed string by the user. Thanks. I need help on how to look for some of the words the users inputed in to =a and search for them on the textfile and print the linen' 'I assume your keywords is meant to be a list? nnThen you use any() to check if any word out of the keywords is in the line. nna=input(""Please enter your problem?"")nproblem= '#keywords' 'not' 'sure' 'how'nnwith open('solutions.txt' 'r') as searchfile:n    for line in searchfile:n        if any(word in line for word in problem):n            print (line)nnnThough you may want to split() your line to improve that detection. nnOtherwise you have a which stores the user's input so you can use that. nna=input(""Please enter your problem?"")nproblem= a.split()nnnThen again problem is a list so you use any() as beforennOr if you want to check if the entire entered value is in a line then nnif a in line:n    print(line)nn' ""I am not sure I understood the question but is this what you want?. this will take the line containing the most words from the user input:nnproblem = a.split(' ')nmax_num current_num = 00  #max_num count the maximum apparition of words from the input in the line| current_num count the current number of apparition of words of the user input in the linenchosen_line = ''nnwith open('solutions.txt' 'r') as searchfile:n    for line in searchfile:n        for word in problem:n            if word in line:n                current_num+=1n        if current_num>max_num:n            print linemax_numcurrent_numn            max_num=current_numn            chosen_line = linen        current_num = 0n    print chosen_linennnbut it seems to me the easiest way to do what you want is to store at the start of each answer the question or even easier - just ask the user the question number and return this corresponding answer.n""",['python-3.x'],"['python-2.7', 'list', 'python-3.x']"
40140836,'Different plots when using pcolormesh and contourf' 'I have a a 2D array of 1's and 0's representing the data quality of each pixel from a satellite sweep. I will eventually be using this array as a mask for another array of data but I first decided to make a plot of the pixel quality array to see where my data was good.nnHowever I've noticed that when I use pcolormesh and contourf to plot the array the resulting picture is different.nnUsing pcolormesh (where lon and lat are corresponding 2D arrays)...n    m = Basemap()n    m.drawcoastlines()n    m.pcolormesh(lonlat badPix)nnResults in this plot:nnnHowever using contourf...nnm = Basemap()nm.drawcoastlines()nm.contourf(lonlat badPix)nnnResults in this plot:nnnI also get this warning when using contourfnnn  WARNING: x coordinate not montonically increasing - contour plotn  may not be what you expect.  If it looks odd your can eithern  adjust the map projection region to be consistent with your data orn  (if your data is on a global lat/lon grid) use the shiftgridn  function to adjust the data to be consistent with the map projectionn  region (see examples/contour_demo.py).nnnThe most confusing part to me is the large blue tail that only shows up on the contourf plot. The red bar on the top of the contourf plot also appears to cover up some of the good data (blue pixels) that are there on the pcolormesh plot nnAny idea whats going on here? I'd really like to know where exactly I have good data so I know when my final masked array should look liken' nan,['matplotlib'],['matplotlib']
40140864,'How to find the index of a value in a list of dictionaries?' 'dict_ulist is a list of dictionaries: {}. Each dictionary has 3 keys.ndict_elist is also a list of dictionaries and they contain 5 keys.nnI know a lot of values for one of the keys in each dictionary.nnI want to go through dict_ulist and find the index of the value i.e. where it is in the list so i can print that particular dictionary. nnI then want to take values from this information and search the other dictionary for the index so I can get the rest of the information from that dictionary.nnhow do I do this?n' nan,"['list', 'dictionary']","['dictionary', 'list']"
40140933,"'What do &= |= and ~ do in Pandas' ""I frequently see code like this at work:nnoverlap &= group'ADMSN_DT'.loci <= group'epi_end'.locjnnnMy question is what do operators such as &= |= and ~ do in pandas?n"" 'From the documentationnnn  The operators are: | for or & for and and ~ for not. These must ben  grouped by using parentheses.nnnAugmented assignment statementsnnn  An augmented assignment evaluates the target (which unlike normaln  assignment statements cannot be an unpacking) and the expressionn  list performs the binary operation specific to the type of assignmentn  on the two operands and assigns the result to the original target.n  The target is only evaluated once.nnnjust like a += 1 increments a a &= b compares a and b and assigns the result to a.nna = 1nb = 0nprint(a & b)n>>> 0na &= bnprint(a)n>>> 0nnnAnd a pandas examplennLet's generate a dataframe of zeros and ones.nnimport numpy as npnimport pandas as pdna = pd.DataFrame(np.random.randint(0 2 size=(64)) columns=list('ABCD'))nb = pd.DataFrame(np.random.randint(0 2 size=(64)) columns=list('ABCD'))nnnOur initial dataframennprint(a)nnnn   A  B  C  Dn0  0  1  1  0n1  0  0  1  0n2  1  0  0  1n3  1  1  0  0n4  0  0  0  1n5  0  0  0  0nnnnprint(b)nnnn   A  B  C  Dn0  0  0  0  0n1  1  1  1  0n2  0  1  1  1n3  0  1  1  1n4  1  1  1  0n5  1  1  1  1nnnnThe 4th row of a and bnnprint(a.loc3)nnnnA    1nB    1nC    0nD    0nName: 1 dtype: int32nnnnprint(b.loc3)nnnnA    0nB    1nC    1nD    1nName: 1 dtype: int32nnnnNow evaluate and assign row 4nna.loc3 &= b.loc3nnnRow 4 of a has changed. Only where both rows have 1 at the same position a 1 is written back to a.nnprint(a.loc3)nnnnA    0nB    1nC    0nD    0nName: 3 dtype: int32nnn'","['python-2.7', 'pandas']",['pandas']
40140942,"'Numpy: How to vectorize parameters of a functional form of a function applied to a data set' 'Ultimately I want to remove all explicit loops in the code below to take advantage of numpy vectorization and function calls in C instead of python.nnBelow is simplified for uses of numpy in python.nI have the following quadratic function:nndef quadratic_func(abcx):n    return a*x*x + b*x + cnnnI am trying to optimize choices of abc given input data x and output data y of the same size (of course this should be done by linear regression...but humor me). Say len(x)=100.  Easy to vectorize with scalars abc to get back a result of length 100.nnLet's say that we know abc should be inside of -1010 and I optimize by building a grid and picking the point with the min sum square error.nna=np.arange(-10.0 10.01 2.0)nnodes=np.array(np.meshgrid(aaa)).T.reshape(-13) #3-d cartesian product with array of nodesnnnFor each of the 1331 nodes I would like to calculate all 1331 of the length 100 return values. nnres=nx=np.random.uniform(-5.05.0 100)nfor node in nodes:n    res.append(quadratic_func(*node x=x))nnnHow can I take advantage of broadcasting so as to get my list of 1331 items each with 100 values that are the results of calling quadratic_func on x?  Answer must use vectorization broadcasting etc to get the orders of magnitude speed improvements I am looking for.  Also the answer must use calls to quadratic_func - or more generally my_func(*node x=x).nnIn real life I am optimizing a non-linear function that is not even close to being convex and has many local minimums.  It is a great functional form to use if I can get to the ""right"" local minimum - I already know how to do that but would like to get there faster!n' 'One approach using a combination of broadcasting and np.einsum -nnnp.einsum('ijjk->ik'nodesx**np.array(210):None)nnnAnother one using matrix-multiplication with np.dot -nnnodes.dot(x**np.array(210):None)nn'",['numpy'],['numpy']
40140958,"'Python/Spyder: General Working Directory' 'So far I have code that opens a text file manipulates it into a pandas data file then exports to excel.nnI'm sharing this code with other people and we all have the same working directory within Spyder. All the code works fine the only lines I want to manipulate are the opening of the file and the exporting of the file.nnwith open(r'C:Users""my_name""Desktopdatafile.txt' 'r') as data_file:nnnnnThe issue here is I want to set my working directory to just ""data"" so that I can just write: nnwith open(r'file.txt' 'r') as data_file:nnnthis way the people I send it to who also have ""data"" as their working directory on their computer can just run the code and it will select the ""file.txt"" that is in their data directory.n' ""The answer that you are technically looking for is using os.chdir() as followsnnimport osnos.chdir('.' 'data')n#THE REST OF THE CODE IS THE SAMEnwith open(r'file.txt' 'r') as data_file:nnnA safer answer would however be nndef doTheThing(fName):n    return os.path.join(os.getcwd()'data'fName)nnwith open(doTheThing('file.txt') 'r') as data_file:nn""",['python-3.x'],['python-2.7']
40141171,"'Python: Finding palindromes in a list' 'def num_sequence (num1 num2):n#This function takes the lower and upper bound and builds a list.n    array = n    for i in range(num2 + 1):n        if i >= num1:n            array.append(i)n    return arraynndef inverted_sequence (array):n#This function takes the previous and list inverts the numbers in every element.n    for i in range(len(array)):n        if arrayi > 10:n            arrayi = str(arrayi)n            #Converts the i element of the array to a string.n            arrayi = arrayi::-1n            #Inverts the the position of the numbers in every element.n            arrayi = int(arrayi)n            #Converts the i element of the array to an integer.n    return arraynnndef main ():n    #Main program.nn    lower = int(input(""Type the lower bound:    ""))n    upper = int(input(""Type the upper bound:    ""))nn    sequence = num_sequence(lower upper)n    inv_sequence = sequence:n    inv_sequence = inverted_sequence(inv_sequence)nn    print (sequence)n    print (inv_sequence)n    """"""While loop inside the for loop that checks if the number is a palindrome.n    if to check if it is a palindrome return True else return False""""""n    pal_count = 0n    seq_sum = n    for i in range(len(sequence)):n        if sequencei != inv_sequencei:n            while sequencei != inv_sequencei:n                seq_sum.append(sequencei + inv_sequencei)n                sequence = seq_sumn                inv_sequence = inverted_sequence(inv_sequence)n                print (seq_sum)n        if sequencei == inv_sequencei:n            pal_count *= 1n    print (pal_count)nnnmain()nnnI am trying to make a program that finds all the palindromes in a range of numbers and if they are not palindromes reverse the number and add it to the original until it becomes a palindrome. In my code I created a list of numbers with two inputs and name the list sequence. inv_sequence is the previous list but with numbers of each element reversed. when i try to add sequencei and inv_sequencei the program throws an error saying that the list is out of range. I am testing the program with the lower bound being 5 and the upper bound being 15.n' 'I assume that you mean that you want the final list to contain the lowest palindrome in the sequence formed by the sum of the previous number in the sequence and the result of reversing the previous number in the sequence.nnIf so here is some code (not bulletproof):nn#checks if a number is a palindrome by comparing the string written fowardsn#with the string written backwardsndef is_pal(x):n    if str(x)==str(x)::-1:n        return Truen    return Falsenn#iterates a number by adding and reversing until it is a palindromndef iter_pal(x):n    while not is_pal(x):n        x+=int(str(x)::-1) #adds the number's reverse to itselfn    return x        nn#main programndef main():n    #gets inputn    lower = int(input(""Type the lower bound:    ""))n    upper = int(input(""Type the upper bound:    ""))nn    #uses range to make the sequence of numbersn    sequence = list(range(lowerupper+1))nn    #iterates through the list performing iter_paln    for i in range(upper-lower+1):n        sequencei=iter_pal(sequencei)nn    #prints the final sequencen    print(sequence)nnmain()nnnI'm not sure what you will do with the Lychrel numbers.n'",['python-3.x'],"['list', 'python-2.7']"
40141190,"'Removing null=True from Django model CharField are values updated to empty string' 'I have a error being thrown when I navigate to my ListCreateAPIView base url:nnurl(r'^tests/$' TestList.as_view())nnnerror:nncoercing to Unicode: need string or buffer NoneType foundnnnwhich I believe to be related to the null=True in many of my CharField's throughout my various models. I ran into this error when attempting to addnDjango Rest Framework Parsers to a ListAPIView like so:nnclass TestList(generics.ListCreateAPIView):n    """"""n    """"""nn    queryset = Tests.objects.all()n    serializer_class = TestSerializern    filter_class = TestFiltern    parser_classes = (FormParser MultiPartParser)nnclass Courses(models.Model):n    created = models.DateTimeField(default=timezone.now)n    name = models.CharField(max_length=200 unique=True)n    test = models.ForeignKey('Tests'n                             blank=Truen                             null=Truen                             on_delete=models.CASCADE)nnnclass Tests(models.Model):n    name = models.CharField(max_length=200)nnnit's either getting upset because of the null=True on the CharField's or perhaps because of the test foreign key I'm not totally sure? Would removing null=True and migrating solve this issue? Additionally I should probably remove the null=True on CharField's anyway would that be updated retroactively in the database? n' nan",['django'],['django']
40141193,'Deploying a Django app with Nginx + Uwsgi' 'So I am kinda new to uwsgi + nginx and I am trying build a docker container for a django app using nginx + uwsgi. The problem that I am experiencing is that I cannot get the nginx + uwsgi part to work. What I have in my uwsgi.ini file is:nnuwsginwsgi-file = /path to/wsgi.pynchdir = /new foldernpythonpath = /var/wwwnsocket = :8000nnnAnd my conf file for nginx looks like this:nnserver {n    listen      8000;nn    server_name 192.168.99.100; #because of docker containern    charset     utf-8;nnn    client_max_body_size 75M;  nn    location / {n        uwsgi_pass  django;n        include     /pathto/uwsgi_params; n        }n    }nnnI saw I have to create a socket to link both of them but every time I create a socket and replace :8000 in the uwsgi.ini file the container of the app simply exits. How am I actually supposed to tell uwsgi and nginx to work together? Furthermore uwsgi seems to not load any apps eventhough I read almost every single topic on the internet that I could find and did everything that was written...n' nan,['django'],['django']
40141258,"'Updating matplotlib.pyplot figure in python' 'I have a script that takes data form an external source runs some analysis on it and then plots a graph in a separate window using matplotlib.pyplot.  I'm running this from iPython in the windows command prompt (with py34.3 activated).  The plot looked perfect when I just wanted to print one time but now I'm trying to automate the updating process...  In a while loop I'm loading new data and printing a graph.  My issue is that plt.show() blocks the rest of my code from executing.  I've tried using plt.ion() and a few other things but none of it seems to work.  For example with plt.ion() my plot is not formatted correctly and after printing the first time it then freezes and stops responding so I have to close it and quit the program.   nnI've checked all over google and stackoverflow and generally am just a little confused about how to apply the answers I've found to my own code.  The most viable options I've found are either using a subprocess using matplotlib animation or just switching to ggplot2 instead of matplotlib.  nnHere's my code I've commented out a few places where I added plt.ion() and things like that:nndef display_script(args):    n    fig = plt.figure()n    a_plt = fig.add_subplot(211)n    a_plt.set_title('A')n    b_plt = fig.add_subplot(212)n    b_plt.set_title('B') n    plt.tight_layout()n    #tried adding plt.ion() here but no dicen    plt.ion()n    plt.show()n    plt_dict = {'A':a_plt'B':b_plt}n    curtime = datetime.datetime.now().time()  n    while curtime < datetime.time(141): n        cur_df = current_data()n        for curchoice in 'A''B':n            for label in some_labels: n                valprojdiffsstyle = #some calculationsn                plt_dictcurchoice.plot(projcolor='b'linestyle=stylelabel=label)n                #plt.pause(0.000001)n            val = #some calculationsn            plt_dictcurchoice.plot(val'-r'label='Current Value')n            #plt.pause(0.000001)n            plt_dictcurchoice.legend(loc = 'lower right')n            #plt.pause(0.000001)n            if curchoice in GLOBAL_LIST: n                plt_dictcurchoice.set_xticklabels(MONTH_LIST1:)n                #plt.pause(0.000001)n            else: n                plt_dictcurchoice.set_xticklabels(MONTH_LIST)n                #plt.pause(0.000001)n            txt = """"n            fig = plt_dictcurchoicen            for mnth in MONTH_LIST: n                this_label = curchoice + '_' + mnthn                if this_label in yest_data.keys(): n                    curval = cur_dfthis_label0n                    diff = curval - yest_datathis_labeln                    txt += ""{0}: {1:.2f} {2:.2f}n"".format(this_labelcurvaldiff)n            if curchoice == 'A': n                a_plt.text(9.27txt)n                #plt.pause(0.000001)n            else: n                a_plt.text(9.22txt)n                #plt.pause(0.000001)n            if curchoice=='A':n                txt = ""  {0:%H:%M:%S} - FLAGS: n n"".format(curtime)n                for i in some_range: n                    txt += "" example text {0}n"".format(i)n                a_plt.text(01txt)n                #plt.pause(0.000001)n        plt.subplots_adjust(bottom=0.2right=0.7)    n        plt.draw()n        #plt.ion()n        #plt.show()#block=False)n        time.sleep(120)n        #plt.close()n        plt.clf()n        #plt.ioff()n        curtime = datetime.datetime.now().time()n    return nn' nan",['matplotlib'],['matplotlib']
40141353,"'Convert multiple columns to one column' ""I'm looking to merge multiple columns to one column.nnHere's my current dataset :nnColumn A  Column B   Column C n    a1       b1        c1 n    b2       a2        e2 nnnI am looking for the following as outputnnColumn D  n  a1n  b1n  c1n  b2 n  a2n  e2nnnIs this possible ? Using R or Python ?n"" 'With the data that you provided in the format you provided you could do this with:nndata.frame(ColumnD=c(t(df)))nn  ColumnDn1      a1n2      b1n3      c1n4      b2n5      a2n6      e2nnnWe transpose the data then combine it.n'",['list'],['pandas']
40141445,"""matplotlib & seaborn: ValueError: Supply a 'c' kwarg or a 'color' kwarg but not both; they differ but their functionalities overlap"" 'I am trying to use the following code to create multiple seaborn regplot in a big figure:nn%matplotlib notebooknimport seaborn as snsnfrom itertools import combinationsnimport matplotlib.pyplot as pltnnpairs = list(combinations(pandas_transformed.drop('prediction'axis=1).columns 2))ncol = pandas_transformed.prediction.map({0: 100 1:010})nnfig axes = plt.subplots(len(pairs) // 3 3 figsize=(12 108))nfor i pair in enumerate(pairs):n    d = pandas_transformedlist(pair)n    ax = axesi // 3 i % 3n    #d.plot.scatter(*pair ax=ax c=col linewidths=0 s=2 alpha = 0.7)n    sns.regplot(x = pair0 y = pair1 data = d fit_reg = False ax = ax x_jitter = Truen             scatter_kws={""c"": col} line_kws = {})nnfig.tight_layout()nnnHowever I got the following error:nnValueErrorTraceback (most recent call last)n<ipython-input-12-ae2676825628> in <module>()n     12     ax = axesi // 3 i % 3n     13     #d.plot.scatter(*pair ax=ax c=col linewidths=0 s=2 alpha = 0.7)n---> 14     sns.regplot(x = pair0 y = pair1 data = d fit_reg = False ax = ax x_jitter = True             scatter_kws={""c"": col} line_kws = {})n     15 n     16 fig.tight_layout()nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in regplot(x y data x_estimator x_bins x_ci scatter fit_reg ci n_boot units order logistic lowess robust logx x_partial y_partial truncate dropna x_jitter y_jitter label color marker scatter_kws line_kws ax)n    777     scatter_kws""marker"" = markern    778     line_kws = {} if line_kws is None else copy.copy(line_kws)n--> 779     plotter.plot(ax scatter_kws line_kws)n    780     return axn    781 nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in plot(self ax scatter_kws line_kws)n    328         # Draw the constituent plotsn    329         if self.scatter:n--> 330             self.scatterplot(ax scatter_kws)n    331         if self.fit_reg:n    332             self.lineplot(ax line_kws)nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in scatterplot(self ax kws)n    357 n    358             x y = self.scatter_datan--> 359             ax.scatter(x y **kws)n    360         else:n    361             # TODO abstractionnn/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc in inner(ax *args **kwargs)n   1817                     warnings.warn(msg % (label_namer func.__name__)n   1818                                   RuntimeWarning stacklevel=2)n-> 1819             return func(ax *args **kwargs)n   1820         pre_doc = inner.__doc__n   1821         if pre_doc is None:nn/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc in scatter(self x y s c marker cmap norm vmin vmax alpha linewidths verts edgecolors **kwargs)n   3787                 facecolors = con   3788             if c is not None:n-> 3789                 raise ValueError(""Supply a 'c' kwarg or a 'color' kwarg""n   3790                                  "" but not both; they differ but""n   3791                                  "" their functionalities overlap."")nnValueError: Supply a 'c' kwarg or a 'color' kwarg but not both; they differ but their functionalities overlap.nnnThe error is really confusing. Since I only supply scatter_kws={""c"": col} the default color is None. And per seaborn document at https://seaborn.github.io/generated/seaborn.regplot.html#seaborn.regplotnncolor : matplotlib colornColor to apply to all plot elements; will be superseded by colors passed in scatter_kws or line_kws.nnnI don't understand why I am getting this error. Does anyone have any idea? Thanks!n' nan","['python-2.7', 'matplotlib']",['matplotlib']
40141540,"'Easier way to check if a string contains only one type of letter in python' ""I have a string '829383&&*&@<<<<>><>GG'. I want a way to measure if a string has only one type of letter. For example the string above would return True because it only has two Gs but this string '829383&&*&@<<<<>><>GGAa' would not. I've been iteratively going through the string having made it into an array. I was hoping someone knew an easier way. n"" 'use filter with str.isalpha function to create a sublist containing only letters then create a set. Final length must be one or your condition isn't met.nnv=""829383&&&@<<<<>><>GG""nnprint(len(set(filter(str.isalphav)))==1)nn' ""Jean-Francois's answer is what I'd actually use 99% of the time but for cases where the string is huge you might want a solution that will return as soon as the second unique character is detected instead of finishing processing:nnfrom future_builtins import map filter  # Only on Py2 to get lazy map/filternnfrom itertools import groupby islicenfrom operator import itemgetternn# Remove non-alphas then reduce consecutive identical alphabetic charactersn# to a single instance of that characternlets = map(itemgetter(0) groupby(filter(str.isalpha somestr)))nn# Skip the first result and if we find a second then there was more than onen# in the stringnif next(islice(lets 1 None) None) is not None:n   # There were at least two unique alphabetic charactersnelse:n   # There were only 0-1 unique alphabetic charactersnnnDistinguishing no alphabetic from one alphabetic could instead be done without islice as:nnatleastone = next(lets None) is not Nonenmultiple = next(lets None) is not Nonenn""",['python-3.x'],['python-2.7']
40141572,"'Python regex : trimming special characters' 'Is it possible to remove special characters using regex?nnI'm attempting to trim:nnnttttttttttButte County High Schooltttttttttnnndown to:nnButte County High Schoolnnnusing    nnregexform = re.sub(""A-Z+a-z+s*""'' schoolstring)nprint regexformnn' 'You do not need regex for this simple task. Use string.strip() instead. For example:nn>>> my_string = 'ttttttttttButte County High Schoolttttttttt'n>>> my_string.strip()n'Butte County High School'nnnIn case it is must to use regex your expression should be:nn>>> re.sub('^A-Za-z0-9s+' '' my_string)n'Butte County High School'nnnIt matches a string of characters that are not letters or numbers.n' 'Except you have reasons to want to use regex you can remove all edge white space with .strip() function in pythonn' ""If you're really set on using regular expressions:nnre.sub(r'^s+|s+$' '' schoolstring)nnnThis will work for:nn'   this is a test   '   # multiple leading and trailing spacesn' this is a test '       # one leading and trailing spacen'this is a test'         # no leading or trailing spacesn'ttthis is a testtt' # leading or trailing whitespace charactersnnnThis expression one or more whitespace characters from the start ^s+ of the string or | one or more whitespace characters from the end of the string s+$.nnHowever string.strip() is simpler for removing leading and trailing space.n""",['regex'],['regex']
40141692,"'twitter mining Memory error' ""I am doing twitter mining where I am dealing with large amount of data .I am getting Memory error in my below code - nn    ids_str = ''.join(str(_id) for _id in ids:100)n    ids = ids100: <--------- this point has memory error .nnnwhere ids dict has around 12.5 Million entries . what could be the issue here could you please suggest.?n"" nan",['python-2.7'],['python-2.7']
40141828,"'Django ImportError No module named x.settings' 'I have the following structure:nnmysiten  -> manage.pyn  -> mysite (again)n        -> __init__.pyn        -> wsgi.pyn        -> settings.pyn         etcn  -> myappn        -> __init__.py            n        -> myscript.pyn        -> models.pyn        etcnnnWhen I run a script from myapp (that does myapp-related things putting stuff in a the database for example) i need to do nnimport djangondjango.setup()nnnin order to be able to from models import MyModel. But if i do this in the myapp directory I get:nnTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""C:Python27libsite-packagesdjango__init__.py"" line 22 in setupn    configure_logging(settings.LOGGING_CONFIG settings.LOGGING)n  File ""C:Python27libsite-packagesdjangoconf__init__.py"" line 53 in __getattr__n    self._setup(name)n  File ""C:Python27libsite-packagesdjangoconf__init__.py"" line 41 in _setupn    self._wrapped = Settings(settings_module)n  File ""C:Python27libsite-packagesdjangoconf__init__.py"" line 97 in __init__n    mod = importlib.import_module(self.SETTINGS_MODULE)n  File ""C:Python27libimportlib__init__.py"" line 37 in import_modulen    __import__(name)nImportError: No module named mysite.settingsnnnWhich I kind of understand since it's further up the directory tree and not in the  same directory as e.g manage.py (the root I guess?). When I issue a python interpreter in mysite where manage.py is located I dont get this error.nnWhat should I do to be able to place my scripts in myapp and still be able to use django.setup() from that dir? n' ""You need to make sure the root of your project is in python path when you run the script. Something like this might help.nnnimport osnimport sysnprojpath = os.path.dirname(__file__)nsys.path.append(os.path.join(projpath '..'))nn""",['django'],['django']
40141856,"'How can I manipulate strings in a slice of a pandas MultiIndex' 'I have a MultiIndex like this:nn                                 metricnsensor  variable   side  nfoo        Speed   Left      Left speedn                  Right     Right speednbar        Speed   Left      Left_Speedn                  Right     Right_Speednbaz        Speed   Left           speednfoo      Support   Left    Left supportn                  Right   Right supportnbar      Support   Left    Left_supportn                  Right   Right_supportnbaz      Support   Left         supportnnnI'm trying to apply a string mapping to a slice of this dataframe:nndf.loc'baz':'Left'.metric.map(lambda s: ""Left_"" + s)nnnHow can I apply this map to just the baz-Left rows and get back the resulting DataFrame?nn                                 metricnsensor  variable   side  nfoo        Speed   Left      Left speedn                  Right     Right speednbar        Speed   Left      Left_Speedn                  Right     Right_Speednbaz        Speed   Left      Left_speednfoo      Support   Left    Left supportn                  Right   Right supportnbar      Support   Left    Left_supportn                  Right   Right_supportnbaz      Support   Left    Left_supportnn' ""I found the following method but i think/hope there must be a more elegant way to achieve that:nnIn 101: index_saved = df.indexnnnLet's sort index in order to get rid of KeyError: 'MultiIndex Slicing requires the index to be fully lexsorted tuple len (3) lexsort depth (0)' error:nnIn 102: df = df.sort_index()nnIn 103: dfnOut103:n                              metricnsensor variable sidenbar    Speed    Left      Left_Speedn                Right    Right_Speedn       Support  Left    Left_supportn                Right  Right_supportnbaz    Speed    Left           speedn       Support  Left         supportnfoo    Speed    Left      Left speedn                Right    Right speedn       Support  Left    Left supportn                Right  Right supportnnIn 119: df.locpd.IndexSlice'baz' : 'Left' 'metric' = n     ...:     'AAA__' + df.locpd.IndexSlice'baz' : 'Left' 'metric'nnIn 120: dfnOut120:n                              metricnsensor variable sidenbar    Speed    Left      Left_Speedn                Right    Right_Speedn       Support  Left    Left_supportn                Right  Right_supportnbaz    Speed    Left      AAA__speedn       Support  Left    AAA__supportnfoo    Speed    Left      Left speedn                Right    Right speedn       Support  Left    Left supportn                Right  Right supportnnnset back old (saved) index:nnIn 121: df = df.reindex(index_saved)nnIn 122: dfnOut122:n                              metricnsensor variable sidenfoo    Speed    Left      Left speedn                Right    Right speednbar    Speed    Left      Left_Speedn                Right    Right_Speednbaz    Speed    Left      AAA__speednfoo    Support  Left    Left supportn                Right  Right supportnbar    Support  Left    Left_supportn                Right  Right_supportnbaz    Support  Left    AAA__supportnn""",['pandas'],['pandas']
40141881,"'pandas groupby transform behaving differently with seemingly equivalent representations' 'consider the dfnndf = pd.DataFrame(dict(A='a' 'a' B=0 1))nnnI expected the following two formulations to be equivalent.nnformulation 1 nndf.groupby('A').transform(np.mean)nnnnnformulation 2nndf.groupby('A').transform(lambda x: np.mean(x))nnnnnI'd consider the results from formulation 2 incorrect.  But before I go crying bug maybe someone has a rational explanation for it.n' ""It looks like a bug to me:nnIn 19: df.groupby('A').transform(lambda x: x.sum())nOut19:n   Bn0  1n1  1nnIn 20: df.groupby('A').transform(lambda x: len(x))nOut20:n   Bn0  2n1  2nnIn 21: df.groupby('A').transform(lambda x: x.sum()/len(x))nOut21:n   Bn0  0n1  0nnnPS Pandas version: 0.19.0n""",['pandas'],['pandas']
40141895,"'How to do a substring using pandas or numpy' 'I'm trying to do a substring on data from column ""ORG"".  I only need the 2nd and 3rd character.  So for 413 I only need 13.  I've tried the following:nnAttempt 1:  dr2'unit' = dr2'ORG'1:2nAttempt 2:  dr2'unit' = dr2'ORG'.str1:2nAttempt 3:  dr2'unit' = dr2'ORG'.str(1:2)nnnMy dataframe:nn    REGION  ORGn90       4  413n91       4  413n92       4  413n93       5  503n94       5  503n95       5  503n96       5  503n97       5  504n98       5  504n99       1  117n100      1  117n101      1  117n102      1  117n103      1  117n104      1  117n105      1  117n106      3    3n107      3    3n108      3    3n109      3    3nnnExpected output:nn    REGION  ORG  UNITn90       4  413  13n91       4  413  13n92       4  413  13n93       5  503  03n94       5  503  03n95       5  503  03n96       5  503  03n97       5  504  04n98       5  504  04n99       1  117  17n100      1  117  17n101      1  117  17n102      1  117  17n103      1  117  17n104      1  117  17n105      1  117  17n106      3    3  03n107      3    3  03n108      3    3  03n109      3    3  03nnnthanks for any and all help!n' ""Your square braces are not matching and you can easily slice with -2:.nnapply str.zfill with a width of 2 to pad the items in the new series:nn>>> import pandas as pdn>>> ld = {'REGION': '4' 'ORG': '413'} {'REGION': '4' 'ORG': '414'}n>>> df = pd.DataFrame(ld)n>>> dfn   ORG REGIONn0  413      4n1  414      4n>>> df'UNIT' = df'ORG'.str-2:.apply(str.zfill args=(2))n>>> dfn   ORG REGION UNITn0  413      4   13n1  414      4   14n2    3      4   03nn""","['pandas', 'numpy']",['pandas']
40142004,'Efficiently summing outer product for 1D NumPy arrays' 'I have a function of the formnnnnOne way to implement this function in numpy is to assemble a matrix to sum over:nny = a*b - np.sum(np.outer(a*b b) axis=0)nnnIs there a better way to implement this function with numpy one that doesn't involve creating an NxN array?n' 'You could use np.einsum -nny = a*b - np.einsum('iij->j'abb)nnnWe can also perform a*b and feed to einsum  -nny = a*b - np.einsum('ij->j'a*bb)nnnOn the second approach we can save some runtime by storing a*b and reusing.nnRuntime test -nnIn 253: a = np.random.rand(4000)nnIn 254: b = np.random.rand(4000)nnIn 255: %timeit np.sum(np.outer(a*b b) axis=0)n10 loops best of 3: 105 ms per loopnnIn 256: %timeit np.einsum('iij->j'abb)n10 loops best of 3: 24.2 ms per loopnnIn 257: %timeit np.einsum('ij->j'a*bb)n10 loops best of 3: 21.9 ms per loopnn',['numpy'],['numpy']
40142024,"'Pandas df to dictionary with values as python lists aggregated from a df column' 'I have a pandas df containing 'features' for stocks which looks like this: nnnnI am now trying to create a dictionary with unique sector as key and a python list of tickers for that unique sector as values so I end up having something that looks like this:nn{'consumer_discretionary': 'AAP'n  'AMZN'n  'AN'n  'AZO'n  'BBBY'n  'BBY'n  'BWA'n  'KMX'n  'CCL'n  'CBS'n  'CHTR'n  'CMG'nnnetc.nnI could iterate over the pandas df rows to create the dictionary but I prefer a  more pythonic solution. Thus far this code is a partial solution:nndf.set_index('sector')'ticker'.to_dict()nnnAny feedback is appreciated.nnUPDATE:nnThe solution by @wrwrwr nndf.set_index('ticker').groupby('sector').groupsnnnpartially works but it returns a pandas series as a the value instead of a python list. Any ideas about how to transform the pandas series into a python list in the same line and w/o having to iterate the dictionary?n' ""Wouldn't f.set_index('ticker').groupby('sector').groups be what you want?nnFor example:nnf = DataFrame({n        'ticker': ('t1' 't2' 't3')n        'sector': ('sa' 'sb' 'sb')n        'name': ('n1' 'n2' 'n3')})nngroups = f.set_index('ticker').groupby('sector').groupsn# {'sa': Index('t1') 'sb': Index('t2' 't3')}nnnTo ensure that they have the type you want:nn{k: list(v) for k v in f.set_index('ticker').groupby('sector').groups.items()}nnnor:nnf.set_index('ticker').groupby('sector').apply(lambda g: list(g.index)).to_dict()nn""","['pandas', 'dictionary']","['pandas', 'dictionary', 'list', 'python-2.7']"
40142166,"'How to fix ""TypeError: len() of unsized object""' ""I am getting:nnTypeError: len() of unsized objectnnafter running the following script:nnfrom numpy import *nnv=array(input('Introduce un vector v: '))nu=array(input('Introduce un vector u: '))nnnv= len(v)nnu= len(u)nndiferenza= 0; i=0nnif nv==nu:nn    while i<nv:n        diferenza=diferenza + ((vi+1-ui+1))**2nn    modulo= sqrt(diferenza)n    print('Distancia' v)nelse:n    print('Vectores de diferente dimensiÃ³n')nnnHow can I fix this?n"" 'Use the arrays' size attribute instead:nnnv = v.sizennu = u.sizennnnnYou also probably want to use numpy.fromstring to take and convert the input string into an array:nn>>> v = np.fromstring(input('enter the elements of the vector separated by comma: ') dtype=int sep='')nenter the elements of the vector separated by comma: 1 2 3n>>> vnarray(1 2 3)n>>> len(v)n3n>>> v.sizen3nn' 'The problem is that a numpy-scalar has no length. When you use input it returns a string (assuming Python3 here) and that's just converted to a numpy-string when you pass it to numpy.array:nn>>> import numpy as npn>>> np.array('abcdefg')narray('abcdefg' n      dtype='<U7')nn>>> len(np.array('abcdefg'))nTypeErrornnnYou need to parse it before you pass it to numpy.array. For example with ast.literal_eval (Thanks @PaulRooney for mentioning it):nn>>> import astn>>> np.array(ast.literal_eval(input('Enter vector'))) # input ""1 2 3""narray(1 2 3)n>>> len(_)n3nnnIf you're dealing with multidimensional array you have to use array.size instead of len.n'",['numpy'],['numpy']
40142265,'pandas parallel do not stop' 'i found a panda groupby solution at here the issue is when i try to run the code it never stop and return the value. is there anything wrong?nnimport pandas as pdnfrom joblib import Parallel delayednimport multiprocessingnndef tmpFunc(df):n    df'c' = df.a + df.bn    return dfnndef applyParallel(dfGrouped func):n    print ('start')n    retLst = Parallel(n_jobs=2)(delayed(func)(group) for name group in dfGrouped)n    print('finish')n    return pd.concat(retLst)nnndf = pd.DataFrame({'a': 6 2 2 'b': 4 5 6}index= 'g1' 'g1' 'g2')napplyParallel(df.groupby(df.index) tmpFunc)nn' nan,['pandas'],['pandas']
40142325,"'Restart python program reseting all lists and variables' ""I'd like to restart my fairly large python program. So far the way I've tried to achieve this is by doing the following: nn   if __name__ == '__main__':n        MyFunction1() n        os.execv(__file__ sys.argv)nnnMy code is divided into many different functions all I really want to do is allow the user to restart the program.nnUsing the above code causes an error second time round when running.nnAny suggestions would be much appreciated even if they simply suggest an alternative. Although with my large code I'm not sure a while loop might do :)n"" nan",['python-2.7'],"['python-2.7', 'python-3.x']"
40142447,"'How to implement multiple inlines in a FormView like in django admin' 'IÂ´m newbie with django I'm trying to replicate the inlines in the Django admin for adding related models to my Foto Model it has three foreign keys to different models I found this coden http://kevindias.com/writing/django-class-based-views-multiple-inline-formsets/nnbut it is something different of what i want because the foreign keys in my case are relations from Foto to other three models. I want to create a Form with all the fields from associated models.nnMy models.py is:nnclass Foto(models.Model):nnfotoID = models.AutoField(primary_key=True)nimgfile = models.ImageField(upload_to='fotos/'null=True blank=True)ncamara = models.ForeignKey(Camara null=True)npunto_muestreo = models.ForeignKey(PuntosMuestreo null=True)ncolector = models.ForeignKey(Colectores null=True)nfecha = models.DateField(blank=True null=True)nndef __str__(self):n    return str(self.filename)nnnclass Colectores(models.Model):nncolectorID = models.AutoField(primary_key=True)nname = models.CharField(max_length=510 null=True)ninstitution = models.CharField(max_length=510 null=True)ne-mail= models.CharField(max_length=255 null=True)ndef __unicode__(self):n    return unicode(self.nombre)nnnclass PuntosMuestreo(models.Model):nnpuntoID = models.AutoField(primary_key=True)nnombre = models.CharField(max_length=255)nlatitud = models.FloatField(blank=True null=True) nlongitud = models.FloatField(blank=True null=True) ndatum = models.CharField(max_length=50 blank=True null=True)nelevacionMinima = models.IntegerField(null=True blank=True)nelevacionMaxima = models.IntegerField(null=True blank=True)nnnclass Camara(models.Model):nncamaraID = models.AutoField(primary_key=True)nmodelo = models.CharField(max_length=510 null=True)ncantidad_fotos = models.IntegerField(null=True blank=True)narchivo_inicial = models.CharField(max_length=255 null=True  blank=True)narchivo_final = models.CharField(max_length=255 null=True  blank=True)nnnIn my views.py I only got an inline for PuntosMuestreo form but with inlineformset_factory canÂ´t include Camara and Colectores inline forms only get  camara as formset.nnviews.pynndef unaPrueba(request):nnFotoFormSet = inlineformset_factory(PuntosMuestreo Foto form=FotoForm  can_delete=False fields='imgfile''fecha' extra=1)nform =  PuntosMuestreoForm()nform_camara =  CamaraForm()nformset = FotoFormSet()nnif request.method == 'POST':n    form = PuntosMuestreoForm(request.POST)n    formset = FotoFormSet(request.POST)n    form_camara = CamaraForm(request.POST)n    if form.is_valid()  and formset.is_valid() and form_camara.is_valid():n        form.save()n        formset.save()n        form_camara.save()n    else:n        form =  PuntosMuestreoForm()n        formset = FotoFormSet()n        form_camara = CamaraForm()nnreturn render_to_response('pruebaform.html' {'form': form 'form2':form_camara 'formset':formset} context_instance=RequestContext(request))nnnthis is my forms.py:nnclass CamaraForm(forms.ModelForm):nnclass Meta:n    model = Camaran    fields= 'modelo' 'mediocaptura' 'cantidad_fotos'nnnclass PuntosMuestreoForm(forms.ModelForm):nnclass Meta:n    model = PuntosMuestreon    fields= 'nombre' 'latitud' 'longitud''datum' 'elevacionMinima' 'elevacionMaxima'nnnclass FotoForm(forms.ModelForm):nnclass Meta:n    model= Foton    widgets = {nn        'fecha': forms.DateInput(attrs={'id':""fecha"" 'class': 'datepicker'})nn    }nn    fields= 'fecha' nndef __init__(self *args **kwargs):n    super(FotoForm self).__init__(*args **kwargs)n    self.fields'imgfile'.label = 'Seleccione un archivo de imagen'nnnI also tried to follow up the http://django-extra-views.readthedocs.io/en/latest/views.htmlnbut I got an error like Camara has no field named 'content_type'nnI would appreciate your help with this I also found this threads nnDjango class-based CreateView and UpdateView with multiple inline formsetsnnbut nothing seem to work for me.nnThanks.nnAngela.n' nan",['django'],['django']
40142494,"'Sorting list with dictionaries values(Maximum to Minimum)' 'I have an array with loads of dictionaries in it. However I want to sort dictionaries in a way where I have maximum value to a specific key in a dictionary.nFor example I have a list that looks like thisnnn    {n        ""num_gurus"": 40n        ""id"": 119749n        ""code"": nulln        ""name"": ""ART 198P""n        ""short_name"": ""ART 198P""n        ""title"": ""Directed Group Study""n        ""department_long"": nulln        ""full_name"": ""Directed Group Study""n        ""department_short"": ""ART""n    }n    {n        ""num_gurus"": 3n        ""id"": 119825n        ""code"": nulln        ""name"": ""ASAMST 198P""n        ""short_name"": ""ASAMST 198P""n        ""title"": ""Supervised Group Study""n        ""department_long"": nulln        ""full_name"": ""Supervised Group Study""n        ""department_short"": ""ASAMST""n    }n    {n        ""num_gurus"": 200n        ""id"": 119904n        ""code"": nulln        ""name"": ""AST 636""n        ""short_name"": ""AST 636""n        ""title"": ""Baudelaire: Art Poetry Modernity""n        ""department_long"": nulln        ""full_name"": ""Baudelaire: Art Poetry Modernity""n        ""department_short"": ""AST""n    }nnnnI want my output to sort my dictionaries where the value of a key attribute 'num_gurus' is maximum to minimum. Expected output would be.nnn    {n        ""num_gurus"": 200n        ""id"": 119904n        ""code"": nulln        ""name"": ""AST 636""n        ""short_name"": ""AST 636""n        ""title"": ""Baudelaire: Art Poetry Modernity""n        ""department_long"": nulln        ""full_name"": ""Baudelaire: Art Poetry Modernity""n        ""department_short"": ""AST""n    }n    {n        ""num_gurus"": 40n        ""id"": 119749n        ""code"": nulln        ""name"": ""ART 198P""n        ""short_name"": ""ART 198P""n        ""title"": ""Directed Group Study""n        ""department_long"": nulln        ""full_name"": ""Directed Group Study""n        ""department_short"": ""ART""n    }n    {n        ""num_gurus"": 3n        ""id"": 119825n        ""code"": nulln        ""name"": ""ASAMST 198P""n        ""short_name"": ""ASAMST 198P""n        ""title"": ""Supervised Group Study""n        ""department_long"": nulln        ""full_name"": ""Supervised Group Study""n        ""department_short"": ""ASAMST""n    }nnnnnI have tried this so farnn    for items in load_as_json:n            for key val in sorted(items'num_gurus'.iteritems() key=lambda (kv): (vk) reverse=True):n                print keyvalnnThis throws me error and doesn't do what I actually want to.nThis is the error I got.n  File ""utils.py"" line 61 in GetPopularCoursesBasedOnGurusn    for key val in sorted(str(items'num_gurus').iteritems() key=lambda (kv): (vk)):nAttributeError: 'str' object has no attribute 'iteritems'nn' 'try this:nnmy_list.sort(key=lambda my_dict: my_dict""num_gurus"" reverse=True)nnnwhat this does is basically two things:nnnkey paramater expects an anonymous function (lambda in python) and then sortsnthe original list values by the values returned bynlambda function. lambda my_dict: my_dict""num_gurus"" returns the ""num_gurus"" item within each dictionary hence the list is sorted by those values.nreverse=True by default sort function sorts from min to max hencenthis simply reverses thatnnnalso I find this very ""unsafe"" as you have no guarentee for ""num_gurus"" key within your dictionaries or a dictionary as a key value hence I'd personally wrap this with some exception handler:  try  exceptnnread more here: https://docs.python.org/2.7/tutorial/errors.html remember better safe than sorry!n' 'For storing the sorted list as new list you can do it using sorted() as:nnsorted(my_list key=lambda x: x'num_gurus' reverse=True)n# returns sorted listnnnwhere my_list is your list of dict objects.nnElse if you want to sort the content of original list i.e my_list then use list.sort() as:nnmy_list.sort(key=lambda x: x""num_gurus"" reverse=True)n# sorts the original listnnnCheck document on: How to do Sorting in listn'",['dictionary'],"['dictionary', 'list', 'python-2.7']"
40142538,"'Scrapy spider for JSON response is giving me error' 'import jsonnimport scrapynnclass SpidyQuotesSpider(scrapy.Spider):nn    name = 'hotelspider'n    start_urls = n     'https://tr.hotels.com/search/listings.json?destination-id=1648683&q-check-out=2016-10-22&q-destination=Didim+T%C3%BCrkiye&q-room-0-adults=2&pg=2&q-rooms=1&start-index=7&q-check-in=2016-10-21&resolved-location=CITY:1648683:UNKNOWN:UNKNOWN&q-room-0-children=0&pn=1'n               nnn    def parse(self response):n        myresponse = json.loads(response.body)n        data = myresponse.get('data')n        body = data.get('body')n        searchresults = body.get('searchResults')nn         for item in searchresults.get('results' ):n            yield {n                'text': item0'altText'n            }nnnthis is the screenshot of the errornnI always get error when I run this script. Can anybody help me where I am doing wrong ? n' 'I can't seem to reproduce your error but upon copying your code I got a key error which pertains to your yield statement. See the code below:nnimport scrapynimport jsonnnnclass SpidyQuotesSpider(scrapy.Spider):n    name = ""hotelspider""n    allowed_domains = ""tr.hotels.com""n    start_urls = (n        'https://tr.hotels.com/search/listings.json?destination-id=1648683&q-check-out=2016-10-22&q-destination=Didim+T%C3%BCrkiye&q-room-0-adults=2&pg=2&q-rooms=1&start-index=7&q-check-in=2016-10-21&resolved-location=CITY:1648683:UNKNOWN:UNKNOWN&q-room-0-children=0&pn=1'n    )nn    def parse(self response):n        myresponse = json.loads(response.body)n        data = myresponse.get('data')n        body = data.get('body')n        searchresults = body.get('searchResults')nn        for item in searchresults.get('results' ):n            yield {n                'text': item'altText'n            }nnnMake sure you are indenting using the same amount of spaces or just use TAB. Though the indentation shown in your code seems fine. Try pasting mine and see what comes up.n'",['python-2.7'],['python-2.7']
40142547,"'Python2.7Socket Connection problems' 'I am making a socket Chat server in python 2.7 but I am unable to connect to the server using my client I get this error:nnFile ""ChatClientV2.py"" line 46 in n    read_sockets write_sockets error_sockets = select.select(socket_list   )nselect.error: (10038 'An operation was attempted on something that is not a socket')nnI do not know why i am getting this error I need to help with this this is my code I use for the client and some extra stuff after but I do not want to be restricted by the code amount so I did not post all of itnnimport socket selectnn#Function to broadcast chat messages to all connected clientsndef broadcast_data (sock message):n    #Do not send the message to master socket and the client who has send us the   messagen    for socket in CONNECTION_LIST:n        if socket != server_socket and socket != sock :n            try :n                socket.send(message)n            except :n                # broken socket connection may be chat client pressed ctrl+c for examplen                socket.close()n                CONNECTION_LIST.remove(socket)nnif __name__ == ""__main__"":nn# List to keep track of socket descriptorsnCONNECTION_LIST = nRECV_BUFFER = 4096 # Advisable to keep it as an exponent of 2nPORT = 5000nnserver_socket = socket.socket(socket.AF_INET socket.SOCK_STREAM)n# this has no effect why ?nserver_socket.setsockopt(socket.SOL_SOCKET socket.SO_REUSEADDR 1)nserver_socket.bind((""192.168.0.8"" PORT))nserver_socket.listen(10)nn# Add server socket to the list of readable connectionsnCONNECTION_LIST.append(server_socket)nnprint ""Chat server started on port "" + str(PORT)nnwhile 1:n    #print CONNECTION_LISTn    # Get the list sockets which are ready to be read through selectn    read_socketswrite_socketserror_sockets = select.select(CONNECTION_LIST)n     for sock in read_sockets:n         #New connectionn         if sock == server_socket:n             # Handle the case in which there is a new connection recieved through server_socketn             sockfd addr = server_socket.accept()n             CONNECTION_LIST.append(sockfd)n             #print ""Client (%s %s) connected"" % addrnn             broadcast_data(sockfd ""entered roomn"")nn        #Some incoming message from a clientn        else:n            # Data recieved from client process itn            try:n                #In Windows sometimes when a TCP program closes abruptlyn                # a ""Connection reset by peer"" exception will be thrownn                data = sock.recv(RECV_BUFFER)n                if data:n                    #broadcast_data(sock ""r"" + '<' + str(sock.getpeername()) + '> ' + data)n                    broadcast_data(sock ""r"" + data)nn            except:n                broadcast_data(sock ""Client (%s %s) is offline"" % addr)n                print ""Client (%s %s) is offline"" % addrn                sock.close()n                CONNECTION_LIST.remove(sock)n                continuennserver_socket.close()nn' nan",['python-2.7'],['python-2.7']
40142642,"'python matplotlib : assign cmap to make multiple color scattering plot' 'I am trying to use matplotlib and seaborn to create a scatter plot. It works fine if the entire plot is only one color like below:nnsns.regplot(x = pair0 y = pair1 data = d fit_reg = False ax = ax x_jitter = True scatter_kws = {'linewidths':0 's':2 'color':'r'})nnnHowever if I need the color of each data point depends on the value in col like:nncol = pandas_df.prediction.map({0: 100 1:010})nsns.regplot(x = pair0 y = pair1 data = d fit_reg = False ax = ax x_jitter = True scatter_kws = {'linewidths':0 's':2 'cmap':""RGB"" 'color':col})nnnwhere pandas_df is a pandas dataframe so col is a series of RGB point like:nn100n010n100n010n   :n   :nnnThen I got the errors:nnIndexErrorTraceback (most recent call last)n<ipython-input-12-e17a2dbdd639> in <module>()n     15     #print dtype(col)n     16     d.plot.scatter(*pair ax=ax c=col linewidths=0 s=2 alpha = 0.7)n---> 17     sns.regplot(x = pair0 y = pair1 data = d fit_reg = False ax = ax x_jitter = True                 scatter_kws = {'linewidths':0 's':2 'cmap':""RGB"" 'color':col})n     18 n     19 fig.tight_layout()nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in regplot(x y data x_estimator x_bins x_ci scatter fit_reg ci n_boot units order logistic lowess robust logx x_partial y_partial truncate dropna x_jitter y_jitter label color marker scatter_kws line_kws ax)n    777     scatter_kws""marker"" = markern    778     line_kws = {} if line_kws is None else copy.copy(line_kws)n--> 779     plotter.plot(ax scatter_kws line_kws)n    780     return axn    781 nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in plot(self ax scatter_kws line_kws)n    328         # Draw the constituent plotsn    329         if self.scatter:n--> 330             self.scatterplot(ax scatter_kws)n    331         if self.fit_reg:n    332             self.lineplot(ax line_kws)nn/usr/local/lib/python2.7/dist-packages/seaborn/linearmodels.pyc in scatterplot(self ax kws)n    353             kws.setdefault(""linewidths"" lw)n    354 n--> 355             if not hasattr(kws'color' 'shape') or kws'color'.shape1 < 4:n    356                 kws.setdefault(""alpha"" .8)n    357 nnIndexError: tuple index out of rangennnWhat did I do wrong in assigning color and cmap in this case? Thanks!n' nan","['python-2.7', 'matplotlib']","['matplotlib', 'pandas']"
40142646,"'Django choices and dictionary' 'I have codennJOBS = 1nCATEGORY_CHOICES = ((JOBS ""Jobs""))nnnAnd code in the modelnncategory = models.IntegerField(choices=CATEGORY_CHOICES default=JOBS)nnnInstead of ""jobs"" I want to add a dictionary and have access to it in the template. For examplennJOBS = 1nCATEGORY_CHOICES = ((JOBS {'title':""Jobs""'icon':""fa fa-briefcase""'slug':""jobs""}))nnnBut instead I get the followingnnnnHow to add the dictionary into the choices?nI was able to create a model which would be set up: title and icon. But instead I decided to create a choice. Title I can add but for the selected item to set the icon?n' ""Tuples are immutable.I Think it's impossible.n"" 'Choices in Django models are (key value) tuples. The key is what's meant to be stored in the model's field when saved and the value is meant to be what's displayed as an option. You can't simply jam a dictionary into the value.nnFor example the below choices would store human in the database and display Humans in a select field.nnspecies = n    ('human' 'Humans')n    ('reptile' 'Reptiles')n    ('cylons' 'Aliens')nnnnInstead you need to restructure how your model your data. You should create a separate Category model that represents the choices which will contain fields for a slug icon and title.nnclass Category(models.Model):n    slug  = models.SlugField()n    title = models.CharField()n    icon  = models.CharField()nnnYou then point your current model at the Category model using a ForeignKey(). nnclass MyModel(models.Model):n    category = models.ForeignKey(Category)nnnFinally you can use a ModelChoiceField when rendering the form to render the related category models (related across the foreign key) as choices in a list. If you use a ModelForm all foreign keys will be represented as ModelChoiceFields by default.n' 'I would comment but sadly not enough rep. The way IntegerField is setup it displays the dictionary value and returns the dictionary key.nnWhat it seems you want to do is have that key determine the results of several other values. What you should do then is in whatever view you submit that form to set those other values based on the key returned by your IntegerField.nnIn other words:nnCATEGORY_CHOICES = ((1 'Jobs')(2 'Cities'))nnnThen later in the class or view that this form is submitted to:nnif CATEGORY_CHOICES  == 1:n    title = 'Jobs'n    icon = 'fa fa-briefcase'n    slug = 'jobs'nelif CATEGORY_CHOICES == 2:n    title = 'Cities'n`   icon = 'fa fa-city'n    slug = 'cities'nn'","['django', 'dictionary']","['django', 'dictionary']"
40142668,"'how can I exit a tkinter window after changing images?' 'So I'm trying to make a little battle scene using Tkinter the code is supposed to change the image wait a couple of seconds then exit the Tkinter window. The code I have just makes a little pause when the button to change images is pressed. I'm still a beginner and some concepts are hard for me to grasp.nHere is the code:nnfrom tkinter import *nimport timennclass MainWindow():nn    def __init__(self main):nn        # canvas for imagen        self.canvas = Canvas(main width=660 height=440)n        self.canvas.grid(row=0 column=0)nn        # imagesn        self.my_images = n        self.my_images.append(PhotoImage(file = ""att1.gif""))n        self.my_images.append(PhotoImage(file = ""att2.gif""))n        self.my_image_number = 0n        # set first image on canvasn        self.image_on_canvas = self.canvas.create_image(0 0 anchor = NW image = self.my_imagesself.my_image_number)nn        # button to change imagen        self.button = Button(main text=""FIGHT"" command=self.onButton)n        self.button.grid(row=1 column=0)nn    #----------------nn    def onButton(self):nn        # next imagen        self.my_image_number = 1n        if self.my_image_number == 1:n            time.sleep(2)n            root.quit()n        # change imagen        self.canvas.itemconfig(self.image_on_canvas image = self.my_imagesself.my_image_number)nnroot = Tk()nMainWindow(root)nnroot.mainloop()nnnsome of this code is borrowed I tried to alter it to fit my purposen' nan",['tkinter'],['tkinter']
40142686,"'converting non-numeric to numeric value using Panda libraries' 'I am a machine learning beginner and wan't to learn ML using python and it's pandas module. So I have a Dataframe like this:nnCOL1    COL2      COL3na     9/8/2016     2nb     12/4/2016    23n         ...nn     1/1/2015     21nnnCOL1 is a String Col2 is a timestamp and Col3 is a number. Now I need to do some analysis on this Dataframe and I want to convert all the non-numeric data to numeric. I tried using DictVectorizer() to convert COL1 and 2 to numeric but first of all I am not sure if this is the best way doing such a thing and second I don't know what to do with the timestamp.nWhen I use DictVectorizer the output would be like:nn{u'COL3: {0:2 1:23  ...n:21} 'COL1': {0: u'a' 1:'b' ...  n:'n'} 'COL2': {0: u'9/8/2016'  1: u'12/4/2016'  ...  n:u'1/1/2016'}}nnnbut from what I learned it should be like this or at least I know I need something like this:nn {COL1:'a' COL2: '9/8/2016'  COL3: 2  and so on}   nnnso questions:n1-what is the best way of converting non- numeric (including date) to numeric values to use in sklearn librariesn2- what is the right way of using DictVectorize()nnAny help would be appreciated. n' 'To encode non-numeric data to numeric you can use scikit-learn's LabelEncoder. It will encode each category such as COL1's a b c to integers.nnAssuming df is your dataframe try:nnfrom sklearn.preprocessing import LabelEncodernenc = LabelEncoder()nenc.fit(df'COL1')ndf'COL1' = enc.transform(df'col1')nnnnenc.fit() creates the corresponding integer values.nenc.transform() applies the encoding to the df values.nnnFor the second column using Pandas to_datetime() function should do the trick like @quinn-weber mentioned try:nndf'COL2' = pd.to_datetime(df'COL2')nn' ""You could convert COL1 with something like this: nnimport pandas as pdnimport stringntable = pd.DataFrame(n    'a''9/8/2016'2n    'b''12/4/2016'23n    'n''1/1/2015'21n columns='COL1' 'COL2' 'COL3')ntable'COL1' = table'COL1'.map(dict(zip(list(string.lowercase) xrange(025))))nnnAs for the timestamp you could do:nntable'COL2' = pd.to_datetime(n    table'COL2' format='%m/%d/%Y'n).dt.strftime(date_format='%Y%m%d')nn""",['pandas'],['pandas']
40142688,'Numpy installation issues with Miniconda2' 'I'm on a windows 10 machine and trying to install caffe for deep learning. The installation steps asked me to install Miniconda so I did. I already had Anaconda2 installed on my system. nnNow when I try to build the solution (using Visual Studio 2013) for caffe I get the following error:nnError 232 error C1083: Cannot open include file: 'numpy/arrayobject.h': No such file or directory C:caffe-masterpythoncaffe_caffe.cpp 10 1 pycaffennnThis is because Miniconda doesn't have numpy installed on it even though I installed it using the following command:nnconda install --yes numpy scipy matplotlib scikit-image pipnnnBut when I open the Miniconda2 console and run import numpy I get an error saying it is not installed.nnSo my question eventually is: How do I install Numpy and Scipy on Miniconda2 when I already have Anaconda2 installed on my system?nnStep by step instructions would be highly appreciated.n' nan,['numpy'],"['numpy', 'matplotlib']"
40142766,"'How to remove elements from a nested json with pandas?' 'I have the following json:nn{nnstatus: {4 items}ntoken_list: 1 itemnnn}nnLet's look it closer:nn{nn    status: {n        code: ""0""n        msg: ""OK""n        credits: ""1""n        remaining_credits: ""39110""n    }n    token_list: n        {n            type: ""sentence""n            id: ""11""n            inip: ""0""n            endp: ""42""n            style: {n                isBold: ""no""n                isItalics: ""no""n                isUnderlined: ""no""n                isTitle: ""no""n            }n            separation: ""A""n            quote_level: ""0""n            affected_by_negation: ""no""n            token_list: n                {n                    type: ""phrase""n                    form: ""The quick brown fox jumps over the lazy dog""n                    id: ""17""n                    inip: ""0""n                    endp: ""42""n                    style: {n                        isBold: ""no""n                        isItalics: ""no""n                        isUnderlined: ""no""n                        isTitle: ""no""n                    }n                    separation: ""_""n                    quote_level: ""0""n                    affected_by_negation: ""no""n                    analysis_list: n                        {n                            tag: ""Z-----------""n                            lemma: ""*""n                            original_form: ""The quick brown fox jumps over the lazy dog""n                        }n                    n                    token_list: n                        {n                            type: ""phrase""n                            form: ""The quick brown fox""n                            id: ""14""n                            inip: ""0""n                            endp: ""18""n                            style: {n                                isBold: ""no""n                                isItalics: ""no""n                                isUnderlined: ""no""n                                isTitle: ""no""n                            }n                            separation: ""_""n                            quote_level: ""0""n                            affected_by_negation: ""no""n                            head: ""4""n                            syntactic_tree_relation_list: n                                {n                                    id: ""5""n                                    type: ""isSubject""n                                }n                            n                            analysis_list: n                                {n                                    tag: ""GN-S3S--""n                                    lemma: ""fox""n                                    original_form: ""The quick brown fox""n                                }n                            n                            token_list: n                                {n                                    form: ""The""n                                    id: ""1""n                                    inip: ""0""n                                    endp: ""2""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""_""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    analysis_list: n                                        {n                                            tag: ""TD-SN9""n                                            lemma: ""the""n                                            original_form: ""the""n                                        }n                                    n                                }n                                {n                                    form: ""quick""n                                    id: ""2""n                                    inip: ""4""n                                    endp: ""8""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""1""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    analysis_list: n                                        {n                                            tag: ""AP-N3""n                                            lemma: ""quick""n                                            original_form: ""quick""n                                        }n                                    n                                }n                                {n                                    form: ""brown""n                                    id: ""3""n                                    inip: ""10""n                                    endp: ""14""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""1""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    analysis_list: n                                        {n                                            tag: ""NC-S-N5""n                                            lemma: ""brown""n                                            original_form: ""brown""n                                            sense_id_list: n                                                {n                                                    sense_id: ""dfa15eba2c""n                                                }n                                            n                                        }n                                    n                                    sense_list: n                                        {n                                            id: ""dfa15eba2c""n                                            form: ""brown""n                                            info: ""sementity/class=class@fiction=nonfiction@id=ODENTITY_COLOR@type=Top>OtherEntity>Color    semld_list=sumo:ColorAttribute""n                                        }n                                    n                                }n                                {n                                    form: ""fox""n                                    id: ""4""n                                    inip: ""16""n                                    endp: ""18""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""1""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    analysis_list: n                                        {n                                            tag: ""NC-S-N4""n                                            lemma: ""fox""n                                            original_form: ""fox""n                                            sense_id_list: n                                                {n                                                    sense_id: ""b198288499""n                                                }n                                            n                                        }n                                    n                                    sense_list: n                                        {n                                            id: ""b198288499""n                                            form: ""fox""n                                            info: ""sementity/class=class@fiction=nonfiction@id=ODENTITY_MAMMAL@type=Top>LivingThing>Animal>Vertebrate>Mammal    semld_list=sumo:Mammal  semtheme_list/id=ODTHEME_ZOOLOGY@type=Top>NaturalSciences>Zoology""n                                        }n                                    n                                }n                            n                        }n                        {n                            form: ""jumps""n                            id: ""5""n                            inip: ""20""n                            endp: ""24""n                            style: {n                                isBold: ""no""n                                isItalics: ""no""n                                isUnderlined: ""no""n                                isTitle: ""no""n                            }n                            separation: ""1""n                            quote_level: ""0""n                            affected_by_negation: ""no""n                            syntactic_tree_relation_list: n                                {n                                    id: ""14""n                                    type: ""iof_isSubject""n                                }n                                {n                                    id: ""16""n                                    type: ""iof_isComplement""n                                }n                            n                            analysis_list: n                                {n                                    tag: ""VI-S3PSA-N-N3""n                                    lemma: ""jump""n                                    original_form: ""jumps""n                                }n                            n                        }n                        {n                            type: ""phrase""n                            form: ""over the lazy dog""n                            id: ""16""n                            inip: ""26""n                            endp: ""42""n                            style: {n                                isBold: ""no""n                                isItalics: ""no""n                                isUnderlined: ""no""n                                isTitle: ""no""n                            }n                            separation: ""1""n                            quote_level: ""0""n                            affected_by_negation: ""no""n                            head: ""6""n                            syntactic_tree_relation_list: n                                {n                                    id: ""5""n                                    type: ""isComplement""n                                }n                            n                            analysis_list: n                                {n                                    tag: ""GY---C--""n                                    lemma: ""over""n                                    original_form: ""over the lazy dog""n                                }n                            n                            token_list: n                                {n                                    form: ""over""n                                    id: ""6""n                                    inip: ""26""n                                    endp: ""29""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""1""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    analysis_list: n                                        {n                                            tag: ""YN4""n                                            lemma: ""over""n                                            original_form: ""over""n                                        }n                                    n                                }n                                {n                                    type: ""phrase""n                                    form: ""the lazy dog""n                                    id: ""15""n                                    inip: ""31""n                                    endp: ""42""n                                    style: {n                                        isBold: ""no""n                                        isItalics: ""no""n                                        isUnderlined: ""no""n                                        isTitle: ""no""n                                    }n                                    separation: ""1""n                                    quote_level: ""0""n                                    affected_by_negation: ""no""n                                    head: ""9""n                                    analysis_list: n                                        {n                                            tag: ""GN-S3---""n                                            lemma: ""dog""n                                            original_form: ""the lazy dog""n                                        }n                                    n                                    token_list: n                                        {n                                            form: ""the""n                                            id: ""7""n                                            inip: ""31""n                                            endp: ""33""n                                            style: {n                                                isBold: ""no""n                                                isItalics: ""no""n                                                isUnderlined: ""no""n                                                isTitle: ""no""n                                            }n                                            separation: ""1""n                                            quote_level: ""0""n                                            affected_by_negation: ""no""n                                            analysis_list: n                                                {n                                                    tag: ""TD-SN9""n                                                    lemma: ""the""n                                                    original_form: ""the""n                                                }n                                            n                                        }n                                        {n                                            form: ""lazy""n                                            id: ""8""n                                            inip: ""35""n                                            endp: ""38""n                                            style: {n                                                isBold: ""no""n                                                isItalics: ""no""n                                                isUnderlined: ""no""n                                                isTitle: ""no""n                                            }n                                            separation: ""1""n                                            quote_level: ""0""n                                            affected_by_negation: ""no""n                                            analysis_list: n                                                {n                                                    tag: ""AP-N1""n                                                    lemma: ""lazy""n                                                    original_form: ""lazy""n                                                    sense_id_list: n                                                        {n                                                            sense_id: ""96d8d33dce""n                                                        }n                                                        {n                                                            sense_id: ""5f0f28c2c7""n                                                        }n                                                    n                                                }n                                            n                                            sense_list: n                                                {n                                                    id: ""5f0f28c2c7""n                                                    form: ""idle""n                                                    info: ""sementity/class=class@fiction=nonfiction@id=ODENTITY_PERSON@type=Top>Person  semld_list=sumo:Human""n                                                }n                                                {n                                                    id: ""96d8d33dce""n                                                    form: ""lazy""n                                                    info: ""sementity/class=class@fiction=nonfiction@id=ODENTITY_PERSON@type=Top>Person  semld_list=sumo:Human""n                                                }n                                            n                                        }n                                        {n                                            form: ""dog""n                                            id: ""9""n                                            inip: ""40""n                                            endp: ""42""n                                            style: {n                                                isBold: ""no""n                                                isItalics: ""no""n                                                isUnderlined: ""no""n                                                isTitle: ""no""n                                            }n                                            separation: ""1""n                                            quote_level: ""0""n                                            affected_by_negation: ""no""n                                            analysis_list: n                                                {n                                                    tag: ""NC-S-N5""n                                                    lemma: ""dog""n                                                    original_form: ""dog""n                                                    sense_id_list: n                                                        {n                                                            sense_id: ""587be6b063""n                                                        }n                                                    n                                                }n                                            n                                            sense_list: n                                                {n                                                    id: ""587be6b063""n                                                    form: ""dog""n                                                    info: ""sementity/class=class@fiction=nonfiction@id=ODENTITY_MAMMAL@type=Top>LivingThing>Animal>Vertebrate>Mammal    semld_list=sumo:Mammal  semtheme_list/id=ODTHEME_ZOOLOGY@type=Top>NaturalSciences>Zoology""n                                                }n                                            n                                        }n                                    n                                }n                            n                        }n                    n                }n            n        }n    nn}nnnHow can I extract in a pandas dataframe all the analysis_list elements into a pandas dataframe?:nn    tag     lemma   original_formn0   Z-----------""   *   The quick brown fox jumps over the lazy dogn1   GN-S3S--""   fox     original_form: ""The quick brown foxn2   TD-SN9""     the     then3   AP-N3   quick   quickn4   NC-S-N4     fox     foxn5   VI-S3PSA-N-N3   jump    jumpsn6   GY---C--    over    over the lazy dogn7   YN4     over    overn8   GN-S3---    dog     the lazy dogn9   TD-SN9  the     then10  AP-N1   lazy    lazyn11  NC-S-N5     dog     dognnnI tried bynndata = json.loads(r.text)ndf = json_normalize(data'token_list')ndf = df'analysis_list'nnnHowever the structure is very nested and I can not visualize how to transform it into a tabular format.n' nan","['python-3.x', 'pandas']","['list', 'pandas']"
40142804,"'Python Array Reshaping Issue to Array with Shape (None 192)' ""I have this error and I'm not sure how do I reshape where there's a dimension with None.nnException: Error when checking : expected input_1 to have shape (None 192) but got array with shape (192 1)nnnHow do I reshape an array to (None 192)? nnI've the array accuracy with shape (12 16) and I did accuracy.reshape(-1) that gives (192). However this is not (None 192).n"" ""This is an error in the library code because (None 192) is an invalid shape for a numpy array - the shape must be a tuple of integers.  nnTo investigate any further we'll have to see the traceback and/or the code which is raising that exception.  n""",['numpy'],['numpy']
40142840,"'Django Internal Server 500 Error AWS Elastic-Beanstalk issue' ""How do I fix the Django Internal Server 500 error on an AWS eb deployed application?nnDo I need to change my allowed hosts in my base.py file to have the ip address of the ec2 in elasticbeanstalk?nn# SECURITY WARNING: keep the secret key used in production secret!n# Raises ImproperlyConfigured exception if SECRET_KEY not in os.environnSECRET_KEY = env('SECRET_KEY')nnALLOWED_HOSTS = nn# Application definitionnnINSTALLED_APPS = (n    'django.contrib.auth'n    'django_admin_bootstrapped'n    'django.contrib.admin'n    'django.contrib.contenttypes'n    'django.contrib.sessions'n    'django.contrib.messages'n    'django.contrib.staticfiles'n)nnn...nnSTATIC_URL = '/static/'nnALLOWED_HOSTS = nnn...n"" nan",['django'],['django']
40143044,"'Removing a subarray after using numpy.split' ""Title kinda says it all I'm trying to make two new matrices after using numpy.split so:nn#A is some mxn matrixnnumfolds=5nfolds = numpy.split(Anumfolds)n#now folds is 5 equalish subarrays which can be called outn#subarray1 is the second fold (the second fifth of A along axis=0 by default)nsubarray1 = folds2n#numpy.delete does not get rid of the second subarray in AnarrayWithoutSubArray1 = numpy.concatenate(numpy.delete(folds2))nnnHow do a make a matrix which is all but one subarray in A in this example. I'd rather not use loops. Thanks in advance.n"" nan",['numpy'],['numpy']
40143157,'Q: What is Big-O complexity of random.choice(list) in Python3' 'What is Big-O complexity of random.choice(list) in Python3 where n is amount of elements in a list ?nnedit. Thank You all for give me the answer now I understand.n' nan,['python-3.x'],"['python-3.x', 'python-2.7']"
40143166,"'finding cubed root using delta and epsilon in Python' 'I am trying to write a program that finds cubed root using delta and epsilon but i'm stuck because i cant figure out why my program runs in an infinite loopnn    num = 100nn    epsilon = 0.01n    guess = num/3.0nnn    while abs(guess**3 - num) >= epsilon:n        delta = abs(guess**3 - num)/100n        if guess**3 > num:n            guess = (guess - delta)n        if guess**3 < num:n            guess = (guess + delta)n    print(""Guess:"" guess)nn' 'First thing you should use if/elif instead of separate if blocks. nnConsider the following:nwhen guess**3 > num is True you update guess by reducing its value so that guess**3 < num (the next if condition) becomes True again which reverses the initial update. In summary the value of guess is never changed in that loop and the loop whirls to infinity.nnSecondly you want to regularize the delta value (penalize it) as it can be come alarming large as the value of num increases.nnnum = 100nnepsilon = 0.01nguess = num/3.0nnwhile abs(guess**3 - num) >= epsilon:n    delta = abs(guess**3 - num)/numn    if guess**3 > num:n        guess = (guess - delta*epsilon**0.5)n    elif guess**3 < num:n        guess = (guess + delta*epsilon**0.5)nprint(""Guess:"" guess)nn'",['python-3.x'],"['python-3.x', 'python-2.7']"
40143173,'Trouble installing pillow for Windows 10' 'Having issues installing Pillow for python djgango. I am using Windows 10 Python 3.6.nnWhen I run pip install pillow==3.3.0. nnValueError: zlib is required unless explicitly disabled using --disable-zlib abortingnnnMy question is how do I properly install its dependency(zlib)?  I cant find any documentation on how to successfully install it in Windows.n' nan,['django'],['python-3.x']
40143267,"'Updating an ManyToMany field with Django rest' 'I'm trying to set up this API so I can use a ""PUT"" to  update one/many ""TAG""s on an item in the model ""MOVIE"". Tags is an M2M on MOVIE. I am posting on the PK of the item in movie.nnMy httpie work (returns a 200OK) but nothing gets created. When I post the whole JSON (using fetch) it just creates the TAG but no M2M relationship on MOVIE (link).nnhttpiennhttp -f PUT http://localhost:8000/api/Edit/3/ tag:='{""name"": ""TEST""}'nnnModels.pynnclass Tag(models.Model):n    name = models.CharField(""Name"" max_length=5000 blank=True)n    taglevel = models.IntegerField(""Tag level"" null=True blank=True)nnclass Movie(models.Model):n    title = models.CharField(""Whats happening?"" max_length=10000 blank=True)n    tag = models.ManyToManyField('Tag' blank=True)nnnSerializers.pynnclass Tag1Serializer(serializers.ModelSerializer):n    class Meta:n        model = Tagn        fields = ('name')nnclass EditSerializer(serializers.ModelSerializer):n    tag = Tag1Serializer(many=True read_only=True)n    class Meta:n            model = Movien            fields = ('title' 'tag' 'info' 'created'  'status')nn    def update(self instance validated_data):n        import pdb; pdb.set_trace()n        tags_data = validated_data.pop('tag')n        for tag_data in tags_data:n            tag_qs = Tag.objects.filter(name__iexact=tag_data'name')n            if tag_qs.exists():n                tag = tag_qs.first()n            else:n                tag = Tag.objects.get(**tag_data)n            instance.tag.add(tag)n        return moviennnViews.pynnclass MovieViewSet(viewsets.ModelViewSet):n    queryset = Movie.objects.all()n    serializer_class = MovieSerializernnnError:nnTracebackn    tags_data = validated_data.pop('tag')nKeyError: 'tag'nn' nan",['django'],['django']
40143365,"'Theano operations returning odd results' 'So I'm trying to learn how to use Theano and specifically use it for neural networks.nI'm on a Windows 10 system using mingw64 and all the rest of the required files from the install page (with the exception of microsoft visual studio and cuda as I do not plan to use my GPU).nEverything seems to work and the ""baby steps"" part of the tutorial worked fine.nWhen I try to run the following the code however I get some odd results -nnself.W = theano.shared(value=np.random.standard_normal((state_dim 4*state_dim)) * np.sqrt(2 / in_dim) name='W' borrow=True)nprint(theano.dot(self.W.get_value() self.W.get_value().T)nnnWith the following error appearing:nnTraceback (most recent call last):n  File ""<stdin>"" line 1 in <module>n  File ""C:mingw64WinPython-64bit-3.4.4.4Qt5python-3.4.4.amd64libsite-packagestheano__init__.py"" line 172 in dotn    (e0 e1))nNotImplementedError: ('Dot failed for the following reasons:' (None None))nnnWhen I try to refer to W without get_value() i.e.n    print(theano.dot(self.W self.W.T))nI get a return value of dot.0.nnWhat am I missing?n' nan",['numpy'],['numpy']
